"","title","author","subject","abstract","meta"
"1","City-Scale Road Audit System using Deep Learning","Sudhir Yarram, Girish Varma, C.V. Jawahar","Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","Road networks in cities are massive and is a critical component of mobility. Fast response to defects, that can occur not only due to regular wear and tear but also because of extreme events like storms, is essential. Hence there is a need for an automated system that is quick, scalable and cost-effective for gathering information about defects. We propose a system for city-scale road audit, using some of the most recent developments in deep learning and semantic segmentation. For building and benchmarking the system, we curated a dataset which has annotations required for road defects. However, many of the labels required for road audit have high ambiguity which we overcome by proposing a label hierarchy. We also propose a multi-step deep learning model that segments the road, subdivide the road further into defects, tags the frame for each defect and finally localizes the defects on a map gathered using GPS. We analyze and evaluate the models on image tagging as well as segmentation at different levels of the label hierarchy.","Mon, 26 Nov 2018 06:49:11 UTC (3,023 KB)"
"2","Frequency Principle in Deep Learning with General Loss Functions and Its Potential Application","Zhi-Qin John Xu","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Previous studies have shown that deep neural networks (DNNs) with common settings often capture target functions from low to high frequency, which is called Frequency Principle (F-Principle). It has also been shown that F-Principle can provide an understanding to the often observed good generalization ability of DNNs. However, previous studies focused on the loss function of mean square error, while various loss functions are used in practice. In this work, we show that the F-Principle holds for a general loss function (e.g., mean square error, cross entropy, etc.). In addition, DNN's F-Principle may be applied to develop numerical schemes for solving various problems which would benefit from a fast converging of low frequency. As an example of the potential usage of F-Principle, we apply DNN in solving differential equations, in which conventional methods (e.g., Jacobi method) is usually slow in solving problems due to the convergence from high to low frequency.","Mon, 26 Nov 2018 02:27:44 UTC (244 KB)"
"3","Real-Time Sleep Staging using Deep Learning on a Smartphone for a Wearable EEG","Abhay Koushik, Judith Amores, Pattie Maes","Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Signal Processing (eess.SP); Neurons and Cognition (q-bio.NC)","We present the first real-time sleep staging system that uses deep learning without the need for servers in a smartphone application for a wearable EEG. We employ real-time adaptation of a single channel Electroencephalography (EEG) to infer from a Time-Distributed 1-D Deep Convolutional Neural Network. Polysomnography (PSG)-the gold standard for sleep staging, requires a human scorer and is both complex and resource-intensive. Our work demonstrates an end-to-end on-smartphone pipeline that can infer sleep stages in just single 30-second epochs, with an overall accuracy of 83.5% on 20-fold cross validation for five-class classification of sleep stages using the open Sleep-EDF dataset.","Sun, 25 Nov 2018 22:25:31 UTC (921 KB)"
"4","An overview of deep learning in medical imaging focusing on MRI","Alexander Selvikvag Lundervold, Arvid Lundervold","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","What has happened in machine learning lately, and what does it mean for the future of medical image analysis? Machine learning has witnessed a tremendous amount of attention over the last few years. The current boom started around 2009 when so-called deep artificial neural networks began outperforming other established models on a number of important benchmarks. Deep neural networks are now the state-of-the-art machine learning models across a variety of areas, from image analysis to natural language processing, and widely deployed in academia and industry. These developments have a huge potential for medical imaging technology, medical data analysis, medical diagnostics and healthcare in general, slowly being realized. We provide a short overview of recent advances and some associated challenges in machine learning applied to medical image processing and image analysis. As this has become a very broad and fast expanding field we will not survey the entire landscape of applications, but put particular focus on deep learning in MRI. Our aim is threefold: (i) give a brief introduction to deep learning with pointers to core references; (ii) indicate how deep learning has been applied to the entire MRI processing chain, from acquisition to image retrieval, from segmentation to disease prediction; (iii) provide a starting point for people interested in experimenting and perhaps contributing to the field of machine learning for medical imaging by pointing out good educational resources, state-of-the-art open-source code, and interesting sources of data and problems related medical imaging.","Sun, 25 Nov 2018 16:40:42 UTC (3,257 KB)"
"5","Glottal Closure Instants Detection From Pathological Acoustic Speech Signal Using Deep Learning","Gurunath Reddy M, Tanumay Mandal, Krothapalli Sreenivasa Rao","Sound (cs.SD); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS); Machine Learning (stat.ML)","In this paper, we propose a classification based glottal closure instants (GCI) detection from pathological acoustic speech signal, which finds many applications in vocal disorder analysis. Till date, GCI for pathological disorder is extracted from laryngeal (glottal source) signal recorded from Electroglottograph, a dedicated device designed to measure the vocal folds vibration around the larynx. We have created a pathological dataset which consists of simultaneous recordings of glottal source and acoustic speech signal of six different disorders from vocal disordered patients. The GCI locations are manually annotated for disorder analysis and supervised learning. We have proposed convolutional neural network based GCI detection method by fusing deep acoustic speech and linear prediction residual features for robust GCI detection. The experimental results showed that the proposed method is significantly better than the state-of-the-art GCI detection methods.","Sun, 25 Nov 2018 06:18:24 UTC (117 KB)"
"6","A Fully Private Pipeline for Deep Learning on Electronic Health Records","Edward Chou, Thao Nguyen, Josh Beal, Albert Haque, Li Fei-Fei","Cryptography and Security (cs.CR)","We introduce an end-to-end private deep learning framework, applied to the task of predicting 30-day readmission from electronic health records. By using differential privacy during training and homomorphic encryption during inference, we demonstrate that our proposed pipeline could maintain high performance while providing robust privacy guarantees against information leak from data transmission or attacks against the model. We also explore several techniques to address the privacy-utility trade-off in deploying neural networks with privacy mechanisms, improving the accuracy of differentially-private training and the computation cost of encrypted operations using ideas from both machine learning and cryptography.","Sun, 25 Nov 2018 05:55:50 UTC (2,452 KB)"
"7","Deep Learning Inference in Facebook Data Centers: Characterization, Performance Optimizations and Hardware Implications","Jongsoo Park, Maxim Naumov, Protonu Basu, Summer Deng, Aravind Kalaiah, Daya Khudia, James Law, Parth Malani, Andrey Malevich, Satish Nadathur, Juan Miguel Pino, Martin Schatz, Alexander Sidorov, Viswanath Sivakumar, Andrew Tulloch, Xiaodong Wang, Yiming Wu, Hector Yuen, Utku Diril, Dmytro Dzhulgakov, Kim Hazelwood, Bill Jia, Yangqing Jia, Lin Qiao, Vijay Rao, Nadav Rotem, Sungjoo Yoo, Mikhail Smelyanskiy","Machine Learning (cs.LG); Machine Learning (stat.ML)","The application of deep learning techniques resulted in remarkable improvement of machine learning models. In this paper provides detailed characterizations of deep learning models used in many Facebook social network services. We present computational characteristics of our models, describe high performance optimizations targeting existing systems, point out their limitations and make suggestions for the future general-purpose/accelerated inference hardware. Also, we highlight the need for better co-design of algorithms, numerics and computing platforms to address the challenges of workloads often run in data centers.","Sat, 24 Nov 2018 19:52:02 UTC (684 KB)"
"8","Polar Decoding on Sparse Graphs with Deep Learning","Weihong Xu (1 and 2), Xiaohu You (2), Chuan Zhang (1 and 2), Yair Be'ery (3) ((1) Lab of Efficient Architectures for Digital-communication and Signal-processing (LEADS), (2) National Mobile Communications Research Laboratory, (3) School of Electrical Engineering, Tel-Aviv University, Tel-Aviv, Israel)","Signal Processing (eess.SP); Information Theory (cs.IT); Machine Learning (cs.LG)","In this paper, we present a sparse neural network decoder (SNND) of polar codes based on belief propagation (BP) and deep learning. At first, the conventional factor graph of polar BP decoding is converted to the bipartite Tanner graph similar to low-density parity-check (LDPC) codes. Then the Tanner graph is unfolded and translated into the graphical representation of deep neural network (DNN). The complex sum-product algorithm (SPA) is modified to min-sum (MS) approximation with low complexity. We dramatically reduce the number of weight by using single weight to parameterize the networks. Optimized by the training techniques of deep learning, proposed SNND achieves comparative decoding performance of SPA and obtains about $0.5$ dB gain over MS decoding on ($128,64$) and ($256,128$) codes. Moreover, $60 \%$ complexity reduction is achieved and the decoding latency is significantly lower than the conventional polar BP.","Sat, 24 Nov 2018 09:50:23 UTC (1,149 KB)"
"9","3D Deep Learning with voxelized atomic configurations for modeling atomistic potentials in complex solid-solution alloys","Rahul Singh, Aayush Sharma, Onur Rauf Bingol, Aditya Balu, Ganesh Balasubramanian, Duane D. Johnson, Soumik Sarkar","Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG); Computational Physics (physics.comp-ph); Machine Learning (stat.ML)","The need for advanced materials has led to the development of complex, multi-component alloys or solid-solution alloys. These materials have shown exceptional properties like strength, toughness, ductility, electrical and electronic properties. Current development of such material systems are hindered by expensive experiments and computationally demanding first-principles simulations. Atomistic simulations can provide reasonable insights on properties in such material systems. However, the issue of designing robust potentials still exists. In this paper, we explore a deep convolutional neural-network based approach to develop the atomistic potential for such complex alloys to investigate materials for insights into controlling properties. In the present work, we propose a voxel representation of the atomic configuration of a cell and design a 3D convolutional neural network to learn the interaction of the atoms. Our results highlight the performance of the 3D convolutional neural network and its efficacy in machine-learning the atomistic potential. We also explore the role of voxel resolution and provide insights into the two bounding box methodologies implemented for voxelization.","Fri, 23 Nov 2018 23:12:22 UTC (3,368 KB)"
"10","On the Importance of Strong Baselines in Bayesian Deep Learning","Jishnu Mukhoti, Pontus Stenetorp, Yarin Gal","Machine Learning (cs.LG); Machine Learning (stat.ML)","Like all sub-fields of machine learning, Bayesian Deep Learning is driven by empirical validation of its theoretical proposals. Given the many aspects of an experiment, it is always possible that minor or even major experimental flaws can slip by both authors and reviewers. One of the most popular experiments used to evaluate approximate inference techniques is the regression experiment on UCI datasets. However, in this experiment, models which have been trained to convergence have often been compared with baselines trained only for a fixed number of iterations. What we find is that if we take a well-established baseline and evaluate it under the same experimental settings, it shows significant improvements in performance. In fact, it outperforms or performs competitively with numerous to several methods that when they were introduced claimed to be superior to the very same baseline method. Hence, by exposing this flaw in experimental procedure, we highlight the importance of using identical experimental setups to evaluate, compare and benchmark methods in Bayesian Deep Learning.","Fri, 23 Nov 2018 08:22:17 UTC (10 KB)"
"11","Feature Selection for Survival Analysis with Competing Risks using Deep Learning","Carl Rietschel, Jinsung Yoon, Mihaela van der Schaar","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning models for survival analysis have gained significant attention in the literature, but they suffer from severe performance deficits when the dataset contains many irrelevant features. We give empirical evidence for this problem in real-world medical settings using the state-of-the-art model DeepHit. Furthermore, we develop methods to improve the deep learning model through novel approaches to feature selection in survival analysis. We propose filter methods for \textit{hard} feature selection and a neural network architecture that weights features for \textit{soft} feature selection. Our experiments on two real-world medical datasets demonstrate that substantial performance improvements against the original models are achievable.","Thu, 22 Nov 2018 22:25:46 UTC (228 KB)"
"12","Deep Learning Based Phase Reconstruction for Speaker Separation: A Trigonometric Perspective","Zhong-Qiu Wang, Ke Tan, DeLiang Wang","Sound (cs.SD); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)","This study investigates phase reconstruction for deep learning based monaural talker-independent speaker separation in the short-time Fourier transform (STFT) domain. The key observation is that, for a mixture of two sources, with their magnitudes accurately estimated and under a geometric constraint, the absolute phase difference between each source and the mixture can be uniquely determined; in addition, the source phases at each time-frequency (T-F) unit can be narrowed down to only two candidates. To pick the right candidate, we propose three algorithms based on iterative phase reconstruction, group delay estimation, and phase-difference sign prediction. State-of-the-art results are obtained on the publicly available wsj0-2mix and 3mix corpus.","Thu, 22 Nov 2018 03:46:44 UTC (725 KB)"
"13","Deep Learning and Density Functional Theory","Kevin Ryczko, David Strubbe, Isaac Tamblyn","Materials Science (cond-mat.mtrl-sci); Computational Physics (physics.comp-ph)","Density functional theory (DFT) is used for quantum mechanical simulations of electrons in molecules and materials, for applications in chemistry, physics, materials science, and engineering. However, usage of DFT for large numbers of atoms is hindered by typical scaling of $\mathcal{O}(N^3)$. Demonstration of a sufficiently accurate reduced model with deep neural networks would enable widespread application of DFT on larger, more complex systems for new scientific discoveries. We show that deep neural networks can be integrated into, or fully replace, the Kohn-Sham density functional theory scheme for multi-electron systems in simple harmonic oscillator and random external potentials. We first show that self-consistent charge densities can be used as input to an extensive deep neural network to make predictions for correlation, exchange, external, kinetic and total energies simultaneously. Additionally, we show that one can also make all of the same predictions with the external potential rather than the self-consistent charge density, which allows one to circumvent the Kohn-Sham scheme altogether. We then show that a self-consistent charge density found from a non-local exchange-correlation functional can be used to make energy predictions for a semi-local exchange-correlation functional. Lastly, we use a deep convolutional inverse graphics network to predict the charge density given an external potential and asses the viability of the predicted charge densities. This work shows that extensive deep neural networks are generalizable and transferable given the variability of the potentials and the fact that they can scale to an arbitrary system size with an $\mathcal{O}(N)$ computational cost.","Wed, 21 Nov 2018 20:03:01 UTC (2,513 KB)"
"14","Solving Nonlinear and High-Dimensional Partial Differential Equations via Deep Learning","Ali Al-Aradi, Adolfo Correia, Danilo Naiff, Gabriel Jardim, Yuri Saporito","Computational Finance (q-fin.CP)","In this work we apply the Deep Galerkin Method (DGM) described in Sirignano and Spiliopoulos (2018) to solve a number of partial differential equations that arise in quantitative finance applications including option pricing, optimal execution, mean field games, etc. The main idea behind DGM is to represent the unknown function of interest using a deep neural network. A key feature of this approach is the fact that, unlike other commonly used numerical approaches such as finite difference methods, it is mesh-free. As such, it does not suffer (as much as other numerical methods) from the curse of dimensionality associated with highdimensional PDEs and PDE systems. The main goals of this paper are to elucidate the features, capabilities and limitations of DGM by analyzing aspects of its implementation for a number of different PDEs and PDE systems. Additionally, we present: (1) a brief overview of PDEs in quantitative finance along with numerical methods for solving them; (2) a brief overview of deep learning and, in particular, the notion of neural networks; (3) a discussion of the theoretical foundations of DGM with a focus on the justification of why this method is expected to perform well.","Wed, 21 Nov 2018 15:34:05 UTC (3,229 KB)"
"15","Modeling Deep Learning Accelerator Enabled GPUs","Md Aamir Raihan, Negar Goli, Tor Aamodt","Mathematical Software (cs.MS); Hardware Architecture (cs.AR)","The efficacy of deep learning has resulted in it becoming one of the most important applications run in data centers today. The NVIDIA Tesla V100 GPU introduced a specialized functional unit called the Tensor Core to meet growing demand for higher performance on this workload. To exploit the full capability of current NVIDIA GPUs machine learning researchers have started to use Tensor Cores. For example, 5 out of 6, 2018 Gordon Bell Award Finalists used Tensor Cores in their work. However, currently no open-source GPU microarchitectural simulators model Tensor Cores. In this paper, we comprehensively investigate NVIDIA's Tensor Core implementation found in Volta and Turing architectures and propose an architectural model for it. Our Tensor Core timing model, implemented in GPGPU-Sim, achieves 99.6% IPC correlation versus a physical V100 GPU. Building upon this we also enable GPGPU-Sim to run NVIDIA's CUTLASS, an open-source CUDA C++ templates library providing customizable GEMM templates including the support for Tensor Cores.","Mon, 19 Nov 2018 00:07:34 UTC (6,528 KB)"
"16","Variance Suppression: Balanced Training Process in Deep Learning","Tao Yi, Xingxuan Wang","Machine Learning (cs.LG); Machine Learning (stat.ML)","Stochastic gradient descent updates parameters with summation gradient computed from a random data batch. This summation will lead to unbalanced training process if the data we obtained is unbalanced. To address this issue, this paper takes the error variance and error mean both into consideration. The adaptively adjusting approach of two terms trading off is also given in our algorithm. Due to this algorithm can suppress error variance, we named it Variance Suppression Gradient Descent (VSSGD). Experimental results have demonstrated that VSSGD can accelerate the training process, effectively prevent overfitting, improve the networks learning capacity from small samples.","Tue, 20 Nov 2018 10:16:31 UTC (1,135 KB)"
"17","Effect of Depth and Width on Local Minima in Deep Learning","Kenji Kawaguchi, Jiaoyang Huang, Leslie Pack Kaelbling","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC); Machine Learning (stat.ML)","In this paper, we analyze the effects of depth and width on the quality of local minima, without strong over-parameterization and simplification assumptions in the literature. Without any simplification assumption, for deep nonlinear neural networks with the squared loss, we theoretically show that the quality of local minima tends to improve towards the global minimum value as depth and width increase. Furthermore, with a locally-induced structure on deep nonlinear neural networks, the values of local minima of neural networks are theoretically proven to be no worse than the globally optimal values of corresponding classical machine learning models. We empirically support our theoretical observation with a synthetic dataset as well as MNIST, CIFAR-10 and SVHN datasets. When compared to previous studies with strong over-parameterization assumptions, the results in this paper do not require over-parameterization, and instead show the gradual effects of over-parameterization as consequences of general results.","Tue, 20 Nov 2018 09:41:52 UTC (417 KB)"
"18","Non-invasive thermal comfort perception based on subtleness magnification and deep learning for energy efficiency","Xiaogang Cheng, Bin Yang, Anders Hedman, Thomas Olofsson, Haibo Li, Luc Van Gool","Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)","Human thermal comfort measurement plays a critical role in giving feedback signals for building energy efficiency. A non-invasive measuring method based on subtleness magnification and deep learning (NIDL) was designed to achieve a comfortable, energy efficient built environment. The method relies on skin feature data, e.g., subtle motion and texture variation, and a 315-layer deep neural network for constructing the relationship between skin features and skin temperature. A physiological experiment was conducted for collecting feature data (1.44 million) and algorithm validation. The non-invasive measurement algorithm based on a partly-personalized saturation temperature model (NIPST) was used for algorithm performance comparisons. The results show that the mean error and median error of the NIDL are 0.4834 Celsius and 0.3464 Celsius which is equivalent to accuracy improvements of 16.28% and 4.28%, respectively.","Mon, 12 Nov 2018 18:24:48 UTC (1,696 KB)"
"19","Deep Learning for Automated Classification of Tuberculosis-Related Chest X-Ray: Dataset Specificity Limits Diagnostic Performance Generalizability","Seelwan Sathitratanacheewin (1 and 2), Krit Pongpirul (1, 2, and 3) ((1) Department of Preventive and Social Medicine, Faculty of Medicine, Chulalongkorn University, Bangkok, Thailand, (2) Thai Health AI Foundation, Bangkok, Thailand, (3) Department of International Health and Department of Health, Behavior, and Society, Johns Hopkins Bloomberg School of Public Health, Baltimore, MD, USA)","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Machine learning has been an emerging tool for various aspects of infectious diseases including tuberculosis surveillance and detection. However, WHO provided no recommendations on using computer-aided tuberculosis detection software because of the small number of studies, methodological limitations, and limited generalizability of the findings. To quantify the generalizability of the machine-learning model, we developed a Deep Convolutional Neural Network (DCNN) model using a TB-specific CXR dataset of one population (National Library of Medicine Shenzhen No.3 Hospital) and tested it with non-TB-specific CXR dataset of another population (National Institute of Health Clinical Centers). The findings suggested that a supervised deep learning model developed by using the training dataset from one population may not have the same diagnostic performance in another population. Technical specification of CXR images, disease severity distribution, overfitting, and overdiagnosis should be examined before implementation in other settings.","Tue, 13 Nov 2018 16:32:42 UTC (227 KB)"
"20","Slum Segmentation and Change Detection : A Deep Learning Approach","Shishira R Maiya, Sudharshan Chandra Babu","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","More than one billion people live in slums around the world. In some developing countries, slum residents make up for more than half of the population and lack reliable sanitation services, clean water, electricity, other basic services. Thus, slum rehabilitation and improvement is an important global challenge, and a significant amount of effort and resources have been put into this endeavor. These initiatives rely heavily on slum mapping and monitoring, and it is essential to have robust and efficient methods for mapping and monitoring existing slum settlements. In this work, we introduce an approach to segment and map individual slums from satellite imagery, leveraging regional convolutional neural networks for instance segmentation using transfer learning. In addition, we also introduce a method to perform change detection and monitor slum change over time. We show that our approach effectively learns slum shape and appearance, and demonstrates strong quantitative results, resulting in a maximum AP of 80.0.","Mon, 19 Nov 2018 15:45:06 UTC (7,461 KB)"
"21","Ambulatory Atrial Fibrillation Monitoring Using Wearable Photoplethysmography with Deep Learning","Maxime Voisin, Yichen Shen, Alireza Aliamiri, Anand Avati, Awni Hannun, Andrew Ng","Medical Physics (physics.med-ph)","We develop an algorithm that accurately detects Atrial Fibrillation (AF) episodes from photoplethysmograms (PPG) recorded in ambulatory free-living conditions. We collect and annotate a dataset containing more than 4000 hours of PPG recorded from a wrist-worn device. Using a 50-layer convolutional neural network, we achieve a test AUC of 95% and show robustness to motion artifacts inherent to PPG signals. Continuous and accurate detection of AF from PPG has the potential to transform consumer wearable devices into clinically useful medical monitoring tools.","Mon, 12 Nov 2018 06:47:23 UTC (875 KB)"
"22","Addressing the Invisible: Street Address Generation for Developing Countries with Deep Learning","Ilke Demir, Ramesh Raskar","Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY); Machine Learning (cs.LG); Machine Learning (stat.ML)","More than half of the world's roads lack adequate street addressing systems. Lack of addresses is even more visible in daily lives of people in developing countries. We would like to object to the assumption that having an address is a luxury, by proposing a generative address design that maps the world in accordance with streets. The addressing scheme is designed considering several traditional street addressing methodologies employed in the urban development scenarios around the world. Our algorithm applies deep learning to extract roads from satellite images, converts the road pixel confidences into a road network, partitions the road network to find neighborhoods, and labels the regions, roads, and address units using graph- and proximity-based algorithms. We present our results on a sample US city, and several developing cities, compare travel times of users using current ad hoc and new complete addresses, and contrast our addressing solution to current industrial and open geocoding alternatives.","Sat, 10 Nov 2018 07:34:04 UTC (7,647 KB)"
"23","How far from automatically interpreting deep learning","Jinwei Zhao, Qizhou Wang, Yufei Wang, Xinhong Hei, Yu Liu","Machine Learning (cs.LG); Machine Learning (stat.ML)","In recent years, deep learning researchers have focused on how to find the interpretability behind deep learning models. However, today cognitive competence of human has not completely covered the deep learning model. In other words, there is a gap between the deep learning model and the cognitive mode. How to evaluate and shrink the cognitive gap is a very important issue. In this paper, the interpretability evaluation, the relationship between the generalization performance and the interpretability of the model and the method for improving the interpretability are concerned. A universal learning framework is put forward to solve the equilibrium problem between the two performances. The uniqueness of solution of the problem is proved and condition of unique solution is obtained. Probability upper bound of the sum of the two performances is analyzed.","Mon, 19 Nov 2018 15:25:02 UTC (714 KB)"
"24","Self-Referenced Deep Learning","Xu Lan, Xiatian Zhu, Shaogang Gong","Computer Vision and Pattern Recognition (cs.CV)","Knowledge distillation is an effective approach to transferring knowledge from a teacher neural network to a student target network for satisfying the low-memory and fast running requirements in practice use. Whilst being able to create stronger target networks compared to the vanilla non-teacher based learning strategy, this scheme needs to train additionally a large teacher model with expensive computational cost. In this work, we present a Self-Referenced Deep Learning (SRDL) strategy. Unlike both vanilla optimisation and existing knowledge distillation, SRDL distils the knowledge discovered by the in-training target model back to itself to regularise the subsequent learning procedure therefore eliminating the need for training a large teacher model. SRDL improves the model generalisation performance compared to vanilla learning and conventional knowledge distillation approaches with negligible extra computational cost. Extensive evaluations show that a variety of deep networks benefit from SRDL resulting in enhanced deployment performance on both coarse-grained object categorisation tasks (CIFAR10, CIFAR100, Tiny ImageNet, and ImageNet) and fine-grained person instance identification tasks (Market-1501).","Mon, 19 Nov 2018 10:41:17 UTC (1,924 KB)"
"25","DeepSeeNet: A deep learning model for automated classification of patient-based age-related macular degeneration severity from color fundus photographs","Yifan Peng, Shazia Dharssi, Qingyu Chen, Tiarnan D. Keenan, Elvira Agron, Wai T. Wong, Emily Y. Chew, Zhiyong Lu","Computer Vision and Pattern Recognition (cs.CV)","In assessing the severity of age-related macular degeneration (AMD), the Age-Related Eye Disease Study (AREDS) Simplified Severity Scale predicts the risk of progression to late AMD. However, its manual use requires the time-consuming participation of expert practitioners. While several automated deep learning (DL) systems have been developed for classifying color fundus photographs of individual eyes by AREDS severity score, none to date has utilized a patient-based scoring system that employs images from both eyes to assign a severity score. DeepSeeNet, a DL model, was developed to classify patients automatically by the AREDS Simplified Severity Scale (score 0-5) using bilateral color fundus images. DeepSeeNet was trained on 58,402 and tested on 900 images from the longitudinal follow up of 4,549 participants from AREDS. Gold standard labels were obtained using reading center grades. DeepSeeNet simulates the human grading process by first detecting individual AMD risk factors (drusen size; pigmentary abnormalities) for each eye and then calculating a patient-based AMD severity score using the AREDS Simplified Severity Scale. DeepSeeNet performed better on patient-based, multi-class classification (accuracy=0.671; kappa=0.558) than retinal specialists (accuracy=0.599; kappa=0.467) with high AUCs in the detection of large drusen (0.94), pigmentary abnormalities (0.93) and late AMD (0.97), respectively. DeepSeeNet demonstrated high accuracy with increased transparency in the automated assignment of individual patients to AMD risk categories based on the AREDS Simplified Severity Scale. These results highlight the potential of deep learning systems to assist and enhance clinical decision-making processes in AMD patients such as early AMD detection and risk prediction for developing late AMD. DeepSeeNet is publicly available on this https URL.","Mon, 19 Nov 2018 04:19:34 UTC (2,098 KB)"
"26","Taming the latency in multi-user VR 360$^\circ$: A QoE-aware deep learning-aided multicast framework","Cristina Perfecto, Mohammed S. Elbamby, Javier Del Ser, Mehdi Bennis","Information Theory (cs.IT)","Immersive virtual reality (VR) applications are known to require ultra-high data rate and low-latency for smooth operation. In this paper, we propose a proactive deep-learning aided joint scheduling and content quality adaptation scheme for multi-user VR field of view (FoV) wireless video streaming. Using a real VR head-tracking dataset, a deep recurrent neural network (DRNN) based on gated recurrent units (GRUs) is leveraged to obtain users' upcoming tiled FoV predictions. Subsequently, to exploit a physical layer FoV-centric millimeter wave (mmWave) multicast transmission, users are hierarchically clustered according to their predicted FoV similarity and location. We pose the problem as a quality admission maximization problem under tight latency constraints, and adopt the Lyapunov framework to model the problem of dynamically admitting and scheduling proactive and real-time high definition (HD) video chunk requests, corresponding to a tile in the FoV of a user cluster for a given video frame, while maintaining the system stability. After decoupling the problem into three subproblems, a matching theory game is proposed to solve the scheduling subproblem by associating chunk requests from clusters of users to mmWave small cell base stations (SBSs) for multicast transmission. Simulation results demonstrate the streaming quality gain and latency reduction brought by using the proposed scheme. It is shown that the prediction of FoV significantly improves the VR streaming experience using proactive scheduling of the video tiles in the users' future FoV. Moreover, multicasting significantly reduces the VR frame delay in a multi-user setting by applying content-reuse in clusters of users with highly overlapping FoVs.","Sun, 18 Nov 2018 19:43:19 UTC (1,874 KB)"
"27","Deep Learning with Inaccurate Training Data for Image Restoration","Bolin Liu, Xiao Shu, Xiaolin Wu","Computer Vision and Pattern Recognition (cs.CV)","In many applications of deep learning, particularly those in image restoration, it is either very difficult, prohibitively expensive, or outright impossible to obtain paired training data precisely as in the real world. In such cases, one is forced to use synthesized paired data to train the deep convolutional neural network (DCNN). However, due to the unavoidable generalization error in statistical learning, the synthetically trained DCNN often performs poorly on real world data. To overcome this problem, we propose a new general training method that can compensate for, to a large extent, the generalization errors of synthetically trained DCNNs.","Sun, 18 Nov 2018 04:01:33 UTC (8,415 KB)"
"28","Classifiers Based on Deep Sparse Coding Architectures are Robust to Deep Learning Transferable Examples","Jacob M. Springer, Charles S. Strauss, Austin M. Thresher, Edward Kim, Garrett T. Kenyon","Machine Learning (cs.LG); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","Although deep learning has shown great success in recent years, researchers have discovered a critical flaw where small, imperceptible changes in the input to the system can drastically change the output classification. These attacks are exploitable in nearly all of the existing deep learning classification frameworks. However, the susceptibility of deep sparse coding models to adversarial examples has not been examined. Here, we show that classifiers based on a deep sparse coding model whose classification accuracy is competitive with a variety of deep neural network models are robust to adversarial examples that effectively fool those same deep learning models. We demonstrate both quantitatively and qualitatively that the robustness of deep sparse coding models to adversarial examples arises from two key properties. First, because deep sparse coding models learn general features corresponding to generators of the dataset as a whole, rather than highly discriminative features for distinguishing specific classes, the resulting classifiers are less dependent on idiosyncratic features that might be more easily exploited. Second, because deep sparse coding models utilize fixed point attractor dynamics with top-down feedback, it is more difficult to find small changes to the input that drive the resulting representations out of the correct attractor basin.","Sat, 17 Nov 2018 19:39:54 UTC (3,471 KB)[v2] Tue, 20 Nov 2018 18:55:55 UTC (3,471 KB)"
"29","A Study of Human Body Characteristics Effect on Micro-Doppler-Based Person Identification using Deep Learning","Sherif Abdulatif, Fady Aziz, Karim Armanious, Bernhard Kleiner, Bin Yang, Urs Schneider","Computer Vision and Pattern Recognition (cs.CV)","Obtaining a smart surveillance requires a sensing system that can capture accurate and detailed information for the human walking style. The radar micro-Doppler ($\boldsymbolレ$-D) analysis is proved to be a reliable metric for studying human locomotions. Thus, $\boldsymbolレ$-D signatures can be used to identify humans based on their walking styles. Additionally, the signatures contain information about the radar cross section (RCS) of the moving subject. This paper investigates the effect of human body characteristics on human identification based on their $\boldsymbolレ$-D signatures. In our proposed experimental setup, a treadmill is used to collect $\boldsymbolレ$-D signatures of 22 subjects with different genders and body characteristics. Convolutional autoencoders (CAE) are then used to extract the latent space representation from the $\boldsymbolレ$-D signatures. It is then interpreted in two dimensions using t-distributed stochastic neighbor embedding (t-SNE). Our study shows that the body mass index (BMI) has a correlation with the $\boldsymbolレ$-D signature of the walking subject. A 50-layer deep residual network is then trained to identify the walking subject based on the $\boldsymbolレ$-D signature. We achieve an accuracy of 98% on the test set with high signal-to-noise-ratio (SNR) and 84% in case of different SNR levels.","Sat, 17 Nov 2018 14:53:22 UTC (10,159 KB)"
"30","Deep learning framework DNN with conditional WGAN for protein solubility prediction","X. Han, L. Zhang, K. Zhou, X. Wang","Quantitative Methods (q-bio.QM)","Protein solubility plays a critical role in improving production yield of recombinant proteins in biocatalyst and pharmaceutical field. To some extent, protein solubility can represent the function and activity of biocatalysts which are mainly composed of recombinant proteins. Highly soluble proteins are more effective in biocatalytic processes and can reduce the cost of biocatalysts. Screening proteins by experiments in vivo is time-consuming and expensive. In literature, large amounts of machine learning models have been investigated, whereas parameters of those models are underdetermined with insufficient data of protein solubility. A data augmentation algorithm that can enlarge the dataset of protein solubility and improve the performance of prediction model is highly desired, which can alleviate the common issue of insufficient data in biotechnology applications for developing machine learning models. We first implemented a novel approach that a data augmentation algorithm, conditional WGAN was used to improve prediction performance of DNN for protein solubility from protein sequence by generating artificial data. After adding mimic data produced from conditional WGAN, the prediction performance represented by $R^{2}$ was improved compared with the $R^{2}$ without data augmentation. After tuning the hyperparameters of two algorithms and organizing the dataset, we achieved a $R^{2}$ value of $45.04\%$, which enhanced $R^{2}$ about $10\%$ compared with the previous study using the same dataset. Data augmentation opens the door to applications of machine learning models on biological data, as machine learning models always fail to be well trained by small datasets.","Sat, 17 Nov 2018 10:34:24 UTC (692 KB)"
"31","Cross-modality deep learning brings bright-field microscopy contrast to holography","Yichen Wu, Yilin Luo, Gunvant Chaudhari, Yair Rivenson, Ayfer Calis, Kevin De Haan, Aydogan Ozcan","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Applied Physics (physics.app-ph)","Deep learning brings bright-field microscopy contrast to holographic images of a sample volume, bridging the volumetric imaging capability of holography with the speckle- and artifact-free image contrast of bright-field incoherent microscopy.","Sat, 17 Nov 2018 05:20:13 UTC (564 KB)"
"32","Deep Learning of Turbulent Scalar Mixing","Maziar Raissi, Hessam Babaee, Peyman Givi","Fluid Dynamics (physics.flu-dyn); Computational Engineering, Finance, and Science (cs.CE); Computational Physics (physics.comp-ph)","Based on recent developments in physics-informed deep learning and deep hidden physics models, we put forth a framework for discovering turbulence models from scattered and potentially noisy spatio-temporal measurements of the probability density function (PDF). The models are for the conditional expected diffusion and the conditional expected dissipation of a Fickian scalar described by its transported single-point PDF equation. The discovered model are appraised against exact solution derived by the amplitude mapping closure (AMC)/ Johnsohn-Edgeworth translation (JET) model of binary scalar mixing in homogeneous turbulence.","Sat, 17 Nov 2018 04:15:54 UTC (2,445 KB)"
"33","Synergistic Drug Combination Prediction by Integrating Multi-omics Data in Deep Learning Models","Tianyu Zhang, Liwei Zhang, Philip R.O. Payne, Fuhai Li","Genomics (q-bio.GN); Machine Learning (cs.LG); Machine Learning (stat.ML)","Drug resistance is still a major challenge in cancer therapy. Drug combination is expected to overcome drug resistance. However, the number of possible drug combinations is enormous, and thus it is infeasible to experimentally screen all effective drug combinations considering the limited resources. Therefore, computational models to predict and prioritize effective drug combinations is important for combinatory therapy discovery in cancer. In this study, we proposed a novel deep learning model, AuDNNsynergy, to prediction drug combinations by integrating multi-omics data and chemical structure data. In specific, three autoencoders were trained using the gene expression, copy number and genetic mutation data of all tumor samples from The Cancer Genome Atlas. Then the physicochemical properties of drugs combined with the output of the three autoencoders, characterizing the individual cancer cell-lines, were used as the input of a deep neural network that predicts the synergy value of given pair-wise drug combinations against the specific cancer cell-lines. The comparison results showed the proposed AuDNNsynergy model outperforms four state-of-art approaches, namely DeepSynergy, Gradient Boosting Machines, Random Forests, and Elastic Nets. Moreover, we conducted the interpretation analysis of the deep learning model to investigate potential vital genetic predictors and the underlying mechanism of synergistic drug combinations on specific cancer cell-lines.","Fri, 16 Nov 2018 22:40:06 UTC (1,001 KB)"
"34","Deep learning approach to coherent noise reduction in optical diffraction tomography","Gunho Choi, Donghun Ryu, Youngju Jo, Youngseo Kim, Weisun Park, Hyun-Seok Min, Yongkeun Park","Optics (physics.optics); Image and Video Processing (eess.IV)","We present a deep neural network to reduce coherent noise in three-dimensional quantitative phase imaging. Inspired by the cycle generative adversarial network, the denoising network was trained to learn a transform between two image domains: clean and noisy refractive index tomograms. The unique feature of this network, distinct from previous machine learning approaches employed in the optical imaging problem, is that it uses unpaired images. The learned network quantitatively demonstrated its performance and generalization capability through denoising experiments of various samples. We concluded by applying our technique to reduce the temporally changing noise emerging from focal drift in time-lapse imaging of biological cells. This reduction cannot be performed using other optical methods for denoising.","Fri, 16 Nov 2018 18:04:40 UTC (1,991 KB)"
"35","Anomaly Detection using Deep Learning based Image Completion","Matthias Haselmann, Dieter P. Gruber, Paul Tabatabai","Computer Vision and Pattern Recognition (cs.CV)","Automated surface inspection is an important task in many manufacturing industries and often requires machine learning driven solutions. Supervised approaches, however, can be challenging, since it is often difficult to obtain large amounts of labeled training data. In this work, we instead perform one-class unsupervised learning on fault-free samples by training a deep convolutional neural network to complete images whose center regions are cut out. Since the network is trained exclusively on fault-free data, it completes the image patches with a fault-free version of the missing image region. The pixel-wise reconstruction error within the cut out region is an anomaly image which can be used for anomaly detection. Results on surface images of decorated plastic parts demonstrate that this approach is suitable for detection of visible anomalies and moreover surpasses all other tested methods.","Fri, 16 Nov 2018 15:36:28 UTC (1,607 KB)"
"36","Concept-Oriented Deep Learning: Generative Concept Representations","Daniel T. Chang","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Generative concept representations have three major advantages over discriminative ones: they can represent uncertainty, they support integration of learning and reasoning, and they are good for unsupervised and semi-supervised learning. We discuss probabilistic and generative deep learning, which generative concept representations are based on, and the use of variational autoencoders and generative adversarial networks for learning generative concept representations, particularly for concepts whose data are sequences, structured data or graphs.","Thu, 15 Nov 2018 23:13:26 UTC (841 KB)"
"37","Stable Tensor Neural Networks for Rapid Deep Learning","Elizabeth Newman, Lior Horesh, Haim Avron, Misha Kilmer","Machine Learning (cs.LG); Numerical Analysis (cs.NA); Numerical Analysis (math.NA); Machine Learning (stat.ML)","We propose a tensor neural network ($t$-NN) framework that offers an exciting new paradigm for designing neural networks with multidimensional (tensor) data. Our network architecture is based on the $t$-product (Kilmer and Martin, 2011), an algebraic formulation to multiply tensors via circulant convolution. In this $t$-product algebra, we interpret tensors as $t$-linear operators analogous to matrices as linear operators, and hence our framework inherits mimetic matrix properties. To exemplify the elegant, matrix-mimetic algebraic structure of our $t$-NNs, we expand on recent work (Haber and Ruthotto, 2017) which interprets deep neural networks as discretizations of non-linear differential equations and introduces stable neural networks which promote superior generalization. Motivated by this dynamic framework, we introduce a stable $t$-NN which facilitates more rapid learning because of its reduced, more powerful parameterization. Through our high-dimensional design, we create a more compact parameter space and extract multidimensional correlations otherwise latent in traditional algorithms. We further generalize our $t$-NN framework to a family of tensor-tensor products (Kernfeld, Kilmer, and Aeron, 2015) which still induce a matrix-mimetic algebraic structure. Through numerical experiments on the MNIST and CIFAR-10 datasets, we demonstrate the more powerful parameterizations and improved generalizability of stable $t$-NNs.","Thu, 15 Nov 2018 19:37:24 UTC (1,667 KB)"
"38","Development and Validation of a Deep Learning Algorithm for Improving Gleason Scoring of Prostate Cancer","Kunal Nagpal, Davis Foote, Yun Liu, Po-Hsuan (Cameron)Chen, Ellery Wulczyn, Fraser Tan, Niels Olson, Jenny L. Smith, Arash Mohtashamian, James H. Wren, Greg S. Corrado, Robert MacDonald, Lily H. Peng, Mahul B. Amin, Andrew J. Evans, Ankur R. Sangoi, Craig H. Mermel, Jason D. Hipp, Martin C. Stumpe","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","For prostate cancer patients, the Gleason score is one of the most important prognostic factors, potentially determining treatment independent of the stage. However, Gleason scoring is based on subjective microscopic examination of tumor morphology and suffers from poor reproducibility. Here we present a deep learning system (DLS) for Gleason scoring whole-slide images of prostatectomies. Our system was developed using 112 million pathologist-annotated image patches from 1,226 slides, and evaluated on an independent validation dataset of 331 slides, where the reference standard was established by genitourinary specialist pathologists. On the validation dataset, the mean accuracy among 29 general pathologists was 0.61. The DLS achieved a significantly higher diagnostic accuracy of 0.70 (p=0.002) and trended towards better patient risk stratification in correlations to clinical follow-up data. Our approach could improve the accuracy of Gleason scoring and subsequent therapy decisions, particularly where specialist expertise is unavailable. The DLS also goes beyond the current Gleason system to more finely characterize and quantitate tumor morphology, providing opportunities for refinement of the Gleason system itself.","Thu, 15 Nov 2018 17:49:50 UTC (2,631 KB)"
"39","Towards Explainable Deep Learning for Credit Lending: A Case Study","Ceena Modarres, Mark Ibrahim, Melissa Louie, John Paisley","Machine Learning (cs.LG); Artificial Intelligence (cs.AI)","Deep learning adoption in the financial services industry has been limited due to a lack of model interpretability. However, several techniques have been proposed to explain predictions made by a neural network. We provide an initial investigation into these techniques for the assessment of credit risk with neural networks.","Thu, 15 Nov 2018 17:03:59 UTC (1,365 KB)"
"40","DeepCSO: Forecasting of Combined Sewer Overflow at a Citywide Level using Multi-task Deep Learning","Duo Zhang, Geir Lindholm, Harsha Ratnaweera","Computers and Society (cs.CY); Machine Learning (cs.LG); Machine Learning (stat.ML)","Combined Sewer Overflow (CSO) is a major problem to be addressed by many cities. Understanding the behavior of sewer system through proper urban hydrological models is an effective method of enhancing sewer system management. Conventional deterministic methods, which heavily rely on physical principles, is inappropriate for real-time purpose due to their expensive computation. On the other hand, data-driven methods have gained huge interests, but most studies only focus on modeling a single component of the sewer system and supply information at a very abstract level. In this paper, we proposed the DeepCSO model, which aims at forecasting CSO events from multiple CSO structures simultaneously in near real time at a citywide level. The proposed model provided an intermediate methodology that combines the flexibility of data-driven methods and the rich information contained in deterministic methods while avoiding the drawbacks of these two methods. A comparison of the results demonstrated that the deep learning based multi-task model is superior to the traditional methods.","Fri, 9 Nov 2018 12:27:28 UTC (1,040 KB)"
"41","Enhancing Operation of a Sewage Pumping Station for Inter Catchment Wastewater Transfer by Using Deep Learning and Hydraulic Model","Duo Zhang, Erlend Skullestad Holland, Geir Lindholm, Harsha Ratnaweera","Computers and Society (cs.CY); Machine Learning (cs.LG); Machine Learning (stat.ML)","This paper presents a novel Inter Catchment Wastewater Transfer (ICWT) method for mitigating sewer overflow. The ICWT aims at balancing the spatial mismatch of sewer flow and treatment capacity of Wastewater Treatment Plant (WWTP), through collaborative operation of sewer system facilities. Using a hydraulic model, the effectiveness of ICWT is investigated in a sewer system in Drammen, Norway. Concerning the whole system performance, we found that the Sren Lemmich pump station plays a vital role in the ICWT framework. To enhance the operation of this pump station, it is imperative to construct a multi-step ahead water level prediction model. Hence, one of the most promising artificial intelligence techniques, Long Short Term Memory (LSTM), is employed to undertake this task. Experiments demonstrated that LSTM is superior to Gated Recurrent Unit (GRU), Recurrent Neural Network (RNN), Feed-forward Neural Network (FFNN) and Support Vector Regression (SVR).","Fri, 9 Nov 2018 12:28:53 UTC (1,298 KB)"
"42","Effects of Lombard Reflex on the Performance of Deep-Learning-Based Audio-Visual Speech Enhancement Systems","Daniel Michelsanti, Zheng-Hua Tan, Sigurdur Sigurdsson, Jesper Jensen","Audio and Speech Processing (eess.AS); Machine Learning (cs.LG); Sound (cs.SD); Image and Video Processing (eess.IV)","Humans tend to change their way of speaking when they are immersed in a noisy environment, a reflex known as Lombard effect. Current speech enhancement systems based on deep learning do not usually take into account this change in the speaking style, because they are trained with neutral (non-Lombard) speech utterances recorded under quiet conditions to which noise is artificially added. In this paper, we investigate the effects that the Lombard reflex has on the performance of audio-visual speech enhancement systems based on deep learning. The results show that a gap in the performance of as much as approximately 5 dB between the systems trained on neutral speech and the ones trained on Lombard speech exists. This indicates the benefit of taking into account the mismatch between neutral and Lombard speech in the design of audio-visual speech enhancement systems.","Thu, 15 Nov 2018 09:29:14 UTC (69 KB)"
"43","On Training Targets and Objective Functions for Deep-Learning-Based Audio-Visual Speech Enhancement","Daniel Michelsanti, Zheng-Hua Tan, Sigurdur Sigurdsson, Jesper Jensen","Audio and Speech Processing (eess.AS); Machine Learning (cs.LG); Sound (cs.SD); Image and Video Processing (eess.IV)","Audio-visual speech enhancement (AV-SE) is the task of improving speech quality and intelligibility in a noisy environment using audio and visual information from a talker. Recently, deep learning techniques have been adopted to solve the AV-SE task in a supervised manner. In this context, the choice of the target, i.e. the quantity to be estimated, and the objective function, which quantifies the quality of this estimate, to be used for training is critical for the performance. This work is the first that presents an experimental study of a range of different targets and objective functions used to train a deep-learning-based AV-SE system. The results show that the approaches that directly estimate a mask perform the best overall in terms of estimated speech quality and intelligibility, although the model that directly estimates the log magnitude spectrum performs as good in terms of estimated speech quality.","Thu, 15 Nov 2018 08:39:04 UTC (25 KB)"
"44","Deep Learning in the Wavelet Domain","Fergal Cotter, Nick Kingsbury","Computer Vision and Pattern Recognition (cs.CV)","This paper examines the possibility of, and the possible advantages to learning the filters of convolutional neural networks (CNNs) for image analysis in the wavelet domain. We are stimulated by both Mallat's scattering transform and the idea of filtering in the Fourier domain. It is important to explore new spaces in which to learn, as these may provide inherent advantages that are not available in the pixel space. However, the scattering transform is limited by its inability to learn in between scattering orders, and any Fourier domain filtering is limited by the large number of filter parameters needed to get localized filters. Instead we consider filtering in the wavelet domain with learnable filters. The wavelet space allows us to have local, smooth filters with far fewer parameters, and learnability can give us flexibility. We present a novel layer which takes CNN activations into the wavelet space, learns parameters and returns to the pixel space. This allows it to be easily dropped in to any neural network without affecting the structure. As part of this work, we show how to pass gradients through a multirate system and give preliminary results.","Wed, 14 Nov 2018 23:33:09 UTC (374 KB)"
"45","Interpretable deep learning for guided structure-property explorations in photovoltaics","Balaji Sesha Sarath Pokuri, Sambuddha Ghosal, Apurva Kokate, Baskar Ganapathysubramnian, Soumik Sarkar","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","The performance of an organic photovoltaic device is intricately connected to its active layer morphology. This connection between the active layer and device performance is very expensive to evaluate, either experimentally or computationally. Hence, designing morphologies to achieve higher performances is non-trivial and often intractable. To solve this, we first introduce a deep convolutional neural network (CNN) architecture that can serve as a fast and robust surrogate for the complex structure-property map. Several tests were performed to gain trust in this trained model. Then, we utilize this fast framework to perform robust microstructural design to enhance device performance.","Wed, 14 Nov 2018 21:08:08 UTC (3,640 KB)[v2] Mon, 19 Nov 2018 19:59:56 UTC (3,640 KB)"
"46","Deep learning in the heterotic orbifold landscape","Andreas Mutter, Erik Parr, Patrick K.S. Vaudrevange","High Energy Physics - Theory (hep-th); High Energy Physics - Phenomenology (hep-ph)","We use deep autoencoder neural networks to draw a chart of the heterotic $\mathbb{Z}_6$-II orbifold landscape. Even though the autoencoder is trained without knowing the phenomenological properties of the $\mathbb{Z}_6$-II orbifold models, we are able to identify fertile islands in this chart where phenomenologically promising models cluster. Then, we apply a decision tree to our chart in order to extract the defining properties of the fertile islands. Based on this information we propose a new search strategy for phenomenologically promising string models.","Wed, 14 Nov 2018 19:01:03 UTC (802 KB)"
"47","Bandana: Using Non-volatile Memory for Storing Deep Learning Models","Assaf Eisenman, Maxim Naumov, Darryl Gardner, Misha Smelyanskiy, Sergey Pupyrev, Kim Hazelwood, Asaf Cidon, Sachin Katti","Machine Learning (cs.LG); Machine Learning (stat.ML)","Typical large-scale recommender systems use deep learning models that are stored on a large amount of DRAM. These models often rely on embeddings, which consume most of the required memory. We present Bandana, a storage system that reduces the DRAM footprint of embeddings, by using Non-volatile Memory (NVM) as the primary storage medium, with a small amount of DRAM as cache. The main challenge in storing embeddings on NVM is its limited read bandwidth compared to DRAM. Bandana uses two primary techniques to address this limitation: first, it stores embedding vectors that are likely to be read together in the same physical location, using hypergraph partitioning, and second, it decides the number of embedding vectors to cache in DRAM by simulating dozens of small caches. These techniques allow Bandana to increase the effective read bandwidth of NVM by 2-3x and thereby significantly reduce the total cost of ownership.","Wed, 14 Nov 2018 17:47:33 UTC (1,227 KB)[v2] Thu, 15 Nov 2018 01:48:26 UTC (887 KB)"
"48","Cross-lingual Short-text Matching with Deep Learning","Asmelash Teka Hadgu","Computation and Language (cs.CL)","The problem of short text matching is formulated as follows: given a pair of sentences or questions, a matching model determines whether the input pair mean the same or not. Models that can automatically identify questions with the same meaning have a wide range of applications in question answering sites and modern chatbots. In this article, we describe the approach by team hahu to solve this problem in the context of the ""CIKM AnalytiCup 2018 - Cross-lingual Short-text Matching of Question Pairs"" that is sponsored by Alibaba. Our solution is an end-to-end system based on current advances in deep learning which avoids heavy feature-engineering and achieves improved performance over traditional machine-learning approaches. The log-loss scores for the first and second rounds of the contest are 0.35 and 0.39 respectively. The team was ranked 7th from 1027 teams in the overall ranking scheme by the organizers that consisted of the two contest scores as well as: innovation and system integrity, understanding data as well as practicality of the solution for business.","Tue, 13 Nov 2018 23:27:06 UTC (115 KB)"
"49","Predicting Distresses using Deep Learning of Text Segments in Annual Reports","Rastin Matin, Casper Hansen, Christian Hansen, Pia Mlgaard","Computation and Language (cs.CL); Computational Finance (q-fin.CP); Risk Management (q-fin.RM)","Corporate distress models typically only employ the numerical financial variables in the firms' annual reports. We develop a model that employs the unstructured textual data in the reports as well, namely the auditors' reports and managements' statements. Our model consists of a convolutional recurrent neural network which, when concatenated with the numerical financial variables, learns a descriptive representation of the text that is suited for corporate distress prediction. We find that the unstructured data provides a statistically significant enhancement of the distress prediction performance, in particular for large firms where accurate predictions are of the utmost importance. Furthermore, we find that auditors' reports are more informative than managements' statements and that a joint model including both managements' statements and auditors' reports displays no enhancement relative to a model including only auditors' reports. Our model demonstrates a direct improvement over existing state-of-the-art models.","Tue, 13 Nov 2018 13:09:58 UTC (80 KB)"
"50","How Secure are Deep Learning Algorithms from Side-Channel based Reverse Engineering?","Manaar Alam, Debdeep Mukhopadhyay","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep Learning algorithms have recently become the de-facto paradigm for various prediction problems, which include many privacy-preserving applications like online medical image analysis. Presumably, the privacy of data in a deep learning system is a serious concern. There have been several efforts to analyze and exploit the information leakages from deep learning architectures to compromise data privacy. In this paper, however, we attempt to provide an evaluation strategy for such information leakages through deep neural network architectures by considering a case study on Convolutional Neural Network (CNN) based image classifier. The approach takes the aid of low-level hardware information, provided by Hardware Performance Counters (HPCs), during the execution of a CNN classifier and a simple hypothesis testing in order to produce an alarm if there exists any information leakage on the actual input.","Tue, 13 Nov 2018 12:42:24 UTC (874 KB)"
"51","An Orchestrated Empirical Study on Deep Learning Frameworks and Platforms","Qianyu Guo, Xiaofei Xie, Lei Ma, Qiang Hu, Ruitao Feng, Li Li, Yang Liu, Jianjun Zhao, Xiaohong Li","Machine Learning (cs.LG); Cryptography and Security (cs.CR); Software Engineering (cs.SE)","Deep learning (DL) has recently achieved tremendous success in a variety of cutting-edge applications, e.g., image recognition, speech and natural language processing, and autonomous driving. Besides the available big data and hardware evolution, DL frameworks and platforms play a key role to catalyze the research, development, and deployment of DL intelligent solutions. However, the difference in computation paradigm, architecture design and implementation of existing DL frameworks and platforms brings challenges for DL software development, deployment, maintenance, and migration. Up to the present, it still lacks a comprehensive study on how current diverse DL frameworks and platforms influence the DL software development process. In this paper, we initiate the first step towards the investigation on how existing state-of-the-art DL frameworks (i.e., TensorFlow, Theano, and Torch) and platforms (i.e., server/desktop, web, and mobile) support the DL software development activities. We perform an in-depth and comparative evaluation on metrics such as learning accuracy, DL model size, robustness, and performance, on state-of-the-art DL frameworks across platforms using two popular datasets MNIST and CIFAR-10. Our study reveals that existing DL frameworks still suffer from compatibility issues, which becomes even more severe when it comes to different platforms. We pinpoint the current challenges and opportunities towards developing high quality and compatible DL systems. To ignite further investigation along this direction to address urgent industrial demands of intelligent solutions, we make all of our assembled feasible toolchain and dataset publicly available.","Tue, 13 Nov 2018 09:51:57 UTC (1,822 KB)"
"52","Vehicle Re-identification Using Quadruple Directional Deep Learning Features","Jianqing Zhu, Huanqiang Zeng, Jingchang Huang, Shengcai Liao, Zhen Lei, Canhui Cai, LiXin Zheng","Computer Vision and Pattern Recognition (cs.CV)","In order to resist the adverse effect of viewpoint variations for improving vehicle re-identification performance, we design quadruple directional deep learning networks to extract quadruple directional deep learning features (QD-DLF) of vehicle images. The quadruple directional deep learning networks are with similar overall architecture, including the same basic deep learning architecture but different directional feature pooling layers. Specifically, the same basic deep learning architecture is a shortly and densely connected convolutional neural network to extract basic feature maps of an input square vehicle image in the first stage. Then, the quadruple directional deep learning networks utilize different directional pooling layers, i.e., horizontal average pooling (HAP) layer, vertical average pooling (VAP) layer, diagonal average pooling (DAP) layer and anti-diagonal average pooling (AAP) layer, to compress the basic feature maps into horizontal, vertical, diagonal and anti-diagonal directional feature maps, respectively. Finally, these directional feature maps are spatially normalized and concatenated together as a quadruple directional deep learning feature for vehicle re-identification. Extensive experiments on both VeRi and VehicleID databases show that the proposed QD-DLF approach outperforms multiple state-of-the-art vehicle re-identification methods.","Tue, 13 Nov 2018 08:44:19 UTC (2,984 KB)"
"53","Hate Speech Detection from Code-mixed Hindi-English Tweets Using Deep Learning Models","Satyajit Kamble, Aditya Joshi","Computation and Language (cs.CL)","This paper reports an increment to the state-of-the-art in hate speech detection for English-Hindi code-mixed tweets. We compare three typical deep learning models using domain-specific embeddings. On experimenting with a benchmark dataset of English-Hindi code-mixed tweets, we observe that using domain-specific embeddings results in an improved representation of target groups, and an improved F-score.","Tue, 13 Nov 2018 07:49:02 UTC (1,682 KB)"
"54","Deep Learning versus Classical Regression for Brain Tumor Patient Survival Prediction","Yannick Suter, Alain Jungo, Michael Rebsamen, Urspeter Knecht, Evelyn Herrmann, Roland Wiest, Mauricio Reyes","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Deep learning for regression tasks on medical imaging data has shown promising results. However, compared to other approaches, their power is strongly linked to the dataset size. In this study, we evaluate 3D-convolutional neural networks (CNNs) and classical regression methods with hand-crafted features for survival time regression of patients with high grade brain tumors. The tested CNNs for regression showed promising but unstable results. The best performing deep learning approach reached an accuracy of 51.5% on held-out samples of the training set. All tested deep learning experiments were outperformed by a Support Vector Classifier (SVC) using 30 radiomic features. The investigated features included intensity, shape, location and deep features. The submitted method to the BraTS 2018 survival prediction challenge is an ensemble of SVCs, which reached a cross-validated accuracy of 72.2% on the BraTS 2018 training set, 57.1% on the validation set, and 42.9% on the testing set. The results suggest that more training data is necessary for a stable performance of a CNN model for direct regression from magnetic resonance images, and that non-imaging clinical patient information is crucial along with imaging information.","Mon, 12 Nov 2018 18:45:08 UTC (2,012 KB)"
"55","Focusing on the Big Picture: Insights into a Systems Approach to Deep Learning for Satellite Imagery","Ritwik Gupta, Carson D. Sestili, Javier A. Vazquez-Trejo, Matthew E. Gaston","Computer Vision and Pattern Recognition (cs.CV)","Deep learning tasks are often complicated and require a variety of components working together efficiently to perform well. Due to the often large scale of these tasks, there is a necessity to iterate quickly in order to attempt a variety of methods and to find and fix bugs. While participating in IARPA's Functional Map of the World challenge, we identified challenges along the entire deep learning pipeline and found various solutions to these challenges. In this paper, we present the performance, engineering, and deep learning considerations with processing and modeling data, as well as underlying infrastructure considerations that support large-scale deep learning tasks. We also discuss insights and observations with regard to satellite imagery and deep learning for image classification.","Mon, 12 Nov 2018 18:25:20 UTC (2,960 KB)"
"56","Deep-learning the Latent Space of Light Transport","Pedro Hermosilla, Sebastian Maisch, Tobias Ritschel, Timo Ropinski","Graphics (cs.GR); Computer Vision and Pattern Recognition (cs.CV)","We suggest a method to directly deep-learn light transport, i. e., the mapping from a 3D geometry-illumination-material configuration to a shaded 2D image. While many previous learning methods have employed 2D convolutional neural networks applied to images, we show for the first time that light transport can be learned directly in 3D. The benefit of 3D over 2D is, that the former can also correctly capture illumination effects related to occluded and/or semi-transparent geometry. To learn 3D light transport, we represent the 3D scene as an unstructured 3D point cloud, which is later, during rendering, projected to the 2D output image. Thus, we suggest a two-stage operator comprising of a 3D network that first transforms the point cloud into a latent representation, which is later on projected to the 2D output image using a dedicated 3D-2D network in a second step. We will show that our approach results in improved quality in terms of temporal coherence while retaining most of the computational efficiency of common 2D methods. As a consequence, the proposed two stage-operator serves as a valuable extension to modern deferred shading approaches.","Mon, 12 Nov 2018 14:55:58 UTC (1,830 KB)"
"57","Learning The Invisible: A Hybrid Deep Learning-Shearlet Framework for Limited Angle Computed Tomography","T. A. Bubba, G. Kutyniok, M. Lassas, M. Marz, W. Samek, S. Siltanen, V. Srinivasan","Computer Vision and Pattern Recognition (cs.CV)","The high complexity of various inverse problems poses a significant challenge to model-based reconstruction schemes, which in such situations often reach their limits. At the same time, we witness an exceptional success of data-based methodologies such as deep learning. However, in the context of inverse problems, deep neural networks mostly act as black box routines, used for instance for a somewhat unspecified removal of artifacts in classical image reconstructions. In this paper, we will focus on the severely ill-posed inverse problem of limited angle computed tomography, in which entire boundary sections are not captured in the measurements. We will develop a hybrid reconstruction framework that fuses model-based sparse regularization with data-driven deep learning. Our method is reliable in the sense that we only learn the part that can provably not be handled by model-based methods, while applying the theoretically controllable sparse regularization technique to the remaining parts. Such a decomposition into visible and invisible segments is achieved by means of the shearlet transform that allows to resolve wavefront sets in the phase space. Furthermore, this split enables us to assign the clear task of inferring unknown shearlet coefficients to the neural network and thereby offering an interpretation of its performance in the context of limited angle computed tomography. Our numerical experiments show that our algorithm significantly surpasses both pure model- and more data-based reconstruction methods.","Mon, 12 Nov 2018 08:36:42 UTC (5,773 KB)"
"58","Deep Learning Based Transmitter Identification using Power Amplifier Nonlinearity","Samer S. Hanna, Danijela Cabric","Signal Processing (eess.SP)","The imperfections in the RF frontend of different transmitters can be used to distinguish them. This process is called transmitter identification using RF fingerprints. The nonlinearity in the power amplifier of the RF frontend is a significant cause of the discrepancy in RF fingerprints, which enables transmitter identification. In this work, we use deep learning to identify different transmitters using their nonlinear characteristics. By developing a nonlinear model generator based on extensive measurements, we were able to extend the evaluation of transmitter identification to include a larger number of transmitters beyond what exists in the literature. We were also able to study the impact of transmitter variability on identification accuracy. Additionally, many other factors were considered including modulation type, length of data used for identification, and type of data being transmitted whether identical or random under a realistic channel model. Simulation results were compared with experiments which confirmed similar trends.","Mon, 12 Nov 2018 00:57:58 UTC (558 KB)"
"59","SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient","Aaron Mishkin, Frederik Kunstner, Didrik Nielsen, Mark Schmidt, Mohammad Emtiyaz Khan","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Uncertainty estimation in large deep-learning models is a computationally challenging task, where it is difficult to form even a Gaussian approximation to the posterior distribution. In such situations, existing methods usually resort to a diagonal approximation of the covariance matrix despite, the fact that these matrices are known to give poor uncertainty estimates. To address this issue, we propose a new stochastic, low-rank, approximate natural-gradient (SLANG) method for variational inference in large, deep models. Our method estimates a ""diagonal plus low-rank"" structure based solely on back-propagated gradients of the network log-likelihood. This requires strictly less gradient computations than methods that compute the gradient of the whole variational objective. Empirical evaluations on standard benchmarks confirm that SLANG enables faster and more accurate estimation of uncertainty than mean-field methods, and performs comparably to state-of-the-art methods.","Sun, 11 Nov 2018 23:18:27 UTC (2,663 KB)"
"60","Deep Learning Framework for Pedestrian Collision Avoidance System (PeCAS)","Peetak Mitra","Computer Vision and Pattern Recognition (cs.CV)","Drowsy driving is a major cause of on-road accidents in the US, which sometimes is fatal to unsuspecting pedestrians. This framework based on Deep Learning proposes an approach to detect the onset of drowsiness in a vehicle operator especially alerting the driver when in the proximity of a pedestrian. Using Convolutional Neural Network (CNN), an approach is proposed to detect drowsiness based on the Viola-Jones algorithm. The pedestrian detector is also based on a deep CNN architecture and is capable to detect multiple pedestrians. In the end, an integration of the output from the two architectures is fed into an Arduino hardware kit to generate warnings for the vehicle operator.","Sun, 11 Nov 2018 19:00:12 UTC (235 KB)"
"61","Explaining Deep Learning Models using Causal Inference","Tanmayee Narendra, Anush Sankaran, Deepak Vijaykeerthy, Senthil Mani","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Although deep learning models have been successfully applied to a variety of tasks, due to the millions of parameters, they are becoming increasingly opaque and complex. In order to establish trust for their widespread commercial use, it is important to formalize a principled framework to reason over these models. In this work, we use ideas from causal inference to describe a general framework to reason over CNN models. Specifically, we build a Structural Causal Model (SCM) as an abstraction over a specific aspect of the CNN. We also formulate a method to quantitatively rank the filters of a convolution layer according to their counterfactual importance. We illustrate our approach with popular CNN architectures such as LeNet5, VGG19, and ResNet32.","Sun, 11 Nov 2018 09:26:55 UTC (163 KB)"
"62","Scene Text Detection and Recognition: The Deep Learning Era","Shangbang Long, Xin He, Cong Ya","Computer Vision and Pattern Recognition (cs.CV)","With the rise and development of deep learning, computer vision has been tremendously transformed and reshaped. As an important research area in computer vision, scene text detection and recognition has been inescapably influenced by this wave of revolution, consequentially entering the era of deep learning. In recent years, the community has witnessed substantial advancements in mindset, approach and performance. This survey is aimed at summarizing and analyzing the major changes and significant progresses of scene text detection and recognition in the deep learning era. Through this article, we devote to: (1) introduce new insights and ideas; (2) highlight recent techniques and benchmarks; (3) look ahead into future trends. Specifically, we will emphasize the dramatic differences brought by deep learning and the grand challenges still remained. We expect that this review paper would serve as a reference book for researchers in this field. Related resources are also collected and compiled in our Github repository: this https URL.","Sat, 10 Nov 2018 13:56:31 UTC (8,170 KB)"
"63","Detecting Work Zones in SHRP 2 NDS Videos Using Deep Learning Based Computer Vision","Franklin Abodo, Robert Rittmuller, Brian Sumner, Andrew Berthaume","Computer Vision and Pattern Recognition (cs.CV)","Naturalistic driving studies seek to perform the observations of human driver behavior in the variety of environmental conditions necessary to analyze, understand and predict that behavior using statistical and physical models. The second Strategic Highway Research Program (SHRP 2) funds a number of transportation safety-related projects including its primary effort, the Naturalistic Driving Study (NDS), and an effort supplementary to the NDS, the Roadway Information Database (RID). This work seeks to expand the range of answerable research questions that researchers might pose to the NDS and RID databases. Specifically, we present the SHRP 2 NDS Video Analytics (SNVA) software application, which extracts information from NDS-instrumented vehicles' forward-facing camera footage and efficiently integrates that information into the RID, tying the video content to geolocations and other trip attributes. Of particular interest to researchers and other stakeholders is the integration of work zone, traffic signal state and weather information. The version of SNVA introduced in this paper focuses on work zone detection, the highest priority. The ability to automate the discovery and cataloging of this information, and to do so quickly, is especially important given the two petabyte (2PB) size of the NDS video data set.","Sat, 10 Nov 2018 13:07:06 UTC (2,229 KB)"
"64","Deep Learning Approach for Building Detection in Satellite Multispectral Imagery","Geesara Prathap, Ilya Afanasyev","Computer Vision and Pattern Recognition (cs.CV)","Building detection from satellite multispectral imagery data is being a fundamental but a challenging problem mainly because it requires correct recovery of building footprints from high-resolution images. In this work, we propose a deep learning approach for building detection by applying numerous enhancements throughout the process. Initial dataset is preprocessed by 2-sigma percentile normalization. Then data preparation includes ensemble modelling where 3 models were created while incorporating OpenStreetMap data. Binary Distance Transformation (BDT) is used for improving data labeling process and the U-Net (Convolutional Networks for Biomedical Image Segmentation) is modified by adding batch normalization wrappers. Afterwards, it is explained how each component of our approach is correlated with the final detection accuracy. Finally, we compare our results with winning solutions of SpaceNet 2 competition for real satellite multispectral images of Vegas, Paris, Shanghai and Khartoum, demonstrating the importance of our solution for achieving higher building detection accuracy.","Sat, 10 Nov 2018 12:53:37 UTC (4,798 KB)"
"65","Reasoning over RDF Knowledge Bases using Deep Learning","Monireh Ebrahimi, Md Kamruzzaman Sarker, Federico Bianchi, Ning Xie, Derek Doran, Pascal Hitzler","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Semantic Web knowledge representation standards, and in particular RDF and OWL, often come endowed with a formal semantics which is considered to be of fundamental importance for the field. Reasoning, i.e., the drawing of logical inferences from knowledge expressed in such standards, is traditionally based on logical deductive methods and algorithms which can be proven to be sound and complete and terminating, i.e. correct in a very strong sense. For various reasons, though, in particular, the scalability issues arising from the ever-increasing amounts of Semantic Web data available and the inability of deductive algorithms to deal with noise in the data, it has been argued that alternative means of reasoning should be investigated which bear high promise for high scalability and better robustness. From this perspective, deductive algorithms can be considered the gold standard regarding correctness against which alternative methods need to be tested. In this paper, we show that it is possible to train a Deep Learning system on RDF knowledge graphs, such that it is able to perform reasoning over new RDF knowledge graphs, with high precision and recall compared to the deductive gold standard.","Fri, 9 Nov 2018 21:00:46 UTC (934 KB)"
"66","Deep Learning Super-Diffusion in Multiplex Networks","Vito M. Leli, Saeed Osat, Timur Tlyachev, Jacob D. Biamonte","Physics and Society (physics.soc-ph); Machine Learning (cs.LG); Social and Information Networks (cs.SI)","Complex network theory has shown success in understanding the emergent and collective behavior of complex systems [1]. Many real-world complex systems were recently discovered to be more accurately modeled as multiplex networks [2-6]---in which each interaction type is mapped to its own network layer; e.g.~multi-layer transportation networks, coupled social networks, metabolic and regulatory networks, etc. A salient physical phenomena emerging from multiplexity is super-diffusion: exhibited by an accelerated diffusion admitted by the multi-layer structure as compared to any single layer. Theoretically super-diffusion was only known to be predicted using the spectral gap of the full Laplacian of a multiplex network and its interacting layers. Here we turn to machine learning which has developed techniques to recognize, classify, and characterize complex sets of data. We show that modern machine learning architectures, such as fully connected and convolutional neural networks, can classify and predict the presence of super-diffusion in multiplex networks with 94.12\% accuracy. Such predictions can be done {\it in situ}, without the need to determine spectral properties of a network.","Fri, 9 Nov 2018 19:18:07 UTC (2,291 KB)"
"67","A generic framework for privacy preserving deep learning","Theo Ryffel, Andrew Trask, Morten Dahl, Bobby Wagner, Jason Mancuso, Daniel Rueckert, Jonathan Passerat-Palmbach","Machine Learning (cs.LG); Cryptography and Security (cs.CR); Machine Learning (stat.ML)","We detail a new framework for privacy preserving deep learning and discuss its assets. The framework puts a premium on ownership and secure processing of data and introduces a valuable representation based on chains of commands and tensors. This abstraction allows one to implement complex privacy preserving constructs such as Federated Learning, Secure Multiparty Computation, and Differential Privacy while still exposing a familiar deep learning API to the end-user. We report early results on the Boston Housing and Pima Indian Diabetes datasets. While the privacy features apart from Differential Privacy do not impact the prediction accuracy, the current implementation of the framework introduces a significant overhead in performance, which will be addressed at a later stage of the development. We believe this work is an important milestone introducing the first reliable, general framework for privacy preserving deep learning.","Fri, 9 Nov 2018 17:10:47 UTC (161 KB)[v2] Tue, 13 Nov 2018 18:11:15 UTC (161 KB)"
"68","Looking Deeper into Deep Learning Model: Attribution-based Explanations of TextCNN","Wenting Xiong, Iftitahu Ni'mah, Juan M. G. Huesca, Werner van Ipenburg, Jan Veldsink, Mykola Pechenizkiy","Information Retrieval (cs.IR); Machine Learning (cs.LG); Machine Learning (stat.ML)","Layer-wise Relevance Propagation (LRP) and saliency maps have been recently used to explain the predictions of Deep Learning models, specifically in the domain of text classification. Given different attribution-based explanations to highlight relevant words for a predicted class label, experiments based on word deleting perturbation is a common evaluation method. This word removal approach, however, disregards any linguistic dependencies that may exist between words or phrases in a sentence, which could semantically guide a classifier to a particular prediction. In this paper, we present a feature-based evaluation framework for comparing the two attribution methods on customer reviews (public data sets) and Customer Due Diligence (CDD) extracted reports (corporate data set). Instead of removing words based on the relevance score, we investigate perturbations based on embedded features removal from intermediate layers of Convolutional Neural Networks. Our experimental study is carried out on embedded-word, embedded-document, and embedded-ngrams explanations. Using the proposed framework, we provide a visualization tool to assist analysts in reasoning toward the model's final prediction.","Thu, 8 Nov 2018 18:23:48 UTC (395 KB)"
"69","A Convergence Theory for Deep Learning via Over-Parameterization","Zeyuan Allen-Zhu, Yuanzhi Li, Zhao Song","Machine Learning (cs.LG); Data Structures and Algorithms (cs.DS); Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC); Machine Learning (stat.ML)","Deep neural networks (DNNs) have demonstrated dominating performance in many fields; since AlexNet, the neural networks used in practice are going wider and deeper. On the theoretical side, a long line of works have been focusing on why we can train neural networks when there is only one hidden layer. The theory of multi-layer networks remains somewhat unsettled. In this work, we prove why simple algorithms such as stochastic gradient descent (SGD) can find $\textit{global minima}$ on the training objective of DNNs. We only make two assumptions: the inputs do not degenerate and the network is over-parameterized. The latter means the number of hidden neurons is sufficiently large: $\textit{polynomial}$ in $L$, the number of DNN layers and in $n$, the number of training samples. As concrete examples, on the training set and starting from randomly initialized weights, we show that SGD attains 100% accuracy in classification tasks, or minimizes regression loss in linear convergence speed $\varepsilon \propto e^{-ヘ(T)}$, with a number of iterations that only scales polynomial in $n$ and $L$. Our theory applies to the widely-used but non-smooth ReLU activation, and to any smooth and possibly non-convex loss functions. In terms of network architectures, our theory at least applies to fully-connected neural networks, convolutional neural networks (CNN), and residual neural networks (ResNet).","Fri, 9 Nov 2018 15:16:13 UTC (770 KB)[v2] Wed, 14 Nov 2018 18:54:20 UTC (772 KB)"
"70","Skeptical Deep Learning with Distribution Correction","Mingxiao An, Yongzhou Chen, Qi Liu, Chuanren Liu, Guangyi Lv, Fangzhao Wu, Jianhui Ma","Machine Learning (cs.LG); Machine Learning (stat.ML)","Recently deep neural networks have been successfully used for various classification tasks, especially for problems with massive perfectly labeled training data. However, it is often costly to have large-scale credible labels in real-world applications. One solution is to make supervised learning robust with imperfectly labeled input. In this paper, we develop a distribution correction approach that allows deep neural networks to avoid overfitting imperfect training data. Specifically, we treat the noisy input as samples from an incorrect distribution, which will be automatically corrected during our training process. We test our approach on several classification datasets with elaborately generated noisy labels. The results show significantly higher prediction and recovery accuracy with our approach compared to alternative methods.","Fri, 9 Nov 2018 09:07:06 UTC (489 KB)"
"71","Deep Learning Predicts Hip Fracture using Confounding Patient and Healthcare Variables","Marcus A. Badgeley, John R. Zech, Luke Oakden-Rayner, Benjamin S. Glicksberg, Manway Liu, William Gale, Michael V. McConnell, Beth Percha, Thomas M. Snyder, Joel T. Dudley","Computer Vision and Pattern Recognition (cs.CV)","Hip fractures are a leading cause of death and disability among older adults. Hip fractures are also the most commonly missed diagnosis on pelvic radiographs. Computer-Aided Diagnosis (CAD) algorithms have shown promise for helping radiologists detect fractures, but the image features underpinning their predictions are notoriously difficult to understand. In this study, we trained deep learning models on 17,587 radiographs to classify fracture, five patient traits, and 14 hospital process variables. All 20 variables could be predicted from a radiograph (p < 0.05), with the best performances on scanner model (AUC=1.00), scanner brand (AUC=0.98), and whether the order was marked ""priority"" (AUC=0.79). Fracture was predicted moderately well from the image (AUC=0.78) and better when combining image features with patient data (AUC=0.86, p=2e-9) or patient data plus hospital process features (AUC=0.91, p=1e-21). The model performance on a test set with matched patient variables was significantly lower than a random test set (AUC=0.67, p=0.003); and when the test set was matched on patient and image acquisition variables, the model performed randomly (AUC=0.52, 95% CI 0.46-0.58), indicating that these variables were the main source of the model's predictive ability overall. We also used Naive Bayes to combine evidence from image models with patient and hospital data and found their inclusion improved performance, but that this approach was nevertheless inferior to directly modeling all variables. If CAD algorithms are inexplicably leveraging patient and process variables in their predictions, it is unclear how radiologists should interpret their predictions in the context of other known patient data. Further research is needed to illuminate deep learning decision processes so that computers and clinicians can effectively cooperate.","Thu, 8 Nov 2018 22:23:07 UTC (4,788 KB)"
"72","Can Deep Learning Outperform Modern Commercial CT Image Reconstruction Methods?","Hongming Shan, Atul Padole, Fatemeh Homayounieh, Uwe Kruger, Ruhani Doda Khera, Chayanin Nitiwarangkul, Mannudeep K. Kalra, Ge Wang","Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)","Commercial iterative reconstruction techniques on modern CT scanners target radiation dose reduction but there are lingering concerns over their impact on image appearance and low contrast detectability. Recently, machine learning, especially deep learning, has been actively investigated for CT. Here we design a novel neural network architecture for low-dose CT (LDCT) and compare it with commercial iterative reconstruction methods used for standard of care CT. While popular neural networks are trained for end-to-end mapping, driven by big data, our novel neural network is intended for end-to-process mapping so that intermediate image targets are obtained with the associated search gradients along which the final image targets are gradually reached. This learned dynamic process allows to include radiologists in the training loop to optimize the LDCT denoising workflow in a task-specific fashion with the denoising depth as a key parameter. Our progressive denoising network was trained with the Mayo LDCT Challenge Dataset, and tested on images of the chest and abdominal regions scanned on the CT scanners made by three leading CT vendors. The best deep learning based reconstructions are systematically compared to the best iterative reconstructions in a double-blinded reader study. It is found that our deep learning approach performs either comparably or favorably in terms of noise suppression and structural fidelity, and runs orders of magnitude faster than the commercial iterative CT reconstruction algorithms.","Thu, 8 Nov 2018 22:04:22 UTC (3,268 KB)"
"73","Deep Learning Applied to the Asteroseismic Modeling of Stars with Coherent Oscillation Modes","Luc Hendriks, Conny Aerts","Solar and Stellar Astrophysics (astro-ph.SR)","We develop a novel method based on machine learning principles to achieve optimal initiation of CPU-intensive computations for forward asteroseismic modeling in a multi-D parameter space. A deep neural network is trained on a precomputed asteroseismology grid containing about 62 million coherent oscillation-mode frequencies derived from stellar evolution models. These models are representative of the core-hydrogen burning stage of intermediate-mass and high-mass stars. The evolution models constitute a 6D parameter space and their predicted low-degree pressure- and gravity-mode oscillations are scanned, using a genetic algorithm. A software pipeline is created to find the best fitting stellar parameters for a given set of observed oscillation frequencies. The proposed method finds the optimal regions in the 6D parameters space in less than a minute, hence providing the optimal starting point for further and more detailed forward asteroseismic modeling in a high-dimensional context. We test and apply the method to seven pulsating stars that were previously modeled asteroseismically by classical grid-based forward modeling based on a $ヶ^2$ statistic and obtain good agreement with past results. Our deep learning methodology opens up the application of asteroseismic modeling in +6D parameter space for thousands of stars pulsating in coherent modes with long lifetimes observed by the $Kepler$ space telescope and to be discovered with the TESS and PLATO space missions, while applications so far were done star-by-star for only a handful of cases. Our method is open source and can be used by anyone freely.","Thu, 8 Nov 2018 19:01:03 UTC (13,008 KB)"
"74","Distance-based Protein Folding Powered by Deep Learning","Jinbo Xu","Biomolecules (q-bio.BM)","Contact-assisted protein folding has made very good progress, but two challenges remain. One is accurate contact prediction for proteins lack of many sequence homologs and the other is that time-consuming folding simulation is often needed to predict good 3D models from predicted contacts. We show that protein distance matrix can be predicted well by deep learning and then directly used to construct 3D models without folding simulation at all. Using distance geometry to construct 3D models from our predicted distance matrices, we successfully folded 21 of the 37 CASP12 hard targets with a median family size of 58 effective sequence homologs within 4 hours on a Linux computer of 20 CPUs. In contrast, contacts predicted by direct coupling analysis (DCA) cannot fold any of them in the absence of folding simulation and the best CASP12 group folded 11 of them by integrating predicted contacts into complex, fragment-based folding simulation. The rigorous experimental validation on 15 CASP13 targets show that among the 3 hardest targets of new fold our distance-based folding servers successfully folded 2 large ones with <150 sequence homologs while the other servers failed on all three, and that our ab initio folding server also predicted the best, high-quality 3D model for a large homology modeling target. Further experimental validation in CAMEO shows that our ab initio folding server predicted correct fold for a membrane protein of new fold with 200 residues and 229 sequence homologs while all the other servers failed. These results imply that deep learning offers an efficient and accurate solution for ab initio folding on a personal computer.","Thu, 8 Nov 2018 15:08:19 UTC (907 KB)[v2] Mon, 12 Nov 2018 01:56:36 UTC (972 KB)"
"75","Explaining Deep Learning Models - A Bayesian Non-parametric Approach","Wenbo Guo, Sui Huang, Yunzhe Tao, Xinyu Xing, Lin Lin","Machine Learning (cs.LG); Machine Learning (stat.ML)","Understanding and interpreting how machine learning (ML) models make decisions have been a big challenge. While recent research has proposed various technical approaches to provide some clues as to how an ML model makes individual predictions, they cannot provide users with an ability to inspect a model as a complete entity. In this work, we propose a novel technical approach that augments a Bayesian non-parametric regression mixture model with multiple elastic nets. Using the enhanced mixture model, we can extract generalizable insights for a target model through a global approximation. To demonstrate the utility of our approach, we evaluate it on different ML models in the context of image recognition. The empirical results indicate that our proposed approach not only outperforms the state-of-the-art techniques in explaining individual decisions but also provides users with an ability to discover the vulnerabilities of the target ML models.","Wed, 7 Nov 2018 16:26:32 UTC (2,277 KB)"
"76","Bayesian Deep Learning for Exoplanet Atmospheric Retrieval","Frank Soboczenski, Michael D. Himes, Molly D. O'Beirne, Simone Zorzan, Atilim Gunes Baydin, Adam D. Cobb, Daniel Angerhausen, Giada N. Arney, Shawn D. Domagal-Goldman","Earth and Planetary Astrophysics (astro-ph.EP); Machine Learning (cs.LG)","Over the past decade, the study of exoplanets has shifted from their detection to the characterization of their atmospheres. Atmospheric retrieval, the inverse modeling technique used to determine an atmosphere's temperature and composition from an observed spectrum, is both time-consuming and compute-intensive, requiring complex algorithms that compare thousands to millions of atmospheric models to the observational data to find the most probable values and associated uncertainties for each model parameter. For rocky, terrestrial planets, the retrieved atmospheric composition can give insight into the surface fluxes of gaseous species necessary to maintain the stability of that atmosphere, which may in turn provide insight into the geological and/or biological processes active on the planet. These atmospheres contain many molecules, some of which are biosignatures, or molecules indicative of biological activity. Runtimes of traditional retrieval models scale with the number of model parameters, so as more molecular species are considered, runtimes can become prohibitively long. Recent advances in machine learning (ML) and computer vision offer new ways to reduce the time to perform a retrieval by orders of magnitude, given a sufficient data set to train with. Here we present an ML-based retrieval framework called Intelligent exoplaNet Atmospheric RetrievAl (INARA) that consists of a Bayesian deep learning model for retrieval and a data set of 3,000,000 spectra of synthetic rocky exoplanets generated using the NASA Planetary Spectrum Generator (PSG). Our work represents the first ML model for rocky, terrestrial exoplanets and the first synthetic data set of spectra generated at this scale.","Thu, 8 Nov 2018 13:03:08 UTC (3,947 KB)"
"77","Activation Functions: Comparison of trends in Practice and Research for Deep Learning","Chigozie Nwankpa, Winifred Ijomah, Anthony Gachagan, Stephen Marshall","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)","Deep neural networks have been successfully used in diverse emerging domains to solve real world complex problems with may more deep learning(DL) architectures, being developed to date. To achieve these state-of-the-art performances, the DL architectures use activation functions (AFs), to perform diverse computations between the hidden layers and the output layers of any given DL architecture. This paper presents a survey on the existing AFs used in deep learning applications and highlights the recent trends in the use of the activation functions for deep learning applications. The novelty of this paper is that it compiles majority of the AFs used in DL and outlines the current trends in the applications and usage of these functions in practical deep learning deployments against the state-of-the-art research results. This compilation will aid in making effective decisions in the choice of the most suitable and appropriate activation function for any given application, ready for deployment. This paper is timely because most research papers on AF highlights similar works and results while this paper will be the first, to compile the trends in AF applications in practice against the research results from literature, found in deep learning research to date.","Thu, 8 Nov 2018 12:28:43 UTC (119 KB)"
"78","Deep Learning can Replicate Adaptive Traders in a Limit-Order-Book Financial Market","Arthur le Calvez, Dave Cliff","Computational Engineering, Finance, and Science (cs.CE); Trading and Market Microstructure (q-fin.TR)","We report successful results from using deep learning neural networks (DLNNs) to learn, purely by observation, the behavior of profitable traders in an electronic market closely modelled on the limit-order-book (LOB) market mechanisms that are commonly found in the real-world global financial markets for equities (stocks & shares), currencies, bonds, commodities, and derivatives. Successful real human traders, and advanced automated algorithmic trading systems, learn from experience and adapt over time as market conditions change; our DLNN learns to copy this adaptive trading behavior. A novel aspect of our work is that we do not involve the conventional approach of attempting to predict time-series of prices of tradeable securities. Instead, we collect large volumes of training data by observing only the quotes issued by a successful sales-trader in the market, details of the orders that trader is executing, and the data available on the LOB (as would usually be provided by a centralized exchange) over the period that the trader is active. In this paper we demonstrate that suitably configured DLNNs can learn to replicate the trading behavior of a successful adaptive automated trader, an algorithmic system previously demonstrated to outperform human traders. We also demonstrate that DLNNs can learn to perform better (i.e., more profitably) than the trader that provided the training data. We believe that this is the first ever demonstration that DLNNs can successfully replicate a human-like, or super-human, adaptive trader operating in a realistic emulation of a real-world financial market. Our results can be considered as proof-of-concept that a DLNN could, in principle, observe the actions of a human trader in a real financial market and over time learn to trade equally as well as that human trader, and possibly better.","Wed, 7 Nov 2018 13:45:19 UTC (485 KB)"
"79","Deep Learning Accelerated Gold Nanocluster Synthesis","Jiali Li, Tiankai Chen, Kaizhuo Lim, Lingtong Chen, Saif A. Khan, Jianping Xie, Xiaonan Wang","Computational Physics (physics.comp-ph); Chemical Physics (physics.chem-ph)","The understanding of inorganic reactions, especially those far from the equilibrium state, is relatively limited due to their inherent complexity. Poor understandings on the underlying synthetic chemistry have constrained the design of efficient synthesis routes towards desired final products, especially those inorganic materials at atomic precision. In this work, using the synthesis of atomically precise gold nanoclusters as a demonstration platform, we have successfully developed a deep learning framework for guiding material synthesis and accelerating the whole workflow. With only 54 examples, the proposed Graph Convolutional Neural Networks (GCNN) plus Siamese Neural Networks (SNN) classification model with the basic descriptors have been trained. The capability of predicting the target synthesis results has been demonstrated with a successful experimental validation. In addition, understandings in the synthesis process can be acquired from a decision tree trained by a large amount of generated data from the well-trained classification model. This study not only provides a data-driven method accelerating gold nanocluster synthesis, but also sheds light on understanding complex inorganic materials synthesis with low data amount.","Wed, 7 Nov 2018 05:56:07 UTC (1,272 KB)[v2] Thu, 8 Nov 2018 02:49:32 UTC (1,272 KB)"
"80","Signal Detection for Faster than Nyquist Transmission Based on Deep Learning","Peiyang Song, Fengkui Gong, Qiang Li, Guo Li, Bing Sun","Signal Processing (eess.SP)","Faster than Nyquist (FTN) has been a promising solution to improve the bandwidth utilization. In this letter, we develop a novel detection architecture based on deep learning (DL) for faster than Nyquist signaling which directly recovers the transmitted bits by received symbols. To the best of our knowledge, this is the first attempt to merge the two technologies of FTN and DL. The simulation results demonstrate that the proposed architecture can effectively address the intersymbol interference (ISI) and achieve the performance comparable to the existing algorithms. Furthermore, the DL- based detection has shown its advantages in severe ISI and high order modulation scenarios over conventional approaches. In a nutshell, deep learning is proved to be a powerful tool for FTN signal detection.","Wed, 7 Nov 2018 05:24:35 UTC (124 KB)"
"81","Bayesian State Estimation for Unobservable Distribution Systems via Deep Learning","Kursat Rasim Mestav, Jaime Luengo-Rozas, Lang Tong","Machine Learning (stat.ML); Machine Learning (cs.LG); Applications (stat.AP)","The problem of state estimation for unobservable distribution systems is considered. A Bayesian approach is proposed that combines Bayesian inference with deep neural networks to achieve the minimum mean squared error estimation of network states for real-time applications. The proposed technique consists of distribution learning for stochastic power injection, a Monte Carlo technique for the training of a deep neural network for state estimation, and a Bayesian bad data detection and cleansing algorithm. Structural characteristics of the deep neural networks are investigated. Simulations illustrate the accuracy of Bayesian state estimation for unobservable systems and demonstrate the benefit of employing a deep neural network. Numerical results show the robustness of Bayesian state estimation against modeling and estimation errors of power injection distributions and the presence of bad data. Comparing with pseudo-measurement techniques, direct Bayesian state estimation with deep neural networks outperforms existing benchmarks.","Wed, 7 Nov 2018 04:37:33 UTC (345 KB)[v2] Tue, 13 Nov 2018 05:11:27 UTC (344 KB)"
"82","Automated Diagnosis of Lymphoma with Digital Pathology Images Using Deep Learning","Hanadi El Achi, Tatiana Belousova, Lei Chen, Amer Wahed, Iris Wang, Zhihong Hu, Zeyad Kanaan, Adan Rios, Andy N.D. Nguyen","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Recent studies have shown promising results in using Deep Learning to detect malignancy in whole slide imaging. However, they were limited to just predicting positive or negative finding for a specific neoplasm. We attempted to use Deep Learning with a convolutional neural network algorithm to build a lymphoma diagnostic model for four diagnostic categories: benign lymph node, diffuse large B cell lymphoma, Burkitt lymphoma, and small lymphocytic lymphoma. Our software was written in Python language. We obtained digital whole slide images of Hematoxylin and Eosin stained slides of 128 cases including 32 cases for each diagnostic category. Four sets of 5 representative images, 40x40 pixels in dimension, were taken for each case. A total of 2,560 images were obtained from which 1,856 were used for training, 464 for validation and 240 for testing. For each test set of 5 images, the predicted diagnosis was combined from prediction of 5 images. The test results showed excellent diagnostic accuracy at 95% for image-by-image prediction and at 10% for set-by-set prediction. This preliminary study provided a proof of concept for incorporating automated lymphoma diagnostic screen into future pathology workflow to augment the pathologists' productivity.","Tue, 30 Oct 2018 19:40:50 UTC (471 KB)"
"83","MAMMO: A Deep Learning Solution for Facilitating Radiologist-Machine Collaboration in Breast Cancer Diagnosis","Trent Kyono, Fiona J. Gilbert, Mihaela van der Schaar","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","With an aging and growing population, the number of women requiring either screening or symptomatic mammograms is increasing. To reduce the number of mammograms that need to be read by a radiologist while keeping the diagnostic accuracy the same or better than current clinical practice, we develop Man and Machine Mammography Oracle (MAMMO) - a clinical decision support system capable of triaging mammograms into those that can be confidently classified by a machine and those that cannot be, thus requiring the reading of a radiologist. The first component of MAMMO is a novel multi-view convolutional neural network (CNN) with multi-task learning (MTL). MTL enables the CNN to learn the radiological assessments known to be associated with cancer, such as breast density, conspicuity, suspicion, etc., in addition to learning the primary task of cancer diagnosis. We show that MTL has two advantages: 1) learning refined feature representations associated with cancer improves the classification performance of the diagnosis task and 2) issuing radiological assessments provides an additional layer of model interpretability that a radiologist can use to debug and scrutinize the diagnoses provided by the CNN. The second component of MAMMO is a triage network, which takes as input the radiological assessment and diagnostic predictions of the first network's MTL outputs and determines which mammograms can be correctly and confidently diagnosed by the CNN and which mammograms cannot, thus needing to be read by a radiologist. Results obtained on a private dataset of 8,162 patients show that MAMMO reduced the number of radiologist readings by 42.8% while improving the overall diagnostic accuracy in comparison to readings done by radiologists alone. We analyze the triage of patients decided by MAMMO to gain a better understanding of what unique mammogram characteristics require radiologists' expertise.","Tue, 30 Oct 2018 10:45:53 UTC (1,353 KB)"
"84","Finding and Following of Honeycombing Regions in Computed Tomography Lung Images by Deep Learning","Emre E<U+011F>riboz, Furkan Kaynar, Songul Varli Albayrak, Benan Musellim, Tuba Selcuk","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","In recent years, besides the medical treatment methods in medical field, Computer Aided Diagnosis (CAD) systems which can facilitate the decision making phase of the physician and can detect the disease at an early stage have started to be used frequently. The diagnosis of Idiopathic Pulmonary Fibrosis (IPF) disease by using CAD systems is very important in that it can be followed by doctors and radiologists. It has become possible to diagnose and follow up the disease with the help of CAD systems by the development of high resolution computed imaging scanners and increasing size of computation power. The purpose of this project is to design a tool that will help specialists diagnose and follow up the IPF disease by identifying areas of honeycombing and ground glass patterns in High Resolution Computed Tomography (HRCT) lung images. Creating a program module that segments the lung pair and creating a self-learner deep learning model from given Computed Tomography (CT) images for the specific diseased regions thanks to doctors are the main purposes of this work. Through the created model, program module will be able to find special regions in given new CT images. In this study, the performance of lung segmentation was tested by the Srensen-Dice coefficient method and the mean performance was measured as 90.7%, testing of the created model was performed with data not used in the training stage of the CNN network, and the average performance was measured as 87.8% for healthy regions, 73.3% for ground-glass areas and 69.1% for honeycombing zones.","Wed, 31 Oct 2018 18:29:45 UTC (2,077 KB)[v2] Thu, 8 Nov 2018 21:25:09 UTC (2,077 KB)"
"85","SDSS-IV MaNGA PyMorph Photometric and Deep Learning Morphological Catalogs and implications for bulge properties and stellar angular momentum","J.-L. Fischer, H. Dominguez Sanchez, M. Bernardi","Astrophysics of Galaxies (astro-ph.GA); Cosmology and Nongalactic Astrophysics (astro-ph.CO)","We describe the SDSS-IV MaNGA PyMorph Photometric (MPP-VAC) and MaNGA Deep Learning Morphology (MDLM-VAC) Value Added Catalogs. The MPP-VAC provides photometric parameters from Sersic and Sersic+Exponential fits to the 2D surface brightness profiles of the MaNGA DR15 galaxy sample. Compared to previous PyMorph analyses of SDSS imaging, our analysis of the MaNGA DR15 incorporates three improvements: the most recent SDSS images; modified criteria for determining bulge-to-disk decompositions; and the fits in MPP-VAC have been eye-balled, and re-fit if necessary, for additional reliability. A companion catalog, the MDLM-VAC, provides Deep Learning-based morphological classifications for the same galaxies. The MDLM-VAC includes a number of morphological properties (e.g., a TType, and a finer separation between elliptical and S0 galaxies). Combining the MPP- and MDLM-VACs allows to show that the MDLM morphological classifications are more reliable than previous work. It also shows that single-Sersic fits to late- and early-type galaxies are likely to return Sersic indices of $n \le 2$ and $\ge 4$, respectively, and this correlation between $n$ and morphology extends to the bulge component as well. While the former is well-known, the latter contradicts some recent work suggesting little correlation between $n$-bulge and morphology. Combining both VACs with MaNGA's spatially resolved spectroscopy allows us to study how the stellar angular momentum depends on morphological type. We find correlations between stellar kinematics, photometric properties, and morphological type even though the spectroscopic data played no role in the construction of the MPP- and MDLM-VACs.","Tue, 6 Nov 2018 19:00:07 UTC (3,089 KB)"
"86","Multi-Level Sensor Fusion with Deep Learning","Valentin Vielzeuf, Alexis Lechervy, Stephane Pateux, Frederic Jurie","Computer Vision and Pattern Recognition (cs.CV)","In the context of deep learning, this article presents an original deep network, namely CentralNet, for the fusion of information coming from different sensors. This approach is designed to efficiently and automatically balance the trade-off between early and late fusion (i.e. between the fusion of low-level vs high-level information). More specifically, at each level of abstraction-the different levels of deep networks-uni-modal representations of the data are fed to a central neural network which combines them into a common embedding. In addition, a multi-objective regularization is also introduced, helping to both optimize the central network and the unimodal networks. Experiments on four multimodal datasets not only show state-of-the-art performance, but also demonstrate that CentralNet can actually choose the best possible fusion strategy for a given problem.","Mon, 5 Nov 2018 15:26:45 UTC (211 KB)"
"87","Revealing Fine Structures of the Retinal Receptive Field by Deep Learning Networks","Qi Yan, Yajing Zheng, Shanshan Jia, Yichen Zhang, Zhaofei Yu, Feng Chen, Yonghong Tian, Tiejun Huang, Jian K. Liu","Neurons and Cognition (q-bio.NC); Machine Learning (cs.LG)","Deep convolutional neural networks (CNNs) have demonstrated impressive performance on many visual tasks. Recently, they became useful models for the visual system in neuroscience. However, it is still not clear what are learned by CNNs in terms of neuronal circuits. When a deep CNN with many layers is used for the visual system, it is not easy to compare the structure components of CNN with possible neuroscience underpinnings due to highly complex circuits from the retina to higher visual cortex. Here we address this issue by focusing on single retinal ganglion cells with biophysical models and recording data from animals. By training CNNs with white noise images to predict neuronal responses, we found that fine structures of the retinal receptive field can be revealed. Specifically, convolutional filters learned are resembling biological components of the retinal circuit. This suggests that a CNN learning from one single retinal cell reveals a minimal neural network carried out in this cell. Furthermore, when CNNs learned from different cells are transferred between cells, there is a diversity of transfer learning performance, which indicates that CNNs are cell-specific. Moreover, when CNNs are transferred between different types of input images, here white noise v.s. natural images, transfer learning shows a good performance, which implies that CNN indeed captures the full computational ability of a single retinal cell for different inputs. Taken together, these results suggest that CNN could be used to reveal structure components of neuronal circuits, and provide a powerful model for neural system identification.","Tue, 6 Nov 2018 11:20:46 UTC (2,050 KB)"
"88","Ultra-fast (milliseconds), multi-dimensional RF pulse design with deep learning","Mads Sloth Vinding, Birk Skyum, Ryan Sangill, Torben Ellegaard Lund","Medical Physics (physics.med-ph)","Purpose: Some advanced RF pulses, like multi-dimensional RF pulses, are often long and require substantial computation time due to a number of constraints and requirements, sometimes hampering clinical use. However, the pulses offer opportunities of reduced-FOV imaging, regional flip-angle homogenization, and localized spectroscopy, e.g., of hyperpolarized metabolites. We propose a novel deep learning approach to ultra-fast design multi-dimensional RF pulses with intention of real-time pulse updates. Methods: The proposed neural network considers input maps of the desired excitation region of interest, and outputs a multi-dimensional RF pulse. The training library is retrieved from a large image database, and the target RF pulses trained upon are calculated with a method of choice. Results: A relatively simple neural network is enough to produce reliable 2D spatial-selective RF pulses of comparable performance to the teaching method. For binary regions of interest, the training library does not need to be vast, hence, re-establishment of the training library is not necessarily cumbersome. The predicted pulses were tested numerically and experimentally. Conclusion: We demonstrate a relatively effortless training of multi-dimensional RF pulses, based on non-MRI related inputs, but working in an MRI setting still. The prediction time of few milliseconds renders real-time updates of advanced RF pulses possible.","Tue, 6 Nov 2018 10:34:18 UTC (2,471 KB)"
"89","Modeling and Predicting Popularity Dynamics via Deep Learning Attention Mechanism","Sha Yuan, Yu Zhang, Jie Tang, Huawei Shen, Xingxing Wei","Social and Information Networks (cs.SI); Machine Learning (cs.LG)","An ability to predict the popularity dynamics of individual items within a complex evolving system has important implications in a wide range of domains. Here we propose a deep learning attention mechanism to model the process through which individual items gain their popularity. We analyze the interpretability of the model with the four key phenomena confirmed independently in the previous studies of long-term popularity dynamics quantification, including the intrinsic quality, the aging effect, the recency effect and the Matthew effect. We analyze the effectiveness of introducing attention model in popularity dynamics prediction. Extensive experiments on a real-large citation data set demonstrate that the designed deep learning attention mechanism possesses remarkable power at predicting the long-term popularity dynamics. It consistently outperforms the existing methods, and achieves a significant performance improvement.","Tue, 6 Nov 2018 01:44:13 UTC (1,355 KB)"
"90","DeepConv-DTI: Prediction of drug-target interactions via deep learning with convolution on protein sequences","Ingoo Lee, Jongsoo Keum, Hojung Nam","Quantitative Methods (q-bio.QM); Machine Learning (cs.LG)","Identification of drug-target interactions (DTIs) plays a key role in drug discovery. The high cost and labor-intensive nature of in vitro and in vivo experiments have highlighted the importance of in silico-based DTI prediction approaches. In several computational models, conventional protein descriptors are shown to be not informative enough to predict accurate DTIs. Thus, in this study, we employ a convolutional neural network (CNN) on raw protein sequences to capture local residue patterns participating in DTIs. With CNN on protein sequences, our model performs better than previous protein descriptor-based models. In addition, our model performs better than the previous deep learning model for massive prediction of DTIs. By examining the pooled convolution results, we found that our model can detect binding sites of proteins for DTIs. In conclusion, our prediction model for detecting local residue patterns of target proteins successfully enriches the protein features of a raw protein sequence, yielding better prediction results than previous approaches.","Tue, 6 Nov 2018 01:39:02 UTC (949 KB)"
"91","Mesh-TensorFlow: Deep Learning for Supercomputers","Noam Shazeer, Youlong Cheng, Niki Parmar, Dustin Tran, Ashish Vaswani, Penporn Koanantakool, Peter Hawkins, HyoukJoong Lee, Mingsheng Hong, Cliff Young, Ryan Sepassi, Blake Hechtman","Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (stat.ML)","Batch-splitting (data-parallelism) is the dominant distributed Deep Neural Network (DNN) training strategy, due to its universal applicability and its amenability to Single-Program-Multiple-Data (SPMD) programming. However, batch-splitting suffers from problems including the inability to train very large models (due to memory constraints), high latency, and inefficiency at small batch sizes. All of these can be solved by more general distribution strategies (model-parallelism). Unfortunately, efficient model-parallel algorithms tend to be complicated to discover, describe, and to implement, particularly on large clusters. We introduce Mesh-TensorFlow, a language for specifying a general class of distributed tensor computations. Where data-parallelism can be viewed as splitting tensors and operations along the ""batch"" dimension, in Mesh-TensorFlow, the user can specify any tensor-dimensions to be split across any dimensions of a multi-dimensional mesh of processors. A Mesh-TensorFlow graph compiles into a SPMD program consisting of parallel operations coupled with collective communication primitives such as Allreduce. We use Mesh-TensorFlow to implement an efficient data-parallel, model-parallel version of the Transformer sequence-to-sequence model. Using TPU meshes of up to 512 cores, we train Transformer models with up to 5 billion parameters, surpassing state of the art results on WMT'14 English-to-French translation task and the one-billion-word language modeling benchmark. Mesh-Tensorflow is available at this https URL .","Mon, 5 Nov 2018 23:25:02 UTC (3,331 KB)"
"92","Deep Learning of Robust and High-Precision Quantum Controls","Re-Bing Wu, Haijin Ding, Daoyi Dong, Xiaoting Wang","Quantum Physics (quant-ph)","Robust and high-precision quantum control is extremely important but challenging for scalable quantum computation. In this letter, we show that this hard problem can be translated to a supervised machine learning task by treating the time-ordered controlled quantum evolution as a layer-ordered deep neural network (DNN). The finding of robust quantum controls is then equivalent to training a DNN with high generalizability. In this way, powerful DNN tuning skills matured in deep learning (DL) can be employed for the discovery of highly robust and precise quantum controls, which opens up a door through which a large family of learning algorithms can be developed. We exemplify this DL-inspired potential by introducing the commonly used trick of batch-based optimization. The resulting b-GRAPE algorithm is demonstrated to be able to remarkably enhance the control robustness while maintaining high fidelity in the implementation of a three-qubit quantum gate.","Mon, 5 Nov 2018 18:02:33 UTC (2,499 KB)"
"93","Active Deep Learning Attacks under Strict Rate Limitations for Online API Calls","Yi Shi, Yalin E. Sagduyu, Kemal Davaslioglu, Jason H. Li","Machine Learning (cs.LG); Cryptography and Security (cs.CR); Machine Learning (stat.ML)","Machine learning has been applied to a broad range of applications and some of them are available online as application programming interfaces (APIs) with either free (trial) or paid subscriptions. In this paper, we study adversarial machine learning in the form of back-box attacks on online classifier APIs. We start with a deep learning based exploratory (inference) attack, which aims to build a classifier that can provide similar classification results (labels) as the target classifier. To minimize the difference between the labels returned by the inferred classifier and the target classifier, we show that the deep learning based exploratory attack requires a large number of labeled training data samples. These labels can be collected by calling the online API, but usually there is some strict rate limitation on the number of allowed API calls. To mitigate the impact of limited training data, we develop an active learning approach that first builds a classifier based on a small number of API calls and uses this classifier to select samples to further collect their labels. Then, a new classifier is built using more training data samples. This updating process can be repeated multiple times. We show that this active learning approach can build an adversarial classifier with a small statistical difference from the target classifier using only a limited number of training data samples. We further consider evasion and causative (poisoning) attacks based on the inferred classifier that is built by the exploratory attack. Evasion attack determines samples that the target classifier is likely to misclassify, whereas causative attack provides erroneous training data samples to reduce the reliability of the re-trained classifier. The success of these attacks show that adversarial machine learning emerges as a feasible threat in the realistic case with limited training data.","Mon, 5 Nov 2018 15:50:30 UTC (250 KB)"
"94","A Biologically Plausible Learning Rule for Deep Learning in the Brain","Isabella Pozzi, Sander Bohte, Pieter Roelfsema","Neural and Evolutionary Computing (cs.NE)","Researchers have proposed that deep learning, which is providing important progress in a wide range of high complexity tasks, might inspire new insights into learning in the brain. However, the methods used for deep learning by artificial neural networks are biologically unrealistic and would need to be replaced by biologically realistic counterparts. Previous biologically plausible reinforcement learning rules, like AGREL and AuGMEnT, showed promising results but focused on shallow networks with three layers. Will these learning rules also generalize to networks with more layers and can they handle tasks of higher complexity? Here, we demonstrate that these learning schemes indeed generalize to deep networks, if we include an attention network that propagates information about the selected action to lower network levels. The resulting learning rule, called Q-AGREL, is equivalent to a particular form of error-backpropagation that trains one output unit at any one time. To demonstrate the utility of the learning scheme for larger problems, we trained networks with two hidden layers on the MNIST dataset, a standard and interesting Machine Learning task. Our results demonstrate that the capability of Q-AGREL is comparable to that of error backpropagation, although the learning rate is 1.5-2 times slower because the network has to learn by trial-and-error and updates the action value of only one output unit at a time. Our results provide new insights into how deep learning can be implemented in the brain.","Mon, 5 Nov 2018 15:01:59 UTC (514 KB)"
"95","Rethinking floating point for deep learning","Jeff Johnson","Numerical Analysis (cs.NA); Machine Learning (cs.LG)","Reducing hardware overhead of neural networks for faster or lower power inference and training is an active area of research. Uniform quantization using integer multiply-add has been thoroughly investigated, which requires learning many quantization parameters, fine-tuning training or other prerequisites. Little effort is made to improve floating point relative to this baseline; it remains energy inefficient, and word size reduction yields drastic loss in needed dynamic range. We improve floating point to be more energy efficient than equivalent bit width integer hardware on a 28 nm ASIC process while retaining accuracy in 8 bits with a novel hybrid log multiply/linear add, Kulisch accumulation and tapered encodings from Gustafson's posit format. With no network retraining, and drop-in replacement of all math and float32 parameters via round-to-nearest-even only, this open-sourced 8-bit log float is within 0.9% top-1 and 0.2% top-5 accuracy of the original float32 ResNet-50 CNN model on ImageNet. Unlike int8 quantization, it is still a general purpose floating point arithmetic, interpretable out-of-the-box. Our 8/38-bit log float multiply-add is synthesized and power profiled at 28 nm at 0.96x the power and 1.12x the area of 8/32-bit integer multiply-add. In 16 bits, our log float multiply-add is 0.59x the power and 0.68x the area of IEEE 754 float16 fused multiply-add, maintaining the same signficand precision and dynamic range, proving useful for training ASICs as well.","Thu, 1 Nov 2018 22:13:57 UTC (132 KB)"
"96","WaveFlow - Towards Integration of Ultrasound Processing with Deep Learning","Piotr Jarosik, Micha Byra, Marcin Lewandowski","Signal Processing (eess.SP)","The ultimate goal of this work is a real-time processing framework for ultrasound image reconstruction augmented with machine learning. To attain this, we have implemented WaveFlow - a set of ultrasound data acquisition and processing tools for TensorFlow. WaveFlow includes: ultrasound Environments (connection points between the input raw ultrasound data source and TensorFlow) and signal processing Operators (ops) library. Raw data can be processed in real-time using algorithms available both in TensorFlow and WaveFlow. Currently, WaveFlow provides ops for B-mode image reconstruction (beamforming), signal processing and quantitative ultrasound. The ops were implemented both for the CPU and GPU, as well as for built-in automated tests and benchmarks. To demonstrate WaveFlow's performance, ultrasound data were acquired from wire and cyst phantoms and elaborated using selected sequences of the ops. We implemented and evaluated: Delay-and-Sum beamformer, synthetic transmit aperture imaging (STAI), plane-wave imaging (PWI), envelope detection algorithm and dynamic range clipping. The benchmarks were executed on the NVidia Titan X GPU integrated in the USPlatform research scanner (us4us Ltd., Poland). We achieved B-mode image reconstruction frame rates of 55 fps, 17 fps for the STAI and the PWI algorithms, respectively. The results showed the feasibility of real-time ultrasound image reconstruction using WaveFlow operators in the TensorFlow framework. WaveFlow source code can be found at github.com/waveflow-team/waveflow","Mon, 5 Nov 2018 09:28:13 UTC (6 KB)"
"97","DSIC: Deep Learning based Self-Interference Cancellation for In-Band Full Duplex Wireless","Hanqing Guo, Nan Zhang, Saeed AlQarni, Shaoen Wu","Networking and Internet Architecture (cs.NI); Information Theory (cs.IT)","In-band full duplex wireless is of utmost interest to future wireless communication and networking due to great potentials of spectrum efficiency. IBFD wireless, however, is throttled by its key challenge, namely self-interference. Therefore, effective self-interference cancellation is the key to enable IBFD wireless. This paper proposes a real-time non-linear self-interference cancellation solution based on deep learning. In this solution, a self-interference channel is modeled by a deep neural network (DNN). Synchronized self-interference channel data is first collected to train the DNN of the self-interference channel. Afterwards, the trained DNN is used to cancel the self-interference at a wireless node. This solution has been implemented on a USRP SDR testbed and evaluated in real world in multiple scenarios with various modulations in transmitting information including numbers, texts as well as images. It results in the performance of 17dB in digital cancellation, which is very close to the self-interference power and nearly cancels the self-interference at a SDR node in the testbed. The solution yields an average of 8.5% bit error rate (BER) over many scenarios and different modulation schemes.","Mon, 5 Nov 2018 03:16:24 UTC (2,793 KB)"
"98","Underwater Fish Detection using Deep Learning for Water Power Applications","Wenwei Xu, Shari Matzner","Computer Vision and Pattern Recognition (cs.CV)","Clean energy from oceans and rivers is becoming a reality with the development of new technologies like tidal and instream turbines that generate electricity from naturally flowing water. These new technologies are being monitored for effects on fish and other wildlife using underwater video. Methods for automated analysis of underwater video are needed to lower the costs of analysis and improve accuracy. A deep learning model, YOLO, was trained to recognize fish in underwater video using three very different datasets recorded at real-world water power sites. Training and testing with examples from all three datasets resulted in a mean average precision (mAP) score of 0.5392. To test how well a model could generalize to new datasets, the model was trained using examples from only two of the datasets and then tested on examples from all three datasets. The resulting model could not recognize fish in the dataset that was not part of the training set. The mAP scores on the other two datasets that were included in the training set were higher than the scores achieved by the model trained on all three datasets. These results indicate that different methods are needed in order to produce a trained model that can generalize to new data sets such as those encountered in real world applications.","Mon, 5 Nov 2018 02:58:09 UTC (621 KB)"
"99","Auto-ML Deep Learning for Rashi Scripts OCR","Shahar Mahpod, Yosi Keller","Computer Vision and Pattern Recognition (cs.CV)","In this work we propose an OCR scheme for manuscripts printed in Rashi font that is an ancient Hebrew font and corresponding dialect used in religious Jewish literature, for more than 600 years. The proposed scheme utilizes a convolution neural network (CNN) for visual inference and Long-Short Term Memory (LSTM) to learn the Rashi scripts dialect. In particular, we derive an AutoML scheme to optimize the CNN architecture, and a book-specific CNN training to improve the OCR accuracy. The proposed scheme achieved an accuracy of more than 99.8% using a dataset of more than 3M annotated letters from the Responsa Project dataset.","Sat, 3 Nov 2018 21:53:47 UTC (2,107 KB)"
"100","Deep Learning based Computer-Aided Diagnosis Systems for Diabetic Retinopathy: A Survey","Norah Asiri, Muhammad Hussain, Hatim A. Abualsamh","Computer Vision and Pattern Recognition (cs.CV)","The outstanding performance of deep learning in various computer vision tasks motivated its application for medical image analysis, in particular, retinal fundus image analysis. It has been applied to a variety of tasks including diagnosis, detection and segmentation of pathologies in retinal fundus images. Many deep learning based techniques have been proposed to analyze retinal fundus images for automatic detection and diagnosis of macular degeneration and diabetic retinopathy. The automatic detection of diabetic retinopathy has the potential to prevent cases of vision loss and blindness by boosting the examination of diabetic patients. We carried out a comprehensive study of the latest deep learning techniques and their use in fundus image analysis. This paper presents the key concepts of deep learning relevant to diabetic retinopathy images analysis and reviews the latest deep learning based contributions in this area. We conclude the paper with a summary of the state-of-the-art, a critical discussion of open challenges and directions for future research.","Sat, 3 Nov 2018 15:58:57 UTC (1,621 KB)"
"101","Deep learning-based fully automatic segmentation of wrist cartilage in MR images","Ekaterina Brui, Aleksandr Y. Efimtcev, Vladimir A. Fokin, Remi Fernandez, Anatoliy G. Levchuk, Augustin C. Ogier, Irina V. Melchakova, David Bendahan, Anna Andreychenko","Medical Physics (physics.med-ph)","The objective of this study is to develop, test and validate a fully automatic, deep learning-based segmentation method for the wrist joint cartilage in magnetic resonance images. The study was conducted in 8 healthy volunteers and 3 patients with wrist joint diseases. 3D MRI datasets (20 in total) were acquired at 1.5T using a VIBE sequence. Wrist cartilage was segmented on coronal slices by a clinician and the convolutional neural network (CNN) was trained, developed and tested using the corresponding segmented masks. For an inter- and intra-observer study wrist cartilage was segmented by three observers once and twice by one observer on a dataset of 20 central coronal slices. Performance of the CNN was compared quantitatively to the manual segmentations using the concordance and the Sorensen-Dice similarity coefficients (DSC). Cartilage segmentations obtained with the CNN showed a substantial agreement with the manual segmentations for the whole wrist joint (DSC - 0.73) and a good agreement (DSC - 0.81) for the central coronal slices. The inter- and intra-observer concordance indices for manual segmentations were 0.55 and 0.85, respectively. The concordance index of the CNN-based segmentation was 0.69 when compared to the manual segmentations. The fully automatic deep-learning based segmentation of the wrist cartilage showed a high concordance with the manual measurements. It could be applied to determine an automatic, quantitative metric in clinical wrist cartilage studies.","Fri, 2 Nov 2018 23:18:17 UTC (598 KB)[v2] Mon, 19 Nov 2018 08:43:49 UTC (598 KB)"
"102","Topological Approaches to Deep Learning","Gunnar Carlsson, Rickard Bruel Gabrielsson","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Algebraic Topology (math.AT); Machine Learning (stat.ML)","We perform topological data analysis on the internal states of convolutional deep neural networks to develop an understanding of the computations that they perform. We apply this understanding to modify the computations so as to (a) speed up computations and (b) improve generalization from one data set of digits to another. One byproduct of the analysis is the production of a geometry on new sets of features on data sets of images, and use this observation to develop a methodology for constructing analogues of CNN's for many other geometries, including the graph structures constructed by topological data analysis.","Fri, 2 Nov 2018 23:18:03 UTC (2,341 KB)"
"103","What evidence does deep learning model use to classify Skin Lesions?","Junyan Wu, Xiaoxiao Li, Eric Z. Chen, Hongda Jiang, Xu Dong, Ruichen Rong","Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)","Melanoma is a type of skin cancer with the most rapidly increasing incidence. Early detection of melanoma using dermoscopy images significantly increases patients' survival rate. However, accurately classifying skin lesions, especially in the early stage, is extremely challenging via dermatologists' observation. Hence, the discovery of reliable biomarkers for melanoma diagnosis will be meaningful. Recent years, deep learning empowered computer-assisted diagnosis has been shown its value in medical imaging-based decision making. However, lots of research focus on improving disease detection accuracy but not exploring the evidence of pathology. In this paper, we propose a method to interpret the deep learning classification findings. Firstly, we propose an accurate neural network architecture to classify skin lesion. Secondly, we utilize a prediction difference analysis method that examining each patch on the image through patch wised corrupting for detecting the biomarkers. Lastly, we validate that our biomarker findings are corresponding to the patterns in the literature. The findings might be significant to guide clinical diagnosis.","Fri, 2 Nov 2018 18:57:50 UTC (4,824 KB)"
"104","One-Bit OFDM Receivers via Deep Learning","Eren Balevi, Jeffrey G. Andrews","Information Theory (cs.IT); Machine Learning (cs.LG); Signal Processing (eess.SP); Machine Learning (stat.ML)","This paper develops novel deep learning-based architectures and design methodologies for an orthogonal frequency division multiplexing (OFDM) receiver under the constraint of one-bit complex quantization. Single bit quantization greatly reduces complexity and power consumption, but makes accurate channel estimation and data detection difficult. This is particularly true for multicarrier waveforms, which have high peak-to-average ratio in the time domain and fragile subcarrier orthogonality in the frequency domain. The severe distortion for one-bit quantization typically results in an error floor even at moderately low signal-to-noise-ratio (SNR) such as 5 dB. For channel estimation (using pilots), we design a novel generative supervised deep neural network (DNN) that can be trained with a reasonable number of pilots. After channel estimation, a neural network-based receiver -- specifically, an autoencoder -- jointly learns a precoder and decoder for data symbol detection. Since quantization prevents end-to-end training, we propose a two-step sequential training policy for this model. With synthetic data, our deep learning-based channel estimation can outperform least squares (LS) channel estimation for unquantized (full-resolution) OFDM at average SNRs up to 14 dB. For data detection, our proposed design achieves lower bit error rate (BER) in fading than unquantized OFDM at average SNRs up to 10 dB.","Fri, 2 Nov 2018 16:36:25 UTC (765 KB)"
"105","Frequentist uncertainty estimates for deep learning","Natasa Tagasovska, David Lopez-Paz","Machine Learning (stat.ML); Machine Learning (cs.LG)","We provide frequentist estimates of aleatoric and epistemic uncertainty for deep neural networks. To estimate aleatoric uncertainty we propose simultaneous quantile regression, a loss function to learn all the conditional quantiles of a given target variable. These quantiles lead to well-calibrated prediction intervals. To estimate epistemic uncertainty we propose training certificates, a collection of diverse non-trivial functions that map all training samples to zero. These certificates map out-of-distribution examples to non-zero values, signaling high epistemic uncertainty. We compare our proposals to prior art in various experiments.","Fri, 2 Nov 2018 14:55:07 UTC (579 KB)"
"106","How the fundamental concepts of mathematics and physics explain deep learning","Jean Thierry-Mieg","Machine Learning (cs.LG); High Energy Physics - Theory (hep-th); Machine Learning (stat.ML)","Starting from the Fermat's principle of least action, which governs classical and quantum mechanics and from the theory of exterior differential forms, which governs the geometry of curved manifolds, we show how to derive the equations governing neural networks in an intrinsic, coordinate invariant way, where the differential dW of the parameters W appears as the cotangent pullback of the differential of the loss function L: dW = -eta f*(dL) where f denotes the action of the network, and eta the learning rate. To be covariant, these equations imply a layer metric which is instrumental in pretraining and explains the role of conjugation when using complex numbers. The differential formalism also clarifies the relation of the gradient descent optimizer with Aristotelian and Newtonian mechanics and why large learning steps break the logic of the linearization procedure. We hope that this formal presentation of the differential geometry of neural networks will encourage some physicists to dive into deep learning, and reciprocally, that the specialists of deep learning will better appreciate the close interconnection of their subject with the foundations of classical and quantum field theory.","Thu, 1 Nov 2018 18:21:42 UTC (14 KB)"
"107","Deep Learning Based Gait Recognition Using Smartphones in the Wild","Qin Zou, Yanling Wang, Yi Zhao, Qian Wang, Chao Shen, Qingquan Li","Machine Learning (cs.LG); Signal Processing (eess.SP); Machine Learning (stat.ML)","Comparing with other biometrics, gait has advantages of being unobtrusive and difficult to conceal. Inertial sensors such as accelerometer and gyroscope are often used to capture gait dynamics. Nowadays, these inertial sensors have commonly been integrated in smartphones and widely used by average person, which makes it very convenient and inexpensive to collect gait data. In this paper, we study gait recognition using smartphones in the wild. Unlike traditional methods that often require the person to walk along a specified road and/or at a normal walking speed, the proposed method collects inertial gait data under a condition of unconstraint without knowing when, where, and how the user walks. To obtain a high performance of person identification and authentication, deep-learning techniques are presented to learn and model the gait biometrics from the walking data. Specifically, a hybrid deep neural network is proposed for robust gait feature representation, where features in the space domain and in the time domain are successively abstracted by a convolutional neural network and a recurrent neural network. In the experiments, two datasets collected by smartphones on a total of 118 subjects are used for evaluations. Experiments show that the proposed method achieves over 93.5% and 93.7% accuracy in person identification and authentication, respectively.","Thu, 1 Nov 2018 12:20:37 UTC (1,115 KB)"
"108","Deep Learning for Tube Amplifier Emulation","Eero-Pekka Damskagg, Lauri Juvela, Etienne Thuillier, Vesa Valimaki","Audio and Speech Processing (eess.AS); Sound (cs.SD)","Analog audio effects and synthesizers often owe their distinct sound to circuit nonlinearities. Faithfully modeling such significant aspect of the original sound in virtual analog software can prove challenging. The current work proposes a generic data-driven approach to virtual analog modeling and applies it to the Fender Bassman 56F-A vacuum-tube amplifier. Specifically, a feedforward variant of the WaveNet deep neural network is trained to carry out a regression on audio waveform samples from input to output of a SPICE model of the tube amplifier. The output signals are pre-emphasized to assist the model at learning the high-frequency content. The results of a listening test suggest that the proposed model accurately emulates the reference device. In particular, the model responds to user control changes, and faithfully restitutes the range of sonic characteristics found across the configurations of the original device.","Thu, 1 Nov 2018 12:03:03 UTC (223 KB)"
"109","Applications of Deep Learning to Nuclear Fusion Research","Diogo R. Ferreira (on behalf of JET Contributors)","Plasma Physics (physics.plasm-ph); Machine Learning (cs.LG)","Nuclear fusion is the process that powers the sun, and it is one of the best hopes to achieve a virtually unlimited energy source for the future of humanity. However, reproducing sustainable nuclear fusion reactions here on Earth is a tremendous scientific and technical challenge. Special devices -- called tokamaks -- have been built around the world, with JET (Joint European Torus, in the UK) being the largest tokamak currently in operation. Such devices confine matter and heat it up to extremely high temperatures, creating a plasma where fusion reactions begin to occur. JET has over one hundred diagnostic systems to monitor what happens inside the plasma, and each 30-second experiment (or pulse) generates about 50 GB of data. In this work, we show how convolutional neural networks (CNNs) can be used to reconstruct the 2D plasma profile inside the device based on data coming from those diagnostics. We also discuss how recurrent neural networks (RNNs) can be used to predict plasma disruptions, which are one of the major problems affecting tokamaks today. Training of such networks is done on NVIDIA GPUs.","Thu, 1 Nov 2018 11:58:59 UTC (1,191 KB)"
"110","Democratizing Production-Scale Distributed Deep Learning","Minghuang Ma, Hadi Pouransari, Daniel Chao, Saurabh Adya, Santiago Akle Serrano, Yi Qin, Dan Gimnicher, Dominic Walsh","Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","The interest and demand for training deep neural networks have been experiencing rapid growth, spanning a wide range of applications in both academia and industry. However, training them distributed and at scale remains difficult due to the complex ecosystem of tools and hardware involved. One consequence is that the responsibility of orchestrating these complex components is often left to one-off scripts and glue code customized for specific problems. To address these restrictions, we introduce \emph{Alchemist} - an internal service built at Apple from the ground up for \emph{easy}, \emph{fast}, and \emph{scalable} distributed training. We discuss its design, implementation, and examples of running different flavors of distributed training. We also present case studies of its internal adoption in the development of autonomous systems, where training times have been reduced by 10x to keep up with the ever-growing data collection.","Wed, 31 Oct 2018 22:39:59 UTC (1,093 KB)[v2] Sat, 3 Nov 2018 05:47:41 UTC (1,092 KB)"
"111","Face Recognition: From Traditional to Deep Learning Methods","Daniel Saez Trigueros, Li Meng, Margaret Hartnett","Computer Vision and Pattern Recognition (cs.CV)","Starting in the seventies, face recognition has become one of the most researched topics in computer vision and biometrics. Traditional methods based on hand-crafted features and traditional machine learning techniques have recently been superseded by deep neural networks trained with very large datasets. In this paper we provide a comprehensive and up-to-date literature review of popular face recognition methods including both traditional (geometry-based, holistic, feature-based and hybrid methods) and deep learning methods.","Wed, 31 Oct 2018 20:58:39 UTC (1,280 KB)"
"112","Scientific Domain Knowledge Improves Exoplanet Transit Classification with Deep Learning","Megan Ansdell, Yani Ioannou, Hugh P. Osborn, Michele Sasdelli, Jeffrey C. Smith, Jon M. Jenkins, Chedy Raissi, Daniel Angerhausen","Earth and Planetary Astrophysics (astro-ph.EP)","Space-based missions such as Kepler, and soon TESS, provide large datasets that must be analyzed efficiently and systematically. Recent work by Shallue & Vanderburg (2018) successfully used state-of-the-art deep learning models to automatically classify Kepler transit signals as either exoplanets or false positives; our application of their model yielded 95.8% accuracy and 95.5% average precision. Here we expand upon that work by including additional scientific domain knowledge into the network architecture and input representations to significantly increase overall model performance to 97.5% accuracy and 98.0% average precision. Notably, we achieve 15-20% gains in recall for the lowest signal-to-noise transits that can correspond to rocky planets in the habitable zone. We input into the network centroid time-series information derived from Kepler data plus key stellar parameters taken from the Kepler DR25 catalogue. We also implement data augmentation techniques to alleviate model over-fitting. These improvements allow us to drastically reduce the size of the model, while still maintaining improved performance; smaller models are better for generalization, for example from Kepler to TESS data. This work illustrates the importance of including expert domain knowledge in even state-of-the-art deep learning models when applying them to scientific research problems that seek to identify weak signals in noisy data. This classification tool will be especially useful for upcoming space-based photometry missions focused on finding small planets, such as TESS and PLATO.","Wed, 31 Oct 2018 17:50:38 UTC (305 KB)[v2] Mon, 12 Nov 2018 05:34:39 UTC (430 KB)[v3] Wed, 21 Nov 2018 16:54:57 UTC (430 KB)"
"113","Performance assessment of the deep learning technologies in grading glaucoma severity","Yi Zhen, Lei Wang, Han Liu, Jian Zhang, Jiantao Pu","Computer Vision and Pattern Recognition (cs.CV)","Objective: To validate and compare the performance of eight available deep learning architectures in grading the severity of glaucoma based on color fundus images. Materials and Methods: We retrospectively collected a dataset of 5978 fundus images and their glaucoma severities were annotated by the consensus of two experienced ophthalmologists. We preprocessed the images to generate global and local regions of interest (ROIs), namely the global field-of-view images and the local disc region images. We then divided the generated images into three independent sub-groups for training, validation, and testing purposes. With the datasets, eight convolutional neural networks (CNNs) (i.e., VGG16, VGG19, ResNet, DenseNet, InceptionV3, InceptionResNet, Xception, and NASNetMobile) were trained separately to grade glaucoma severity, and validated quantitatively using the area under the receiver operating characteristic (ROC) curve and the quadratic kappa score. Results: The CNNs, except VGG16 and VGG19, achieved average kappa scores of 80.36% and 78.22% when trained from scratch on global and local ROIs, and 85.29% and 82.72% when fine-tuned using the pre-trained weights, respectively. VGG16 and VGG19 achieved reasonable accuracy when trained from scratch, but they failed when using pre-trained weights for global and local ROIs. Among these CNNs, the DenseNet had the highest classification accuracy (i.e., 75.50%) based on pre-trained weights when using global ROIs, as compared to 65.50% when using local ROIs. Conclusion: The experiments demonstrated the feasibility of the deep learning technology in grading glaucoma severity. In particular, global field-of-view images contain relatively richer information that may be critical for glaucoma assessment, suggesting that we should use the entire field-of-view of a fundus image for training a deep learning network.","Wed, 31 Oct 2018 16:12:30 UTC (345 KB)"
"114","SUNet: a deep learning architecture for acute stroke lesion segmentation and outcome prediction in multimodal MRI","Albert Clerigues, Sergi Valverde, Jose Bernal, Jordi Freixenet, Arnau Oliver, Xavier Llado","Computer Vision and Pattern Recognition (cs.CV)","Acute stroke lesion segmentation and prediction tasks are of great clinical interest as they can help doctors make better informed time-critical treatment decisions. Automatic segmentation of these lesions is a complex task due to their heterogeneous appearance, dynamic evolution and inter-patient differences. Typically, acute stroke lesion tasks are approached with methods developed for chronic stroke or other brain lesions. However, the pathophysiology and anatomy of acute stroke establishes an inherently different problem that needs special consideration. In this work, we propose a novel deep learning architecture specially designed for acute stroke tasks that involve approximating complex non-linear functions with reduced data. Within our strategy, class imbalance is tackled using a hybrid strategy based on state-of-the-art train sampling strategies designed for other brain lesion related tasks, which is more suited to the anatomy and pathophysiology of acute stroke lesions. The proposed method is evaluated on three unrelated public international challenge datasets (ISLES) without any dataset specific hyper-parameter tuning. These involve the tasks of sub-acute stroke lesion segmentation, acute stroke penumbra estimation and chronic extent prediction from acute MR images. The performance of the proposed architecture is analysed both against similar deep learning architectures from chronic stroke and related biomedical tasks and also by submitting the segmented test images for blind online evaluation on each of the challenges. When compared with the rest of submitted strategies, our method achieves top-rank performance among the best submitted entries in all the three challenges, showing its capability to deal with different unrelated tasks without hyper-parameter tuning. In order to promote the reproducibility of our results, a public version of the proposed method has been released.","Wed, 31 Oct 2018 14:34:39 UTC (883 KB)"
"115","The Medico-Task 2018: Disease Detection in the Gastrointestinal Tract using Global Features and Deep Learning","Vajira Thambawita, Debesh Jha, Michael Riegler, Pal Halvorsen, Hugo Lewi Hammer, Havard D. Johansen, Dag Johansen","Machine Learning (cs.LG); Machine Learning (stat.ML)","In this paper, we present our approach for the 2018 Medico Task classifying diseases in the gastrointestinal tract. We have proposed a system based on global features and deep neural networks. The best approach combines two neural networks, and the reproducible experimental results signify the efficiency of the proposed model with an accuracy rate of 95.80%, a precision of 95.87%, and an F1-score of 95.80%.","Wed, 31 Oct 2018 13:35:23 UTC (58 KB)"
"116","Application of Deep Learning on Predicting Prognosis of Acute Myeloid Leukemia with Cytogenetics, Age, and Mutations","Mei Lin, Vanya Jaitly, Iris Wang, Zhihong Hu, Lei Chen, Md. Amer Wahed, Zeyad Kanaan, Adan Rios, Andy N.D. Nguyen","Machine Learning (cs.LG); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)","We explore how Deep Learning (DL) can be utilized to predict prognosis of acute myeloid leukemia (AML). Out of TCGA (The Cancer Genome Atlas) database, 94 AML cases are used in this study. Input data include age, 10 common cytogenetic and 23 most common mutation results; output is the prognosis (diagnosis to death, DTD). In our DL network, autoencoders are stacked to form a hierarchical DL model from which raw data are compressed and organized and high-level features are extracted. The network is written in R language and is designed to predict prognosis of AML for a given case (DTD of more than or less than 730 days). The DL network achieves an excellent accuracy of 83% in predicting prognosis. As a proof-of-concept study, our preliminary results demonstrate a practical application of DL in future practice of prognostic prediction using next-gen sequencing (NGS) data.","Tue, 30 Oct 2018 15:03:35 UTC (349 KB)"
"117","A Closer Look at Deep Learning Heuristics: Learning rate restarts, Warmup and Distillation","Akhilesh Gotmare, Nitish Shirish Keskar, Caiming Xiong, Richard Socher","Machine Learning (cs.LG); Machine Learning (stat.ML)","The convergence rate and final performance of common deep learning models have significantly benefited from heuristics such as learning rate schedules, knowledge distillation, skip connections, and normalization layers. In the absence of theoretical underpinnings, controlled experiments aimed at explaining these strategies can aid our understanding of deep learning landscapes and the training dynamics. Existing approaches for empirical analysis rely on tools of linear interpolation and visualizations with dimensionality reduction, each with their limitations. Instead, we revisit such analysis of heuristics through the lens of recently proposed methods for loss surface and representation analysis, viz., mode connectivity and canonical correlation analysis (CCA), and hypothesize reasons for the success of the heuristics. In particular, we explore knowledge distillation and learning rate heuristics of (cosine) restarts and warmup using mode connectivity and CCA. Our empirical analysis suggests that: (a) the reasons often quoted for the success of cosine annealing are not evidenced in practice; (b) that the effect of learning rate warmup is to prevent the deeper layers from creating training instability; and (c) that the latent knowledge shared by the teacher is primarily disbursed to the deeper layers.","Mon, 29 Oct 2018 19:36:07 UTC (2,335 KB)"
"118","Reinforcement Learning and Deep Learning based Lateral Control for Autonomous Driving","Dong Li, Dongbin Zhao, Qichao Zhang, Yaran Chen","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)","This paper investigates the vision-based autonomous driving with deep learning and reinforcement learning methods. Different from the end-to-end learning method, our method breaks the vision-based lateral control system down into a perception module and a control module. The perception module which is based on a multi-task learning neural network first takes a driver-view image as its input and predicts the track features. The control module which is based on reinforcement learning then makes a control decision based on these features. In order to improve the data efficiency, we propose visual TORCS (VTORCS), a deep reinforcement learning environment which is based on the open racing car simulator (TORCS). By means of the provided functions, one can train an agent with the input of an image or various physical sensor measurement, or evaluate the perception algorithm on this simulator. The trained reinforcement learning controller outperforms the linear quadratic regulator (LQR) controller and model predictive control (MPC) controller on different tracks. The experiments demonstrate that the perception module shows promising performance and the controller is capable of controlling the vehicle drive well along the track center with visual input.","Tue, 30 Oct 2018 14:43:36 UTC (1,568 KB)"
"119","Deep Learning for the Gaussian Wiretap Channel","Rick Fritschek, Rafael F. Schaefer, Gerhard Wunder","Information Theory (cs.IT)","End-to-end learning of communication systems with neural networks and particularly autoencoders is an emerging research direction which gained popularity in the last year. In this approach, neural networks learn to simultaneously optimize encoding and decoding functions to establish reliable message transmission. In this paper, this line of thinking is extended to communication scenarios in which an eavesdropper must further be kept ignorant about the communication. The secrecy of the transmission is achieved by utilizing a modified secure loss function based on cross-entropy which can be implemented with state-of-the-art machine-learning libraries. This secure loss function approach is applied in a Gaussian wiretap channel setup, for which it is shown that the neural network learns a trade-off between reliable communication and information secrecy by clustering learned constellations. As a result, an eavesdropper with higher noise cannot distinguish between the symbols anymore.","Tue, 30 Oct 2018 11:10:28 UTC (181 KB)"
"120","Deep Learning as Feature Encoding for Emotion Recognition","Bhalaji Nagarajan, V Ramana Murthy Oruganti","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning is popular as an end-to-end framework extracting the prominent features and performing the classification also. In this paper, we extensively investigate deep networks as an alternate to feature encoding technique of low level descriptors for emotion recognition on the benchmark EmoDB dataset. Fusion performance with such obtained encoded features with other available features is also investigated. Highest performance to date in the literature is observed.","Tue, 30 Oct 2018 09:53:28 UTC (803 KB)[v2] Wed, 14 Nov 2018 10:57:31 UTC (0 KB)"
"121","Multi-label Multi-task Deep Learning for Behavioral Coding","James Gibson, David C. Atkins, Torrey Creed, Zac Imel, Panayiotis Georgiou, Shrikanth Narayanan","Computation and Language (cs.CL)","We propose a methodology for estimating human behaviors in psychotherapy sessions using mutli-label and multi-task learning paradigms. We discuss the problem of behavioral coding in which data of human interactions is the annotated with labels to describe relevant human behaviors of interest. We describe two related, yet distinct, corpora consisting of therapist client interactions in psychotherapy sessions. We experimentally compare the proposed learning approaches for estimating behaviors of interest in these datasets. Specifically, we compare single and multiple label learning approaches, single and multiple task learning approaches, and evaluate the performance of these approaches when incorporating turn context. We demonstrate the prediction performance gains which can be achieved by using the proposed paradigms and discuss the insights these models provide into these complex interactions.","Mon, 29 Oct 2018 18:57:30 UTC (2,871 KB)[v2] Mon, 5 Nov 2018 23:25:33 UTC (2,872 KB)"
"122","Content Selection in Deep Learning Models of Summarization","Chris Kedzie, Kathleen McKeown, Hal Daume III","Computation and Language (cs.CL)","We carry out experiments with deep learning models of summarization across the domains of news, personal stories, meetings, and medical articles in order to understand how content selection is performed. We find that many sophisticated features of state of the art extractive summarizers do not improve performance over simpler models. These results suggest that it is easier to create a summarizer for a new domain than previous work suggests and bring into question the benefit of deep learning models for summarization for those domains that do have massive datasets (i.e., news). At the same time, they suggest important questions for new research in summarization; namely, new forms of sentence representations or external knowledge sources are needed that are better suited to the summarization task.","Mon, 29 Oct 2018 18:42:46 UTC (289 KB)"
"123","Prediction of Discretization of GMsFEM using Deep Learning","Min Wang, Siu Wun Cheung, Eric T. Chung, Yalchin Efendiev, Wing Tat Leung, Yating Wang","Numerical Analysis (math.NA)","In this paper, we propose a deep-learning-based approach to a class of multiscale problems. THe Generalized Multiscale Finite Element Method (GMsFEM) has been proven successful as a model reduction technique of flow problems in heterogeneous and high-contrast porous media. The key ingredients of GMsFEM include mutlsicale basis functions and coarse-scale parameters, which are obtained from solving local problems in each coarse neighborhood. Given a fixed medium, these quantities are precomputed by solving local problems in an offline stage, and result in a reduced-order model. However, these quantities have to be re-computed in case of varying media. The objective of our work is to make use of deep learning techniques to mimic the nonlinear relation between the permeability field and the GMsFEM discretizations, and use neural networks to perform fast computation of GMsFEM ingredients repeatedly for a class of media. We provide numerical experiments to investigate the predictive power of neural networks and the usefulness of the resultant multiscale model in solving channelized porous media flow problems.","Mon, 29 Oct 2018 16:45:39 UTC (5,443 KB)"
"124","A Comparative Measurement Study of Deep Learning as a Service Framework","Yanzhao Wu, Ling Liu, Calton Pu, Wenqi Cao, Semih Sahin, Wenqi Wei, Qi Zhang","Performance (cs.PF); Machine Learning (cs.LG)","Big data powered Deep Learning (DL) and its applications have blossomed in recent years, fueled by three technological trends: a large amount of digitized data openly accessible, a growing number of DL software frameworks in open source and commercial markets, and a selection of affordable parallel computing hardware devices. However, no single DL framework, to date, dominates in terms of performance and accuracy even for baseline classification tasks on standard datasets, making the selection of a DL framework an overwhelming task. This paper takes a holistic approach to conduct empirical comparison and analysis of four representative DL frameworks with three unique contributions. First, given a selection of CPU-GPU configurations, we show that for a specific DL framework, different configurations of its hyper-parameters may have significant impact on both performance and accuracy of DL applications. Second, the optimal configuration of hyper-parameters for one DL framework (e.g., TensorFlow) often does not work well for another DL framework (e.g., Caffe or Torch) under the same CPU-GPU runtime environment. Third, we also conduct a comparative measurement study on the resource consumption patterns of four DL frameworks and their performance and accuracy implications, including CPU and memory usage, and their correlations to varying settings of hyper-parameters under different configuration combinations of hardware, parallel computing libraries. We argue that this measurement study provides in-depth empirical comparison and analysis of four representative DL frameworks, and offers practical guidance for service providers to deploying and delivering DL as a Service (DLaaS) and for application developers and DLaaS consumers to select the right DL frameworks for the right DL workloads.","Mon, 29 Oct 2018 16:03:41 UTC (2,015 KB)"
"125","Deep learning long-range information in undirected graphs with wave networks","Matthew K. Matlock, Arghya Datta, Na Le Dang, Kevin Jiang, S. Joshua Swamidass","Machine Learning (cs.LG); Machine Learning (stat.ML)","Graph algorithms are key tools in many fields of science and technology. Some of these algorithms depend on propagating information between distant nodes in a graph. Recently, there have been a number of deep learning architectures proposed to learn on undirected graphs. However, most of these architectures aggregate information in the local neighborhood of a node, and therefore they may not be capable of efficiently propagating long-range information. To solve this problem we examine a recently proposed architecture, wave, which propagates information back and forth across an undirected graph in waves of nonlinear computation. We compare wave to graph convolution, an architecture based on local aggregation, and find that wave learns three different graph-based tasks with greater efficiency and accuracy. These three tasks include (1) labeling a path connecting two nodes in a graph, (2) solving a maze presented as an image, and (3) computing voltages in a circuit. These tasks range from trivial to very difficult, but wave can extrapolate from small training examples to much larger testing examples. These results show that wave may be able to efficiently solve a wide range of problems that require long-range information propagation across undirected graphs. An implementation of the wave network, and example code for the maze problem are included in the tflon deep learning toolkit (this https URL).","Mon, 29 Oct 2018 14:35:40 UTC (1,544 KB)"
"126","Ruuh: A Deep Learning Based Conversational Social Agent","Sonam Damani, Nitya Raviprakash, Umang Gupta, Ankush Chatterjee, Meghana Joshi, Khyatti Gupta, Kedhar Nath Narahari, Puneet Agrawal, Manoj Kumar Chinnakotla, Sneha Magapu, Abhishek Mathur","Computation and Language (cs.CL)","Dialogue systems and conversational agents are becoming increasingly popular in the modern society but building an agent capable of holding intelligent conversation with its users is a challenging problem for artificial intelligence. In this demo, we demonstrate a deep learning based conversational social agent called ""Ruuh"" (facebook.com/Ruuh) designed by a team at Microsoft India to converse on a wide range of topics. Ruuh needs to think beyond the utilitarian notion of merely generating ""relevant"" responses and meet a wider range of user social needs, like expressing happiness when user's favorite team wins, sharing a cute comment on showing the pictures of the user's pet and so on. The agent also needs to detect and respond to abusive language, sensitive topics and trolling behavior of the users. Many of these problems pose significant research challenges which will be demonstrated in our demo. Our agent has interacted with over 2 million real world users till date which has generated over 150 million user conversations.","Mon, 22 Oct 2018 14:26:13 UTC (373 KB)"
"127","Software Engineering Challenges of Deep Learning","Anders Arpteg, Bjorn Brinne, Luka Crnkovic-Friis, Jan Bosch","Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","Surprisingly promising results have been achieved by deep learning (DL) systems in recent years. Many of these achievements have been reached in academic settings, or by large technology companies with highly skilled research groups and advanced supporting infrastructure. For companies without large research groups or advanced infrastructure, building high-quality production-ready systems with DL components has proven challenging. There is a clear lack of well-functioning tools and best practices for building DL systems. It is the goal of this research to identify what the main challenges are, by applying an interpretive research approach in close collaboration with companies of varying size and type. A set of seven projects have been selected to describe the potential with this new technology and to identify associated main challenges. A set of 12 main challenges has been identified and categorized into the three areas of development, production, and organizational challenges. Furthermore, a mapping between the challenges and the projects is defined, together with selected motivating descriptions of how and why the challenges apply to specific projects. Compared to other areas such as software engineering or database technologies, it is clear that DL is still rather immature and in need of further work to facilitate development of high-quality systems. The challenges identified in this paper can be used to guide future research by the software engineering and DL communities. Together, we could enable a large number of companies to start taking advantage of the high potential of the DL technology.","Mon, 29 Oct 2018 10:05:37 UTC (23 KB)"
"128","Deep learning tutorial for denoising","Siwei Yu, Jianwei Ma, Wenlong Wang","Geophysics (physics.geo-ph); Machine Learning (cs.LG); Signal Processing (eess.SP)","We herein introduce deep learning to seismic noise attenuation. Compared with traditional seismic noise attenuation algorithms that depend on signal models and their corresponding prior assumptions, a deep neural network is trained based on a large training set, where the inputs are the raw datasets and the corresponding outputs are the desired clean data. After the completion of training, the deep learning method achieves adaptive denoising with no requirements of (i) accurate modeling of the signal and noise, and (ii) optimal parameters tuning. We call this intelligent denoising. We use a convolutional neural network as the basic tool for deep learning. The training set is generated with manually added noise in random and linear noise attenuation, and with the wave equation in the multiple attenuation. Stochastic gradient descent is used to solve the optimal parameters for the convolutional neural network. The runtime of deep learning on a graphics processing unit for denoising has the same order as the $f-x$ deconvolutional method. Synthetic and field results show the potential applications of deep learning in the automation of random noise attenuation with unknown variance, linear noise, and multiples.","Sat, 27 Oct 2018 07:39:09 UTC (7,330 KB)"
"129","Deep learning based 2.5D flow field estimation for maximum intensity projections of 4D optical coherence tomography","Max-Heinrich Laves, Luder A. Kahrs, Tobias Ortmaier","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","In laser microsurgery, image-based control of the ablation laser can lead to higher accuracy and patient safety. However, camera-based image acquisition lacks the subcutaneous tissue perception. Optical coherence tomography (OCT) as high-resolution imaging modality yields transsectional images of tissue and can provide the missing depth information. Therefore, this paper deals with the tracking of distinctive subcutaneous structures on OCTs for automated control of ablation lasers in microsurgery. We present a deep learning based tracking scheme for concise representations of subsequent 3D OCT volumes. For each of the volume, a compact representation is created by calculating maximum intensity projections and projecting the depth value, were the maximum intensity voxel is found, onto an image plane. These depth images are then used for tracking by estimating the dense optical flow and depth changes with a self-supervisely trained convolutional neural network. Tracking performances are evaluated on a dataset of ex vivo human temporal bone with rigid ground truth transformations and on an in vivo sequence of human skin with non-rigid transformations. First quantitative evaluation reveals a mean endpoint error of 2.27voxel for scene flow estimation. Object tracking on 4D OCT data enables its use for sub-epithelial tracking of tissue structures for image-guidance in automated laser incision control for microsurgery.","Fri, 26 Oct 2018 07:10:51 UTC (987 KB)"
"130","Automating Generation of Low Precision Deep Learning Operators","Meghan Cowan, Thierry Moreau, Tianqi Chen, Luis Ceze","Machine Learning (cs.LG); Machine Learning (stat.ML)","State of the art deep learning models have made steady progress in the fields of computer vision and natural language processing, at the expense of growing model sizes and computational complexity. Deploying these models on low power and mobile devices poses a challenge due to their limited compute capabilities and strict energy budgets. One solution that has generated significant research interest is deploying highly quantized models that operate on low precision inputs and weights less than eight bits, trading off accuracy for performance. These models have a significantly reduced memory footprint (up to 32x reduction) and can replace multiply-accumulates with bitwise operations during compute intensive convolution and fully connected layers. Most deep learning frameworks rely on highly engineered linear algebra libraries such as ATLAS or Intel's MKL to implement efficient deep learning operators. To date, none of the popular deep learning directly support low precision operators, partly due to a lack of optimized low precision libraries. In this paper we introduce a work flow to quickly generate high performance low precision deep learning operators for arbitrary precision that target multiple CPU architectures and include optimizations such as memory tiling and vectorization. We present an extensive case study on low power ARM Cortex-A53 CPU, and show how we can generate 1-bit, 2-bit convolutions with speedups up to 16x over an optimized 16-bit integer baseline and 2.3x better than handwritten implementations.","Thu, 25 Oct 2018 18:52:48 UTC (406 KB)"
"131","Heterogeneous Treatment Effect Estimation through Deep Learning","Ran Chen, Hanzhong Liu","Methodology (stat.ME)","Estimating heterogeneous treatment effect is an important task in causal inference with wide application fields. It has also attracted increasing attention from machine learning community in recent years. In this work, we reinterpret the heterogeneous treatment effect estimation and propose ways to borrow strength from neural networks. We analyze the strengths and drawbacks of integrating neural networks into heterogeneous treatment effect estimation and clarify the aspects that need to be taken into consideration when designing a specific network. We proposed a specific network under our guidelines. In simulations, we show that our network performs better when the structure of data is complex, and reach a draw under the cases where other methods could be proved to be optimal.","Thu, 25 Oct 2018 17:56:57 UTC (6,545 KB)"
"132","Forecasting Individualized Disease Trajectories using Interpretable Deep Learning","Ahmed M. Alaa, Mihaela van der Schaar","Machine Learning (cs.LG); Machine Learning (stat.ML)","Disease progression models are instrumental in predicting individual-level health trajectories and understanding disease dynamics. Existing models are capable of providing either accurate predictions of patients prognoses or clinically interpretable representations of disease pathophysiology, but not both. In this paper, we develop the phased attentive state space (PASS) model of disease progression, a deep probabilistic model that captures complex representations for disease progression while maintaining clinical interpretability. Unlike Markovian state space models which assume memoryless dynamics, PASS uses an attention mechanism to induce ""memoryful"" state transitions, whereby repeatedly updated attention weights are used to focus on past state realizations that best predict future states. This gives rise to complex, non-stationary state dynamics that remain interpretable through the generated attention weights, which designate the relationships between the realized state variables for individual patients. PASS uses phased LSTM units (with time gates controlled by parametrized oscillations) to generate the attention weights in continuous time, which enables handling irregularly-sampled and potentially missing medical observations. Experiments on data from a realworld cohort of patients show that PASS successfully balances the tradeoff between accuracy and interpretability: it demonstrates superior predictive accuracy and learns insightful individual-level representations of disease progression.","Wed, 24 Oct 2018 16:51:35 UTC (1,835 KB)"
"133","A Deep Learning Mechanism for Efficient Information Dissemination in Vehicular Floating Content","Gaetano Manzo, Juan Sebastian Otalora Montenegro, Gianluca Rizzo","Machine Learning (stat.ML); Machine Learning (cs.LG)","Handling the tremendous amount of network data, produced by the explosive growth of mobile traffic volume, is becoming of main priority to achieve desired performance targets efficiently. Opportunistic communication such as FloatingContent (FC), can be used to offload part of the cellular traffic volume to vehicular-to-vehicular communication (V2V), leaving the infrastructure the task of coordinating the communication. Existing FC dimensioning approaches have limitations, mainly due to unrealistic assumptions and on a coarse partitioning of users, which results in over-dimensioning. Shaping the opportunistic communication area is a crucial task to achieve desired application performance efficiently. In this work, we propose a solution for this open challenge. In particular, the broadcasting areas called Anchor Zone (AZ), are selected via a deep learning approach to minimize communication resources achieving desired message availability. No assumption required to fit the classifier in both synthetic and real mobility. A numerical study is made to validate the effectiveness and efficiency of the proposed method. The predicted AZ configuration can achieve an accuracy of 89.7%within 98% of confidence level. By cause of the learning approach, the method performs even better in real scenarios, saving up to 27% of resources compared to previous work analytically modelled","Wed, 24 Oct 2018 14:36:54 UTC (1,024 KB)"
"134","Deep Learning Scooping Motion using Bilateral Teleoperations","Hitoe Ochi, Weiwei Wan, Yajue Yang, Natsuki Yamanobe, Jia Pan, Kensuke Harada","Robotics (cs.RO)","We present bilateral teleoperation system for task learning and robot motion generation. Our system includes a bilateral teleoperation platform and a deep learning software. The deep learning software refers to human demonstration using the bilateral teleoperation platform to collect visual images and robotic encoder values. It leverages the datasets of images and robotic encoder information to learn about the inter-modal correspondence between visual images and robot motion. In detail, the deep learning software uses a combination of Deep Convolutional Auto-Encoders (DCAE) over image regions, and Recurrent Neural Network with Long Short-Term Memory units (LSTM-RNN) over robot motor angles, to learn motion taught be human teleoperation. The learnt models are used to predict new motion trajectories for similar tasks. Experimental results show that our system has the adaptivity to generate motion for similar scooping tasks. Detailed analysis is performed based on failure cases of the experimental results. Some insights about the cans and cannots of the system are summarized.","Wed, 24 Oct 2018 14:18:56 UTC (5,771 KB)"
"135","Dermatologist Level Dermoscopy Skin Cancer Classification Using Different Deep Learning Convolutional Neural Networks Algorithms","Amirreza Rezvantalab, Habib Safigholi, Somayeh Karimijeshni","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","In this paper, the effectiveness and capability of convolutional neural networks have been studied in the classification of 8 skin diseases. Different pre-trained state-of-the-art architectures (DenseNet 201, ResNet 152, Inception v3, InceptionResNet v2) were used and applied on 10135 dermoscopy skin images in total (HAM10000: 10015, PH2: 120). The utilized dataset includes 8 diagnostic categories - melanoma, melanocytic nevi, basal cell carcinoma, benign keratosis, actinic keratosis and intraepithelial carcinoma, dermatofibroma, vascular lesions, and atypical nevi. The aim is to compare the ability of deep learning with the performance of highly trained dermatologists. Overall, the mean results show that all deep learning models outperformed dermatologists (at least 11%). The best ROC AUC values for melanoma and basal cell carcinoma are 94.40% (ResNet 152) and 99.30% (DenseNet 201) versus 82.26% and 88.82% of dermatologists, respectively. Also, DenseNet 201 had the highest macro and micro averaged AUC values for overall classification (98.16%, 98.79%, respectively).","Sun, 21 Oct 2018 23:27:59 UTC (1,256 KB)"
"136","From Machine to Machine: An OCT-trained Deep Learning Algorithm for Objective Quantification of Glaucomatous Damage in Fundus Photographs","Felipe A. Medeiros, Alessandro A. Jammal, Atalie C. Thompson","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)","Previous approaches using deep learning algorithms to classify glaucomatous damage on fundus photographs have been limited by the requirement for human labeling of a reference training set. We propose a new approach using spectral-domain optical coherence tomography (SDOCT) data to train a deep learning algorithm to quantify glaucomatous structural damage on optic disc photographs. The dataset included 32,820 pairs of optic disc photos and SDOCT retinal nerve fiber layer (RNFL) scans from 2,312 eyes of 1,198 subjects. A deep learning convolutional neural network was trained to assess optic disc photographs and predict SDOCT average RNFL thickness. The performance of the algorithm was evaluated in an independent test sample. The mean prediction of average RNFL thickness from all 6,292 optic disc photos in the test set was 83.3$\pm$14.5 $レ$m, whereas the mean average RNFL thickness from all corresponding SDOCT scans was 82.5$\pm$16.8 $レ$m (P = 0.164). There was a very strong correlation between predicted and observed RNFL thickness values (r = 0.832; P<0.001), with mean absolute error of the predictions of 7.39 $レ$m. The areas under the receiver operating characteristic curves for discriminating glaucoma from healthy eyes with the deep learning predictions and actual SDOCT measurements were 0.944 (95$\%$ CI: 0.912- 0.966) and 0.940 (95$\%$ CI: 0.902 - 0.966), respectively (P = 0.724). In conclusion, we introduced a novel deep learning approach to assess optic disc photographs and provide quantitative information about the amount of neural damage. This approach could potentially be used to diagnose and stage glaucomatous damage from optic disc photographs.","Sat, 20 Oct 2018 05:03:42 UTC (5,139 KB)"
"137","Predicting optical coherence tomography-derived diabetic macular edema grades from fundus photographs using deep learning","Avinash Varadarajan, Pinal Bavishi, Paisan Raumviboonsuk, Peranut Chotcomwongse, Subhashini Venugopalan, Arunachalam Narayanaswamy, Jorge Cuadros, Kuniyoshi Kanai, George Bresnick, Mongkol Tadarati, Sukhum Silpa-archa, Jirawut Limwattanayingyong, Variya Nganthavee, Joe Ledsam, Pearse A Keane, Greg S Corrado, Lily Peng, Dale R Webster","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Diabetic eye disease is one of the fastest growing causes of preventable blindness. With the advent of anti-VEGF (vascular endothelial growth factor) therapies, it has become increasingly important to detect center-involved diabetic macular edema. However, center-involved diabetic macular edema is diagnosed using optical coherence tomography (OCT), which is not generally available at screening sites because of cost and workflow constraints. Instead, screening programs rely on the detection of hard exudates as a proxy for DME on color fundus photographs, often resulting in high false positive or false negative calls. To improve the accuracy of DME screening, we trained a deep learning model to use color fundus photographs to predict DME grades derived from OCT exams. Our ""OCT-DME"" model had an AUC of 0.89 (95% CI: 0.87-0.91), which corresponds to a sensitivity of 85% at a specificity of 80%. In comparison, three retinal specialists had similar sensitivities (82-85%), but only half the specificity (45-50%, p<0.001 for each comparison with model). The positive predictive value (PPV) of the OCT-DME model was 61% (95% CI: 56-66%), approximately double the 36-38% by the retina specialists. In addition, we used saliency and other techniques to examine how the model is making its prediction. The ability of deep learning algorithms to make clinically relevant predictions that generally require sophisticated 3D-imaging equipment from simple 2D images has broad relevance to many other applications in medical imaging.","Thu, 18 Oct 2018 23:22:33 UTC (764 KB)[v2] Mon, 19 Nov 2018 01:46:59 UTC (765 KB)"
"138","Projecting Trouble: Light Based Adversarial Attacks on Deep Learning Classifiers","Nicole Nichols, Robert Jasper","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","This work demonstrates a physical attack on a deep learning image classification system using projected light onto a physical scene. Prior work is dominated by techniques for creating adversarial examples which directly manipulate the digital input of the classifier. Such an attack is limited to scenarios where the adversary can directly update the inputs to the classifier. This could happen by intercepting and modifying the inputs to an online API such as Clarifai or Cloud Vision. Such limitations have led to a vein of research around physical attacks where objects are constructed to be inherently adversarial or adversarial modifications are added to cause misclassification. Our work differs from other physical attacks in that we can cause misclassification dynamically without altering physical objects in a permanent way. We construct an experimental setup which includes a light projection source, an object for classification, and a camera to capture the scene. Experiments are conducted against 2D and 3D objects from CIFAR-10. Initial tests show projected light patterns selected via differential evolution could degrade classification from 98% to 22% and 89% to 43% probability for 2D and 3D targets respectively. Subsequent experiments explore sensitivity to physical setup and compare two additional baseline conditions for all 10 CIFAR classes. Some physical targets are more susceptible to perturbation. Simple attacks show near equivalent success, and 6 of the 10 classes were disrupted by light.","Tue, 16 Oct 2018 17:47:07 UTC (7,208 KB)"
"139","Incremental Deep Learning for Robust Object Detection in Unknown Cluttered Environments","Dong Kyun Shin, Minhaz Uddin Ahmed, Phill Kyu Rhee","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Object detection in streaming images is a major step in different detection-based applications, such as object tracking, action recognition, robot navigation, and visual surveillance applications. In mostcases, image quality is noisy and biased, and as a result, the data distributions are disturbed and imbalanced. Most object detection approaches, such as the faster region-based convolutional neural network (Faster RCNN), Single Shot Multibox Detector with 300x300 inputs (SSD300), and You Only Look Once version 2 (YOLOv2), rely on simple sampling without considering distortions and noise under real-world changing environments, despite poor object labeling. In this paper, we propose an Incremental active semi-supervised learning (IASSL) technology for unseen object detection. It combines batch-based active learning (AL) and bin-based semi-supervised learning (SSL) to leverage the strong points of AL's exploration and SSL's exploitation capabilities. A collaborative sampling method is also adopted to measure the uncertainty and diversity of AL and the confidence in SSL. Batch-based AL allows us to select more informative, confident, and representative samples with low cost. Bin-based SSL divides streaming image samples into several bins, and each bin repeatedly transfers the discriminative knowledge of convolutional neural network (CNN) deep learning to the next bin until the performance criterion is reached. IASSL can overcome noisy and biased labels in unknown, cluttered data distributions. We obtain superior performance, compared to state-of-the-art technologies such as Faster RCNN, SSD300, and YOLOv2.","Sat, 13 Oct 2018 17:10:41 UTC (1,367 KB)"
"140","Solving Poisson's Equation using Deep Learning in Particle Simulation of PN Junction","Zhongyang Zhang (1), Ling Zhang (1), Ze Sun (1), Nicholas Erickson (1), Ryan From (2), Jun Fan (1) ((1) Missouri S&T EMC Laboratory, Rolla, MO, USA (2) Boeing Company, St. Louis, MO, USA)","Computational Physics (physics.comp-ph); Artificial Intelligence (cs.AI); Signal Processing (eess.SP)","Simulating the dynamic characteristics of a PN junction at the microscopic level requires solving the Poisson's equation at every time step. Solving at every time step is a necessary but time-consuming process when using the traditional finite difference (FDM) approach. Deep learning is a powerful technique to fit complex functions. In this work, deep learning is utilized to accelerate solving Poisson's equation in a PN junction. The role of the boundary condition is emphasized in the loss function to ensure a better fitting. The resulting I-V curve for the PN junction, using the deep learning solver presented in this work, shows a perfect match to the I-V curve obtained using the finite difference method, with the advantage of being 10 times faster at every time step.","Wed, 24 Oct 2018 05:25:18 UTC (443 KB)[v2] Thu, 25 Oct 2018 01:19:21 UTC (435 KB)"
"141","Deep learning enables high-throughput analysis of particle-aggregation-based bio-sensors imaged using holography","Yichen Wu, Aniruddha Ray, Qingshan Wei, Alborz Feizi, Xin Tong, Eva Chen, Yi Luo, Aydogan Ozcan","Instrumentation and Detectors (physics.ins-det); Applied Physics (physics.app-ph); Optics (physics.optics)","Aggregation-based assays, using micro- and nano-particles have been widely accepted as an efficient and cost-effective bio-sensing tool, particularly in microbiology, where particle clustering events are used as a metric to infer the presence of a specific target analyte and quantify its concentration. Here, we present a sensitive and automated readout method for aggregation-based assays using a wide-field lens-free on-chip microscope, with the ability to rapidly analyze and quantify microscopic particle aggregation events in 3D, using deep learning-based holographic image reconstruction. In this method, the computation time for hologram reconstruction and particle autofocusing steps remains constant, regardless of the number of particles/clusters within the 3D sample volume, which provides a major throughput advantage, brought by deep learning-based image reconstruction. As a proof of concept, we demonstrate rapid detection of herpes simplex virus (HSV) by monitoring the clustering of antibody-coated micro-particles, achieving a detection limit of ~5 viral copies per micro-liter (i.e., ~25 copies per test).","Wed, 24 Oct 2018 04:23:13 UTC (1,939 KB)"
"142","Deep Learning with Long Short-Term Memory for Time Series Prediction","Yuxiu Hua, Zhifeng Zhao, Rongpeng Li, Xianfu Chen, Zhiming Liu, Honggang Zhang","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG)","Time series prediction can be generalized as a process that extracts useful information from historical records and then determines future values. Learning long-range dependencies that are embedded in time series is often an obstacle for most algorithms, whereas Long Short-Term Memory (LSTM) solutions, as a specific kind of scheme in deep learning, promise to effectively overcome the problem. In this article, we first give a brief introduction to the structure and forward propagation mechanism of the LSTM model. Then, aiming at reducing the considerable computing cost of LSTM, we put forward the Random Connectivity LSTM (RCLSTM) model and test it by predicting traffic and user mobility in telecommunication networks. Compared to LSTM, RCLSTM is formed via stochastic connectivity between neurons, which achieves a significant breakthrough in the architecture formation of neural networks. In this way, the RCLSTM model exhibits a certain level of sparsity, which leads to an appealing decrease in the computational complexity and makes the RCLSTM model become more applicable in latency-stringent application scenarios. In the field of telecommunication networks, the prediction of traffic series and mobility traces could directly benefit from this improvement as we further demonstrate that the prediction accuracy of RCLSTM is comparable to that of the conventional LSTM no matter how we change the number of training samples or the length of input sequences.","Wed, 24 Oct 2018 03:06:38 UTC (876 KB)"
"143","A Deep-Learning-Based Fashion Attributes Detection Model","Menglin Jia, Yichen Zhou, Mengyun Shi, Bharath Hariharan","Computer Vision and Pattern Recognition (cs.CV)","Analyzing fashion attributes is essential in the fashion design process. Current fashion forecasting firms, such as WGSN utilizes information from all around the world (from fashion shows, visual merchandising, blogs, etc). They gather information by experience, by observation, by media scan, by interviews, and by exposed to new things. Such information analyzing process is called abstracting, which recognize similarities or differences across all the garments and collections. In fact, such abstraction ability is useful in many fashion careers with different purposes. Fashion forecasters abstract across design collections and across time to identify fashion change and directions; designers, product developers and buyers abstract across a group of garments and collections to develop a cohesive and visually appeal lines; sales and marketing executives abstract across product line each season to recognize selling points; fashion journalist and bloggers abstract across runway photos to recognize symbolic core concepts that can be translated into editorial features. Fashion attributes analysis for such fashion insiders requires much detailed and in-depth attributes annotation than that for consumers, and requires inference on multiple domains. In this project, we propose a data-driven approach for recognizing fashion attributes. Specifically, a modified version of Faster R-CNN model is trained on images from a large-scale localization dataset with 594 fine-grained attributes under different scenarios, for example in online stores and street snapshots. This model will then be used to detect garment items and classify clothing attributes for runway photos and fashion illustrations.","Wed, 24 Oct 2018 01:22:01 UTC (2,032 KB)"
"144","nGraph-HE: A Graph Compiler for Deep Learning on Homomorphically Encrypted Data","Fabian Boemer, Yixing Lao, Casimir Wierzynski","Cryptography and Security (cs.CR)","Homomorphic encryption (HE)--the ability to perform computations on encrypted data--is an attractive remedy to increasing concerns about data privacy in the field of machine learning. However, building models that operate on ciphertext is currently labor-intensive and requires simultaneous expertise in deep learning, cryptography, and software engineering. Deep learning frameworks, together with recent advances in graph compilers, have greatly accelerated the training and deployment of deep learning models to a variety of computing platforms. Here, we introduce nGraph-HE, an extension of the nGraph deep learning compiler, which allows data scientists to deploy trained models with popular frameworks like TensorFlow, MXNet and PyTorch directly, while simply treating HE as another hardware target. This combination of frameworks and graph compilers greatly simplifies the development of privacy-preserving machine learning systems, provides a clean abstraction barrier between deep learning and HE, allows HE libraries to exploit HE-specific graph optimizations, and comes at a low cost in runtime overhead versus native HE operations.","Tue, 23 Oct 2018 23:01:38 UTC (272 KB)"
"145","NestDNN: Resource-Aware Multi-Tenant On-Device Deep Learning for Continuous Mobile Vision","Biyi Fang, Xiao Zeng, Mi Zhang","Computer Vision and Pattern Recognition (cs.CV)","Mobile vision systems such as smartphones, drones, and augmented-reality headsets are revolutionizing our lives. These systems usually run multiple applications concurrently and their available resources at runtime are dynamic due to events such as starting new applications, closing existing applications, and application priority changes. In this paper, we present NestDNN, a framework that takes the dynamics of runtime resources into account to enable resource-aware multi-tenant on-device deep learning for mobile vision systems. NestDNN enables each deep learning model to offer flexible resource-accuracy trade-offs. At runtime, it dynamically selects the optimal resource-accuracy trade-off for each deep learning model to fit the model's resource demand to the system's available runtime resources. In doing so, NestDNN efficiently utilizes the limited resources in mobile vision systems to jointly maximize the performance of all the concurrently running applications. Our experiments show that compared to the resource-agnostic status quo approach, NestDNN achieves as much as 4.2% increase in inference accuracy, 2.0x increase in video frame processing rate and 1.7x reduction on energy consumption.","Tue, 23 Oct 2018 21:07:42 UTC (1,728 KB)"
"146","DeepLSR: Deep learning approach for laser speckle reduction","Taylor L. Bobrow, Faisal Mahmood, Miguel Inserni, Nicholas J. Durr","Computer Vision and Pattern Recognition (cs.CV)","We present a deep learning approach for laser speckle reduction ('DeepLSR') on images illuminated with a multi-wavelength, red-green-blue laser. We acquired a set of images from a variety of objects illuminated with laser light, both with and without optical speckle reduction, and an incoherent light-emitting diode. An adversarial network was then trained for paired image-to-image translation to transform images from a source domain of coherent illumination to a target domain of incoherent illumination. When applied to a new image set of coherently-illuminated test objects, this network reconstructs incoherently-illuminated images with an average peak signal-to-noise ratio and structural similarity index of 36 dB and 0.91, respectively, compared to 30 dB and 0.88 using optical speckle reduction, and 30 dB and 0.88 using non-local means processing. We demonstrate proof-of-concept for speckle-reduced laser endoscopy by applying DeepLSR to images of ex-vivo gastrointestinal tissue illuminated with a fiber-coupled laser source. For applications that require speckle-reduced imaging, DeepLSR holds promise to enable the use of coherent sources that are more stable, efficient, compact, and brighter than conventional alternatives.","Tue, 23 Oct 2018 18:36:35 UTC (3,232 KB)"
"147","Using Deep Learning for price prediction by exploiting stationary limit order book features","Avraam Tsantekidis, Nikolaos Passalis, Anastasios Tefas, Juho Kanniainen, Moncef Gabbouj, Alexandros Iosifidis","Machine Learning (cs.LG); Statistical Finance (q-fin.ST); Machine Learning (stat.ML)","The recent surge in Deep Learning (DL) research of the past decade has successfully provided solutions to many difficult problems. The field of quantitative analysis has been slowly adapting the new methods to its problems, but due to problems such as the non-stationary nature of financial data, significant challenges must be overcome before DL is fully utilized. In this work a new method to construct stationary features, that allows DL models to be applied effectively, is proposed. These features are thoroughly tested on the task of predicting mid price movements of the Limit Order Book. Several DL models are evaluated, such as recurrent Long Short Term Memory (LSTM) networks and Convolutional Neural Networks (CNN). Finally a novel model that combines the ability of CNNs to extract useful features and the ability of LSTMs' to analyze time series, is proposed and evaluated. The combined model is able to outperform the individual LSTM and CNN models in the prediction horizons that are tested.","Tue, 23 Oct 2018 16:53:03 UTC (263 KB)"
"148","ISA Mapper: A Compute and Hardware Agnostic Deep Learning Compiler","Matthew Sotoudeh, Anand Venkat, Michael Anderson, Evangelos Georganas, Alexander Heinecke, Jason Knight","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","Domain specific accelerators present new challenges and opportunities for code generation onto novel instruction sets, communication fabrics, and memory architectures. In this paper we introduce an intermediate representation (IR) which enables both deep learning computational kernels and hardware capabilities to be described in the same IR. We then formulate and apply instruction mapping to determine the possible ways a computation can be performed on a hardware system. Next, our scheduler chooses a specific mapping and determines the data movement and computation order. In order to manage the large search space of mappings and schedules, we developed a flexible framework that allows heuristics, cost models, and potentially machine learning to facilitate this search problem. With this system, we demonstrate the automated extraction of matrix multiplication kernels out of recent deep learning kernels such as depthwise-separable convolution. In addition, we demonstrate two to five times better performance on DeepBench sized GEMMs and GRU RNN execution when compared to state-of-the-art (SOTA) implementations on new hardware and up to 85% of the performance for SOTA implementations on existing hardware.","Fri, 12 Oct 2018 23:54:00 UTC (363 KB)"
"149","Applying Deep Learning To Airbnb Search","Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tao Xu, Shulin Yang, Huizhong Duan, Qing Zhang, Nick Barrow-Williams, Bradley C. Turnbull, Brendan M. Collins, Thomas Legrand","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (stat.ML)","The application to search ranking is one of the biggest machine learning success stories at Airbnb. Much of the initial gains were driven by a gradient boosted decision tree model. The gains, however, plateaued over time. This paper discusses the work done in applying neural networks in an attempt to break out of that plateau. We present our perspective not with the intention of pushing the frontier of new modeling techniques. Instead, ours is a story of the elements we found useful in applying neural networks to a real life product. Deep learning was steep learning for us. To other teams embarking on similar journeys, we hope an account of our struggles and triumphs will provide some useful pointers. Bon voyage!","Mon, 22 Oct 2018 23:11:01 UTC (4,438 KB)[v2] Wed, 24 Oct 2018 18:28:03 UTC (4,438 KB)"
"150","Smart Network Field Theory: The Technophysics of Blockchain and Deep Learning","Melanie Swan, Renato P. dos Santos","Physics and Society (physics.soc-ph)","The aim of this paper is to propose a theoretical construct, smart network field theory, for the characterization, monitoring, and control of smart network systems. Smart network systems are intelligent autonomously-operating networks, a new form of global computational infrastructure that includes blockchains, deep learning, and autonomous-strike UAVs. These kinds of large-scale networks are a contemporary reality with thousands, millions, and billions of constituent elements, and entail a foundational and theoretically-robust model for their design and operation. Hence this work proposes smart network field theory, drawing from statistical physics, effective field theories, and model systems, for criticality detection and fleet-many item orchestration in smart network systems. Smart network field theory falls within the broader concern of technophysics (the application of physics to the study of technology), in which a key objective is deriving standardized methods for assessing system criticality and phase transition, and defining interim system structure between the levels of microscopic noise and macroscopic labels. The farther implications of this work include the possibility of recasting the P/NP computational complexity schema as one no longer based on traditional time (concurrency) and space constraints, due to the availability of smart network computational resources.","Mon, 1 Oct 2018 11:52:15 UTC (1,098 KB)"
"151","Scaling up Deep Learning for PDE-based Models","Philipp Haehnel, Jakub Marecek, Julien Monteil, Fearghal O'Donncha","Machine Learning (cs.LG); Machine Learning (stat.ML)","In numerous applications, forecasting relies on numerical solvers for partial differential equations (PDEs). Although the use of deep-learning techniques has been proposed, the uses have been restricted by the fact the training data are obtained using PDE solvers. Thereby, the uses were limited to domains, where the PDE solver was applicable, but no further. We present methods for training on small domains, while applying the trained models on larger domains, with consistency constraints ensuring the solutions are physically meaningful even at the boundary of the small domains. We demonstrate the results on an air-pollution forecasting model for Dublin, Ireland.","Mon, 22 Oct 2018 17:46:23 UTC (434 KB)"
"152","Coupled Longitudinal and Lateral Control of a Vehicle using Deep Learning","Guillaume Devineau, Philip Polack, Florent Altche, Fabien Moutarde","Machine Learning (cs.LG); Robotics (cs.RO); Systems and Control (cs.SY); Machine Learning (stat.ML)","This paper explores the capability of deep neural networks to capture key characteristics of vehicle dynamics, and their ability to perform coupled longitudinal and lateral control of a vehicle. To this extent, two different artificial neural networks are trained to compute vehicle controls corresponding to a reference trajectory, using a dataset based on high-fidelity simulations of vehicle dynamics. In this study, control inputs are chosen as the steering angle of the front wheels, and the applied torque on each wheel. The performance of both models, namely a Multi-Layer Perceptron (MLP) and a Convolutional Neural Network (CNN), is evaluated based on their ability to drive the vehicle on a challenging test track, shifting between long straight lines and tight curves. A comparison to conventional decoupled controllers on the same track is also provided.","Mon, 22 Oct 2018 15:35:12 UTC (1,523 KB)"
"153","AST-Based Deep Learning for Detecting Malicious PowerShell","Gili Rusak, Abdullah Al-Dujaili, Una-May O'Reilly","Software Engineering (cs.SE); Machine Learning (cs.LG); Machine Learning (stat.ML)","With the celebrated success of deep learning, some attempts to develop effective methods for detecting malicious PowerShell programs employ neural nets in a traditional natural language processing setup while others employ convolutional neural nets to detect obfuscated malicious commands at a character level. While these representations may express salient PowerShell properties, our hypothesis is that tools from static program analysis will be more effective. We propose a hybrid approach combining traditional program analysis (in the form of abstract syntax trees) and deep learning. This poster presents preliminary results of a fundamental step in our approach: learning embeddings for nodes of PowerShell ASTs. We classify malicious scripts by family type and explore embedded program vector representations.","Wed, 3 Oct 2018 16:03:53 UTC (500 KB)"
"154","Named Entity Disambiguation using Deep Learning on Graphs","Alberto Cetoli, Mohammad Akbari, Stefano Bragaglia, Andrew D. O'Harney, Marc Sloan","Computation and Language (cs.CL)","We tackle \ac{NED} by comparing entities in short sentences with \wikidata{} graphs. Creating a context vector from graphs through deep learning is a challenging problem that has never been applied to \ac{NED}. Our main contribution is to present an experimental study of recent neural techniques, as well as a discussion about which graph features are most important for the disambiguation task. In addition, a new dataset (\wikidatadisamb{}) is created to allow a clean and scalable evaluation of \ac{NED} with \wikidata{} entries, and to be used as a reference in future research. In the end our results show that a \ac{Bi-LSTM} encoding of the graph triplets performs best, improving upon the baseline models and scoring an \rm{F1} value of $91.6\%$ on the \wikidatadisamb{} test set","Mon, 22 Oct 2018 10:16:07 UTC (189 KB)"
"155","Unsupervised Detection of Anomalous Sound based on Deep Learning and the Neyman-Pearson Lemma","Yuma Koizumi, Shoichiro Saito, Hisashi Uematsum Yuta Kawachi, Noboru Harada","Machine Learning (stat.ML); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)","This paper proposes a novel optimization principle and its implementation for unsupervised anomaly detection in sound (ADS) using an autoencoder (AE). The goal of unsupervised-ADS is to detect unknown anomalous sound without training data of anomalous sound. Use of an AE as a normal model is a state-of-the-art technique for unsupervised-ADS. To decrease the false positive rate (FPR), the AE is trained to minimize the reconstruction error of normal sounds and the anomaly score is calculated as the reconstruction error of the observed sound. Unfortunately, since this training procedure does not take into account the anomaly score for anomalous sounds, the true positive rate (TPR) does not necessarily increase. In this study, we define an objective function based on the Neyman-Pearson lemma by considering ADS as a statistical hypothesis test. The proposed objective function trains the AE to maximize the TPR under an arbitrary low FPR condition. To calculate the TPR in the objective function, we consider that the set of anomalous sounds is the complementary set of normal sounds and simulate anomalous sounds by using a rejection sampling algorithm. Through experiments using synthetic data, we found that the proposed method improved the performance measures of ADS under low FPR conditions. In addition, we confirmed that the proposed method could detect anomalous sounds in real environments.","Mon, 22 Oct 2018 08:20:59 UTC (845 KB)"
"156","ComNet: Combination of Deep Learning and Expert Knowledge in OFDM Receivers","Xuanxuan Gao, Shi Jin, Chao-Kai Wen, Geoffrey Ye Li","Signal Processing (eess.SP); Information Theory (cs.IT)","In this article, we propose a model-driven deep learning (DL) approach that combines DL with the expert knowledge to replace the existing orthogonal frequency-division multiplexing (OFDM) receiver in wireless communications. Different from the data-driven fully connected deep neural network (FC-DNN) method, we adopt the block-by-block signal processing method that divides the receiver into channel estimation subnet and signal detection subnet. Each subnet is constructed by a DNN and uses the existing simple and traditional solution as initialization. The proposed model-driven DL receiver offers more accurate channel estimation comparing with the linear minimum mean-squared error (LMMSE) method and exhibits higher data recovery accuracy comparing with the existing methods and FC-DNN. Simulation results further demonstrate the robustness of the proposed approach in terms of signal-to-noise ratio and its superiority to the FC-DNN approach in the computational complexities or the memory usage.","Mon, 22 Oct 2018 04:41:46 UTC (336 KB)"
"157","Analog-to-digital conversion revolutionized by deep learning","Shaofu Xu, Xiuting Zou, Bowen Ma, Jianping Chen, Lei Yu, Weiwen Zou","Signal Processing (eess.SP); Applied Physics (physics.app-ph)","As the bridge between the analog world and digital computers, analog-to-digital converters are generally used in modern information systems such as radar, surveillance, and communications. For the configuration of analog-to-digital converters in future high-frequency broadband systems, we introduce a revolutionary architecture that adopts deep learning technology to overcome tradeoffs between bandwidth, sampling rate, and accuracy. A photonic front-end provides broadband capability for direct sampling and speed multiplication. Trained deep neural networks learn the patterns of system defects, maintaining high accuracy of quantized data in a succinct and adaptive manner. Based on numerical and experimental demonstrations, we show that the proposed architecture outperforms state-of-the-art analog-to-digital converters, confirming the potential of our approach in future analog-to-digital converter design and performance enhancement of future information systems.","Sun, 21 Oct 2018 07:19:54 UTC (2,013 KB)"
"158","To Compress, or Not to Compress: Characterizing Deep Learning Model Compression for Embedded Inference","Qing Qin, Jie Ren, Jialong Yu, Ling Gao, Hai Wang, Jie Zheng, Yansong Feng, Jianbin Fang, Zheng Wang","Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF); Machine Learning (stat.ML)","The recent advances in deep neural networks (DNNs) make them attractive for embedded systems. However, it can take a long time for DNNs to make an inference on resource-constrained computing devices. Model compression techniques can address the computation issue of deep inference on embedded devices. This technique is highly attractive, as it does not rely on specialized hardware, or computation-offloading that is often infeasible due to privacy concerns or high latency. However, it remains unclear how model compression techniques perform across a wide range of DNNs. To design efficient embedded deep learning solutions, we need to understand their behaviors. This work develops a quantitative approach to characterize model compression techniques on a representative embedded deep learning architecture, the NVIDIA Jetson Tx2. We perform extensive experiments by considering 11 influential neural network architectures from the image classification and the natural language processing domains. We experimentally show that how two mainstream compression techniques, data quantization and pruning, perform on these network architectures and the implications of compression techniques to the model storage size, inference time, energy consumption and performance metrics. We demonstrate that there are opportunities to achieve fast deep inference on embedded systems, but one must carefully choose the compression settings. Our results provide insights on when and how to apply model compression techniques and guidelines for designing efficient embedded deep learning systems.","Sun, 21 Oct 2018 05:09:45 UTC (1,793 KB)"
"159","Deep Learning with the Random Neural Network and its Applications","Yonghua Yin","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG)","The random neural network (RNN) is a mathematical model for an ""integrate and fire"" spiking network that closely resembles the stochastic behaviour of neurons in mammalian brains. Since its proposal in 1989, there have been numerous investigations into the RNN's applications and learning algorithms. Deep learning (DL) has achieved great success in machine learning. Recently, the properties of the RNN for DL have been investigated, in order to combine their power. Recent results demonstrate that the gap between RNNs and DL can be bridged and the DL tools based on the RNN are faster and can potentially be used with less energy expenditure than existing methods.","Mon, 8 Oct 2018 14:47:51 UTC (2,872 KB)"
"160","How can deep learning advance computational modeling of sensory information processing?","Jessica A. F. Thompson, Yoshua Bengio, Elia Formisano, Marc Schonwiesner","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning, computational neuroscience, and cognitive science have overlapping goals related to understanding intelligence such that perception and behaviour can be simulated in computational systems. In neuroimaging, machine learning methods have been used to test computational models of sensory information processing. Recently, these model comparison techniques have been used to evaluate deep neural networks (DNNs) as models of sensory information processing. However, the interpretation of such model evaluations is muddied by imprecise statistical conclusions. Here, we make explicit the types of conclusions that can be drawn from these existing model comparison techniques and how these conclusions change when the model in question is a DNN. We discuss how DNNs are amenable to new model comparison techniques that allow for stronger conclusions to be made about the computational mechanisms underlying sensory information processing.","Tue, 25 Sep 2018 23:39:34 UTC (31 KB)"
"161","Sequenced-Replacement Sampling for Deep Learning","Chiu Man Ho, Dae Hoon Park, Wei Yang, Yi Chang","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","We propose sequenced-replacement sampling (SRS) for training deep neural networks. The basic idea is to assign a fixed sequence index to each sample in the dataset. Once a mini-batch is randomly drawn in each training iteration, we refill the original dataset by successively adding samples according to their sequence index. Thus we carry out replacement sampling but in a batched and sequenced way. In a sense, SRS could be viewed as a way of performing ""mini-batch augmentation"". It is particularly useful for a task where we have a relatively small images-per-class such as CIFAR-100. Together with a longer period of initial large learning rate, it significantly improves the classification accuracy in CIFAR-100 over the current state-of-the-art results. Our experiments indicate that training deeper networks with SRS is less prone to over-fitting. In the best case, we achieve an error rate as low as 10.10%.","Fri, 19 Oct 2018 00:55:47 UTC (642 KB)"
"162","A Comparative Analysis of Registration Tools: Traditional vs Deep Learning Approach on High Resolution Tissue Cleared Data","Abdullah Nazib, Clinton Fookes, Dimitri Perrin","Computer Vision and Pattern Recognition (cs.CV)","Image registration plays an important role in comparing images. It is particularly important in analyzing medical images like CT, MRI, PET, etc. to quantify different biological samples, to monitor disease progression and to fuse different modalities to support better diagnosis. The recent emergence of tissue clearing protocols enable us to take images at cellular level resolution. Image registration tools developed for other modalities are currently unable to manage images of such extreme high resolution. The recent popularity of deep learning based methods in the computer vision community justifies a rigorous investigation of deep-learning based methods on tissue cleared images along with their traditional counterparts. In this paper, we investigate and compare the performance of a deep learning based registration method with traditional optimization based methods on samples from tissue-clearing methods. From the comparative results it is found that a deep-learning based method outperforms all traditional registration tools in terms of registration time and has achieved promising registration accuracy.","Fri, 19 Oct 2018 00:22:07 UTC (1,169 KB)"
"163","Compositional Verification for Autonomous Systems with Deep Learning Components","Corina S. Pasareanu, Divya Gopinath, Huafeng Yu","Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","As autonomy becomes prevalent in many applications, ranging from recommendation systems to fully autonomous vehicles, there is an increased need to provide safety guarantees for such systems. The problem is difficult, as these are large, complex systems which operate in uncertain environments, requiring data-driven machine-learning components. However, learning techniques such as Deep Neural Networks, widely used today, are inherently unpredictable and lack the theoretical foundations to provide strong assurance guarantees. We present a compositional approach for the scalable, formal verification of autonomous systems that contain Deep Neural Network components. The approach uses assume-guarantee reasoning whereby {\em contracts}, encoding the input-output behavior of individual components, allow the designer to model and incorporate the behavior of the learning-enabled components working side-by-side with the other components. We illustrate the approach on an example taken from the autonomous vehicles domain.","Thu, 18 Oct 2018 23:16:23 UTC (219 KB)"
"164","Deep Learning vs. Human Graders for Classifying Severity Levels of Diabetic Retinopathy in a Real-World Nationwide Screening Program","Paisan Raumviboonsuk, Jonathan Krause, Peranut Chotcomwongse, Rory Sayres, Rajiv Raman, Kasumi Widner, Bilson J L Campana, Sonia Phene, Kornwipa Hemarat, Mongkol Tadarati, Sukhum Silpa-Acha, Jirawut Limwattanayingyong, Chetan Rao, Oscar Kuruvilla, Jesse Jung, Jeffrey Tan, Surapong Orprayoon, Chawawat Kangwanwongpaisan, Ramase Sukulmalpaiboon, Chainarong Luengchaichawang, Jitumporn Fuangkaew, Pipat Kongsap, Lamyong Chualinpha, Sarawuth Saree, Srirat Kawinpanitan, Korntip Mitvongsa, Siriporn Lawanasakol, Chaiyasit Thepchatri, Lalita Wongpichedchai, Greg S Corrado, Lily Peng, Dale R Webster","Computer Vision and Pattern Recognition (cs.CV)","Deep learning algorithms have been used to detect diabetic retinopathy (DR) with specialist-level accuracy. This study aims to validate one such algorithm on a large-scale clinical population, and compare the algorithm performance with that of human graders. 25,326 gradable retinal images of patients with diabetes from the community-based, nation-wide screening program of DR in Thailand were analyzed for DR severity and referable diabetic macular edema (DME). Grades adjudicated by a panel of international retinal specialists served as the reference standard. Across different severity levels of DR for determining referable disease, deep learning significantly reduced the false negative rate (by 23%) at the cost of slightly higher false positive rates (2%). Deep learning algorithms may serve as a valuable tool for DR screening.","Thu, 18 Oct 2018 22:17:45 UTC (1,190 KB)"
"165","Well, how accurate is it? A Study of Deep Learning Methods for Reynolds-Averaged Navier-Stokes Simulations","Nils Thuerey, Konstantin Weissenow, Harshit Mehrotra, Nischal Mainali, Lukas Prantl, Xiangyu Hu","Machine Learning (cs.LG); Fluid Dynamics (physics.flu-dyn); Machine Learning (stat.ML)","With this study we investigate the accuracy of deep learning models for the inference of Reynolds-Averaged Navier-Stokes solutions. We focus on a modernized U-net architecture, and evaluate a large number of trained neural networks with respect to their accuracy for the calculation of pressure and velocity distributions. In particular, we illustrate how training data size and the number of weights influence the accuracy of the solutions. With our best models we arrive at a mean relative pressure and velocity error of less than 3% across a range of previously unseen airfoil shapes. In addition all source code is publicly available in order to ensure reproducibility and to provide a starting point for researchers interested in deep learning methods for physics problems. While this work focuses on RANS solutions, the neural network architecture and learning setup are very generic, and applicable to a wide range of PDE boundary value problems on Cartesian grids.","Thu, 18 Oct 2018 18:01:01 UTC (2,769 KB)"
"166","Deep Learning from Shallow Dives: Sonar Image Generation and Training for Underwater Object Detection","Sejin Lee, Byungjae Park, Ayoung Kim","Robotics (cs.RO)","Among underwater perceptual sensors, imaging sonar has been highlighted for its perceptual robustness underwater. The major challenge of imaging sonar, however, arises from the difficulty in defining visual features despite limited resolution and high noise levels. Recent developments in deep learning provide a powerful solution for computer-vision researches using optical images. Unfortunately, deep learning-based approaches are not well established for imaging sonars, mainly due to the scant data in the training phase. Unlike the abundant publically available terrestrial images, obtaining underwater images is often costly, and securing enough underwater images for training is not straightforward. To tackle this issue, this paper presents a solution to this field's lack of data by introducing a novel end-to-end image-synthesizing method in the training image preparation phase. The proposed method present image synthesizing scheme to the images captured by an underwater simulator. Our synthetic images are based on the sonar imaging models and noisy characteristics to represent the real data obtained from the sea. We validate the proposed scheme by training using a simulator and by testing the simulated images with real underwater sonar images obtained from a water tank and the sea.","Thu, 18 Oct 2018 11:20:23 UTC (7,831 KB)"
"167","Deep Learning for Encrypted Traffic Classification: An Overview","Shahbaz Rezaei, Xin Liu","Networking and Internet Architecture (cs.NI)","Traffic classification has been studied for two decades and applied to a wide range of applications from QoS provisioning and billing in ISPs to security-related applications in firewalls and intrusion detection systems. Port-based, data packet inspection, and classical machine learning methods have been used extensively in the past, but their accuracy have been declined due to the dramatic changes in the Internet traffic, particularly the increase in encrypted traffic. With the proliferation of deep learning methods, researchers have recently investigated these methods for traffic classification task and reported high accuracy. In this article, we present a general framework for deep-learning-based traffic classification. We discuss commonly used deep learning methods and their application in traffic classification tasks. Then, we present open problems and their challenges, as well as opportunities for traffic classification.","Thu, 18 Oct 2018 05:55:05 UTC (829 KB)"
"168","A Deep Learning Approach to Galaxy Cluster X-ray Masses","M. Ntampaka, J. ZuHone, D. Eisenstein, D. Nagai, A. Vikhlinin, L. Hernquist, F. Marinacci, D. Nelson, R. Pakmor, A. Pillepich, P. Torrey, M. Vogelsberger","Cosmology and Nongalactic Astrophysics (astro-ph.CO)","We present a machine-learning approach for estimating galaxy cluster masses from Chandra mock images. We utilize a Convolutional Neural Network (CNN), a deep machine learning tool commonly used in image recognition tasks. The CNN is trained and tested on our sample of 7,896 Chandra X-ray mock observations, which are based on 329 massive clusters from the IllustrisTNG simulation. Our CNN learns from a low resolution spatial distribution of photon counts and does not use spectral information. Despite our simplifying assumption to neglect spectral information, the resulting mass values estimated by the CNN exhibit small bias in comparison to the true masses of the simulated clusters (-0.02 dex) and reproduce the cluster masses with low intrinsic scatter, 8% in our best fold and 12% averaging over all. In contrast, a more standard core-excised luminosity method achieves 15-18% scatter. We interpret the results with an approach inspired by Google DeepDream and find that the CNN ignores the central regions of clusters, which are known to have high scatter with mass.","Wed, 17 Oct 2018 18:00:05 UTC (1,600 KB)"
"169","The Newton Scheme for Deep Learning","Junqing Qiu, Guoren Zhong, Yihua Lu, Kun Xin, Huihuan Qian, Xi Zhu","Machine Learning (cs.LG); Classical Physics (physics.class-ph)","We introduce a neural network (NN) strictly governed by Newton's Law, with the nature required basis functions derived from the fundamental classic mechanics. Then, by classifying the training model as a quick procedure of 'force pattern' recognition, we developed the Newton physics-based NS scheme. Once the force pattern is confirmed, the neuro network simply does the checking of the 'pattern stability' instead of the continuous fitting by computational resource consuming big data-driven processing. In the given physics's law system, once the field is confirmed, the mathematics bases for the force field description actually are not diverged but denumerable, which can save the function representations from the exhaustible available mathematics bases. In this work, we endorsed Newton's Law into the deep learning technology and proposed Newton Scheme (NS). Under NS, the user first identifies the path pattern, like the constant acceleration movement.The object recognition technology first loads mass information, then, the NS finds the matched physical pattern and describe and predict the trajectory of the movements with nearly zero error. We compare the major contribution of this NS with the TCN, GRU and other physics inspired 'FIND-PDE' methods to demonstrate fundamental and extended applications of how the NS works for the free-falling, pendulum and curve soccer balls.The NS methodology provides more opportunity for the future deep learning advances.","Tue, 16 Oct 2018 04:30:02 UTC (1,325 KB)"
"170","Deep Learning Based Power Control for Quality-Driven Wireless Video Transmissions","Chuang Ye, M. Cenk Gursoy, Senem Velipasalar","Machine Learning (cs.LG); Information Theory (cs.IT); Image and Video Processing (eess.IV); Machine Learning (stat.ML)","In this paper, wireless video transmission to multiple users under total transmission power and minimum required video quality constraints is studied. In order to provide the desired performance levels to the end-users in real-time video transmissions while using the energy resources efficiently, we assume that power control is employed. Due to the presence of interference, determining the optimal power control is a non-convex problem but can be solved via monotonic optimization framework. However, monotonic optimization is an iterative algorithm and can often entail considerable computational complexity, making it not suitable for real-time applications. To address this, we propose a learning-based approach that treats the input and output of a resource allocation algorithm as an unknown nonlinear mapping and a deep neural network (DNN) is employed to learn this mapping. This learned mapping via DNN can provide the optimal power level quickly for given channel conditions.","Tue, 16 Oct 2018 05:14:05 UTC (344 KB)"
"171","Multi-Task Deep Learning for Legal Document Translation, Summarization and Multi-Label Classification","Ahmed Elnaggar, Christoph Gebendorfer, Ingo Glaser, Florian Matthes","Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG); Machine Learning (stat.ML)","The digitalization of the legal domain has been ongoing for a couple of years. In that process, the application of different machine learning (ML) techniques is crucial. Tasks such as the classification of legal documents or contract clauses as well as the translation of those are highly relevant. On the other side, digitized documents are barely accessible in this field, particularly in Germany. Today, deep learning (DL) is one of the hot topics with many publications and various applications. Sometimes it provides results outperforming the human level. Hence this technique may be feasible for the legal domain as well. However, DL requires thousands of samples to provide decent results. A potential solution to this problem is multi-task DL to enable transfer learning. This approach may be able to overcome the data scarcity problem in the legal domain, specifically for the German language. We applied the state of the art multi-task model on three tasks: translation, summarization, and multi-label classification. The experiments were conducted on legal document corpora utilizing several task combinations as well as various model parameters. The goal was to find the optimal configuration for the tasks at hand within the legal domain. The multi-task DL approach outperformed the state of the art results in all three tasks. This opens a new direction to integrate DL technology more efficiently in the legal domain.","Tue, 16 Oct 2018 08:54:50 UTC (478 KB)"
"172","Analysis of Railway Accidents' Narratives Using Deep Learning","Mojtaba Heidarysafa, Kamran Kowsari, Laura E. Barnes, Donald E. Brown","Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","Automatic understanding of domain specific texts in order to extract useful relationships for later use is a non-trivial task. One such relationship would be between railroad accidents' causes and their correspondent descriptions in reports. From 2001 to 2016 rail accidents in the U.S. cost more than $4.6B. Railroads involved in accidents are required to submit an accident report to the Federal Railroad Administration (FRA). These reports contain a variety of fixed field entries including primary cause of the accidents (a coded variable with 389 values) as well as a narrative field which is a short text description of the accident. Although these narratives provide more information than a fixed field entry, the terminologies used in these reports are not easy to understand by a non-expert reader. Therefore, providing an assisting method to fill in the primary cause from such domain specific texts(narratives) would help to label the accidents with more accuracy. Another important question for transportation safety is whether the reported accident cause is consistent with narrative description. To address these questions, we applied deep learning methods together with powerful word embeddings such as Word2Vec and GloVe to classify accident cause values for the primary cause field using the text in the narratives. The results show that such approaches can both accurately classify accident causes based on report narratives and find important inconsistencies in accident reporting.","Wed, 17 Oct 2018 04:30:02 UTC (2,840 KB)"
"173","Autonomous Deep Learning: Continual Learning Approach for Dynamic Environments","Andri Ashfahani, Mahardhika Pratama","Machine Learning (cs.LG); Machine Learning (stat.ML)","The feasibility of deep neural networks (DNNs) to address data stream problems still requires intensive study because of the static and offline nature of conventional deep learning approaches. A deep continual learning algorithm, namely autonomous deep learning (ADL), is proposed in this paper. Unlike traditional deep learning methods, ADL features a flexible structure where its network structure can be constructed from scratch with the absence of initial network structure via the self-constructing network structure. ADL specifically addresses catastrophic forgetting by having a different-depth structure which is capable of achieving a trade-off between plasticity and stability. Network significance (NS) formula is proposed to drive the hidden nodes growing and pruning mechanism. Drift detection scenario (DDS) is put forward to signal distributional changes in data streams which induce the creation of a new hidden layer. Maximum information compression index (MICI) method plays an important role as a complexity reduction module eliminating redundant layers. The efficacy of ADL is numerically validated under the prequential test-then-train procedure in lifelong environments using nine popular data stream problems. The numerical results demonstrate that ADL consistently outperforms recent continual learning methods while characterizing the automatic construction of network structures.","Wed, 17 Oct 2018 01:40:45 UTC (252 KB)"
"174","Improving Data Quality through Deep Learning and Statistical Models","Wei Dai, Kenji Yoshigoe, William Parsley","Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","Traditional data quality control methods are based on users experience or previously established business rules, and this limits performance in addition to being a very time consuming process with lower than desirable accuracy. Utilizing deep learning, we can leverage computing resources and advanced techniques to overcome these challenges and provide greater value to users. In this paper, we, the authors, first review relevant works and discuss machine learning techniques, tools, and statistical quality models. Second, we offer a creative data quality framework based on deep learning and statistical model algorithm for identifying data quality. Third, we use data involving salary levels from an open dataset published by the state of Arkansas to demonstrate how to identify outlier data and how to improve data quality via deep learning. Finally, we discuss future work.","Tue, 16 Oct 2018 16:57:07 UTC (1,041 KB)"
"175","Collaborative Deep Learning Across Multiple Data Centers","Kele Xu, Haibo Mi, Dawei Feng, Huaimin Wang, Chuan Chen, Zibin Zheng, Xu Lan","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Valuable training data is often owned by independent organizations and located in multiple data centers. Most deep learning approaches require to centralize the multi-datacenter data for performance purpose. In practice, however, it is often infeasible to transfer all data to a centralized data center due to not only bandwidth limitation but also the constraints of privacy regulations. Model averaging is a conventional choice for data parallelized training, but its ineffectiveness is claimed by previous studies as deep neural networks are often non-convex. In this paper, we argue that model averaging can be effective in the decentralized environment by using two strategies, namely, the cyclical learning rate and the increased number of epochs for local model training. With the two strategies, we show that model averaging can provide competitive performance in the decentralized mode compared to the data-centralized one. In a practical environment with multiple data centers, we conduct extensive experiments using state-of-the-art deep network architectures on different types of data. Results demonstrate the effectiveness and robustness of the proposed method.","Tue, 16 Oct 2018 08:33:33 UTC (637 KB)"
"176","Quasi-hyperbolic momentum and Adam for deep learning","Jerry Ma, Denis Yarats","Machine Learning (cs.LG); Machine Learning (stat.ML)","Momentum-based acceleration of stochastic gradient descent (SGD) is widely used in deep learning. We propose the quasi-hyperbolic momentum algorithm (QHM) as an extremely simple alteration of momentum SGD, averaging a plain SGD step with a momentum step. We describe numerous connections to and identities with other algorithms, and we characterize the set of two-state optimization algorithms that QHM can recover. Finally, we propose a QH variant of Adam called QHAdam, and we empirically demonstrate that our algorithms lead to significantly improved training in a variety of settings, including a new state-of-the-art result on WMT16 EN-DE. We hope that these empirical results, combined with the conceptual and practical simplicity of QHM and QHAdam, will spur interest from both practitioners and researchers. PyTorch code is immediately available.","Tue, 16 Oct 2018 03:58:14 UTC (3,962 KB)"
"177","Super-resolution MRI through Deep Learning","Qing Lyu, Chenyu You, Hongming Shan, Ge Wang","Medical Physics (physics.med-ph)","Magnetic resonance imaging (MRI) is extensively used for diagnosis and image-guided therapeutics. Due to hardware, physical and physiological limitations, acquisition of high-resolution MRI data takes long scan time at high system cost, and could be limited to low spatial coverage and also subject to motion artifacts. Super-resolution MRI can be achieved with deep learning, which is a promising approach and has a great potential for preclinical and clinical imaging. Compared with polynomial interpolation or sparse-coding algorithms, deep learning extracts prior knowledge from big data and produces superior MRI images from a low-resolution counterpart. In this paper, we adapt two state-of-the-art neural network models for CT denoising and deblurring, transfer them for super-resolution MRI, and demonstrate encouraging super-resolution MRI results toward two-fold resolution enhancement.","Tue, 16 Oct 2018 01:14:42 UTC (769 KB)"
"178","Named-Entity Linking Using Deep Learning For Legal Documents: A Transfer Learning Approach","Ahmed Elnaggar, Robin Otto, Florian Matthes","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (stat.ML)","In the legal domain it is important to differentiate between words in general, and afterwards to link the occurrences of the same entities. The topic to solve these challenges is called Named-Entity Linking (NEL). Current supervised neural networks designed for NEL use publicly available datasets for training and testing. However, this paper focuses especially on the aspect of applying transfer learning approach using networks trained for NEL to legal documents. Experiments show consistent improvement in the legal datasets that were created from the European Union law in the scope of this research. Using transfer learning approach, we reached F1-score of 98.90\% and 98.01\% on the legal small and large test dataset.","Mon, 15 Oct 2018 20:38:00 UTC (244 KB)"
"179","Stop Illegal Comments: A Multi-Task Deep Learning Approach","Ahmed Elnaggar, Bernhard Waltl, Ingo Glaser, Jorg Landthaler, Elena Scepankova, Florian Matthes","Information Retrieval (cs.IR); Computation and Language (cs.CL); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning methods are often difficult to apply in the legal domain due to the large amount of labeled data required by deep learning methods. A recent new trend in the deep learning community is the application of multi-task models that enable single deep neural networks to perform more than one task at the same time, for example classification and translation tasks. These powerful novel models are capable of transferring knowledge among different tasks or training sets and therefore could open up the legal domain for many deep learning applications. In this paper, we investigate the transfer learning capabilities of such a multi-task model on a classification task on the publicly available Kaggle toxic comment dataset for classifying illegal comments and we can report promising results.","Mon, 15 Oct 2018 20:22:44 UTC (3,799 KB)"
"180","Deep learning-based super-resolution in coherent imaging systems","Tairan Liu, Kevin de Haan, Yair Rivenson, Zhensong Wei, Xin Zeng, Yibo Zhang, Aydogan Ozcan","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Applied Physics (physics.app-ph); Optics (physics.optics)","We present a deep learning framework based on a generative adversarial network (GAN) to perform super-resolution in coherent imaging systems. We demonstrate that this framework can enhance the resolution of both pixel size-limited and diffraction-limited coherent imaging systems. We experimentally validated the capabilities of this deep learning-based coherent imaging approach by super-resolving complex images acquired using a lensfree on-chip holographic microscope, the resolution of which was pixel size-limited. Using the same GAN-based approach, we also improved the resolution of a lens-based holographic imaging system that was limited in resolution by the numerical aperture of its objective lens. This deep learning-based super-resolution framework can be broadly applied to enhance the space-bandwidth product of coherent imaging systems using image data and convolutional neural networks, and provides a rapid, non-iterative method for solving inverse image reconstruction or enhancement problems in optics.","Mon, 15 Oct 2018 18:55:26 UTC (1,703 KB)"
"181","Deep Learning Seismic Interface Detection using the Frozen Gaussian Approximation","James C. Hateley, Jay Roberts, Kyle Mylonakis, Xu Yang","Geophysics (physics.geo-ph)","We propose a deep learning algorithm for seismic interface detection, with the neural networks trained by synthetic high-frequency seismograms, efficiently generated by the frozen Gaussian approximation (FGA). The usage of high-frequency data is advantageous due to the fact that it can provide high resolution of substructures. However, generation of sufficient synthetic high-frequency data sets for training neural networks are, in general, computationally challenging to well-known methods. This bottleneck is overcome by a highly scalable computational platform built upon the FGA, which comes from the semiclassical theory and approximates the wavefields by a sum of fixed-width (frozen) Gaussian wave packets. We first generate the time series of synthetic seismogram data by FGA, which contains accurate traveltime information (from the ray path) but not exact amplitude information (with asymptotic errors not shrinking to zero even at extremely fine numerical resolution). With the synthetic seismogram generated by the FGA, we build network models using an open source API, GeoSeg, developed using Keras and Tensorflow. In particular, networks using encoder-decoder and UNet architectures, despite only being trained on FGA data, can detect an interface with a high success rate from the seismograms generated by the spectral element method (a different numerical method with exact amplitude information at fine numerical resolution). All the tests are done for P-waves (acoustic) and P- and S-waves (elastic), respectively.","Mon, 15 Oct 2018 18:52:03 UTC (865 KB)"
"182","Improved Photometric Classification of Supernovae using Deep Learning","Adam Moss","Instrumentation and Methods for Astrophysics (astro-ph.IM)","We present improved photometric supernovae classification using deep recurrent neural networks. The main improvements over previous work are (i) the introduction of a time gate in the recurrent cell that uses the observational time as an input; (ii) greatly increased data augmentation including time translation, addition of Gaussian noise and early truncation of the lightcurve. For post Supernovae Photometric Classification Challenge (SPCC) data, using a training fraction of $5.2\%$ (1103 supernovae) of a representational dataset, we obtain a type Ia vs. non type Ia classification accuracy of $93.2 \pm 0.1\%$, a Receiver Operating Characteristic curve AUC of $0.980 \pm 0.002$ and a SPCC figure-of-merit of $F_1=0.57 \pm 0.01$. Using a representational dataset of $50\%$ ($10660$ supernovae), we obtain a classification accuracy of $96.6 \pm 0.1\%$, an AUC of $0.995 \pm 0.001$ and $F_1=0.76 \pm 0.01$. We found the non-representational training set of the SPCC resulted in a large degradation in performance due to a lack of faint supernovae, but this can be migrated by the introduction of only a small number ($\sim 100$) of faint training samples. We also outline ways in which this could be achieved using unsupervised domain adaptation.","Mon, 15 Oct 2018 15:01:35 UTC (560 KB)"
"183","Virtualization of tissue staining in digital pathology using an unsupervised deep learning approach","Amal Lahiani, Jacob Gildenblat, Irina Klaman, Shadi Albarqouni, Nassir Navab, Eldad Klaiman","Computer Vision and Pattern Recognition (cs.CV)","Histopathological evaluation of tissue samples is a key practice in patient diagnosis and drug development, especially in oncology. Historically, Hematoxylin and Eosin (H&E) has been used by pathologists as a gold standard staining. However, in many cases, various target specific stains, including immunohistochemistry (IHC), are needed in order to highlight specific structures in the tissue. As tissue is scarce and staining procedures are tedious, it would be beneficial to generate images of stained tissue virtually. Virtual staining could also generate in-silico multiplexing of different stains on the same tissue segment. In this paper, we present a sample application that generates FAP-CK virtual IHC images from Ki67-CD8 real IHC images using an unsupervised deep learning approach based on CycleGAN. We also propose a method to deal with tiling artifacts caused by normalization layers and we validate our approach by comparing the results of tissue analysis algorithms for virtual and real images.","Mon, 15 Oct 2018 14:45:53 UTC (2,618 KB)"
"184","Novel deep learning methods for track reconstruction","Steven Farrell, Paolo Calafiura, Mayur Mudigonda, Prabhat, Dustin Anderson, Jean-Roch Vlimant, Stephan Zheng, Josh Bendavid, Maria Spiropulu, Giuseppe Cerati, Lindsey Gray, Jim Kowalkowski, Panagiotis Spentzouris, Aristeidis Tsaris","High Energy Physics - Experiment (hep-ex); Data Analysis, Statistics and Probability (physics.data-an)","For the past year, the HEP.TrkX project has been investigating machine learning solutions to LHC particle track reconstruction problems. A variety of models were studied that drew inspiration from computer vision applications and operated on an image-like representation of tracking detector data. While these approaches have shown some promise, image-based methods face challenges in scaling up to realistic HL-LHC data due to high dimensionality and sparsity. In contrast, models that can operate on the spacepoint representation of track measurements (""hits"") can exploit the structure of the data to solve tasks efficiently. In this paper we will show two sets of new deep learning models for reconstructing tracks using space-point data arranged as sequences or connected graphs. In the first set of models, Recurrent Neural Networks (RNNs) are used to extrapolate, build, and evaluate track candidates akin to Kalman Filter algorithms. Such models can express their own uncertainty when trained with an appropriate likelihood loss function. The second set of models use Graph Neural Networks (GNNs) for the tasks of hit classification and segment classification. These models read a graph of connected hits and compute features on the nodes and edges. They adaptively learn which hit connections are important and which are spurious. The models are scaleable with simple architecture and relatively few parameters. Results for all models will be presented on ACTS generic detector simulated data.","Sun, 14 Oct 2018 21:29:20 UTC (1,239 KB)"
"185","Deep Learning-Based Channel Estimation","Mehran Soltani, Ali Mirzaei, Vahid Pourahmadi, Hamid Sheikhzadeh","Information Theory (cs.IT)","In this paper, we present a deep learning (DL) algorithm for channel estimation in communication systems. We consider the time-frequency response of a fast fading communication channel as a two-dimensional image. The aim is to find the unknown values of the channel response using some known values at the pilot locations. To this end, a general pipeline using deep image processing techniques, image super-resolution (SR) and image restoration (IR) is proposed. This scheme considers the pilot values, altogether, as a low-resolution image and uses an SR network cascaded with a denoising autoencoder as an IR network to estimate the channel. Moreover, a simple implementation of the proposed pipeline is presented. The estimation error shows that the presented algorithm is comparable to the minimum mean square error (MMSE) with full knowledge of the channel statistics and it is better than ALMMSE (an approximation to linear MMSE). The results confirm that this pipeline can be used efficiently in channel estimation.","Sat, 13 Oct 2018 17:08:52 UTC (360 KB)"
"186","Embedded deep learning in ophthalmology: Making ophthalmic imaging smarter","Petteri Teikari, Raymond P. Najjar, Leopold Schmetterer, Dan Milea","Computer Vision and Pattern Recognition (cs.CV)","Deep learning has recently gained high interest in ophthalmology, due to its ability to detect clinically significant features for diagnosis and prognosis. Despite these significant advances, little is known about the ability of various deep learning systems to be embedded within ophthalmic imaging devices, allowing automated image acquisition. In this work, we will review the existing and future directions for ""active acquisition"" embedded deep learning, leading to as high quality images with little intervention by the human operator. In clinical practice, the improved image quality should translate into more robust deep learning-based clinical diagnostics. Embedded deep learning will be enabled by the constantly improving hardware performance with low cost. We will briefly review possible computation methods in larger clinical systems. Briefly, they can be included in a three-layer framework composed of edge, fog and cloud layers, the former being performed at a device-level. Improved edge layer performance via ""active acquisition"" serves as an automatic data curation operator translating to better quality data in electronic health records (EHRs), as well as on the cloud layer, for improved deep learning-based clinical data mining.","Sat, 13 Oct 2018 15:20:32 UTC (3,526 KB)"
"187","Deep learning based cloud detection for remote sensing images by the fusion of multi-scale convolutional features","Zhiwei Li, Huanfeng Shen, Qing Cheng, Yuhao Liu, Shucheng You, Zongyi He","Computer Vision and Pattern Recognition (cs.CV)","Cloud detection is an important preprocessing step for the precise application of optical satellite imagery. In this paper, we propose a deep convolutional neural network based cloud detection method named multi-scale convolutional feature fusion (MSCFF) for remote sensing images. In the network architecture of MSCFF, the encoder and corresponding decoder modules, which provide both local and global context by densifying feature maps with trainable filter banks, are utilized to extract multi-scale and high-level spatial features. The feature maps of multiple scales are then up-sampled and concatenated, and a novel MSCFF module is designed to fuse the features of different scales for the output. The output feature maps of the network are regarded as probability maps, and fed to a binary classifier for the final pixel-wise cloud and cloud shadow segmentation. The MSCFF method was validated on hundreds of globally distributed optical satellite images, with spatial resolutions ranging from 0.5 to 50 m, including Landsat-5/7/8, Gaofen-1/2/4, Sentinel-2, Ziyuan-3, CBERS-04, Huanjing-1, and collected high-resolution images exported from Google Earth. The experimental results indicate that MSCFF has obvious advantages over the traditional rule-based cloud detection methods and the state-of-the-art deep learning models in terms of accuracy, especially in bright surface covered areas. The effectiveness of MSCFF means that it has great promise for the practical application of cloud detection for multiple types of satellite imagery. Our established global high-resolution cloud detection validation dataset has been made available online.","Sat, 13 Oct 2018 05:58:47 UTC (4,419 KB)"
"188","DeepWeeds: A Multiclass Weed Species Image Dataset for Deep Learning","Alex Olsen, Dmitry A. Konovalov, Bronson Philippa, Peter Ridd, Jake C. Wood, Jamie Johns, Wesley Banks, Benjamin Girgenti, Owen Kenny, James Whinney, Brendan Calvert, Mostafa Rahimi Azghadi, Ronald D. White","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Robotic weed control has seen increased research in the past decade with its potential for boosting productivity in agriculture. Majority of works focus on developing robotics for arable croplands, ignoring the significant weed management problems facing rangeland stock farmers. Perhaps the greatest obstacle to widespread uptake of robotic weed control is the robust detection of weed species in their natural environment. The unparalleled successes of deep learning make it an ideal candidate for recognising various weed species in the highly complex Australian rangeland environment. This work contributes the first large, public, multiclass image dataset of weed species from the Australian rangelands; allowing for the development of robust detection methods to make robotic weed control viable. The DeepWeeds dataset consists of 17,509 labelled images of eight nationally significant weed species native to eight locations across northern Australia. This paper also presents a baseline for classification performance on the dataset using the benchmark deep learning models, Inception-v3 and ResNet-50. These models achieved an average classification performance of 87.9% and 90.5%, respectively. This strong result bodes well for future field implementation of robotic weed control methods in the Australian rangelands.","Tue, 9 Oct 2018 05:53:26 UTC (8,547 KB)"
"189","A Gentle Introduction to Deep Learning in Medical Image Processing","Andreas Maier, Christopher Syben, Tobias Lasser, Christian Riess","Computer Vision and Pattern Recognition (cs.CV)","This paper tries to give a gentle introduction to deep learning in medical image processing, proceeding from theoretical foundations to applications. We first discuss general reasons for the popularity of deep learning, including several major breakthroughs in computer science. Next, we start reviewing the fundamental basics of the perceptron and neural networks, along with some fundamental theory that is often omitted. Doing so allows us to understand the reasons for the rise of deep learning in many application domains. Obviously medical image processing is one of these areas which has been largely affected by this rapid progress, in particular in image detection and recognition, image segmentation, image registration, and computer-aided diagnosis. There are also recent trends in physical simulation, modelling, and reconstruction that have led to astonishing results. Yet, some of these approaches neglect prior knowledge and hence bear the risk of producing implausible results. These apparent weaknesses highlight current limitations of deep learning. However, we also briefly discuss promising approaches that might be able to resolve these problems in the future.","Fri, 12 Oct 2018 08:27:53 UTC (4,128 KB)"
"190","Martingale Functional Control variates via Deep Learning","Marc Sabate Vidales, David Siska, Lukasz Szpruch","Computational Finance (q-fin.CP); Machine Learning (cs.LG); Numerical Analysis (math.NA)","We propose black-box-type control variate for Monte Carlo simulations by leveraging the Martingale Representation Theorem and artificial neural networks. We developed several learning algorithms for finding martingale control variate functionals both for the Markovian and non-Markovian setting. The proposed algorithms guarantee convergence to the true solution independently of the quality of the deep learning approximation of the control variate functional. We believe that this is important as the current theory of deep learning functions approximations lacks theoretical foundation. However the quality of the deep learning functional approximation determines the level of benefit of the control variate. The methods are empirically shown to work for high-dimensional problems. We provide diagnostics that shed light on appropriate network architectures.","Thu, 11 Oct 2018 15:53:38 UTC (377 KB)"
"191","Deep Learning for Image Denoising: A Survey","Chunwei Tian, Yong Xu, Lunke Fei, Ke Yan","Computer Vision and Pattern Recognition (cs.CV)","Since the proposal of big data analysis and Graphic Processing Unit (GPU), the deep learning technology has received a great deal of attention and has been widely applied in the field of imaging processing. In this paper, we have an aim to completely review and summarize the deep learning technologies for image denoising proposed in recent years. Morever, we systematically analyze the conventional machine learning methods for image denoising. Finally, we point out some research directions for the deep learning technologies in image denoising.","Thu, 11 Oct 2018 14:43:43 UTC (1,528 KB)"
"192","Deep Learning-Based Model Predictive Control for Resonant Power Converters","Sergio Lucia, Denis Navarro, Benjamin Karg, Hector Sarnago, Oscar Lucia","Optimization and Control (math.OC)","Resonant power converters offer improved levels of efficiency and power density. In order to implement such systems, advanced control techniques are required to take the most of the power converter. In this context, model predictive control arises as a powerful tool that is able to consider nonlinearities and constraints, but it requires the solution of complex optimization problems or strong simplifying assumptions that hinder its application in real situations. Motivated by recent theoretical advances in the field of deep learning, this paper proposes to learn, offline, the optimal control policy defined by a complex model predictive formulation using deep neural networks so that the online use of the learned controller requires only the evaluation of a neural network. The obtained learned controller can be executed very rapidly on embedded hardware. We show the potential of the presented approach on a Hardware-in-the-Loop setup of an FPGA-controlled resonant power converter.","Thu, 11 Oct 2018 07:29:11 UTC (1,074 KB)"
"193","Policy Design for Active Sequential Hypothesis Testing using Deep Learning","Dhruva Kartik, Ekraam Sabir, Urbashi Mitra, Prem Natarajan","Information Theory (cs.IT); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (cs.SY); Statistics Theory (math.ST)","Information theory has been very successful in obtaining performance limits for various problems such as communication, compression and hypothesis testing. Likewise, stochastic control theory provides a characterization of optimal policies for Partially Observable Markov Decision Processes (POMDPs) using dynamic programming. However, finding optimal policies for these problems is computationally hard in general and thus, heuristic solutions are employed in practice. Deep learning can be used as a tool for designing better heuristics in such problems. In this paper, the problem of active sequential hypothesis testing is considered. The goal is to design a policy that can reliably infer the true hypothesis using as few samples as possible by adaptively selecting appropriate queries. This problem can be modeled as a POMDP and bounds on its value function exist in literature. However, optimal policies have not been identified and various heuristics are used. In this paper, two new heuristics are proposed: one based on deep reinforcement learning and another based on a KL-divergence zero-sum game. These heuristics are compared with state-of-the-art solutions and it is demonstrated using numerical experiments that the proposed heuristics can achieve significantly better performance than existing methods in some scenarios.","Thu, 11 Oct 2018 06:15:05 UTC (866 KB)"
"194","A Blended Deep Learning Approach for Predicting User Intended Actions","Fei Tan, Zhi Wei, Jun He, Xiang Wu, Bo Peng, Haoran Liu, Zhenyu Yan","Machine Learning (cs.LG); Human-Computer Interaction (cs.HC); Machine Learning (stat.ML)","User intended actions are widely seen in many areas. Forecasting these actions and taking proactive measures to optimize business outcome is a crucial step towards sustaining the steady business growth. In this work, we focus on pre- dicting attrition, which is one of typical user intended actions. Conventional attrition predictive modeling strategies suffer a few inherent drawbacks. To overcome these limitations, we propose a novel end-to-end learning scheme to keep track of the evolution of attrition patterns for the predictive modeling. It integrates user activity logs, dynamic and static user profiles based on multi-path learning. It exploits historical user records by establishing a decaying multi-snapshot technique. And finally it employs the precedent user intentions via guiding them to the subsequent learning procedure. As a result, it addresses all disadvantages of conventional methods. We evaluate our methodology on two public data repositories and one private user usage dataset provided by Adobe Creative Cloud. The extensive experiments demonstrate that it can offer the appealing performance in comparison with several existing approaches as rated by different popular metrics. Furthermore, we introduce an advanced interpretation and visualization strategy to effectively characterize the periodicity of user activity logs. It can help to pinpoint important factors that are critical to user attrition and retention and thus suggests actionable improvement targets for business practice. Our work will provide useful insights into the prediction and elucidation of other user intended actions as well.","Thu, 11 Oct 2018 02:48:20 UTC (1,099 KB)"
"195","Secure Deep Learning Engineering: A Software Quality Assurance Perspective","Lei Ma, Felix Juefei-Xu, Minhui Xue, Qiang Hu, Sen Chen, Bo Li, Yang Liu, Jianjun Zhao, Jianxiong Yin, Simon See","Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)","Over the past decades, deep learning (DL) systems have achieved tremendous success and gained great popularity in various applications, such as intelligent machines, image processing, speech processing, and medical diagnostics. Deep neural networks are the key driving force behind its recent success, but still seem to be a magic black box lacking interpretability and understanding. This brings up many open safety and security issues with enormous and urgent demands on rigorous methodologies and engineering practice for quality enhancement. A plethora of studies have shown that the state-of-the-art DL systems suffer from defects and vulnerabilities that can lead to severe loss and tragedies, especially when applied to real-world safety-critical applications. In this paper, we perform a large-scale study and construct a paper repository of 223 relevant works to the quality assurance, security, and interpretation of deep learning. We, from a software quality assurance perspective, pinpoint challenges and future opportunities towards universal secure deep learning engineering. We hope this work and the accompanied paper repository can pave the path for the software engineering community towards addressing the pressing industrial demand of secure intelligent applications.","Wed, 10 Oct 2018 14:04:08 UTC (398 KB)"
"196","A Deep Learning Approach to the Inversion of Borehole Resistivity Measurements","M. Shahriari, D. Pardo, A. Picon, A. Galdran, J. Del Ser, C. Torres-Verdin","Machine Learning (cs.LG)","We use borehole resistivity measurements to map the electrical properties of the subsurface and to increase the productivity of a reservoir. When used for geosteering purposes, it becomes essential to invert them in real time. In this work, we explore the possibility of using Deep Neural Network (DNN) to perform a rapid inversion of borehole resistivity measurements. Herein, we build a DNN that approximates the following inverse problem: given a set of borehole resistivity measurements, the DNN is designed to deliver a physically meaningful and data-consistent piecewise one-dimensional layered model of the surrounding subsurface. Once the DNN is built, we can perform the actual inversion of the field measurements in real time. We illustrate the performance of DNN of logging-while-drilling measurements acquired on high-angle wells via synthetic data.","Fri, 5 Oct 2018 13:50:19 UTC (6,363 KB)"
"197","Apprenticeship Bootstrapping Via Deep Learning with a Safety Net for UAV-UGV Interaction","Hung Nguyen, Vu Tran, Tung Nguyen, Matthew Garratt, Kathryn Kasmarik, Michael Barlow, Sreenatha Anavatti, Hussein Abbass","Robotics (cs.RO)","In apprenticeship learning (AL), agents learn by watching or acquiring human demonstrations on some tasks of interest. However, the lack of human demonstrations in novel tasks where they may not be a human expert yet, or when it is too expensive and/or time consuming to acquire human demonstrations motivated a new algorithm: Apprenticeship bootstrapping (ABS). The basic idea is to learn from demonstrations on sub-tasks then autonomously bootstrap a model on the main, more complex, task. The original ABS used inverse reinforcement learning (ABS-IRL). However, the approach is not suitable for continuous action spaces. In this paper, we propose ABS via Deep learning (ABS-DL). It is first validated in a simulation environment on an aerial and ground coordination scenario, where an Unmanned Aerial Vehicle (UAV) is required to maintain three Unmanned Ground Vehicles (UGVs) within a field of view of the UAV 's camera (FoV). Moving a machine learning algorithm from a simulation environment to an actual physical platform is challenging because `mistakes' made by the algorithm while learning could lead to the damage of the platform. We then take this extra step to test the algorithm in a physical environment. We propose a safety-net as a protection layer to ensure that the autonomy of the algorithm in learning does not compromise the safety of the platform. The tests of ABS-DL in the real environment can guarantee a damage-free, collision avoidance behaviour of autonomous bodies. The results show that performance of the proposed approach is comparable to that of a human, and competitive to the traditional approach using expert demonstrations performed on the composite task. The proposed safety-net approach demonstrates its advantages when it enables the UAV to operate more safely under the control of the ABS-DL algorithm.","Wed, 10 Oct 2018 02:46:23 UTC (3,447 KB)"
"198","Multi-Institutional Deep Learning Modeling Without Sharing Patient Data: A Feasibility Study on Brain Tumor Segmentation","Micah J Sheller, G Anthony Reina, Brandon Edwards, Jason Martin, Spyridon Bakas","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning models for semantic segmentation of images require large amounts of data. In the medical imaging domain, acquiring sufficient data is a significant challenge. Labeling medical image data requires expert knowledge. Collaboration between institutions could address this challenge, but sharing medical data to a centralized location faces various legal, privacy, technical, and data-ownership challenges, especially among international institutions. In this study, we introduce the first use of federated learning for multi-institutional collaboration, enabling deep learning modeling without sharing patient data. Our quantitative results demonstrate that the performance of federated semantic segmentation models (Dice=0.852) on multimodal brain scans is similar to that of models trained by sharing data (Dice=0.862). We compare federated learning with two alternative collaborative learning methods and find that they fail to match the performance of federated learning.","Wed, 10 Oct 2018 00:05:44 UTC (629 KB)[v2] Mon, 22 Oct 2018 18:51:38 UTC (629 KB)"
"199","Inter-Scanner Harmonization of High Angular Resolution DW-MRI using Null Space Deep Learning","Vishwesh Nath, Prasanna Parvathaneni, Colin B. Hansen, Allison E. Hainline, Camilo Bermudez, Samuel Remedios, Justin A. Blaber, Kurt G. Schilling, Ilwoo Lyu, Vaibhav Janve, Yurui Gao, Iwona Stepniewska, Baxter P. Rogers, Allen T. Newton, L. Taylor Davis, Jeff Luci, Adam W. Anderson, Bennett A. Landman","Computer Vision and Pattern Recognition (cs.CV)","Diffusion-weighted magnetic resonance imaging (DW-MRI) allows for non-invasive imaging of the local fiber architecture of the human brain at a millimetric scale. Multiple classical approaches have been proposed to detect both single (e.g., tensors) and multiple (e.g., constrained spherical deconvolution, CSD) fiber population orientations per voxel. However, existing techniques generally exhibit low reproducibility across MRI scanners. Herein, we propose a data-driven tech-nique using a neural network design which exploits two categories of data. First, training data were acquired on three squirrel monkey brains using ex-vivo DW-MRI and histology of the brain. Second, repeated scans of human subjects were acquired on two different scanners to augment the learning of the network pro-posed. To use these data, we propose a new network architecture, the null space deep network (NSDN), to simultaneously learn on traditional observed/truth pairs (e.g., MRI-histology voxels) along with repeated observations without a known truth (e.g., scan-rescan MRI). The NSDN was tested on twenty percent of the histology voxels that were kept completely blind to the network. NSDN significantly improved absolute performance relative to histology by 3.87% over CSD and 1.42% over a recently proposed deep neural network approach. More-over, it improved reproducibility on the paired data by 21.19% over CSD and 10.09% over a recently proposed deep approach. Finally, NSDN improved gen-eralizability of the model to a third in vivo human scanner (which was not used in training) by 16.08% over CSD and 10.41% over a recently proposed deep learn-ing approach. This work suggests that data-driven approaches for local fiber re-construction are more reproducible, informative and precise and offers a novel, practical method for determining these models.","Tue, 9 Oct 2018 21:52:10 UTC (656 KB)"
"200","Optimized Gated Deep Learning Architectures for Sensor Fusion","Myung Seok Shim, Peng Li","Machine Learning (cs.LG); Machine Learning (stat.ML)","Sensor fusion is a key technology that integrates various sensory inputs to allow for robust decision making in many applications such as autonomous driving and robot control. Deep neural networks have been adopted for sensor fusion in a body of recent studies. Among these, the so-called netgated architecture was proposed, which has demonstrated improved performances over the conventional convolutional neural networks (CNN). In this paper, we address several limitations of the baseline negated architecture by proposing two further optimized architectures: a coarser-grained gated architecture employing (feature) group-level fusion weights and a two-stage gated architectures leveraging both the group-level and feature level fusion weights. Using driving mode prediction and human activity recognition datasets, we demonstrate the significant performance improvements brought by the proposed gated architectures and also their robustness in the presence of sensor noise and failures.","Mon, 8 Oct 2018 18:24:12 UTC (994 KB)"
"201","Novel Massive MIMO Channel Sounding Data Applied to Deep Learning-based Indoor Positioning","Maximilian Arnold, Jakob Hoydis, Stephan ten Brink","Signal Processing (eess.SP)","With a significant increase in area throughput, Massive MIMO has become an enabling technology for fifth generation (5G) wireless mobile communication systems. Although prototypes were built, an openly available dataset for channel impulse responses to verify assumptions, e.g. regarding channel sparsity, is not yet available. In this paper, we introduce a novel channel sounder architecture, capable of measuring multiantenna and multi-subcarrier channel state information (CSI) at different frequency bands, antenna geometries and propagation environments. The channel sounder has been verified by evaluation of channel data from first measurements. Such datasets can be used to study various deep-learning (DL) techniques in different applications, e.g., for indoor user positioning in three dimensions, as is done in this paper. Not only do we achieve an accuracy better than 25 cm for line of sight (LoS), as is comparable to state-of-the-art conventional positioning techniques, but also obtain similar precision for the more challenging case of non-line of sight (NLoS). Further extensive indoor/outdoor measurement campaigns will provide a more comprehensive open CSI dataset, tagged with positions, for the scientific community to further test various algorithms.","Mon, 8 Oct 2018 05:40:04 UTC (2,346 KB)"
"202","Deep learning with differential Gaussian process flows","Pashupati Hegde, Markus Heinonen, Harri Lahdesmaki, Samuel Kaski","Machine Learning (cs.LG); Machine Learning (stat.ML)","We propose a novel deep learning paradigm of differential flows that learn a stochastic differential equation transformations of inputs prior to a standard classification or regression function. The key property of differential Gaussian processes is the warping of inputs through infinitely deep, but infinitesimal, differential fields, that generalise discrete layers into a dynamical system. We demonstrate state-of-the-art results that exceed the performance of deep Gaussian processes and neural networks","Tue, 9 Oct 2018 15:15:23 UTC (3,672 KB)[v2] Mon, 15 Oct 2018 11:46:33 UTC (2,587 KB)"
"203","Hartley Spectral Pooling for Deep Learning","Hao Zhang, Jianwei Ma","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Signal Processing (eess.SP); Machine Learning (stat.ML)","In most convolution neural networks (CNNs), downsampling hidden layers is adopted for increasing computation efficiency and the receptive field size. Such operation is commonly so-called pooling. Maximation and averaging over sliding windows (max/average pooling), and plain downsampling in the form of strided convolution are popular pooling methods. Since the pooling is a lossy procedure, a motivation of our work is to design a new pooling approach for less lossy in the dimensionality reduction. Inspired by the Fourier spectral pooling(FSP) proposed by Rippel et. al. [1], we present the Hartley transform based spectral pooling method in CNNs. Compared with FSP, the proposed spectral pooling avoids the use of complex arithmetic for frequency representation and reduces the computation. Spectral pooling preserves more structure features for network's discriminability than max and average pooling. We empirically show that Hartley spectral pooling gives rise to the convergence of training CNNs on MNIST and CIFAR-10 datasets.","Sun, 7 Oct 2018 06:57:01 UTC (804 KB)"
"204","A Comprehensive Survey of Deep Learning for Image Captioning","Md. Zakir Hossain, Ferdous Sohel, Mohd Fairuz Shiratuddin, Hamid Laga","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Generating a description of an image is called image captioning. Image captioning requires to recognize the important objects, their attributes and their relationships in an image. It also needs to generate syntactically and semantically correct sentences. Deep learning-based techniques are capable of handling the complexities and challenges of image captioning. In this survey paper, we aim to present a comprehensive review of existing deep learning-based image captioning techniques. We discuss the foundation of the techniques to analyze their performances, strengths and limitations. We also discuss the datasets and the evaluation metrics popularly used in deep learning based automatic image captioning.","Sat, 6 Oct 2018 16:31:52 UTC (3,066 KB)[v2] Sun, 14 Oct 2018 04:55:06 UTC (3,066 KB)"
"205","Deep Learning: Extrapolation Tool for Ab Initio Nuclear Theory","Gianina Alina Negoita, James P. Vary, Glenn R. Luecke, Pieter Maris, Andrey M. Shirokov, Ik Jae Shin, Youngman Kim, Esmond G. Ng, Chao Yang, Matthew Lockner, Gurpur M. Prabhu","Nuclear Theory (nucl-th); Machine Learning (cs.LG)","Ab initio approaches in nuclear theory, such as the No-Core Shell Model (NCSM), have been developed for approximately solving finite nuclei with realistic strong interactions. The NCSM and other approaches require an extrapolation of the results obtained in a finite basis space to the infinite basis space limit and assessment of the uncertainty of those extrapolations. Each observable requires a separate extrapolation and most observables have no proven extrapolation method. We propose a feed-forward artificial neural network (ANN) method as an extrapolation tool to obtain the ground state energy and the ground state point-proton root-mean-square (rms) radius along with their extrapolation uncertainties. The designed ANNs are sufficient to produce results for these two very different observables in $^6$Li from the ab initio NCSM results in small basis spaces that satisfy the following theoretical physics condition: independence of basis space parameters in the limit of extremely large matrices. Comparisons of the ANN results with other extrapolation methods are also provided.","Sat, 6 Oct 2018 00:44:34 UTC (319 KB)[v2] Sat, 10 Nov 2018 02:59:05 UTC (319 KB)"
"206","DeepImageSpam: Deep Learning based Image Spam Detection","Amara Dinesh Kumar, Vinayakumar R, Soman KP","Computer Vision and Pattern Recognition (cs.CV); Cryptography and Security (cs.CR)","Hackers and spammers are employing innovative and novel techniques to deceive novice and even knowledgeable internet users. Image spam is one of such technique where the spammer varies and changes some portion of the image such that it is indistinguishable from the original image fooling the users. This paper proposes a deep learning based approach for image spam detection using the convolutional neural networks which uses a dataset with 810 natural images and 928 spam images for classification achieving an accuracy of 91.7% outperforming the existing image processing and machine learning techniques","Wed, 3 Oct 2018 09:35:01 UTC (278 KB)"
"207","Saliency Prediction in the Deep Learning Era: An Empirical Investigation","Ali Borji","Computer Vision and Pattern Recognition (cs.CV)","Visual saliency models have enjoyed a big leap in performance in recent years, thanks to advances in deep learning and large scale annotated data. Despite enormous effort and huge breakthroughs, however, models still fall short in reaching human-level accuracy. In this work, I explore the landscape of the field emphasizing on new deep saliency models, benchmarks, and datasets. A large number of image and video saliency models are reviewed and compared over two image benchmarks and two large scale video datasets. Further, I identify factors that contribute to the gap between models and humans and discuss remaining issues that need to be addressed to build the next generation of more powerful saliency models. Some specific questions that are addressed include: in what ways current models fail, how to remedy them, what can be learned from cognitive studies of attention, how explicit saliency judgments relate to fixations, how to conduct fair model comparison, and what are the emerging applications of saliency models.","Mon, 8 Oct 2018 21:50:27 UTC (13,276 KB)[v2] Thu, 11 Oct 2018 18:35:17 UTC (12,685 KB)"
"208","Illumination Pattern Design with Deep Learning for Single-Shot Fourier Ptychographic Microscopy","Yi Fei Cheng, Megan Strachan, Zachary Weiss, Moniher Deb, Dawn Carone, Vidya Ganapati","Image and Video Processing (eess.IV)","Fourier ptychographic microscopy allows for the collection of images with a high space-bandwidth product at the cost of temporal resolution. In Fourier ptychographic microscopy, the light source of a conventional widefield microscope is replaced with a light-emitting diode (LED) matrix, and multiple images are collected with different LED illumination patterns. From these images, a higher-resolution image can be computationally reconstructed without sacrificing field-of-view. We use deep learning to achieve single-shot imaging without sacrificing the space-bandwidth product, reducing the acquisition time in Fourier ptychographic microscopy by a factor of 69. In our deep learning approach, a training dataset of high-resolution images is used to jointly optimize a single LED illumination pattern with the parameters of a reconstruction algorithm. Our work paves the way for high-throughput imaging in biological studies.","Fri, 5 Oct 2018 16:41:32 UTC (3,934 KB)"
"209","Wide and Deep Learning for Peer-to-Peer Lending","Kaveh Bastani, Elham Asgari, Hamed Namavari","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Risk Management (q-fin.RM)","This paper proposes a two-stage scoring approach to help lenders decide their fund allocations in the peer-to-peer (P2P) lending market. The existing scoring approaches focus on only either probability of default (PD) prediction, known as credit scoring, or profitability prediction, known as profit scoring, to identify the best loans for investment. Credit scoring fails to deliver the main need of lenders on how much profit they may obtain through their investment. On the other hand, profit scoring can satisfy that need by predicting the investment profitability. However, profit scoring completely ignores the class imbalance problem where most of the past loans are non-default. Consequently, ignorance of the class imbalance problem significantly affects the accuracy of profitability prediction. Our proposed two-stage scoring approach is an integration of credit scoring and profit scoring to address the above challenges. More specifically, stage 1 is designed as credit scoring to identify non-default loans while the imbalanced nature of loan status is considered in PD prediction. The loans identified as non-default are then moved to stage 2 for prediction of profitability, measured by internal rate of return. Wide and deep learning is used to build the predictive models in both stages to achieve both memorization and generalization. Extensive numerical studies are conducted based on real-world data to verify the effectiveness of the proposed approach. The numerical studies indicate our two-stage scoring approach outperforms the existing credit scoring and profit scoring approaches.","Fri, 5 Oct 2018 00:54:06 UTC (1,769 KB)[v2] Tue, 9 Oct 2018 02:03:13 UTC (1,440 KB)"
"210","Deep learning cardiac motion analysis for human survival prediction","Ghalib A. Bello, Timothy J.W. Dawes, Jinming Duan, Carlo Biffi, Antonio de Marvao, Luke S.G.E. Howard, J. Simon R. Gibbs, Martin R. Wilkins, Stuart A. Cook, Daniel Rueckert, Declan P. O'Regan","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Motion analysis is used in computer vision to understand the behaviour of moving objects in sequences of images. Optimising the interpretation of dynamic biological systems requires accurate and precise motion tracking as well as efficient representations of high-dimensional motion trajectories so that these can be used for prediction tasks. Here we use image sequences of the heart, acquired using cardiac magnetic resonance imaging, to create time-resolved three-dimensional segmentations using a fully convolutional network trained on anatomical shape priors. This dense motion model formed the input to a supervised denoising autoencoder (4Dsurvival), which is a hybrid network consisting of an autoencoder that learns a task-specific latent code representation trained on observed outcome data, yielding a latent representation optimised for survival prediction. To handle right-censored survival outcomes, our network used a Cox partial likelihood loss function. In a study of 302 patients the predictive accuracy (quantified by Harrell's C-index) was significantly higher (p < .0001) for our model C=0.73 (95$\%$ CI: 0.68 - 0.78) than the human benchmark of C=0.59 (95$\%$ CI: 0.53 - 0.65). This work demonstrates how a complex computer vision task using high-dimensional medical image data can efficiently predict human survival.","Mon, 8 Oct 2018 11:34:38 UTC (2,803 KB)"
"211","Characterizing Deep-Learning I/O Workloads in TensorFlow","Steven W. D. Chien, Stefano Markidis, Chaitanya Prasad Sishtla, Luis Santos, Pawel Herman, Sai Narasimhamurthy, Erwin Laure","Distributed, Parallel, and Cluster Computing (cs.DC)","The performance of Deep-Learning (DL) computing frameworks rely on the performance of data ingestion and checkpointing. In fact, during the training, a considerable high number of relatively small files are first loaded and pre-processed on CPUs and then moved to accelerator for computation. In addition, checkpointing and restart operations are carried out to allow DL computing frameworks to restart quickly from a checkpoint. Because of this, I/O affects the performance of DL applications. In this work, we characterize the I/O performance and scaling of TensorFlow, an open-source programming framework developed by Google and specifically designed for solving DL problems. To measure TensorFlow I/O performance, we first design a micro-benchmark to measure TensorFlow reads, and then use a TensorFlow mini-application based on AlexNet to measure the performance cost of I/O and checkpointing in TensorFlow. To improve the checkpointing performance, we design and implement a burst buffer. We find that increasing the number of threads increases TensorFlow bandwidth by a maximum of 2.3x and 7.8x on our benchmark environments. The use of the tensorFlow prefetcher results in a complete overlap of computation on accelerator and input pipeline on CPU eliminating the effective cost of I/O on the overall performance. The use of a burst buffer to checkpoint to a fast small capacity storage and copy asynchronously the checkpoints to a slower large capacity storage resulted in a performance improvement of 2.6x with respect to checkpointing directly to slower storage on our benchmark environment.","Sat, 6 Oct 2018 18:31:51 UTC (344 KB)"
"212","Deep Learning for micro-Electrocorticographic (レECoG) Data","Xi Wang, C. Alexis Gkogkidis, Robin T. Schirrmeister, Felix A. Heilmeyer, Mortimer Gierthmuehlen, Fabian Kohler, Martin Schuettler, Thomas Stieglitz, Tonio Ball","Signal Processing (eess.SP); Neurons and Cognition (q-bio.NC)","Machine learning can extract information from neural recordings, e.g., surface EEG, ECoG and レECoG, and therefore plays an important role in many research and clinical applications. Deep learning with artificial neural networks has recently seen increasing attention as a new approach in brain signal decoding. Here, we apply a deep learning approach using convolutional neural networks to レECoG data obtained with a wireless, chronically implanted system in an ovine animal model. Regularized linear discriminant analysis (rLDA), a filter bank component spatial pattern (FBCSP) algorithm and convolutional neural networks (ConvNets) were applied to auditory evoked responses captured by レECoG. We show that compared with rLDA and FBCSP, significantly higher decoding accuracy can be obtained by ConvNets trained in an end-to-end manner, i.e., without any predefined signal features. Deep learning thus proves a promising technique for レECoG-based brain-machine interfacing applications.","Fri, 5 Oct 2018 09:44:09 UTC (1,479 KB)"
"213","Deep Learning Approaches for Understanding Simple Speech Commands","Roman A. Solovyev, Maxim Vakhrushev, Alexander Radionov, Vladimir Aliev, Alexey A. Shvets","Sound (cs.SD); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS)","Automatic classification of sound commands is becoming increasingly important, especially for mobile and embedded devices. Many of these devices contain both cameras and microphones, and companies that develop them would like to use the same technology for both of these classification tasks. One way of achieving this is to represent sound commands as images, and use convolutional neural networks when classifying images as well as sounds. In this paper we consider several approaches to the problem of sound classification that we applied in TensorFlow Speech Recognition Challenge organized by Google Brain team on the Kaggle platform. Here we show different representation of sounds (Wave frames, Spectrograms, Mel-Spectrograms, MFCCs) and apply several 1D and 2D convolutional neural networks in order to get the best performance. Our experiments show that we found appropriate sound representation and corresponding convolutional neural networks. As a result we achieved good classification accuracy that allowed us to finish the challenge on 8-th place among 1315 teams.","Thu, 4 Oct 2018 17:42:18 UTC (766 KB)"
"214","Direct Prediction of Cardiovascular Mortality from Low-dose Chest CT using Deep Learning","Sanne G.M. van Velzen, Majd Zreik, Nikolas Lessmann, Max A. Viergever, Pim A. de Jong, Helena M. Verkooijen, Ivana I<U+0161>gum","Computer Vision and Pattern Recognition (cs.CV)","Cardiovascular disease (CVD) is a leading cause of death in the lung cancer screening population. Chest CT scans made in lung cancer screening are suitable for identification of participants at risk of CVD. Existing methods analyzing CT images from lung cancer screening for prediction of CVD events or mortality use engineered features extracted from the images combined with patient information. In this work we propose a method that automatically predicts 5-year cardiovascular mortality directly from chest CT scans without the need for hand-crafting image features. A set of 1,583 participants of the National Lung Screening Trial was included (1,188 survivors, 395 non-survivors). Low-dose chest CT images acquired at baseline were analyzed and the follow-up time was 5 years. To limit the analysis to the heart region, the heart was first localized by our previously developed algorithm for organ localization exploiting convolutional neural networks. Thereafter, a convolutional autoencoder was used to encode the identified heart region. Finally, based on the extracted encodings subjects were classified into survivors or non-survivors using a support vector machine classifier. The performance of the method was assessed in eight cross-validation experiments with 1,433 images used for training, 50 for validation and 100 for testing. The method achieved a performance with an area under the ROC curve of 0.72. The results demonstrate that prediction of cardiovascular mortality directly from low-dose screening chest CT scans, without hand-crafted features, is feasible, allowing identification of subjects at risk of fatal CVD events.","Thu, 4 Oct 2018 15:33:14 UTC (462 KB)"
"215","Italian Event Detection Goes Deep Learning","Tommaso Caselli","Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","This paper reports on a set of experiments with different word embeddings to initialize a state-of-the-art Bi-LSTM-CRF network for event detection and classification in Italian, following the EVENTI evaluation exercise. The net- work obtains a new state-of-the-art result by improving the F1 score for detection of 1.3 points, and of 6.5 points for classification, by using a single step approach. The results also provide further evidence that embeddings have a major impact on the performance of such architectures.","Thu, 4 Oct 2018 14:09:20 UTC (63 KB)"
"216","Exascale Deep Learning for Climate Analytics","Thorsten Kurth, Sean Treichler, Joshua Romero, Mayur Mudigonda, Nathan Luehr, Everett Phillips, Ankur Mahesh, Michael Matheson, Jack Deslippe, Massimiliano Fatica, Prabhat, Michael Houston","Distributed, Parallel, and Cluster Computing (cs.DC)","We extract pixel-level masks of extreme weather patterns using variants of Tiramisu and DeepLabv3+ neural networks. We describe improvements to the software frameworks, input pipeline, and the network training algorithms necessary to efficiently scale deep learning on the Piz Daint and Summit systems. The Tiramisu network scales to 5300 P100 GPUs with a sustained throughput of 21.0 PF/s and parallel efficiency of 79.0%. DeepLabv3+ scales up to 27360 V100 GPUs with a sustained throughput of 325.8 PF/s and a parallel efficiency of 90.7% in single precision. By taking advantage of the FP16 Tensor Cores, a half-precision version of the DeepLabv3+ network achieves a peak and sustained throughput of 1.13 EF/s and 999.0 PF/s respectively.","Wed, 3 Oct 2018 22:45:53 UTC (1,736 KB)"
"217","McTorch, a manifold optimization library for deep learning","Mayank Meghwanshi, Pratik Jawanpuria, Anoop Kunchukuttan, Hiroyuki Kasai, Bamdev Mishra","Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","In this paper, we introduce McTorch, a manifold optimization library for deep learning that extends PyTorch. It aims to lower the barrier for users wishing to use manifold constraints in deep learning applications, i.e., when the parameters are constrained to lie on a manifold. Such constraints include the popular orthogonality and rank constraints, and have been recently used in a number of applications in deep learning. McTorch follows PyTorch's architecture and decouples manifold definitions and optimizers, i.e., once a new manifold is added it can be used with any existing optimizer and vice-versa. McTorch is available at this https URL .","Wed, 3 Oct 2018 16:02:20 UTC (80 KB)[v2] Thu, 4 Oct 2018 04:12:12 UTC (80 KB)"
"218","A deep learning pipeline for product recognition on store shelves","Alessio Tonioni, Eugenio Serro, Luigi Di Stefano","Computer Vision and Pattern Recognition (cs.CV)","Recognition of grocery products in store shelves poses peculiar challenges. Firstly, the task mandates the recognition of an extremely high number of different items, in the order of several thousands for medium-small shops, with many of them featuring small inter and intra class variability. Then, available product databases usually include just one or a few studio-quality images per product (referred to herein as reference images), whilst at test time recognition is performed on pictures displaying a portion of a shelf containing several products and taken in the store by cheap cameras (referred to as query images). Moreover, as the items on sale in a store as well as their appearance change frequently over time, a practical recognition system should handle seamlessly new products/packages. Inspired by recent advances in object detection and image retrieval, we propose to leverage on state of the art object detectors based on deep learning to obtain an initial productagnostic item detection. Then, we pursue product recognition through a similarity search between global descriptors computed on reference and cropped query images. To maximize performance, we learn an ad-hoc global descriptor by a CNN trained on reference images based on an image embedding loss. Our system is computationally expensive at training time but can perform recognition rapidly and accurately at test time.","Wed, 3 Oct 2018 13:36:26 UTC (7,914 KB)[v2] Thu, 4 Oct 2018 16:18:40 UTC (7,914 KB)"
"219","Theory of Generative Deep Learning : Probe Landscape of Empirical Error via Norm Based Capacity Control","Wendi Xu, Ming Zhang","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)","Despite its remarkable empirical success as a highly competitive branch of artificial intelligence, deep learning is often blamed for its widely known low interpretation and lack of firm and rigorous mathematical foundation. However, most theoretical endeavor is devoted in discriminative deep learning case, whose complementary part is generative deep learning. To the best of our knowledge, we firstly highlight landscape of empirical error in generative case to complete the full picture through exquisite design of image super resolution under norm based capacity control. Our theoretical advance in interpretation of the training dynamic is achieved from both mathematical and biological sides.","Wed, 3 Oct 2018 08:10:51 UTC (938 KB)"
"220","Extreme Augmentation : Can deep learning based medical image segmentation be trained using a single manually delineated scan?","Bilwaj Gaonkar, Alex Bui, Matthew Brown, Luke Macyszyn","Computer Vision and Pattern Recognition (cs.CV)","Yes, it can. Data augmentation is perhaps the oldest preprocessing step in computer vision literature. Almost every computer vision model trained on imaging data uses some form of augmentation. In this paper, we use the inter-vertebral disk segmentation task alongside a deep residual U-Net as the learning model, to explore the effectiveness of augmentation. In the extreme, we observed that a model trained on patches extracted from just one scan, with each patch augmented 50 times; achieved a Dice score of 0.73 in a validation set of 40 cases. Qualitative evaluation indicated a clinically usable segmentation algorithm, which appropriately segments regions of interest, alongside limited false positive specks. When the initial patches are extracted from nine scans the average Dice coefficient jumps to 0.86 and most of the false positives disappear. While this still falls short of state-of-the-art deep learning based segmentation of discs reported in literature, qualitative examination reveals that it does yield segmentation, which can be amended by expert clinicians with minimal effort to generate additional data for training improved deep models. Extreme augmentation of training data, should thus be construed as a strategy for training deep learning based algorithms, when very little manually annotated data is available to work with. Models trained with extreme augmentation can then be used to accelerate the generation of manually labelled data. Hence, we show that extreme augmentation can be a valuable tool in addressing scaling up small imaging data sets to address medical image segmentation tasks.","Wed, 3 Oct 2018 08:10:35 UTC (3,203 KB)"
"221","A Deep Learning Architecture for De-identification of Patient Notes: Implementation and Evaluation","Kaung Khin, Philipp Burckhardt, Rema Padman","Computation and Language (cs.CL)","De-identification is the process of removing 18 protected health information (PHI) from clinical notes in order for the text to be considered not individually identifiable. Recent advances in natural language processing (NLP) has allowed for the use of deep learning techniques for the task of de-identification. In this paper, we present a deep learning architecture that builds on the latest NLP advances by incorporating deep contextualized word embeddings and variational drop out Bi-LSTMs. We test this architecture on two gold standard datasets and show that the architecture achieves state-of-the-art performance on both data sets while also converging faster than other systems without the use of dictionaries or other knowledge sources.","Wed, 3 Oct 2018 02:53:04 UTC (58 KB)"
"222","Deep Learning Based Caching for Self-Driving Car in Multi-access Edge Computing","Anselme Ndikumana, Nguyen H. Tran, Choong Seon Hong","Networking and Internet Architecture (cs.NI)","Once self-driving car becomes a reality and passengers are no longer worry about it, they will need to find new ways of entertainment. However, retrieving entertainment contents at the Data Center (DC) can hinder content delivery service due to high delay of car-to-DC communication. To address these challenges, we propose a deep learning based caching for self-driving car, by using Deep Learning approaches deployed on the Multi-access Edge Computing (MEC) structure. First, at DC, Multi-Layer Perceptron (MLP) is used to predict the probabilities of contents to be requested in specific areas. To reduce the car-DC delay, MLP outputs are logged into MEC servers attached to roadside units. Second, in order to cache entertainment contents stylized for car passengers' features such as age and gender, Convolutional Neural Network (CNN) is used to predict age and gender of passengers. Third, each car requests MLP output from MEC server and compares its CNN and MLP outputs by using k-means and binary classification. Through this, the self-driving car can identify the contents need to be downloaded from the MEC server and cached. Finally, we formulate deep learning based caching in the self-driving car that enhances entertainment services as an optimization problem whose goal is to minimize content downloading delay. To solve the formulated problem, a Block Successive Majorization-Minimization (BS-MM) technique is applied. The simulation results show that the accuracy of our prediction for the contents need to be cached in the areas of the self-driving car is achieved at 98.04% and our approach can minimize delay.","Wed, 3 Oct 2018 00:35:40 UTC (4,360 KB)"
"223","PromID: human promoter prediction by deep learning","Ramzan Umarov, Hiroyuki Kuwahara, Yu Li, Xin Gao, Victor Solovyev","Genomics (q-bio.GN); Machine Learning (cs.LG); Machine Learning (stat.ML)","Computational identification of promoters is notoriously difficult as human genes often have unique promoter sequences that provide regulation of transcription and interaction with transcription initiation complex. While there are many attempts to develop computational promoter identification methods, we have no reliable tool to analyze long genomic sequences. In this work we further develop our deep learning approach that was relatively successful to discriminate short promoter and non-promoter sequences. Instead of focusing on the classification accuracy, in this work we predict the exact positions of the TSS inside the genomic sequences testing every possible location. We studied human promoters to find effective regions for discrimination and built corresponding deep learning models. These models use adaptively constructed negative set which iteratively improves the models discriminative ability. The developed promoter identification models significantly outperform the previously developed promoter prediction programs by considerably reducing the number of false positive predictions. The best model we have built has recall 0.76, precision 0.77 and MCC 0.76, while the next best tool FPROM achieved precision 0.48 and MCC 0.60 for the recall of 0.75. Our method is available at this http URL.","Tue, 2 Oct 2018 17:35:46 UTC (3,344 KB)"
"224","Training compact deep learning models for video classification using circulant matrices","Alexandre Araujo, Benjamin Negrevergne, Yann Chevaleyre, Jamal Atif","Computer Vision and Pattern Recognition (cs.CV)","In real world scenarios, model accuracy is hardly the only factor to consider. Large models consume more memory and are computationally more intensive, which makes them difficult to train and to deploy, especially on mobile devices. In this paper, we build on recent results at the crossroads of Linear Algebra and Deep Learning which demonstrate how imposing a structure on large weight matrices can be used to reduce the size of the model. We propose very compact models for video classification based on state-of-the-art network architectures such as Deep Bag-of-Frames, NetVLAD and NetFisherVectors. We then conduct thorough experiments using the large YouTube-8M video classification dataset. As we will show, the circulant DBoF embedding achieves an excellent trade-off between size and accuracy.","Tue, 2 Oct 2018 09:45:15 UTC (51 KB)[v2] Mon, 8 Oct 2018 08:40:40 UTC (42 KB)"
"225","Cloud Chaser: Real Time Deep Learning Computer Vision on Low Computing Power Devices","Zhengyi Luo, Austin Small, Liam Dugan, Stephen Lane","Computer Vision and Pattern Recognition (cs.CV)","Internet of Things(IoT) devices, mobile phones, and robotic systems are often denied the power of deep learning algorithms due to their limited computing power. However, to provide time critical services such as emergency response, home assistance, surveillance, etc, these devices often need real time analysis of their camera data. This paper strives to offer a viable approach to integrate high-performance deep learning based computer vision algorithms with low-resource and low-power devices by leveraging the computing power of the cloud. By offloading the computation work to the cloud, no dedicated hardware is needed to enable deep neural networks on existing low computing power devices. A Raspberry Pi based robot, Cloud Chaser, is built to demonstrate the power of using cloud computing to perform real time vision tasks. Furthermore, to reduce latency and improve real time performance, compression algorithms are proposed and evaluated for streaming real-time video frames to the cloud.","Tue, 2 Oct 2018 05:08:12 UTC (3,478 KB)"
"226","Dynamic Sparse Graph for Efficient Deep Learning","Liu Liu, Lei Deng, Xing Hu, Maohua Zhu, Guoqi Li, Yufei Ding, Yuan Xie","Machine Learning (cs.LG); Machine Learning (stat.ML)","We propose to execute deep neural networks (DNNs) with dynamic and sparse graph (DSG) structure for compressive memory and accelerative execution during both training and inference. The great success of DNNs motivates the pursuing of lightweight models for the deployment onto embedded devices. However, most of the previous studies optimize for inference while neglect training or even complicate it. Training is far more intractable, since (i) the neurons dominate the memory cost rather than the weights in inference; (ii) the dynamic activation makes previous sparse acceleration via one-off optimization on fixed weight invalid; (iii) batch normalization (BN) is critical for maintaining accuracy while its activation reorganization damages the sparsity. To address these issues, DSG activates only a small amount of neurons with high selectivity at each iteration via a dimension-reduction search (DRS) and obtains the BN compatibility via a double-mask selection (DMS). Experiments show significant memory saving (1.7-4.5x) and operation reduction (2.3-4.4x) with little accuracy loss on various benchmarks.","Mon, 1 Oct 2018 17:55:43 UTC (980 KB)"
"227","Enhancing Geometric Deep Learning via Graph Filter Deconvolution","Jingkang Yang, Santiago Segarra","Signal Processing (eess.SP)","In this paper, we incorporate a graph filter deconvolution step into the classical geometric convolutional neural network pipeline. More precisely, under the assumption that the graph domain plays a role in the generation of the observed graph signals, we pre-process every signal by passing it through a sparse deconvolution operation governed by a pre-specified filter bank. This deconvolution operation is formulated as a group-sparse recovery problem, and convex relaxations that can be solved efficiently are put forth. The deconvolved signals are then fed into the geometric convolutional neural network, yielding better classification performance than their unprocessed counterparts. Numerical experiments showcase the effectiveness of the deconvolution step on classification tasks on both synthetic and real-world settings.","Mon, 24 Sep 2018 03:23:24 UTC (1,475 KB)"
"228","One Network to Solve All ROIs: Deep Learning CT for Any ROI using Differentiated Backprojection","Yoseob Han, Jong Chul Ye","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Computed tomography for region-of-interest (ROI) reconstruction has advantages of reducing X-ray radiation dose and using a small detector. However, standard analytic reconstruction methods suffer from severe cupping artifacts, and existing model-based iterative reconstruction methods require extensive computations. Recently, we proposed a deep neural network to learn the cupping artifact, but the network is not well generalized for different ROIs due to the singularities in the corrupted images. Therefore, there is an increasing demand for a neural network that works well for any ROI sizes. In this paper, two types of neural networks are designed. The first type learns ROI size-specific cupping artifacts from the analytic reconstruction images, whereas the second type network is to learn to invert the finite Hilbert transform from the truncated differentiated backprojection (DBP) data. Their generalizability for any ROI sizes is then examined. Experimental results show that the new type of neural network significantly outperforms the existing iterative methods for any ROI size in spite of significantly reduced run-time complexity. Since the proposed method consistently surpasses existing methods for any ROIs, it can be used as a general CT reconstruction engine for many practical applications without compromising possible detector truncation.","Mon, 1 Oct 2018 01:51:33 UTC (2,146 KB)"
"229","Deep Learning for End-to-End Atrial Fibrillation Recurrence Estimation","Riddhish Bhalodia, Anupama Goparaju, Tim Sodergren, Alan Morris, Evgueni Kholmovski, Nassir Marrouche, Joshua Cates, Ross Whitaker, Shireen Elhabian","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Left atrium shape has been shown to be an independent predictor of recurrence after atrial fibrillation (AF) ablation. Shape-based representation is imperative to such an estimation process, where correspondence-based representation offers the most flexibility and ease-of-computation for population-level shape statistics. Nonetheless, population-level shape representations in the form of image segmentation and correspondence models derived from cardiac MRI require significant human resources with sufficient anatomy-specific expertise. In this paper, we propose a machine learning approach that uses deep networks to estimate AF recurrence by predicting shape descriptors directly from MRI images, with NO image pre-processing involved. We also propose a novel data augmentation scheme to effectively train a deep network in a limited training data setting. We compare this new method of estimating shape descriptors from images with the state-of-the-art correspondence-based shape modeling that requires image segmentation and correspondence optimization. Results show that the proposed method and the current state-of-the-art produce statistically similar outcomes on AF recurrence, eliminating the need for expensive pre-processing pipelines and associated human labor.","Sun, 30 Sep 2018 22:10:28 UTC (711 KB)"
"230","DELMU: A Deep Learning Approach to Maximising the Utility of Virtualised Millimetre-Wave Backhauls","Rui Li, Chaoyun Zhang, Paul Patras, Pan Cao, John S. Thompson","Networking and Internet Architecture (cs.NI)","Advances in network programmability enable operators to 'slice' the physical infrastructure into independent logical networks. By this approach, each network slice aims to accommodate the demands of increasingly diverse services. However, precise allocation of resources to slices across future 5G millimetre-wave backhaul networks, to optimise the total network utility, is challenging. This is because the performance of different services often depends on conflicting requirements, including bandwidth, sensitivity to delay, or the monetary value of the traffic incurred. In this paper, we put forward a general rate utility framework for slicing mm-wave backhaul links, encompassing all known types of service utilities, i.e. logarithmic, sigmoid, polynomial, and linear. We then introduce DELMU, a deep learning solution that tackles the complexity of optimising non-convex objective functions built upon arbitrary combinations of such utilities. Specifically, by employing a stack of convolutional blocks, DELMU can learn correlations between traffic demands and achievable optimal rate assignments. We further regulate the inferences made by the neural network through a simple 'sanity check' routine, which guarantees both flow rate admissibility within the network's capacity region and minimum service levels. The proposed method can be trained within minutes, following which it computes rate allocations that match those obtained with state-of-the-art global optimisation algorithms, yet orders of magnitude faster. This confirms the applicability of DELMU to highly dynamic traffic regimes and we demonstrate up to 62% network utility gains over a baseline greedy approach.","Sun, 30 Sep 2018 11:17:30 UTC (263 KB)[v2] Tue, 2 Oct 2018 11:01:42 UTC (263 KB)"
"231","A Deep Learning Framework for Single-Sided Sound Speed Inversion in Medical Ultrasound","Micha Feigin, Daniel Freedman, Brian W. Anthony","Machine Learning (cs.LG); Signal Processing (eess.SP); Tissues and Organs (q-bio.TO); Machine Learning (stat.ML)","Ultrasound elastography is gaining traction as an accessible and useful diagnostic tool for such things as cancer detection and differentiation as well as liver and thyroid disease diagnostics. Unfortunately, state of the art acoustic radiation force techniques, essential to promote this goal, are limited to high end ultrasound hardware due to high power requirements; are extremely sensitive to patient and sonographer motion; and generally suffer from low frame rates. Researchers have shown that pressure wave velocity possesses similar diagnostic abilities to shear wave velocity. Using pressure waves removes the need for generating shear waves, which in turn enables elasticity based diagnostic techniques on portable and low cost devices. However, current travel time tomography and full waveform inversion techniques for recovering pressure wave velocities require a full circumferential field of view. Focus based techniques, on the other hand, provide only localized measurements, are sensitive to the intermediate medium and require capturing multiple frames. In this paper, we present a single sided sound speed inversion solution using a fully convolutional deep neural network. We show that it is possible to invert for longitudinal sound speed in soft tissue at real time frame rates. For the computation, analysis is performed on channel data information from three diagonal plane waves. This is the first step towards a full waveform solver using a Deep Learning framework for the elastic and viscoelastic inverse problem.","Sun, 30 Sep 2018 06:07:00 UTC (11,252 KB)[v2] Fri, 2 Nov 2018 21:26:04 UTC (5,644 KB)"
"232","Posture recognition using an RGB-D camera : exploring 3D body modeling and deep learning approaches","Mohamed El Amine Elforaici, Ismail Chaaraoui, Wassim Bouachir, Youssef Ouakrim, Neila Mezghani","Computer Vision and Pattern Recognition (cs.CV)","The emergence of RGB-D sensors offered new possibilities for addressing complex artificial vision problems efficiently. Human posture recognition is among these computer vision problems, with a wide range of applications such as ambient assisted living and intelligent health care systems. In this context, our paper presents novel methods and ideas to design automatic posture recognition systems using an RGB-D camera. More specifically, we introduce two supervised methods to learn and recognize human postures using the main types of visual data provided by an RGB-D camera. The first method is based on convolutional features extracted from 2D images. Convolutional Neural Networks (CNNs) are trained to recognize human postures using transfer learning on RGB and depth images. Secondly, we propose to model the posture using the body joint configuration in the 3D space. Posture recognition is then performed through SVM classification of 3D skeleton-based features. To evaluate the proposed methods, we created a challenging posture recognition dataset with a considerable variability regarding the acquisition conditions. The experimental results demonstrated comparable performances and high precision for both methods in recognizing human postures, with a slight superiority for the CNN-based method when applied on depth images. Moreover, the two approaches demonstrated a high robustness to several perturbation factors, such as scale and orientation change.","Sun, 30 Sep 2018 03:50:09 UTC (558 KB)[v2] Sat, 13 Oct 2018 00:07:11 UTC (558 KB)"
"233","Directional Analysis of Stochastic Gradient Descent via von Mises-Fisher Distributions in Deep learning","Cheolhyoung Lee, Kyunghyun Cho, Wanmo Kang","Machine Learning (cs.LG); Machine Learning (stat.ML)","Although stochastic gradient descent (SGD) is a driving force behind the recent success of deep learning, our understanding of its dynamics in a high-dimensional parameter space is limited. In recent years, some researchers have used the stochasticity of minibatch gradients, or the signal-to-noise ratio, to better characterize the learning dynamics of SGD. Inspired from these work, we here analyze SGD from a geometrical perspective by inspecting the stochasticity of the norms and directions of minibatch gradients. We propose a model of the directional concentration for minibatch gradients through von Mises-Fisher (VMF) distribution, and show that the directional uniformity of minibatch gradients increases over the course of SGD. We empirically verify our result using deep convolutional networks and observe a higher correlation between the gradient stochasticity and the proposed directional uniformity than that against the gradient norm stochasticity, suggesting that the directional statistics of minibatch gradients is a major factor behind SGD.","Sat, 29 Sep 2018 05:16:43 UTC (515 KB)"
"234","DeepSSM: A Deep Learning Framework for Statistical Shape Modeling from Raw Images","Riddhish Bhalodia, Shireen Y. Elhabian, Ladislav Kavan, Ross T. Whitaker","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Statistical shape modeling is an important tool to characterize variation in anatomical morphology. Typical shapes of interest are measured using 3D imaging and a subsequent pipeline of registration, segmentation, and some extraction of shape features or projections onto some lower-dimensional shape space, which facilitates subsequent statistical analysis. Many methods for constructing compact shape representations have been proposed, but are often impractical due to the sequence of image preprocessing operations, which involve significant parameter tuning, manual delineation, and/or quality control by the users. We propose DeepSSM: a deep learning approach to extract a low-dimensional shape representation directly from 3D images, requiring virtually no parameter tuning or user assistance. DeepSSM uses a convolutional neural network (CNN) that simultaneously localizes the biological structure of interest, establishes correspondences, and projects these points onto a low-dimensional shape representation in the form of PCA loadings within a point distribution model. To overcome the challenge of the limited availability of training images, we present a novel data augmentation procedure that uses existing correspondences on a relatively small set of processed images with shape statistics to create plausible training samples with known shape parameters. Hence, we leverage the limited CT/MRI scans (40-50) into thousands of images needed to train a CNN. After the training, the CNN automatically produces accurate low-dimensional shape representations for unseen images. We validate DeepSSM for three different applications pertaining to modeling pediatric cranial CT for characterization of metopic craniosynostosis, femur CT scans identifying morphologic deformities of the hip due to femoroacetabular impingement, and left atrium MRI scans for atrial fibrillation recurrence prediction.","Fri, 28 Sep 2018 22:53:49 UTC (2,953 KB)"
"235","Deep learning systems as complex networks","Alberto Testolin, Michele Piccolini, Samir Suweis","Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG); Machine Learning (stat.ML)","Thanks to the availability of large scale digital datasets and massive amounts of computational power, deep learning algorithms can learn representations of data by exploiting multiple levels of abstraction. These machine learning methods have greatly improved the state-of-the-art in many challenging cognitive tasks, such as visual object recognition, speech processing, natural language understanding and automatic translation. In particular, one class of deep learning models, known as deep belief networks, can discover intricate statistical structure in large data sets in a completely unsupervised fashion, by learning a generative model of the data using Hebbian-like learning mechanisms. Although these self-organizing systems can be conveniently formalized within the framework of statistical mechanics, their internal functioning remains opaque, because their emergent dynamics cannot be solved analytically. In this article we propose to study deep belief networks using techniques commonly employed in the study of complex networks, in order to gain some insights into the structural and functional properties of the computational graph resulting from the learning process.","Fri, 28 Sep 2018 10:06:36 UTC (1,858 KB)"
"236","Deep Learning Bandgaps of Topologically Doped Graphene","Yuan Dong, Chuhan Wu, Chi Zhang, Yingda Liu, Jianlin Cheng, Jian Lin","Materials Science (cond-mat.mtrl-sci); Computational Physics (physics.comp-ph)","Manipulation of material properties via precise doping affords enormous tunable phenomena to explore. Recent advance shows that in the atomic and nano scales topological states of dopants play crucial roles in determining their properties. However, such determination is largely unknown due to the incredible size of topological states. Here, we present a case study of developing deep learning algorithms to predict bandgaps of boron-nitrogen pair doped graphene with arbitrary dopant topologies. A material descriptor system that enables to correlate structures with the bandgaps was developed for convolutional neuron networks (CNNs). Bandgaps calculated by the ab initio calculations and the corresponding structures were fed as input datasets to train VGG16 convolutional network, residual convolutional network, and concatenate convolutional network. Then these trained CNNs were used to predict bandgaps of doped graphene with various dopant topologies. All of them afford great prediction accuracy, showing square of the coefficient of correlation (R2) of > 90% and root-mean-square errors of ~ 0.1 eV for the predicted bandgaps. They are much better than those predicted by a shallow machine learning method - support vector machine. The transfer learning was further performed by leveraging data generated from smaller systems to improve the prediction for large systems. Success of this work provides a cornerstone for future investigation of topologically doped graphene and other 2D materials. Moreover, given ubiquitous existence of topologies in materials, this work will stimulate widespread interests in applying deep learning algorithms to topological design of materials crossing atomic, nano-, meso-, and macro- scales.","Fri, 28 Sep 2018 05:02:49 UTC (1,788 KB)"
"237","FanStore: Enabling Efficient and Scalable I/O for Distributed Deep Learning","Zhao Zhang, Lei Huang, Uri Manor, Linjing Fang, Gabriele Merlo, Craig Michoski, John Cazes, Niall Gaffney","Distributed, Parallel, and Cluster Computing (cs.DC)","Emerging Deep Learning (DL) applications introduce heavy I/O workloads on computer clusters. The inherent long lasting, repeated, and random file access pattern can easily saturate the metadata and data service and negatively impact other users. In this paper, we present FanStore, a transient runtime file system that optimizes DL I/O on existing hardware/software stacks. FanStore distributes datasets to the local storage of compute nodes, and maintains a global namespace. With the techniques of system call interception, distributed metadata management, and generic data compression, FanStore provides a POSIX-compliant interface with native hardware throughput in an efficient and scalable manner. Users do not have to make intrusive code changes to use FanStore and take advantage of the optimized I/O. Our experiments with benchmarks and real applications show that FanStore can scale DL training to 512 compute nodes with over 90\% scaling efficiency.","Thu, 27 Sep 2018 23:33:11 UTC (419 KB)"
"238","A Deep Learning Approach to Denoise Optical Coherence Tomography Images of the Optic Nerve Head","Sripad Krishna Devalla, Giridhar Subramanian, Tan Hung Pham, Xiaofei Wang, Shamira Perera, Tin A. Tun, Tin Aung, Leopold Schmetterer, Alexandre H. Thiery, Michael J. A. Girard","Computer Vision and Pattern Recognition (cs.CV)","Purpose: To develop a deep learning approach to de-noise optical coherence tomography (OCT) B-scans of the optic nerve head (ONH). Methods: Volume scans consisting of 97 horizontal B-scans were acquired through the center of the ONH using a commercial OCT device (Spectralis) for both eyes of 20 subjects. For each eye, single-frame (without signal averaging), and multi-frame (75x signal averaging) volume scans were obtained. A custom deep learning network was then designed and trained with 2,328 ""clean B-scans"" (multi-frame B-scans), and their corresponding ""noisy B-scans"" (clean B-scans + gaussian noise) to de-noise the single-frame B-scans. The performance of the de-noising algorithm was assessed qualitatively, and quantitatively on 1,552 B-scans using the signal to noise ratio (SNR), contrast to noise ratio (CNR), and mean structural similarity index metrics (MSSIM). Results: The proposed algorithm successfully denoised unseen single-frame OCT B-scans. The denoised B-scans were qualitatively similar to their corresponding multi-frame B-scans, with enhanced visibility of the ONH tissues. The mean SNR increased from $4.02 \pm 0.68$ dB (single-frame) to $8.14 \pm 1.03$ dB (denoised). For all the ONH tissues, the mean CNR increased from $3.50 \pm 0.56$ (single-frame) to $7.63 \pm 1.81$ (denoised). The MSSIM increased from $0.13 \pm 0.02$ (single frame) to $0.65 \pm 0.03$ (denoised) when compared with the corresponding multi-frame B-scans. Conclusions: Our deep learning algorithm can denoise a single-frame OCT B-scan of the ONH in under 20 ms, thus offering a framework to obtain superior quality OCT B-scans with reduced scanning times and minimal patient discomfort.","Thu, 27 Sep 2018 15:53:36 UTC (3,381 KB)"
"239","Real-time 3D Pose Estimation with a Monocular Camera Using Deep Learning and Object Priors On an Autonomous Racecar","Ankit Dhall","Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","We propose a complete pipeline that allows object detection and simultaneously estimate the pose of these multiple object instances using just a single image. A novel ""keypoint regression"" scheme with a cross-ratio term is introduced that exploits prior information about the object's shape and size to regress and find specific feature points. Further, a priori 3D information about the object is used to match 2D-3D correspondences and accurately estimate object positions up to a distance of 15m. A detailed discussion of the results and an in-depth analysis of the pipeline is presented. The pipeline runs efficiently on a low-powered Jetson TX2 and is deployed as part of the perception pipeline on a real-time autonomous vehicle cruising at a top speed of 54 km/hr.","Thu, 27 Sep 2018 14:45:19 UTC (8,242 KB)"
"240","Deep Learning and Holographic QCD","Koji Hashimoto, Sotaro Sugishita, Akinori Tanaka, Akio Tomiya","High Energy Physics - Theory (hep-th); High Energy Physics - Lattice (hep-lat); High Energy Physics - Phenomenology (hep-ph)","We apply the relation between deep learning (DL) and the AdS/CFT correspondence to a holographic model of QCD. Using a lattice QCD data of the chiral condensate at a finite temperature as our training data, the deep learning procedure holographically determines an emergent bulk metric as neural network weights. The emergent bulk metric is found to have both a black hole horizon and a finite-height IR wall, so shares both the confining and deconfining phases, signaling the cross-over thermal phase transition of QCD. In fact, a quark antiquark potential holographically calculated by the emergent bulk metric turns out to possess both the linear confining part and the Debye screening part, as is often observed in lattice QCD. From this we argue the discrepancy between the chiral symmetry breaking and the quark confinement in the holographic QCD. The DL method is shown to provide a novel data-driven holographic modeling of QCD, and sheds light on the mechanism of emergence of the bulk geometries in the AdS/CFT correspondence.","Thu, 27 Sep 2018 14:19:54 UTC (1,469 KB)"
"241","Towards increased trustworthiness of deep learning segmentation methods on cardiac MRI","Jorg Sander, Bob D. de Vos, Jelmer M. Wolterink, Ivana I<U+0161>gum","Computer Vision and Pattern Recognition (cs.CV)","Current state-of-the-art deep learning segmentation methods have not yet made a broad entrance into the clinical setting in spite of high demand for such automatic methods. One important reason is the lack of reliability caused by models that fail unnoticed and often locally produce anatomically implausible results that medical experts would not make. This paper presents an automatic image segmentation method based on (Bayesian) dilated convolutional networks (DCNN) that generate segmentation masks and spatial uncertainty maps for the input image at hand. The method was trained and evaluated using segmentation of the left ventricle (LV) cavity, right ventricle (RV) endocardium and myocardium (Myo) at end-diastole (ED) and end-systole (ES) in 100 cardiac 2D MR scans from the MICCAI 2017 Challenge (ACDC). Combining segmentations and uncertainty maps and employing a human-in-the-loop setting, we provide evidence that image areas indicated as highly uncertain regarding the obtained segmentation almost entirely cover regions of incorrect segmentations. The fused information can be harnessed to increase segmentation performance. Our results reveal that we can obtain valuable spatial uncertainty maps with low computational effort using DCNNs.","Thu, 27 Sep 2018 09:49:46 UTC (1,715 KB)[v2] Sat, 29 Sep 2018 07:31:22 UTC (1,716 KB)"
"242","Image Reconstruction Using Deep Learning","Po-Yu Liu, Edmund Y. Lam","Computer Vision and Pattern Recognition (cs.CV)","This paper proposes a deep learning architecture that attains statistically significant improvements over traditional algorithms in Poisson image denoising espically when the noise is strong. Poisson noise commonly occurs in low-light and photon- limited settings, where the noise can be most accurately modeled by the Poission distribution. Poisson noise traditionally prevails only in specific fields such as astronomical imaging. However, with the booming market of surveillance cameras, which commonly operate in low-light environments, or mobile phones, which produce noisy night scene pictures due to lower-grade sensors, the necessity for an advanced Poisson image denoising algorithm has increased. Deep learning has achieved amazing breakthroughs in other imaging problems, such image segmentation and recognition, and this paper proposes a deep learning denoising network that outperforms traditional algorithms in Poisson denoising especially when the noise is strong. The architecture incorporates a hybrid of convolutional and deconvolutional layers along with symmetric connections. The denoising network achieved statistically significant 0.38dB, 0.68dB, and 1.04dB average PSNR gains over benchmark traditional algorithms in experiments with image peak values 4, 2, and 1. The denoising network can also operate with shorter computational time while still outperforming the benchmark algorithm by tuning the reconstruction stride sizes.","Thu, 27 Sep 2018 08:58:38 UTC (5,033 KB)"
"243","Towards a Hands-Free Query Optimizer through Deep Learning","Ryan Marcus, Olga Papaemmanouil","Databases (cs.DB)","Query optimization remains one of the most important and well-studied problems in database systems. However, traditional query optimizers are complex heuristically-driven systems, requiring large amounts of time to tune for a particular database and requiring even more time to develop and maintain in the first place. In this vision paper, we argue that a new type of query optimizer, based on deep reinforcement learning, can drastically improve on the state-of-the-art. We identify potential complications for future research that integrates deep learning with query optimization and describe three novel deep learning based approaches that can lead the way to end-to-end learning-based query optimizers.","Wed, 26 Sep 2018 19:51:03 UTC (441 KB)"
"244","Morphed Learning: Towards Privacy-Preserving for Deep Learning Based Applications","Juncheng Shen, Juzheng Liu, Yiran Chen, Hai Li","Machine Learning (cs.LG)","The concern of potential privacy violation has prevented efficient use of big data for improving deep learning based applications. In this paper, we propose Morphed Learning, a privacy-preserving technique for deep learning based on data morphing that, allows data owners to share their data without leaking sensitive privacy information. Morphed Learning allows the data owners to send securely morphed data and provides the server with an Augmented Convolutional layer to train the network on morphed data without performance loss. Morphed Learning has these three features: (1) Strong protection against reverse-engineering on the morphed data; (2) Acceptable computational and data transmission overhead with no correlation to the depth of the neural network; (3) No degradation of the neural network performance. Theoretical analyses on CIFAR-10 dataset and VGG-16 network show that our method is capable of providing 10^89 morphing possibilities with only 5% computational overhead and 10% transmission overhead under limited knowledge attack scenario. Further analyses also proved that our method can offer same resilience against full knowledge attack if more resources are provided.","Thu, 20 Sep 2018 07:37:10 UTC (482 KB)"
"245","A Model-Driven Deep Learning Network for MIMO Detection","Hengtao He, Chao-Kai Wen, Shi Jin, Geoffrey Ye Li","Information Theory (cs.IT)","In this paper, we propose a model-driven deep learning network for multiple-input multiple-output (MIMO) detection. The structure of the network is specially designed by unfolding the iterative algorithm. Some trainable parameters are optimized through deep learning techniques to improve the detection performance. Since the number of trainable variables of the network is equal to that of the layers, the network can be easily trained within a very short time. Furthermore, the network can handle time-varying channel with only a single training. Numerical results show that the proposed approach can improve the performance of the iterative algorithm significantly under Rayleigh and correlated MIMO channels.","Tue, 25 Sep 2018 06:31:37 UTC (44 KB)"
"246","Towards Automated Post-Earthquake Inspections with Deep Learning-based Condition-Aware Models","Vedhus Hoskere, Yasutaka Narazaki, Tu A. Hoang, Billie F. Spencer Jr","Computer Vision and Pattern Recognition (cs.CV)","In the aftermath of an earthquake, rapid structural inspections are required to get citizens back in to their homes and offices in a safe and timely manner. These inspections gfare typically conducted by municipal authorities through structural engineer volunteers. As manual inspec-tions can be time consuming, laborious and dangerous, research has been underway to develop methods to help speed up and increase the automation of the entire process. Researchers typi-cally envisage the use of unmanned aerial vehicles (UAV) for data acquisition and computer vision for data processing to extract actionable information. In this work we propose a new framework to generate vision-based condition-aware models that can serve as the basis for speeding up or automating higher level inspection decisions. The condition-aware models are generated by projecting the inference of trained deep-learning models on a set of images of a structure onto a 3D mesh model generated through multi-view stereo from the same image set. Deep fully convolutional residual networks are used for semantic segmentation of images of buildings to provide (i) damage information such as cracks and spalling (ii) contextual infor-mation such as the presence of a building and visually identifiable components like windows and doors. The proposed methodology was implemented on a damaged building that was sur-veyed by the authors after the Central Mexico Earthquake in September 2017 and qualitative-ly evaluated. Results demonstrate the promise of the proposed method towards the ultimate goal of rapid and automated post-earthquake inspections.","Mon, 24 Sep 2018 19:59:07 UTC (1,599 KB)"
"247","Autonomous Deep Learning: Incremental Learning of Denoising Autoencoder for Evolving Data Streams","Mahardhika Pratama, Andri Ashfahani, Yew Soon Ong, Savitha Ramasamy, Edwin Lughofer","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","The generative learning phase of Autoencoder (AE) and its successor Denosing Autoencoder (DAE) enhances the flexibility of data stream method in exploiting unlabelled samples. Nonetheless, the feasibility of DAE for data stream analytic deserves in-depth study because it characterizes a fixed network capacity which cannot adapt to rapidly changing environments. An automated construction of a denoising autoeconder, namely deep evolving denoising autoencoder (DEVDAN), is proposed in this paper. DEVDAN features an open structure both in the generative phase and in the discriminative phase where input features can be automatically added and discarded on the fly. A network significance (NS) method is formulated in this paper and is derived from the bias-variance concept. This method is capable of estimating the statistical contribution of the network structure and its hidden units which precursors an ideal state to add or prune input features. Furthermore, DEVDAN is free of the problem- specific threshold and works fully in the single-pass learning fashion. The efficacy of DEVDAN is numerically validated using nine non-stationary data stream problems simulated under the prequential test-then-train protocol where DEVDAN is capable of delivering an improvement of classification accuracy to recently published online learning works while having flexibility in the automatic extraction of robust input features and in adapting to rapidly changing environments.","Mon, 24 Sep 2018 17:49:09 UTC (64 KB)"
"248","Detecting Features of Tools, Objects, and Actions from Effects in a Robot using Deep Learning","Namiko Saito, Kitae Kim, Shingo Murata, Tetsuya Ogata, Shigeki Sugano","Robotics (cs.RO); Machine Learning (cs.LG); Machine Learning (stat.ML)","We propose a tool-use model that can detect the features of tools, target objects, and actions from the provided effects of object manipulation. We construct a model that enables robots to manipulate objects with tools, using infant learning as a concept. To realize this, we train sensory-motor data recorded during a tool-use task performed by a robot with deep learning. Experiments include four factors: (1) tools, (2) objects, (3) actions, and (4) effects, which the model considers simultaneously. For evaluation, the robot generates predicted images and motions given information of the effects of using unknown tools and objects. We confirm that the robot is capable of detecting features of tools, objects, and actions by learning the effects and executing the task.","Sun, 23 Sep 2018 15:24:21 UTC (1,435 KB)"
"249","Identification and Visualization of the Underlying Independent Causes of the Diagnostic of Diabetic Retinopathy made by a Deep Learning Classifier","Jordi de la Torre, Aida Valls, Domenec Puig, Pere Romero-Aroca","Machine Learning (stat.ML); Machine Learning (cs.LG)","Interpretability is a key factor in the design of automatic classifiers for medical diagnosis. Deep learning models have been proven to be a very effective classification algorithm when trained in a supervised way with enough data. The main concern is the difficulty of inferring rationale interpretations from them. Different attempts have been done in last years in order to convert deep learning classifiers from high confidence statistical black box machines into self-explanatory models. In this paper we go forward into the generation of explanations by identifying the independent causes that use a deep learning model for classifying an image into a certain class. We use a combination of Independent Component Analysis with a Score Visualization technique. In this paper we study the medical problem of classifying an eye fundus image into 5 levels of Diabetic Retinopathy. We conclude that only 3 independent components are enough for the differentiation and correct classification between the 5 disease standard classes. We propose a method for visualizing them and detecting lesions from the generated visual maps.","Sun, 23 Sep 2018 09:51:12 UTC (2,681 KB)"
"250","DeepOrigin: End-to-End Deep Learning for Detection of New Malware Families","Ilay Cordonsky, Ishai Rosenberg, Guillaume Sicard, Eli David","Cryptography and Security (cs.CR)","In this paper, we present a novel method of differentiating known from previously unseen malware families. We utilize transfer learning by learning compact file representations that are used for a new classification task between previously seen malware families and novel ones. The learned file representations are composed of static and dynamic features of malware and are invariant to small modifications that do not change their malicious functionality. Using an extensive dataset that consists of thousands of variants of malicious files, we were able to achieve 97.7% accuracy when classifying between seen and unseen malware families. Our method provides an important focalizing tool for cybersecurity researchers and greatly improves the overall ability to adapt to the fast-moving pace of the current threat landscape.","Sat, 22 Sep 2018 19:41:45 UTC (186 KB)"
"251","Automated Classification of Sleep Stages and EEG Artifacts in Mice with Deep Learning","Justus T. C. Schwabedal, Daniel Sippel, Moritz D. Brandt, Stephan Bialonski","Quantitative Methods (q-bio.QM); Machine Learning (cs.LG)","Sleep scoring is a necessary and time-consuming task in sleep studies. In animal models (such as mice) or in humans, automating this tedious process promises to facilitate long-term studies and to promote sleep biology as a data-driven field. We introduce a deep neural network model that is able to predict different states of consciousness (Wake, Non-REM, REM) in mice from EEG and EMG recordings with excellent scoring results for out-of-sample data. Predictions are made on epochs of 4 seconds length, and epochs are classified as artifact-free or not. The model architecture draws on recent advances in deep learning and in convolutional neural networks research. In contrast to previous approaches towards automated sleep scoring, our model does not rely on manually defined features of the data but learns predictive features automatically. We expect deep learning models like ours to become widely applied in different fields, automating many repetitive cognitive tasks that were previously difficult to tackle.","Sat, 22 Sep 2018 15:02:02 UTC (223 KB)"
"252","Combinatorial Designs for Deep Learning","Shoko Chisaki, Ryoh Fuji-Hara, Nobuko Miyamoto","Combinatorics (math.CO)","Deep learning is a multi-layer neural network. It can be regarded as a chain of complete bipartite graphs. The nodes of the first partite is the input layer and the last is the output layer. The edges of a bipartite graph function as weights which are represented as a matrix. The values of i-th partite are computed by multiplication of the weight matrix and values of (i-1)-th partite. Using mass training and teacher data, the weight parameters are estimated little by little. Overfitting (or Overlearning) refers to a model that models the 'training data' too well. It then becomes difficult for the model to generalize to new data which were not in the training set. The most popular method to avoid overfitting is called dropout. Dropout deletes a random sample of activations (nodes) to zero during the training process. A random sample of nodes cause more irregular frequency of dropout edges. We propose a combinatorial design on dropout nodes from each partite which balances frequency of edges. We analyze and construct such designs in this paper.","Sat, 22 Sep 2018 08:23:53 UTC (413 KB)"
"253","Power Market Price Forecasting via Deep Learning","Yongli Zhu, Songtao Lu, Renchang Dai, Guangyi Liu, Zhiwei Wang","Machine Learning (cs.LG); Machine Learning (stat.ML)","A study on power market price forecasting by deep learning is presented. As one of the most successful deep learning frameworks, the LSTM (Long short-term memory) neural network is utilized. The hourly prices data from the New England and PJM day-ahead markets are used in this study. First, a LSTM network is formulated and trained. Then the raw input and output data are preprocessed by unit scaling, and the trained network is tested on the real price data under different input lengths, forecasting horizons and data sizes. Its performance is also compared with other existing methods. The forecasted results demonstrate that, the LSTM deep neural network can outperform the others under different application settings in this problem.","Tue, 18 Sep 2018 19:00:18 UTC (545 KB)[v2] Tue, 23 Oct 2018 13:49:04 UTC (543 KB)"
"254","On-field player workload exposure and knee injury risk monitoring via deep learning","William R. Johnson, Ajmal Mian, David Lloyd, Jacqueline Alderson","Computer Vision and Pattern Recognition (cs.CV)","In sports analytics, an understanding of accurate on-field 3D knee joint moments (KJM) could provide an early warning system for athlete workload exposure and knee injury risk. Traditionally, this analysis has relied on captive laboratory force plates and associated downstream biomechanical modeling, and many researchers have approached the problem of portability by extrapolating models built on linear statistics. An alternative approach would be to capitalize on recent advances in deep learning. In this study, using the pre-trained CaffeNet convolutional neural network (CNN) model, multivariate regression of marker-based motion capture to 3D KJM for three sports-related movement types were compared. The strongest overall mean correlation to source modeling of 0.8895 was achieved over the initial 33 % of stance phase for sidestepping. The accuracy of these mean predictions of the three critical KJM associated with anterior cruciate ligament (ACL) injury demonstrate the feasibility of on-field knee injury assessment using deep learning in lieu of laboratory embedded force plates. This multidisciplinary research approach significantly advances machine representation of real-world physical models with practical application for both community and professional level athletes.","Fri, 21 Sep 2018 10:09:48 UTC (4,745 KB)"
"255","SG-FCN: A Motion and Memory-Based Deep Learning Model for Video Saliency Detection","Meijun Sun, Ziqi Zhou, QinGhua Hu, Zheng Wang, Jianmin Jiang","Computer Vision and Pattern Recognition (cs.CV)","Data-driven saliency detection has attracted strong interest as a result of applying convolutional neural networks to the detection of eye fixations. Although a number of imagebased salient object and fixation detection models have been proposed, video fixation detection still requires more exploration. Different from image analysis, motion and temporal information is a crucial factor affecting human attention when viewing video sequences. Although existing models based on local contrast and low-level features have been extensively researched, they failed to simultaneously consider interframe motion and temporal information across neighboring video frames, leading to unsatisfactory performance when handling complex scenes. To this end, we propose a novel and efficient video eye fixation detection model to improve the saliency detection performance. By simulating the memory mechanism and visual attention mechanism of human beings when watching a video, we propose a step-gained fully convolutional network by combining the memory information on the time axis with the motion information on the space axis while storing the saliency information of the current frame. The model is obtained through hierarchical training, which ensures the accuracy of the detection. Extensive experiments in comparison with 11 state-of-the-art methods are carried out, and the results show that our proposed model outperforms all 11 methods across a number of publicly available datasets.","Fri, 21 Sep 2018 08:36:15 UTC (2,192 KB)"
"256","Brain Tumor Segmentation Using Deep Learning by Type Specific Sorting of Images","Zahra Sobhaninia, Safiyeh Rezaei, Alireza Noroozi, Mehdi Ahmadi, Hamidreza Zarrabi, Nader Karimi, Ali Emami, Shadrokh Samavi","Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)","Recently deep learning has been playing a major role in the field of computer vision. One of its applications is the reduction of human judgment in the diagnosis of diseases. Especially, brain tumor diagnosis requires high accuracy, where minute errors in judgment may lead to disaster. For this reason, brain tumor segmentation is an important challenge for medical purposes. Currently several methods exist for tumor segmentation but they all lack high accuracy. Here we present a solution for brain tumor segmenting by using deep learning. In this work, we studied different angles of brain MR images and applied different networks for segmentation. The effect of using separate networks for segmentation of MR images is evaluated by comparing the results with a single network. Experimental evaluations of the networks show that Dice score of 0.73 is achieved for a single network and 0.79 in obtained for multiple networks.","Thu, 20 Sep 2018 18:24:09 UTC (340 KB)"
"257","DuPLO: A DUal view Point deep Learning architecture for time series classificatiOn","Roberto Interdonato, Dino Ienco, Raffaele Gaetano, Kenji Ose","Computer Vision and Pattern Recognition (cs.CV)","Nowadays, modern Earth Observation systems continuously generate huge amounts of data. A notable example is represented by the Sentinel-2 mission, which provides images at high spatial resolution (up to 10m) with high temporal revisit period (every 5 days), which can be organized in Satellite Image Time Series (SITS). While the use of SITS has been proved to be beneficial in the context of Land Use/Land Cover (LULC) map generation, unfortunately, machine learning approaches commonly leveraged in remote sensing field fail to take advantage of spatio-temporal dependencies present in such data. Recently, new generation deep learning methods allowed to significantly advance research in this field. These approaches have generally focused on a single type of neural network, i.e., Convolutional Neural Networks (CNNs) or Recurrent Neural Networks (RNNs), which model different but complementary information: spatial autocorrelation (CNNs) and temporal dependencies (RNNs). In this work, we propose the first deep learning architecture for the analysis of SITS data, namely \method{} (DUal view Point deep Learning architecture for time series classificatiOn), that combines Convolutional and Recurrent neural networks to exploit their complementarity. Our hypothesis is that, since CNNs and RNNs capture different aspects of the data, a combination of both models would produce a more diverse and complete representation of the information for the underlying land cover classification task. Experiments carried out on two study sites characterized by different land cover characteristics (i.e., the \textit{Gard} site in France and the \textit{Reunion Island} in the Indian Ocean), demonstrate the significance of our proposal.","Thu, 20 Sep 2018 12:19:35 UTC (4,336 KB)"
"258","Accelerating Flash Calculation through Deep Learning Methods","Yu Li, Tao Zhang, Shuyu Sun, Xin Gao","Computational Engineering, Finance, and Science (cs.CE); Chemical Physics (physics.chem-ph); Computational Physics (physics.comp-ph)","In the past two decades, researchers have made remarkable progress in accelerating flash calculation, which is very useful in a variety of engineering processes. In this paper, general phase splitting problem statements and flash calculation procedures using the Successive Substitution Method are reviewed, while the main shortages are pointed out. Two acceleration methods, Newton's method and the Sparse Grids Method are presented afterwards as a comparison with the deep learning model proposed in this paper. A detailed introduction from artificial neural networks to deep learning methods is provided here with the authors' own remarks. Factors in the deep learning model are investigated to show their effect on the final result. A selected model based on that has been used in a flash calculation predictor with comparison with other methods mentioned above. It is shown that results from the optimized deep learning model meet the experimental data well with the shortest CPU time. More comparison with experimental data has been conducted to show the robustness of our model.","Wed, 19 Sep 2018 17:37:58 UTC (3,065 KB)[v2] Sat, 29 Sep 2018 09:25:26 UTC (3,202 KB)"
"259","Deep Learning Based Rib Centerline Extraction and Labeling","Matthias Lenga, Tobias Klinder, Christian Burger, Jens von Berg, Astrid Franz, Cristian Lorenz","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Automated extraction and labeling of rib centerlines is a typically needed prerequisite for more advanced assisted reading tools that help the radiologist to efficiently inspect all 24 ribs in a CT volume. In this paper, we combine a deep learning-based rib detection with a dedicated centerline extraction algorithm applied to the detection result for the purpose of fast, robust and accurate rib centerline extraction and labeling from CT volumes. More specifically, we first apply a fully convolutional neural network (FCNN) to generate a probability map for detecting the first rib pair, the twelfth rib pair, and the collection of all intermediate ribs. In a second stage, a newly designed centerline extraction algorithm is applied to this multi-label probability map. Finally, the distinct detection of first and twelfth rib separately, allows to derive individual rib labels by simple sorting and counting the detected centerlines. We applied our method to CT volumes from 116 patients which included a variety of different challenges and achieved a centerline accuracy of 0.787 mm with respect to manual centerline annotations.","Wed, 19 Sep 2018 09:09:23 UTC (3,483 KB)"
"260","New approach for solar tracking systems based on computer vision, low cost hardware and deep learning","Jose A. Carballo, Javier Bonilla, Manuel Berenguel, Jesus Fernandez-Reche, Gines Garcia","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","In this work, a new approach for Sun tracking systems is presented. Due to the current system limitations regarding costs and operational problems, a new approach based on low cost, computer vision open hardware and deep learning has been developed. The preliminary tests carried out successfully in Plataforma solar de Almeria (PSA), reveal the great potential and show the new approach as a good alternative to traditional systems. The proposed approach can provide key variables for the Sun tracking system control like cloud movements prediction, block and shadow detection, atmospheric attenuation or measures of concentrated solar radiation, which can improve the control strategies of the system and therefore the system performance.","Wed, 19 Sep 2018 08:09:04 UTC (16,640 KB)"
"261","Deep learning approach in multi-scale prediction of turbulent mixing-layer","Jinu Lee, Sangseung Lee, Donghyun You","Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)","Achievement of solutions in Navier-Stokes equation is one of challenging quests, especially for its closure problem. For achievement of particular solutions, there are variety of numerical simulations including Direct Numerical Simulation (DNS) or Large Eddy Simulation (LES). These methods analyze flow physics through efficient reduced-order modeling such as proper orthogonal decomposition or Koopman method, showing prominent fidelity in fluid dynamics. Generative adversarial network (GAN) is a reprint of neurons in brain as combinations of linear operations, using competition between generator and discriminator. Current paper propose deep learning network for prediction of small-scale movements with large-scale inspections only, using GAN. Therefore DNS result of three-dimensional mixing-layer was filtered blurring out the small-scaled structures, then is predicted of its detailed structures, utilizing Generative Adversarial Network (GAN). This enables multi-resolution analysis being asked to predict fine-resolution solution with only inspection of blurry one. Within the grid scale, current paper present deep learning approach of modeling small scale features in turbulent flow. The presented method is expected to have its novelty in utilization of unprocessed simulation data, achievement of 3D structures in prediction by processing 3D convolutions, and predicting precise solution with less computational costs.","Wed, 19 Sep 2018 06:09:28 UTC (1,894 KB)[v2] Mon, 12 Nov 2018 15:19:20 UTC (1,911 KB)"
"262","Deep-learning models improve on community-level diagnosis for common congenital heart disease lesions","Rima Arnaout, Lara Curran, Erin Chinn, Yili Zhao, Anita Moon-Grady","Computer Vision and Pattern Recognition (cs.CV)","Prenatal diagnosis of tetralogy of Fallot (TOF) and hypoplastic left heart syndrome (HLHS), two serious congenital heart defects, improves outcomes and can in some cases facilitate in utero interventions. In practice, however, the fetal diagnosis rate for these lesions is only 30-50 percent in community settings. Improving fetal diagnosis of congenital heart disease is therefore critical. Deep learning is a cutting-edge machine learning technique for finding patterns in images but has not yet been applied to prenatal diagnosis of congenital heart disease. Using 685 retrospectively collected echocardiograms from fetuses 18-24 weeks of gestational age from 2000-2018, we trained convolutional and fully-convolutional deep learning models in a supervised manner to (i) identify the five canonical screening views of the fetal heart and (ii) segment cardiac structures to calculate fetal cardiac biometrics. We then trained models to distinguish by view between normal hearts, TOF, and HLHS. In a holdout test set of images, F-score for identification of the five most important fetal cardiac views was 0.95. Binary classification of unannotated cardiac views of normal heart vs. TOF reached an overall sensitivity of 75% and a specificity of 76%, while normal vs. HLHS reached a sensitivity of 100% and specificity of 90%, both well above average diagnostic rates for these lesions. Furthermore, segmentation-based measurements for cardiothoracic ratio (CTR), cardiac axis (CA), and ventricular fractional area change (FAC) were compatible with clinically measured metrics for normal, TOF, and HLHS hearts. Thus, using guideline-recommended imaging, deep learning models can significantly improve detection of fetal congenital heart disease compared to the common standard of care.","Wed, 19 Sep 2018 03:16:26 UTC (2,618 KB)"
"263","A Study on Deep Learning Based Sauvegrain Method for Measurement of Puberty Bone Age","Seung Bin Baik, Keum Gang Cha","Computer Vision and Pattern Recognition (cs.CV)","This study applies a technique to expand the number of images to a level that allows deep learning. And the applicability of the Sauvegrain method through deep learning with relatively few elbow X-rays is studied. The study was composed of processes similar to the physicians' bone age assessment procedures. The selected reference images were learned without being included in the evaluation data, and at the same time, the data was extended to accommodate the number of cases. In addition, we adjusted the X-ray images to better images using U-Net and selected the ROI with RPN + so as to be able to perform bone age estimation through CNN. The mean absolute error of the Sauvegrain method based on deep learning is 2.8 months and the Mean Absolute Percentage Error (MAPE) is 0.018. This result shows that X - ray analysis using the Sauvegrain method shows higher accuracy than that of the age group of puberty even in the deep learning base. This means that deep learning of the Suvegrain method can be measured at a level similar to that of an expert, based on the extended X-ray image with the image data extension technique. Finally, we applied the Sauvegrain method to deep learning for accurate measurement of bone age at puberty. As a result, the present study is based on deep learning, and compared with the evaluation results of experts, it is possible to overcome limitations of the method of measuring bone age based on machine learning which was in TW3 or Greulich & Pyle due to lack of X- I confirmed the fact. And we also presented the Sauvegrain method, which is applicable to adolescents as well.","Tue, 18 Sep 2018 23:47:08 UTC (669 KB)"
"264","Deep learning of mixing by two 'atoms' of stratified turbulence","Hesam Salehipour, W. Richard Peltier","Fluid Dynamics (physics.flu-dyn)","Current global ocean models rely on ad-hoc parameterizations of diapycnal mixing, in which the efficiency of mixing is globally assumed to be fixed at $20\%$, despite increasing evidence that this assumption is questionable. As an ansatz for small-scale ocean turbulence, we may focus on stratified shear flows susceptible to either Kelvin-Helmholtz (KHI) or Holmboe wave (HWI) instability. Recently, an unprecedented volume of data has been generated through direct numerical simulation (DNS) of these flows. In this paper, we describe the application of deep learning methods to the discovery of a generic parameterization of diapycnal mixing using the available DNS dataset. We furthermore demonstrate that the proposed model is far more universal compared to recently published parameterizations. We show that a neural network appropriately trained on KHI- and HWI-induced turbulence is capable of predicting mixing efficiency associated with unseen regions of the parameter space well beyond the range of the training data. Strikingly, the high-level patterns learned based on the KHI and weakly stratified HWI are `transferable' to predict HWI-induced mixing efficiency under much more strongly stratified conditions, suggesting that through the application of appropriate networks, significant universal abstractions of density stratified turbulent mixing have been recognized.","Tue, 18 Sep 2018 01:48:21 UTC (625 KB)[v2] Sat, 3 Nov 2018 18:09:30 UTC (1,332 KB)"
"265","DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep Learning","Kashyap Popat, Subhabrata Mukherjee, Andrew Yates, Gerhard Weikum","Computation and Language (cs.CL); Machine Learning (cs.LG)","Misinformation such as fake news is one of the big challenges of our society. Research on automated fact-checking has proposed methods based on supervised learning, but these approaches do not consider external evidence apart from labeled training instances. Recent approaches counter this deficit by considering external sources related to a claim. However, these methods require substantial feature modeling and rich lexicons. This paper overcomes these limitations of prior work with an end-to-end model for evidence-aware credibility assessment of arbitrary textual claims, without any human intervention. It presents a neural network model that judiciously aggregates signals from external evidence articles, the language of these articles and the trustworthiness of their sources. It also derives informative features for generating user-comprehensible explanations that makes the neural network predictions transparent to the end-user. Experiments with four datasets and ablation studies show the strength of our method.","Mon, 17 Sep 2018 19:51:18 UTC (984 KB)"
"266","Left Ventricle Segmentation and Volume Estimation on Cardiac MRI using Deep Learning","Ehab Abdelmaguid, Jolene Huang, Sanjay Kenchareddy, Disha Singla, Laura Wilke, Mai H. Nguyen, Ilkay Altintas","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","In the United States, heart disease is the leading cause of death for both men and women, accounting for 610,000 deaths each year [1]. Physicians use Magnetic Resonance Imaging (MRI) scans to take images of the heart in order to non-invasively estimate its structural and functional parameters for cardiovascular diagnosis and disease management. The end-systolic volume (ESV) and end-diastolic volume (EDV) of the left ventricle (LV), and the ejection fraction (EF) are indicators of heart disease. These measures can be derived from the segmented contours of the LV; thus, consistent and accurate segmentation of the LV from MRI images are critical to the accuracy of the ESV, EDV, and EF, and to non-invasive cardiac disease detection. In this work, various image preprocessing techniques, model configurations using the U-Net deep learning architecture, postprocessing methods, and approaches for volume estimation are investigated. An end-to-end analytics pipeline with multiple stages is provided for automated LV segmentation and volume estimation. First, image data are reformatted and processed from DICOM and NIfTI formats to raw images in array format. Secondly, raw images are processed with multiple image preprocessing methods and cropped to include only the Region of Interest (ROI). Thirdly, preprocessed images are segmented using U-Net models. Lastly, post processing of segmented images to remove extra contours along with intelligent slice and frame selection are applied, followed by calculation of the ESV, EDV, and EF. This analytics pipeline is implemented and runs on a distributed computing environment with a GPU cluster at the San Diego Supercomputer Center at UCSD.","Fri, 14 Sep 2018 06:40:07 UTC (2,369 KB)[v2] Wed, 21 Nov 2018 16:58:27 UTC (2,402 KB)"
"267","Binary Classification of Alzheimer Disease using sMRI Imaging modality and Deep Learning","Ahsan Bin Tufail, Qiu-Na Zhang, Yong-Kui Ma","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)","Alzheimer Disease (AD) is the most common form of dementia affecting the elderly population worldwide. Many neuroimaging modalities have been used to check the detection and progression of AD of which structural Magnetic Resonance Imaging (sMRI) is an important one. The recent rise in the popularity of deep learning methods with applications in computer vision, reinforcement learning and artificial intelligence has created a resurgence in the application of these methods to the classification of AD through different imaging modalities. In this study, by utilizing the concept of transfer learning in deep learning, we propose a classification framework to differentiate subjects with Clinical Dementia Rating (CDR) of zero from subjects with CDR greater than zero by using deep learning architectures such as Xception and Inception version 3 in the Keras deep learning library. The attained validation set accuracies are as high as 99.12% for the Inception version 3 network and 97.97% for the Xception network. The presented results suggest that meaningful predictors composed of sMRI and network measures may offer the possibility for early detection of subjects in the early stages of AD.","Sun, 9 Sep 2018 01:46:37 UTC (487 KB)"
"268","Revisit Multinomial Logistic Regression in Deep Learning: Data Dependent Model Initialization for Image Recognition","Bowen Cheng, Rong Xiao, Yandong Guo, Yuxiao Hu, Jianfeng Wang, Lei Zhang","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","We study in this paper how to initialize the parameters of multinomial logistic regression (a fully connected layer followed with softmax and cross entropy loss), which is widely used in deep neural network (DNN) models for classification problems. As logistic regression is widely known not having a closed-form solution, it is usually randomly initialized, leading to several deficiencies especially in transfer learning where all the layers except for the last task-specific layer are initialized using a pre-trained model. The deficiencies include slow convergence speed, possibility of stuck in local minimum, and the risk of over-fitting. To address those deficiencies, we first study the properties of logistic regression and propose a closed-form approximate solution named regularized Gaussian classifier (RGC). Then we adopt this approximate solution to initialize the task-specific linear layer and demonstrate superior performance over random initialization in terms of both accuracy and convergence speed on various tasks and datasets. For example, for image classification, our approach can reduce the training time by 10 times and achieve 3.2% gain in accuracy for Flickr-style classification. For object detection, our approach can also be 10 times faster in training for the same accuracy, or 5% better in terms of mAP for VOC 2007 with slightly longer training.","Mon, 17 Sep 2018 11:23:33 UTC (1,158 KB)"
"269","A Deep Learning Framework for Unsupervised Affine and Deformable Image Registration","Bob D. de Vos, Floris F. Berendsen, Max A. Viergever, Hessam Sokooti, Marius Staring, Ivana Isgum","Computer Vision and Pattern Recognition (cs.CV)","Image registration, the process of aligning two or more images, is the core technique of many (semi-)automatic medical image analysis tasks. Recent studies have shown that deep learning methods, notably convolutional neural networks (ConvNets), can be used for image registration. Thus far training of ConvNets for registration was supervised using predefined example registrations. However, obtaining example registrations is not trivial. To circumvent the need for predefined examples, and thereby to increase convenience of training ConvNets for image registration, we propose the Deep Learning Image Registration (DLIR) framework for \textit{unsupervised} affine and deformable image registration. In the DLIR framework ConvNets are trained for image registration by exploiting image similarity analogous to conventional intensity-based image registration. After a ConvNet has been trained with the DLIR framework, it can be used to register pairs of unseen images in one shot. We propose flexible ConvNets designs for affine image registration and for deformable image registration. By stacking multiple of these ConvNets into a larger architecture, we are able to perform coarse-to-fine image registration. We show for registration of cardiac cine MRI and registration of chest CT that performance of the DLIR framework is comparable to conventional image registration while being several orders of magnitude faster.","Mon, 17 Sep 2018 11:14:54 UTC (4,633 KB)"
"270","Model-Driven Deep Learning for Physical Layer Communications","Hengtao He, Shi Jin, Chao-Kai Wen, Feifei Gao, Geoffrey Ye Li, Zongben Xu","Information Theory (cs.IT); Machine Learning (cs.LG)","Intelligent communication is gradually considered as the mainstream direction in future wireless communications. As a major branch of machine learning, deep learning (DL) has been applied in physical layer communications and has demonstrated an impressive performance improvement in recent years. However, most of the existing works related to DL focus on data-driven approaches, which consider the communication system as a black box and train it by using a huge volume of data. Training a network requires sufficient computing resources and extensive time, both of which are rarely found in communication devices. By contrast, model-driven DL approaches combine communication domain knowledge with DL to reduce the demand for computing resources and training time. This article reviews the recent advancements in the application of model-driven DL approaches in physical layer communications, including transmission scheme, receiver design, and channel information recovery. Several open issues for further research are also highlighted after presenting the comprehensive survey.","Mon, 17 Sep 2018 07:52:58 UTC (939 KB)"
"271","Autonomous Exploration, Reconstruction, and Surveillance of 3D Environments Aided by Deep Learning","Louis Ly, Yen-Hsi Richard Tsai","Machine Learning (cs.LG); Machine Learning (stat.ML)","We study the problem of visibility-based exploration, reconstruction and surveillance in the context of supervised learning. Using a level set representation of data and information, we train a convolutional neural network to determine vantage points that maximize visibility. We show that this method drastically reduces the on-line computational cost and determines a small set of vantage points that solve the problem. This enables us to efficiently produce highly-resolved and topologically accurate maps of complex 3D environments. We present realistic simulations on 2D and 3D urban environments.","Mon, 17 Sep 2018 05:24:14 UTC (3,143 KB)"
"272","Comparison of Deep Learning and the Classical Machine Learning Algorithm for the Malware Detection","Mohit Sewak, Sanjay K. Sahay, Hemant Rathore","Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","Recently, Deep Learning has been showing promising results in various Artificial Intelligence applications like image recognition, natural language processing, language modeling, neural machine translation, etc. Although, in general, it is computationally more expensive as compared to classical machine learning techniques, their results are found to be more effective in some cases. Therefore, in this paper, we investigated and compared one of the Deep Learning Architecture called Deep Neural Network (DNN) with the classical Random Forest (RF) machine learning algorithm for the malware classification. We studied the performance of the classical RF and DNN with 2, 4 & 7 layers architectures with the four different feature sets, and found that irrespective of the features inputs, the classical RF accuracy outperforms the DNN.","Sun, 16 Sep 2018 14:40:16 UTC (161 KB)"
"273","An investigation of a deep learning based malware detection system","Mohit Sewak, Sanjay K. Sahay, Hemant Rathore","Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","We investigate a Deep Learning based system for malware detection. In the investigation, we experiment with different combination of Deep Learning architectures including Auto-Encoders, and Deep Neural Networks with varying layers over Malicia malware dataset on which earlier studies have obtained an accuracy of (98%) with an acceptable False Positive Rates (1.07%). But these results were done using extensive man-made custom domain features and investing corresponding feature engineering and design efforts. In our proposed approach, besides improving the previous best results (99.21% accuracy and a False Positive Rate of 0.19%) indicates that Deep Learning based systems could deliver an effective defense against malware. Since it is good in automatically extracting higher conceptual features from the data, Deep Learning based systems could provide an effective, general and scalable mechanism for detection of existing and unknown malware.","Sun, 16 Sep 2018 14:39:28 UTC (61 KB)"
"274","An FPGA-Accelerated Design for Deep Learning Pedestrian Detection in Self-Driving Vehicles","Abdallah Moussawi, Kamal Haddad, Anthony Chahine","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","With the rise of self-driving vehicles comes the risk of accidents and the need for higher safety, and protection for pedestrian detection in the following scenarios: imminent crashes, thus the car should crash into an object and avoid the pedestrian, and in the case of road intersections, where it is important for the car to stop when pedestrians are crossing. Currently, a special topology of deep neural networks called Fused Deep Neural Network (F-DNN) is considered to be the state of the art in pedestrian detection, as it has the lowest miss rate, yet it is very slow. Therefore, acceleration is needed to speed up the performance. This project proposes two contributions to address this problem, by using a deep neural network used for object detection, called Single Shot Multi-Box Detector (SSD). The first contribution is training and tuning the hyperparameters of SSD to improve pedestrian detection. The second contribution is a new FPGA design for accelerating the model on the Altera Arria 10 platform. The final system will be used in self-driving vehicles in real-time. Preliminary results of the improved SSD shows 3% higher miss-rate than F-DNN on Caltech pedestrian detection benchmark, but 4x performance improvement. The acceleration design is expected to achieve an additional performance improvement significantly outweighing the minimal difference in accuracy.","Sun, 16 Sep 2018 14:16:33 UTC (987 KB)"
"275","Deep Learning with Experience Ranking Convolutional Neural Network for Robot Manipulator","Hai Nguyen, Hung Manh La, Matthew Deans","Robotics (cs.RO)","Supervised learning, more specifically Convolutional Neural Networks (CNN), has surpassed human ability in some visual recognition tasks such as detection of traffic signs, faces and handwritten numbers. On the other hand, even state-of-the-art reinforcement learning (RL) methods have difficulties in environments with sparse and binary rewards. They requires manually shaping reward functions, which might be challenging to come up with. These tasks, however, are trivial to human. One of the reasons that human are better learners in these tasks is that we are embedded with much prior knowledge of the world. These knowledge might be either embedded in our genes or learned from imitation - a type of supervised learning. For that reason, the best way to narrow the gap between machine and human learning ability should be to mimic how we learn so well in various tasks by a combination of RL and supervised learning. Our method, which integrates Deep Deterministic Policy Gradients and Hindsight Experience Replay (RL method specifically dealing with sparse rewards) with an experience ranking CNN, provides a significant speedup over the learning curve on simulated robotics tasks. Experience ranking allows high-reward transitions to be replayed more frequently, and therefore help learn more efficiently. Our proposed approach can also speed up learning in any other tasks that provide additional information for experience ranking.","Sun, 16 Sep 2018 05:58:46 UTC (5,830 KB)"
"276","Development of deep learning algorithms to categorize free-text notes pertaining to diabetes: convolution neural networks achieve higher accuracy than support vector machines","Boyi Yang, Adam Wright","Computation and Language (cs.CL); Machine Learning (cs.LG); Machine Learning (stat.ML)","Health professionals can use natural language processing (NLP) technologies when reviewing electronic health records (EHR). Machine learning free-text classifiers can help them identify problems and make critical decisions. We aim to develop deep learning neural network algorithms that identify EHR progress notes pertaining to diabetes and validate the algorithms at two institutions. The data used are 2,000 EHR progress notes retrieved from patients with diabetes and all notes were annotated manually as diabetic or non-diabetic. Several deep learning classifiers were developed, and their performances were evaluated with the area under the ROC curve (AUC). The convolutional neural network (CNN) model with a separable convolution layer accurately identified diabetes-related notes in the Brigham and Womens Hospital testing set with the highest AUC of 0.975. Deep learning classifiers can be used to identify EHR progress notes pertaining to diabetes. In particular, the CNN-based classifier can achieve a higher AUC than an SVM-based classifier.","Sun, 16 Sep 2018 04:21:38 UTC (851 KB)"
"277","OffsetNet: Deep Learning for Localization in the Lung using Rendered Images","Jake Sganga, David Eng, Chauncey Graetzel, David Camarillo","Computer Vision and Pattern Recognition (cs.CV)","Navigating surgical tools in the dynamic and tortuous anatomy of the lung's airways requires accurate, real-time localization of the tools with respect to the preoperative scan of the anatomy. Such localization can inform human operators or enable closed-loop control by autonomous agents, which would require accuracy not yet reported in the literature. In this paper, we introduce a deep learning architecture, called OffsetNet, to accurately localize a bronchoscope in the lung in real-time. After training on only 30 minutes of recorded camera images in conserved regions of a lung phantom, OffsetNet tracks the bronchoscope's motion on a held-out recording through these same regions at an update rate of 47 Hz and an average position error of 1.4 mm. Because this model performs poorly in less conserved regions, we augment the training dataset with simulated images from these regions. To bridge the gap between camera and simulated domains, we implement domain randomization and a generative adversarial network (GAN). After training on simulated images, OffsetNet tracks the bronchoscope's motion in less conserved regions at an average position error of 2.4 mm, which meets conservative thresholds required for successful tracking.","Sat, 15 Sep 2018 04:15:16 UTC (4,002 KB)"
"278","Macquarie University at BioASQ 6b: Deep learning and deep reinforcement learning for query-based multi-document summarisation","Diego Molla","Computation and Language (cs.CL)","This paper describes Macquarie University's contribution to the BioASQ Challenge (BioASQ 6b, Phase B). We focused on the extraction of the ideal answers, and the task was approached as an instance of query-based multi-document summarisation. In particular, this paper focuses on the experiments related to the deep learning and reinforcement learning approaches used in the submitted runs. The best run used a deep learning model under a regression-based framework. The deep learning architecture used features derived from the output of LSTM chains on word embeddings, plus features based on similarity with the query, and sentence position. The reinforcement learning approach was a proof-of-concept prototype that trained a global policy using REINFORCE. The global policy was implemented as a neural network that used $tf.idf$ features encoding the candidate sentence, question, and context.","Fri, 14 Sep 2018 07:26:31 UTC (385 KB)"
"279","Context2Name: A Deep Learning-Based Approach to Infer Natural Variable Names from Usage Contexts","Rohan Bavishi, Michael Pradel, Koushik Sen","Software Engineering (cs.SE); Machine Learning (cs.LG); Programming Languages (cs.PL); Machine Learning (stat.ML)","Most of the JavaScript code deployed in the wild has been minified, a process in which identifier names are replaced with short, arbitrary and meaningless names. Minified code occupies less space, but also makes the code extremely difficult to manually inspect and understand. This paper presents Context2Name, a deep learningbased technique that partially reverses the effect of minification by predicting natural identifier names for minified names. The core idea is to predict from the usage context of a variable a name that captures the meaning of the variable. The approach combines a lightweight, token-based static analysis with an auto-encoder neural network that summarizes usage contexts and a recurrent neural network that predict natural names for a given usage context. We evaluate Context2Name with a large corpus of real-world JavaScript code and show that it successfully predicts 47.5% of all minified identifiers while taking only 2.9 milliseconds on average to predict a name. A comparison with the state-of-the-art tools JSNice and JSNaughty shows that our approach performs comparably in terms of accuracy while improving in terms of efficiency. Moreover, Context2Name complements the state-of-the-art by predicting 5.3% additional identifiers that are missed by both existing tools.","Fri, 31 Aug 2018 20:52:10 UTC (3,019 KB)"
"280","A Deep Learning and Gamification Approach to Energy Conservation at Nanyang Technological University","Ioannis C. Konstantakopoulos, Andrew R. Barkan, Shiying He, Tanya Veeravalli, Huihan Liu, Costas Spanos","Machine Learning (cs.LG); Machine Learning (stat.ML)","The implementation of smart building technology in the form of smart infrastructure applications has great potential to improve sustainability and energy efficiency by leveraging humans-in-the-loop strategy. However, human preference in regard to living conditions is usually unknown and heterogeneous in its manifestation as control inputs to a building. Furthermore, the occupants of a building typically lack the independent motivation necessary to contribute to and play a key role in the control of smart building infrastructure. Moreover, true human actions and their integration with sensing/actuation platforms remains unknown to the decision maker tasked with improving operational efficiency. By modeling user interaction as a sequential discrete game between non-cooperative players, we introduce a gamification approach for supporting user engagement and integration in a human-centric cyber-physical system. We propose the design and implementation of a large-scale network game with the goal of improving the energy efficiency of a building through the utilization of cutting-edge Internet of Things (IoT) sensors and cyber-physical systems sensing/actuation platforms. A benchmark utility learning framework that employs robust estimations for classical discrete choice models provided for the derived high dimensional imbalanced data. To improve forecasting performance, we extend the benchmark utility learning scheme by leveraging Deep Learning end-to-end training with Deep bi-directional Recurrent Neural Networks. We apply the proposed methods to high dimensional data from a social game experiment designed to encourage energy efficient behavior among smart building occupants in Nanyang Technological University (NTU) residential housing. Using occupant-retrieved actions for resources such as lighting and A/C, we simulate the game defined by the estimated utility functions.","Thu, 13 Sep 2018 18:52:16 UTC (5,120 KB)[v2] Tue, 25 Sep 2018 19:09:19 UTC (5,128 KB)"
"281","Full Workspace Generation of Serial-link Manipulators by Deep Learning based Jacobian Estimation","Peiyuan Liao, Jiajun Mao","Robotics (cs.RO)","Apart from solving complicated problems that require a certain level of intelligence, fine-tuned deep neural networks can also create fast algorithms for slow, numerical tasks. In this paper, we introduce an improved version of [1]'s work, a fast, deep-learning framework capable of generating the full workspace of serial-link manipulators. The architecture consists of two neural networks: an estimation net that approximates the manipulator Jacobian, and a confidence net that measures the confidence of the approximation. We also introduce M3 (Manipulability Maps of Manipulators), a MATLAB robotics library based on [2](RTB), the datasets generated by which are used by this work. Results have shown that not only are the neural networks significantly faster than numerical inverse kinematics, it also offers superior accuracy when compared to other machine learning alternatives. Implementations of the algorithm (based on Keras[3]), including benchmark evaluation script, are available at this https URL . The M3 Library APIs and datasets are also available at this https URL .","Fri, 31 Aug 2018 05:58:38 UTC (906 KB)[v2] Fri, 14 Sep 2018 00:19:52 UTC (906 KB)"
"282","Deep Learning-based Image Super-Resolution Considering Quantitative and Perceptual Quality","Jun-Ho Choi, Jun-Hyuk Kim, Manri Cheon, Jong-Seok Lee","Computer Vision and Pattern Recognition (cs.CV)","Recently, it has been shown that in super-resolution, there exists a tradeoff relationship between the quantitative and perceptual quality of super-resolved images, which correspond to the similarity to the ground-truth images and the naturalness, respectively. In this paper, we propose a novel super-resolution method that can improve the perceptual quality of the upscaled images while preserving the conventional quantitative performance. The proposed method employs a deep network for multi-pass upscaling in company with a discriminator network and two quantitative score predictor networks. Experimental results demonstrate that the proposed method achieves a good balance of the quantitative and perceptual quality, showing more satisfactory results than existing methods.","Thu, 13 Sep 2018 06:03:56 UTC (4,669 KB)"
"283","Deep Learning for Waveform Estimation and Imaging in Passive Radar","Bariscan Yonel, Eric Mason, Birsen Yazici","Signal Processing (eess.SP)","We consider a bistatic configuration with a stationary transmitter transmitting unknown waveforms of opportunity and a moving receiver, and present a Deep Learning (DL) framework for passive synthetic aperture radar (SAR) imaging. Existing passive radar methods require two or more antennas which are either spatially separated or colocated with sufficient directivity to estimate the underlying waveform prior to imaging. Our approach to passive radar only requires a single receiver, hence reduces cost and increases versatility. We approach DL from an optimization perspective and formulate image reconstruction as a machine learning task. By unfolding the iterations of a proximal gradient descent algorithm, we construct a deep recurrent neural network (RNN) that is parameterized by transmitted waveforms. We cascade the RNN structure with a decoder stage to form a recurrent-auto encoder architecture. We then utilize backpropagation to learn transmitted waveforms by training the network in an unsupervised manner using SAR measurements. The highly non-convex problem of backpropagation is guided to a feasible solution over the parameter space by initializing the network with the known components of the SAR forward model. Moreover, prior information regarding the waveform structure is incorporated during initialization and backpropagation. We demonstrate the effectiveness of the DL-based approach through extensive numerical simulations that show focused, high contrast imagery using a single receiver antenna at realistic SNR levels.","Thu, 13 Sep 2018 04:42:37 UTC (415 KB)[v2] Wed, 19 Sep 2018 17:53:13 UTC (646 KB)"
"284","FINN-R: An End-to-End Deep-Learning Framework for Fast Exploration of Quantized Neural Networks","Michaela Blott, Thomas Preusser, Nicholas Fraser, Giulio Gambardella, Kenneth O'Brien, Yaman Umuroglu","Hardware Architecture (cs.AR)","Convolutional Neural Networks have rapidly become the most successful machine learning algorithm, enabling ubiquitous machine vision and intelligent decisions on even embedded computing-systems. While the underlying arithmetic is structurally simple, compute and memory requirements are challenging. One of the promising opportunities is leveraging reduced-precision representations for inputs, activations and model parameters. The resulting scalability in performance, power efficiency and storage footprint provides interesting design compromises in exchange for a small reduction in accuracy. FPGAs are ideal for exploiting low-precision inference engines leveraging custom precisions to achieve the required numerical accuracy for a given application. In this article, we describe the second generation of the FINN framework, an end-to-end tool which enables design space exploration and automates the creation of fully customized inference engines on FPGAs. Given a neural network description, the tool optimizes for given platforms, design targets and a specific precision. We introduce formalizations of resource cost functions and performance predictions, and elaborate on the optimization algorithms. Finally, we evaluate a selection of reduced precision neural networks ranging from CIFAR-10 classifiers to YOLO-based object detection on a range of platforms including PYNQ and AWS\,F1, demonstrating new unprecedented measured throughput at 50TOp/s on AWS-F1 and 5TOp/s on embedded devices.","Wed, 12 Sep 2018 17:24:49 UTC (1,422 KB)"
"285","Deep learning to achieve clinically applicable segmentation of head and neck anatomy for radiotherapy","Stanislav Nikolov, Sam Blackwell, Ruheena Mendes, Jeffrey De Fauw, Clemens Meyer, Cian Hughes, Harry Askham, Bernardino Romera-Paredes, Alan Karthikesalingam, Carlton Chu, Dawn Carnell, Cheng Boon, Derek D'Souza, Syed Ali Moinuddin, Kevin Sullivan, DeepMind Radiographer Consortium, Hugh Montgomery, Geraint Rees, Ricky Sharma, Mustafa Suleyman, Trevor Back, Joseph R. Ledsam, Olaf Ronneberger","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Medical Physics (physics.med-ph); Machine Learning (stat.ML)","Over half a million individuals are diagnosed with head and neck cancer each year worldwide. Radiotherapy is an important curative treatment for this disease, but it requires manually intensive delineation of radiosensitive organs at risk (OARs). This planning process can delay treatment commencement. While auto-segmentation algorithms offer a potentially time-saving solution, the challenges in defining, quantifying and achieving expert performance remain. Adopting a deep learning approach, we demonstrate a 3D U-Net architecture that achieves performance similar to experts in delineating a wide range of head and neck OARs. The model was trained on a dataset of 663 deidentified computed tomography (CT) scans acquired in routine clinical practice and segmented according to consensus OAR definitions. We demonstrate its generalisability through application to an independent test set of 24 CT scans available from The Cancer Imaging Archive collected at multiple international sites previously unseen to the model, each segmented by two independent experts and consisting of 21 OARs commonly segmented in clinical practice. With appropriate validation studies and regulatory approvals, this system could improve the effectiveness of radiotherapy pathways.","Wed, 12 Sep 2018 13:42:38 UTC (14,911 KB)"
"286","Deep learning for time series classification: a review","Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, Pierre-Alain Muller","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Time Series Classification (TSC) is an important and challenging problem in data mining. With the increase of time series data availability, hundreds of TSC algorithms have been proposed. Among these methods, only a few have considered Deep Neural Networks (DNNs) to perform this task. This is surprising as deep learning has seen very successful applications in the last years. DNNs have indeed revolutionized the field of computer vision especially with the advent of novel deeper architectures such as Residual and Convolutional Neural Networks. Apart from images, sequential data such as text and audio can also be processed with DNNs to reach state of the art performance for document classification and speech recognition. In this article, we study the current state of the art performance of deep learning algorithms for TSC by presenting an empirical study of the most recent DNN architectures for TSC. We give an overview of the most successful deep learning applications in various time series domains under a unified taxonomy of DNNs for TSC. We also provide an open source deep learning framework to the TSC community where we implemented each of the compared approaches and evaluated them on a univariate TSC benchmark (the UCR archive) and 12 multivariate time series datasets. By training 8,730 deep learning models on 97 time series datasets, we propose the most exhaustive study of DNNs for TSC to date.","Wed, 12 Sep 2018 10:55:33 UTC (4,032 KB)"
"287","Deep Learning in Information Security","Stefan Thaler, Vlado Menkovski, Milan Petkovic","Cryptography and Security (cs.CR); Machine Learning (cs.LG)","Machine learning has a long tradition of helping to solve complex information security problems that are difficult to solve manually. Machine learning techniques learn models from data representations to solve a task. These data representations are hand-crafted by domain experts. Deep Learning is a sub-field of machine learning, which uses models that are composed of multiple layers. Consequently, representations that are used to solve a task are learned from the data instead of being manually designed. In this survey, we study the use of DL techniques within the domain of information security. We systematically reviewed 77 papers and presented them from a data-centric perspective. This data-centric perspective reflects one of the most crucial advantages of DL techniques -- domain independence. If DL-methods succeed to solve problems on a data type in one domain, they most likely will also succeed on similar data from another domain. Other advantages of DL methods are unrivaled scalability and efficiency, both regarding the number of examples that can be analyzed as well as with respect of dimensionality of the input data. DL methods generally are capable of achieving high-performance and generalize well. However, information security is a domain with unique requirements and challenges. Based on an analysis of our reviewed papers, we point out shortcomings of DL-methods to those requirements and discuss further research opportunities.","Wed, 12 Sep 2018 09:38:47 UTC (151 KB)"
"288","Deep Learning Based Multi-modal Addressee Recognition in Visual Scenes with Utterances","Thao Minh Le, Nobuyuki Shimizu, Takashi Miyazaki, Koichi Shinoda","Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","With the widespread use of intelligent systems, such as smart speakers, addressee recognition has become a concern in human-computer interaction, as more and more people expect such systems to understand complicated social scenes, including those outdoors, in cafeterias, and hospitals. Because previous studies typically focused only on pre-specified tasks with limited conversational situations such as controlling smart homes, we created a mock dataset called Addressee Recognition in Visual Scenes with Utterances (ARVSU) that contains a vast body of image variations in visual scenes with an annotated utterance and a corresponding addressee for each scenario. We also propose a multi-modal deep-learning-based model that takes different human cues, specifically eye gazes and transcripts of an utterance corpus, into account to predict the conversational addressee from a specific speaker's view in various real-life conversational scenarios. To the best of our knowledge, we are the first to introduce an end-to-end deep learning model that combines vision and transcripts of utterance for addressee recognition. As a result, our study suggests that future addressee recognition can reach the ability to understand human intention in many social situations previously unexplored, and our modality dataset is a first step in promoting research in this field.","Wed, 12 Sep 2018 07:43:23 UTC (682 KB)"
"289","Joint Segmentation and Uncertainty Visualization of Retinal Layers in Optical Coherence Tomography Images using Bayesian Deep Learning","Suman Sedai, Bhavna Antony, Dwarikanath Mahapatra, Rahil Garnavi","Computer Vision and Pattern Recognition (cs.CV)","Optical coherence tomography (OCT) is commonly used to analyze retinal layers for assessment of ocular diseases. In this paper, we propose a method for retinal layer segmentation and quantification of uncertainty based on Bayesian deep learning. Our method not only performs end-to-end segmentation of retinal layers, but also gives the pixel wise uncertainty measure of the segmentation output. The generated uncertainty map can be used to identify erroneously segmented image regions which is useful in downstream analysis. We have validated our method on a dataset of 1487 images obtained from 15 subjects (OCT volumes) and compared it against the state-of-the-art segmentation algorithms that does not take uncertainty into account. The proposed uncertainty based segmentation method results in comparable or improved performance, and most importantly is more robust against noise.","Wed, 12 Sep 2018 07:22:15 UTC (1,356 KB)"
"290","What can linguistics and deep learning contribute to each other?","Tal Linzen","Computation and Language (cs.CL)","Joe Pater's target article calls for greater interaction between neural network research and linguistics. I expand on this call and show how such interaction can benefit both fields. Linguists can contribute to research on neural networks for language technologies by clearly delineating the linguistic capabilities that can be expected of such systems, and by constructing controlled experimental paradigms that can determine whether those desiderata have been met. In the other direction, neural networks can benefit the scientific study of language by providing infrastructure for modeling human sentence processing and for evaluating the necessity of particular innate constraints on language acquisition.","Tue, 11 Sep 2018 21:55:11 UTC (189 KB)[v2] Fri, 14 Sep 2018 13:59:20 UTC (197 KB)"
"291","Efficient Road Lane Marking Detection with Deep Learning","Ping-Rong Chen, Shao-Yuan Lo, Hsueh-Ming Hang, Sheng-Wei Chan, Jing-Jhih Lin","Computer Vision and Pattern Recognition (cs.CV)","Lane mark detection is an important element in the road scene analysis for Advanced Driver Assistant System (ADAS). Limited by the onboard computing power, it is still a challenge to reduce system complexity and maintain high accuracy at the same time. In this paper, we propose a Lane Marking Detector (LMD) using a deep convolutional neural network to extract robust lane marking features. To improve its performance with a target of lower complexity, the dilated convolution is adopted. A shallower and thinner structure is designed to decrease the computational cost. Moreover, we also design post-processing algorithms to construct 3rd-order polynomial models to fit into the curved lanes. Our system shows promising results on the captured road scenes.","Tue, 11 Sep 2018 15:58:48 UTC (1,145 KB)"
"292","Does it care what you asked? Understanding Importance of Verbs in Deep Learning QA System","Barbara Rychalska, Dominika Basaj, Przemyslaw Biecek, Anna Wroblewska","Computation and Language (cs.CL)","In this paper we present the results of an investigation of the importance of verbs in a deep learning QA system trained on SQuAD dataset. We show that main verbs in questions carry little influence on the decisions made by the system - in over 90% of researched cases swapping verbs for their antonyms did not change system decision. We track this phenomenon down to the insides of the net, analyzing the mechanism of self-attention and values contained in hidden layers of RNN. Finally, we recognize the characteristics of the SQuAD dataset as the source of the problem. Our work refers to the recently popular topic of adversarial examples in NLP, combined with investigating deep net structure.","Tue, 11 Sep 2018 08:37:07 UTC (309 KB)"
"293","General Resolution Enhancement Method in Atomic Force Microscopy (AFM) Using Deep Learning","Y. Liu, Q. M. Sun, Dr. W. H. Lu, Dr. H. L. Wang, Y. Sun, Z. T. Wang, X. Lu, Prof. K. Y. Zeng","Data Analysis, Statistics and Probability (physics.data-an); Materials Science (cond-mat.mtrl-sci)","This paper develops a resolution enhancement method for post-processing the images from Atomic Force Microscopy (AFM). This method is based on deep learning neural networks in the AFM topography measurements. In this study, a very deep convolution neural network is developed to derive the high-resolution topography image from the low-resolution topography image. The AFM measured images from various materials are tested in this study. The derived high-resolution AFM images are comparable with the experimental measured high-resolution images measured at the same locations. The results suggest that this method can be developed as a general post-processing method for AFM image analysis.","Tue, 11 Sep 2018 07:09:14 UTC (1,339 KB)"
"294","Comparing Computing Platforms for Deep Learning on a Humanoid Robot","Alexander Biddulph, Trent Houlistion, Alexandre Mendes, Stephan K. Chalup","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","The goal of this study is to test two different computing platforms with respect to their suitability for running deep networks as part of a humanoid robot software system. One of the platforms is the CPU-centered Intel NUC7i7BNH and the other is a NVIDIA Jetson TX2 system that puts more emphasis on GPU processing. The experiments addressed a number of benchmarking tasks including pedestrian detection using deep neural networks. Some of the results were unexpected but demonstrate that platforms exhibit both advantages and disadvantages when taking computational performance and electrical power requirements of such a system into account.","Tue, 11 Sep 2018 03:25:36 UTC (5,567 KB)"
"295","URBAN-i: From urban scenes to mapping slums, transport modes, and pedestrians in cities using deep learning and computer vision","Mohamed R. Ibrahim, James Haworth, Tao Cheng","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)","Within the burgeoning expansion of deep learning and computer vision across the different fields of science, when it comes to urban development, deep learning and computer vision applications are still limited towards the notions of smart cities and autonomous vehicles. Indeed, a wide gap of knowledge appears when it comes to cities and urban regions in less developed countries where the chaos of informality is the dominant scheme. How can deep learning and Artificial Intelligence (AI) untangle the complexities of informality to advance urban modelling and our understanding of cities? Various questions and debates can be raised concerning the future of cities of the North and the South in the paradigm of AI and computer vision. In this paper, we introduce a new method for multipurpose realistic-dynamic urban modelling relying on deep learning and computer vision, using deep Convolutional Neural Networks (CNN), to sense and detect informality and slums in urban scenes from aerial and street view images in addition to detection of pedestrian and transport modes. The model has been trained on images of urban scenes in cities across the globe. The model shows a good validation of understanding a wide spectrum of nuances among the planned and the unplanned regions, including informal and slum areas. We attempt to advance urban modelling for better understanding the dynamics of city developments. We also aim to exemplify the significant impacts of AI in cities beyond how smart cities are discussed and perceived in the mainstream. The algorithms of the URBAN-i model are fully-coded in Python programming with the pre-trained deep learning models to be used as a tool for mapping and city modelling in the various corner of the globe, including informal settlements and slum regions.","Mon, 10 Sep 2018 21:49:38 UTC (3,317 KB)"
"296","Deep Learning Towards Mobile Applications","Ji Wang, Bokai Cao, Philip S. Yu, Lichao Sun, Weidong Bao, Xiaomin Zhu","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)","Recent years have witnessed an explosive growth of mobile devices. Mobile devices are permeating every aspect of our daily lives. With the increasing usage of mobile devices and intelligent applications, there is a soaring demand for mobile applications with machine learning services. Inspired by the tremendous success achieved by deep learning in many machine learning tasks, it becomes a natural trend to push deep learning towards mobile applications. However, there exist many challenges to realize deep learning in mobile applications, including the contradiction between the miniature nature of mobile devices and the resource requirement of deep neural networks, the privacy and security concerns about individuals' data, and so on. To resolve these challenges, during the past few years, great leaps have been made in this area. In this paper, we provide an overview of the current challenges and representative achievements about pushing deep learning on mobile devices from three aspects: training with mobile data, efficient inference on mobile devices, and applications of mobile deep learning. The former two aspects cover the primary tasks of deep learning. Then, we go through our two recent applications that apply the data collected by mobile devices to inferring mood disturbance and user identification. Finally, we conclude this paper with the discussion of the future of this area.","Mon, 10 Sep 2018 19:28:57 UTC (548 KB)"
"297","Not Just Privacy: Improving Performance of Private Deep Learning in Mobile Cloud","Ji Wang, Jianguo Zhang, Weidong Bao, Xiaomin Zhu, Bokai Cao, Philip S. Yu","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (stat.ML)","The increasing demand for on-device deep learning services calls for a highly efficient manner to deploy deep neural networks (DNNs) on mobile devices with limited capacity. The cloud-based solution is a promising approach to enabling deep learning applications on mobile devices where the large portions of a DNN are offloaded to the cloud. However, revealing data to the cloud leads to potential privacy risk. To benefit from the cloud data center without the privacy risk, we design, evaluate, and implement a cloud-based framework ARDEN which partitions the DNN across mobile devices and cloud data centers. A simple data transformation is performed on the mobile device, while the resource-hungry training and the complex inference rely on the cloud data center. To protect the sensitive information, a lightweight privacy-preserving mechanism consisting of arbitrary data nullification and random noise addition is introduced, which provides strong privacy guarantee. A rigorous privacy budget analysis is given. Nonetheless, the private perturbation to the original data inevitably has a negative impact on the performance of further inference on the cloud side. To mitigate this influence, we propose a noisy training method to enhance the cloud-side network robustness to perturbed data. Through the sophisticated design, ARDEN can not only preserve privacy but also improve the inference performance. To validate the proposed ARDEN, a series of experiments based on three image datasets and a real mobile application are conducted. The experimental results demonstrate the effectiveness of ARDEN. Finally, we implement ARDEN on a demo system to verify its practicality.","Mon, 10 Sep 2018 16:09:58 UTC (1,044 KB)[v2] Wed, 19 Sep 2018 02:50:41 UTC (1,159 KB)"
"298","Guiding the Creation of Deep Learning-based Object Detectors","Angela Casado, Jonathan Heras","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Object detection is a computer vision field that has applications in several contexts ranging from biomedicine and agriculture to security. In the last years, several deep learning techniques have greatly improved object detection models. Among those techniques, we can highlight the YOLO approach, that allows the construction of accurate models that can be employed in real-time applications. However, as most deep learning techniques, YOLO has a steep learning curve and creating models using this approach might be challenging for non-expert users. In this work, we tackle this problem by constructing a suite of Jupyter notebooks that democratizes the construction of object detection models using YOLO. The suitability of our approach has been proven with a dataset of stomata images where we have achieved a mAP of 90.91%.","Thu, 6 Sep 2018 07:07:12 UTC (1,714 KB)"
"299","Deep Learning Based Detection of Cosmological Diffuse Radio Sources","Claudio Gheller, Franco Vazza, Annalisa Bonafede","Instrumentation and Methods for Astrophysics (astro-ph.IM)","In this paper we introduce a reliable, fully automated and fast algorithm to detect extended extragalactic radio sources (cluster of galaxies, filaments) in existing and forthcoming surveys (like LOFAR and SKA). The proposed solution is based on the adoption of a Deep Learning approach, more specifically a Convolutional Neural Network, that proved to perform outstandingly in the processing, recognition and classification of images. The challenge, in the case of radio interferometric data, is the presence of noise and the lack of a sufficiently large number of labeled images for the training. We have specifically addressed these problems and the resulting software, COSMODEEP proved to be an accurate, efficient and effective solution for detecting very faint sources in the simulated radio images. We present the comparison with standard source finding techniques, and discuss advantages and limitations of our new approach.","Mon, 10 Sep 2018 13:57:07 UTC (8,320 KB)"
"300","Privacy-Preserving Deep Learning for any Activation Function","Le Trieu Phong, Tran Thi Phuong","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (stat.ML)","This paper considers the scenario that multiple data owners wish to apply a machine learning method over the combined dataset of all owners to obtain the best possible learning output but do not want to share the local datasets owing to privacy concerns. We design systems for the scenario that the stochastic gradient descent (SGD) algorithm is used as the machine learning method because SGD (or its variants) is at the heart of recent deep learning techniques over neural networks. Our systems differ from existing systems in the following features: {\bf (1)} any activation function can be used, meaning that no privacy-preserving-friendly approximation is required; {\bf (2)} gradients computed by SGD are not shared but the weight parameters are shared instead; and {\bf (3)} robustness against colluding parties even in the extreme case that only one honest party exists. We prove that our systems, while privacy-preserving, achieve the same learning accuracy as SGD and hence retain the merit of deep learning with respect to accuracy. Finally, we conduct several experiments using benchmark datasets, and show that our systems outperform previous system in terms of learning accuracies.","Mon, 10 Sep 2018 12:36:05 UTC (411 KB)"
"301","Shallow vs deep learning architectures for white matter lesion segmentation in the early stages of multiple sclerosis","Francesco La Rosa, Mario Joao Fartaria, Tobias Kober, Jonas Richiardi, Cristina Granziera, Jean-Philippe Thiran, Meritxell Bach Cuadra","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","In this work, we present a comparison of a shallow and a deep learning architecture for the automated segmentation of white matter lesions in MR images of multiple sclerosis patients. In particular, we train and test both methods on early stage disease patients, to verify their performance in challenging conditions, more similar to a clinical setting than what is typically provided in multiple sclerosis segmentation challenges. Furthermore, we evaluate a prototype naive combination of the two methods, which refines the final segmentation. All methods were trained on 32 patients, and the evaluation was performed on a pure test set of 73 cases. Results show low lesion-wise false positives (30%) for the deep learning architecture, whereas the shallow architecture yields the best Dice coefficient (63%) and volume difference (19%). Combining both shallow and deep architectures further improves the lesion-wise metrics (69% and 26% lesion-wise true and false positive rate, respectively).","Mon, 10 Sep 2018 08:50:34 UTC (2,349 KB)"
"302","Approximation and Estimation for High-Dimensional Deep Learning Networks","Andrew R. Barron, Jason M. Klusowski","Machine Learning (stat.ML); Machine Learning (cs.LG)","It has been experimentally observed in recent years that multi-layer artificial neural networks have a surprising ability to generalize, even when trained with far more parameters than observations. Is there a theoretical basis for this? The best available bounds on their metric entropy and associated complexity measures are essentially linear in the number of parameters, which is inadequate to explain this phenomenon. Here we examine the statistical risk (mean squared predictive error) of multi-layer networks with $\ell^1$-type controls on their parameters and with ramp activation functions (also called lower-rectified linear units). In this setting, the risk is shown to be upper bounded by $[(L^3 \log d)/n]^{1/2}$, where $d$ is the input dimension to each layer, $L$ is the number of layers, and $n$ is the sample size. In this way, the input dimension can be much larger than the sample size and the estimator can still be accurate, provided the target function has such $\ell^1$ controls and that the sample size is at least moderately large compared to $L^3\log d$. The heart of the analysis is the development of a sampling strategy that demonstrates the accuracy of a sparse covering of deep ramp networks. Lower bounds show that the identified risk is close to being optimal.","Mon, 10 Sep 2018 02:21:40 UTC (51 KB)[v2] Tue, 18 Sep 2018 17:49:00 UTC (52 KB)"
"303","A case for deep learning in semantics","Christopher Potts","Computation and Language (cs.CL)","Pater's target article builds a persuasive case for establishing stronger ties between theoretical linguistics and connectionism (deep learning). This commentary extends his arguments to semantics, focusing in particular on issues of learning, compositionality, and lexical meaning.","Mon, 10 Sep 2018 00:34:34 UTC (40 KB)"
"304","PhaseLink: A Deep Learning Approach to Seismic Phase Association","Zachary E. Ross, Yisong Yue, Men-Andrin Meier, Egill Hauksson, Thomas H. Heaton","Machine Learning (cs.LG); Geophysics (physics.geo-ph); Machine Learning (stat.ML)","Seismic phase association is a fundamental task in seismology that pertains to linking together phase detections on different sensors that originate from a common earthquake. It is widely employed to detect earthquakes on permanent and temporary seismic networks, and underlies most seismicity catalogs produced around the world. This task can be challenging because the number of sources is unknown, events frequently overlap in time, or can occur simultaneously in different parts of a network. We present PhaseLink, a framework based on recent advances in deep learning for grid-free earthquake phase association. Our approach learns to link phases together that share a common origin, and is trained entirely on tens of millions of synthetic sequences of P- and S-wave arrival times generated using a simple 1D velocity model. Our approach is simple to implement for any tectonic regime, suitable for real-time processing, and can naturally incorporate errors in arrival time picks. Rather than tuning a set of ad hoc hyperparameters to improve performance, PhaseLink can be improved by simply adding examples of problematic cases to the training dataset. We demonstrate the state-of-the-art performance of PhaseLink on a challenging recent sequence from southern California, and synthesized sequences from Japan designed to test the point at which the method fails. These tests show that PhaseLink can precisely associate P- and S-picks to events that are separated by ~12 seconds in origin time. This approach is expected to improve the resolution of seismicity catalogs, add stability to real-time seismic monitoring, and streamline automated processing of large seismic datasets.","Sat, 8 Sep 2018 21:39:29 UTC (2,786 KB)"
"305","Unsupervised Person Re-identification by Deep Learning Tracklet Association","Minxian Li, Xiatian Zhu, Shaogang Gong","Computer Vision and Pattern Recognition (cs.CV)","Mostexistingpersonre-identification(re-id)methods relyon supervised model learning on per-camera-pair manually labelled pairwise training data. This leads to poor scalability in practical re-id deployment due to the lack of exhaustive identity labelling of image positive and negative pairs for every camera pair. In this work, we address this problem by proposing an unsupervised re-id deep learning approach capable of incrementally discovering and exploiting the underlying re-id discriminative information from automatically generated person tracklet data from videos in an end-to-end model optimisation. We formulate a Tracklet Association Unsupervised Deep Learning (TAUDL) framework characterised by jointly learning per-camera (within-camera) tracklet association (labelling) and cross-camera tracklet correlation by maximising the discovery of most likely tracklet relationships across camera views. Extensive experiments demonstrate the superiority of the proposed TAUDL model over the state-of-the-art unsupervised and domain adaptation re- id methods using six person re-id benchmarking datasets.","Sat, 8 Sep 2018 20:49:01 UTC (4,048 KB)"
"306","NV center based nano-NMR enhanced by deep learning","Nati Aharon, Amit Rotem, Liam P. McGuinness, Fedor Jelezko, Alex Retzker, Zohar Ringel","Quantum Physics (quant-ph)","The growing field of nano-NMR seeks to estimate spectra or discriminate between spectra of minuscule amounts of complex molecules. While this field holds great promise, nano-NMR experiments suffer from adverse inherent noise. In this work we present strong indications that deep learning algorithms can efficiently mitigate the adversarial effects of noise. Over a wide range of scenarios we show that this approach outperforms Bayesian methods even when the latter have full pre-knowledge of the noise model and the former has none. These the deep learning algorithms also emerge as much more efficient in terms of computational resources and run times. On the basis of various real-world scenarios in which the noise is complex and difficult to model, we argue that deep learning is likely to become a dominant tool in the field.","Fri, 7 Sep 2018 17:18:09 UTC (1,368 KB)"
"307","Deep Learning for Generic Object Detection: A Survey","Li Liu, Wanli Ouyang, Xiaogang Wang, Paul Fieguth, Jie Chen, Xinwang Liu, Matti Pietikainen","Computer Vision and Pattern Recognition (cs.CV)","Generic object detection, aiming at locating object instances from a large number of predefined categories in natural images, is one of the most fundamental and challenging problems in computer vision. Deep learning techniques have emerged in recent years as powerful methods for learning feature representations directly from data, and have led to remarkable breakthroughs in the field of generic object detection. Given this time of rapid evolution, the goal of this paper is to provide a comprehensive survey of the recent achievements in this field brought by deep learning techniques. More than 250 key contributions are included in this survey, covering many aspects of generic object detection research: leading detection frameworks and fundamental subproblems including object feature representation, object proposal generation, context information modeling and training strategies; evaluation issues, specifically benchmark datasets, evaluation metrics, and state of the art performance. We finish by identifying promising directions for future research.","Thu, 6 Sep 2018 18:42:04 UTC (3,487 KB)"
"308","Deep learning for in vitro prediction of pharmaceutical formulations","Yilong Yang, Zhuyifan Ye, Yan Su, Qianqian Zhao, Xiaoshan Li, Defang Ouyang","Machine Learning (cs.LG); Machine Learning (stat.ML)","Current pharmaceutical formulation development still strongly relies on the traditional trial-and-error approach by individual experiences of pharmaceutical scientists, which is laborious, time-consuming and costly. Recently, deep learning has been widely applied in many challenging domains because of its important capability of automatic feature extraction. The aim of this research is to use deep learning to predict pharmaceutical formulations. In this paper, two different types of dosage forms were chosen as model systems. Evaluation criteria suitable for pharmaceutics were applied to assessing the performance of the models. Moreover, an automatic dataset selection algorithm was developed for selecting the representative data as validation and test datasets. Six machine learning methods were compared with deep learning. The result shows the accuracies of both two deep neural networks were above 80% and higher than other machine learning models, which showed good prediction in pharmaceutical formulations. In summary, deep learning with the automatic data splitting algorithm and the evaluation criteria suitable for pharmaceutical formulation data was firstly developed for the prediction of pharmaceutical formulations. The cross-disciplinary integration of pharmaceutics and artificial intelligence may shift the paradigm of pharmaceutical researches from experience-dependent studies to data-driven methodologies.","Thu, 6 Sep 2018 16:03:18 UTC (994 KB)"
"309","Deep Learning-Based Decoding for Constrained Sequence Codes","Congzhe Cao, Duanshun Li, Ivan Fair","Information Theory (cs.IT); Machine Learning (cs.LG); Signal Processing (eess.SP); Machine Learning (stat.ML)","Constrained sequence codes have been widely used in modern communication and data storage systems. Sequences encoded with constrained sequence codes satisfy constraints imposed by the physical channel, hence enabling efficient and reliable transmission of coded symbols. Traditional encoding and decoding of constrained sequence codes rely on table look-up, which is prone to errors that occur during transmission. In this paper, we introduce constrained sequence decoding based on deep learning. With multiple layer perception (MLP) networks and convolutional neural networks (CNNs), we are able to achieve low bit error rates that are close to maximum a posteriori probability (MAP) decoding as well as improve the system throughput. Moreover, implementation of capacity-achieving fixed-length codes, where the complexity is prohibitively high with table look-up decoding, becomes practical with deep learning-based decoding.","Thu, 6 Sep 2018 07:44:33 UTC (255 KB)"
"310","Connecting Image Denoising and High-Level Vision Tasks via Deep Learning","Ding Liu, Bihan Wen, Jianbo Jiao, Xianming Liu, Zhangyang Wang, Thomas S. Huang","Computer Vision and Pattern Recognition (cs.CV)","Image denoising and high-level vision tasks are usually handled independently in the conventional practice of computer vision, and their connection is fragile. In this paper, we cope with the two jointly and explore the mutual influence between them with the focus on two questions, namely (1) how image denoising can help improving high-level vision tasks, and (2) how the semantic information from high-level vision tasks can be used to guide image denoising. First for image denoising we propose a convolutional neural network in which convolutions are conducted in various spatial resolutions via downsampling and upsampling operations in order to fuse and exploit contextual information on different scales. Second we propose a deep neural network solution that cascades two modules for image denoising and various high-level tasks, respectively, and use the joint loss for updating only the denoising network via back-propagation. We experimentally show that on one hand, the proposed denoiser has the generality to overcome the performance degradation of different high-level vision tasks. On the other hand, with the guidance of high-level vision information, the denoising network produces more visually appealing results. Extensive experiments demonstrate the benefit of exploiting image semantics simultaneously for image denoising and high-level vision tasks via deep learning. The code is available online: this https URL","Thu, 6 Sep 2018 05:13:22 UTC (5,453 KB)"
"311","Geometry of Deep Learning for Magnetic Resonance Fingerprinting","Mohammad Golbabaee, Dongdong Chen, Pedro A. Gomez, Marion I. Menzel, Mike E. Davies","Machine Learning (cs.LG); Machine Learning (stat.ML)","Current popular methods for Magnetic Resonance Fingerprint (MRF) recovery are bottlenecked by the heavy storage and computation requirements of a dictionary-matching (DM) step due to the growing size and complexity of the fingerprint dictionaries in multi-parametric quantitative MRI applications. In this paper we study a deep learning approach to address these shortcomings. Coupled with a dimensionality reduction first layer, the proposed MRF-Net is able to reconstruct quantitative maps by saving more than 60 times in memory and computations required for a DM baseline. Fine-grid manifold enumeration i.e. the MRF dictionary is only used for training the network and not during image reconstruction. We show that the MRF-Net provides a piece-wise affine approximation to the Bloch response manifold projection and that rather than memorizing the dictionary, the network efficiently clusters this manifold and learns a set of hierarchical matched-filters for affine regression of the NMR characteristics in each segment.","Wed, 5 Sep 2018 22:10:16 UTC (349 KB)[v2] Sun, 4 Nov 2018 20:46:12 UTC (972 KB)"
"312","Galaxy detection and identification using deep learning and data augmentation","Roberto E. Gonzalez, Roberto P. Munoz, Cristian A. Hernandez","Instrumentation and Methods for Astrophysics (astro-ph.IM)","We present a method for automatic detection and classification of galaxies which includes a novel data-augmentation procedure to make trained models more robust against the data taken from different instruments and contrast-stretching functions. This method is shown as part of AstroCV, a growing open source computer vision repository for processing and analyzing big astronomical datasets, including high performance Python and C++ algorithms used in the areas of image processing and computer vision. The underlying models were trained using convolutional neural networks and deep learning techniques, which provide better results than methods based on manual feature engineering and SVMs in most of the cases where training datasets are large. The detection and classification methods were trained end-to-end using public datasets such as the Sloan Digital Sky Survey (SDSS), the Galaxy Zoo, and private datasets such as the Next Generation Virgo (NGVS) and Fornax (NGFS) surveys. Training results are strongly bound to the conversion method from raw FITS data for each band into a 3-channel color image. Therefore, we propose data augmentation for the training using 5 conversion methods. This greatly improves the overall galaxy detection and classification for images produced from different instruments, bands and data reduction procedures. The detection and classification methods were trained using the deep learning framework DARKNET and the real-time object detection system YOLO. These methods are implemented in C language and CUDA platform, and makes intensive use of graphical processing units (GPU). Using a single high-end Nvidia GPU card, it can process a SDSS image in 50 milliseconds and a DECam image in less than 3 seconds.","Wed, 5 Sep 2018 18:51:24 UTC (2,246 KB)"
"313","Efficient Egocentric Visual Perception Combining Eye-tracking, a Software Retina and Deep Learning","Nina Hristozova, Piotr Ozimek, Jan Paul Siebert","Computer Vision and Pattern Recognition (cs.CV)","We present ongoing work to harness biological approaches to achieving highly efficient egocentric perception by combining the space-variant imaging architecture of the mammalian retina with Deep Learning methods. By pre-processing images collected by means of eye-tracking glasses to control the fixation locations of a software retina model, we demonstrate that we can reduce the input to a DCNN by a factor of 3, reduce the required number of training epochs and obtain over 98% classification rates when training and validating the system on a database of over 26,000 images of 9 object classes.","Wed, 5 Sep 2018 17:19:07 UTC (8,319 KB)"
"314","Merging datasets through deep learning","Kavitha Srinivas, Abraham Gale, Julian Dolby","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Merging datasets is a key operation for data analytics. A frequent requirement for merging is joining across columns that have different surface forms for the same entity (e.g., the name of a person might be represented as ""Douglas Adams"" or ""Adams, Douglas""). Similarly, ontology alignment can require recognizing distinct surface forms of the same entity, especially when ontologies are independently developed. However, data management systems are currently limited to performing merges based on string equality, or at best using string similarity. We propose an approach to performing merges based on deep learning models. Our approach depends on (a) creating a deep learning model that maps surface forms of an entity into a set of vectors such that alternate forms for the same entity are closest in vector space, (b) indexing these vectors using a nearest neighbors algorithm to find the forms that can be potentially joined together. To build these models, we had to adapt techniques from metric learning due to the characteristics of the data; specifically we describe novel sample selection techniques and loss functions that work for this problem. To evaluate our approach, we used Wikidata as ground truth and built models from datasets with approximately 1.1M people's names (200K identities) and 130K company names (70K identities). We developed models that allow for joins with precision@1 of .75-.81 and recall of .74-.81. We make the models available for aligning people or companies across multiple datasets.","Wed, 5 Sep 2018 16:19:26 UTC (2,469 KB)"
"315","Zero Shot Learning for Code Education: Rubric Sampling with Deep Learning Inference","Mike Wu, Milan Mosse, Noah Goodman, Chris Piech","Machine Learning (cs.LG); Computers and Society (cs.CY); Machine Learning (stat.ML)","In modern computer science education, massive open online courses (MOOCs) log thousands of hours of data about how students solve coding challenges. Being so rich in data, these platforms have garnered the interest of the machine learning community, with many new algorithms attempting to autonomously provide feedback to help future students learn. But what about those first hundred thousand students? In most educational contexts (i.e. classrooms), assignments do not have enough historical data for supervised learning. In this paper, we introduce a human-in-the-loop ""rubric sampling"" approach to tackle the ""zero shot"" feedback challenge. We are able to provide autonomous feedback for the first students working on an introductory programming assignment with accuracy that substantially outperforms data-hungry algorithms and approaches human level fidelity. Rubric sampling requires minimal teacher effort, can associate feedback with specific parts of a student's solution and can articulate a student's misconceptions in the language of the instructor. Deep learning inference enables rubric sampling to further improve as more assignment specific student data is acquired. We demonstrate our results on a novel dataset from Code.org, the world's largest programming education platform.","Wed, 5 Sep 2018 07:13:30 UTC (4,553 KB)"
"316","SchNetPack: A Deep Learning Toolbox For Atomistic Systems","K.T. Schutt, P. Kessel, M. Gastegger, K. Nicoli, A. Tkatchenko, K.-R. Muller","Computational Physics (physics.comp-ph); Chemical Physics (physics.chem-ph)","SchNetPack is a toolbox for the development and application of deep neural networks to the prediction of potential energy surfaces and other quantum-chemical properties of molecules and materials. It contains basic building blocks of atomistic neural networks, manages their training and provides simple access to common benchmark datasets. This allows for an easy implementation and evaluation of new models. For now, SchNetPack includes implementations of (weighted) atomcentered symmetry functions and the deep tensor neural network SchNet as well as ready-to-use scripts that allow to train these models on molecule and material datasets. Based upon the PyTorch deep learning framework, SchNetPack allows to efficiently apply the neural networks to large datasets with millions of reference calculations as well as parallelize the model across multiple GPUs. Finally, SchNetPack provides an interface to the Atomic Simulation Environment in order to make trained models easily accessible to researchers that are not yet familiar with neural networks.","Tue, 4 Sep 2018 16:25:45 UTC (2,002 KB)"
"317","Automated segmentation on the entire cardiac cycle using a deep learning work-flow","Nicolo Savioli, Miguel Silva Vieira, Pablo Lamata, Giovanni Montana","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","The segmentation of the left ventricle (LV) from CINE MRI images is essential to infer important clinical parameters. Typically, machine learning algorithms for automated LV segmentation use annotated contours from only two cardiac phases, diastole, and systole. In this work, we present an analysis work-flow for fully-automated LV segmentation that learns from images acquired through the cardiac cycle. The workflow consists of three components: first, for each image in the sequence, we perform an automated localization and subsequent cropping of the bounding box containing the cardiac silhouette. Second, we identify the LV contours using a Temporal Fully Convolutional Neural Network (T-FCNN), which extends Fully Convolutional Neural Networks (FCNN) through a recurrent mechanism enforcing temporal coherence across consecutive frames. Finally, we further defined the boundaries using either one of two components: fully-connected Conditional Random Fields (CRFs) with Gaussian edge potentials and Semantic Flow. Our initial experiments suggest that significant improvement in performance can potentially be achieved by using a recurrent neural network component that explicitly learns cardiac motion patterns whilst performing LV segmentation.","Fri, 31 Aug 2018 17:07:31 UTC (466 KB)"
"318","Deep Learning Based Vehicle Make-Model Classification","Burak Satar, Ahmet Emir Dirik","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","This paper studies the problems of vehicle make & model classification. Some of the main challenges are reaching high classification accuracy and reducing the annotation time of the images. To address these problems, we have created a fine-grained database using online vehicle marketplaces of Turkey. A pipeline is proposed to combine an SSD (Single Shot Multibox Detector) model with a CNN (Convolutional Neural Network) model to train on the database. In the pipeline, we first detect the vehicles by following an algorithm which reduces the time for annotation. Then, we feed them into the CNN model. It is reached approximately 4% better classification accuracy result than using a conventional CNN model. Next, we propose to use the detected vehicles as ground truth bounding box (GTBB) of the images and feed them into an SSD model in another pipeline. At this stage, it is reached reasonable classification accuracy result without using perfectly shaped GTBB. Lastly, an application is implemented in a use case by using our proposed pipelines. It detects the unauthorized vehicles by comparing their license plate numbers and make & models. It is assumed that license plates are readable.","Thu, 23 Aug 2018 14:05:31 UTC (4,084 KB)"
"319","Image Reassembly Combining Deep Learning and Shortest Path Problem","M.-M. Paumard, D. Picard, H. Tabia","Computer Vision and Pattern Recognition (cs.CV)","This paper addresses the problem of reassembling images from disjointed fragments. More specifically, given an unordered set of fragments, we aim at reassembling one or several possibly incomplete images. The main contributions of this work are: 1) several deep neural architectures to predict the relative position of image fragments that outperform the previous state of the art; 2) casting the reassembly problem into the shortest path in a graph problem for which we provide several construction algorithms depending on available information; 3) a new dataset of images taken from the Metropolitan Museum of Art (MET) dedicated to image reassembly for which we provide a clear setup and a strong baseline.","Tue, 4 Sep 2018 11:39:03 UTC (1,294 KB)"
"320","Improving the Expressiveness of Deep Learning Frameworks with Recursion","Eunji Jeong, Joo Seong Jeong, Soojeong Kim, Gyeong-In Yu, Byung-Gon Chun","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (stat.ML)","Recursive neural networks have widely been used by researchers to handle applications with recursively or hierarchically structured data. However, embedded control flow deep learning frameworks such as TensorFlow, Theano, Caffe2, and MXNet fail to efficiently represent and execute such neural networks, due to lack of support for recursion. In this paper, we add recursion to the programming model of existing frameworks by complementing their design with recursive execution of dataflow graphs as well as additional APIs for recursive definitions. Unlike iterative implementations, which can only understand the topological index of each node in recursive data structures, our recursive implementation is able to exploit the recursive relationships between nodes for efficient execution based on parallel computation. We present an implementation on TensorFlow and evaluation results with various recursive neural network models, showing that our recursive implementation not only conveys the recursive nature of recursive neural networks better than other implementations, but also uses given resources more effectively to reduce training and inference time.","Tue, 4 Sep 2018 08:31:21 UTC (1,216 KB)"
"321","A Deep Learning Spatiotemporal Prediction Framework for Mobile Crowdsourced Services","Ahmed Ben Said, Abdelkarim Erradi, Azadeh Ghari Neiat, Athman Bouguettaya","Machine Learning (cs.LG); Machine Learning (stat.ML)","This papers presents a deep learning-based framework to predict crowdsourced service availability spatially and temporally. A novel two-stage prediction model is introduced based on historical spatio-temporal traces of mobile crowdsourced services. The prediction model first clusters mobile crowdsourced services into regions. The availability prediction of a mobile crowdsourced service at a certain location and time is then formulated as a classification problem. To determine the availability duration of predicted mobile crowdsourced services, we formulate a forecasting task of time series using the Gramian Angular Field. We validated the effectiveness of the proposed framework through multiple experiments.","Tue, 4 Sep 2018 07:03:58 UTC (1,589 KB)"
"322","Spatial-Spectral Fusion by Combining Deep Learning and Variation Model","Huanfeng Shen, Menghui Jiang, Jie Li, Qiangqiang Yuan, Yanchong Wei, Liangpei Zhang","Computer Vision and Pattern Recognition (cs.CV)","In the field of spatial-spectral fusion, the model-based method and the deep learning (DL)-based method are state-of-the-art. This paper presents a fusion method that incorporates the deep neural network into the model-based method for the most common case in the spatial-spectral fusion: PAN/multispectral (MS) fusion. Specifically, we first map the gradient of the high spatial resolution panchromatic image (HR-PAN) and the low spatial resolution multispectral image (LR-MS) to the gradient of the high spatial resolution multispectral image (HR-MS) via a deep residual convolutional neural network (CNN). Then we construct a fusion framework by the LR-MS image, the gradient prior learned from the gradient network, and the ideal fused image. Finally, an iterative optimization algorithm is used to solve the fusion model. Both quantitative and visual assessments on high-quality images from various sources demonstrate that the proposed fusion method is superior to all the mainstream algorithms included in the comparison in terms of overall fusion accuracy.","Tue, 4 Sep 2018 01:39:04 UTC (1,052 KB)"
"323","Learned Cardinalities: Estimating Correlated Joins with Deep Learning","Andreas Kipf, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter Boncz, Alfons Kemper","Databases (cs.DB)","We describe a new deep learning approach to cardinality estimation. MSCN is a multi-set convolutional network, tailored to representing relational query plans, that employs set semantics to capture query features and true cardinalities. MSCN builds on sampling-based estimation, addressing its weaknesses when no sampled tuples qualify a predicate, and in capturing join-crossing correlations. Our evaluation of MSCN using a real-world dataset shows that deep learning significantly enhances the quality of cardinality estimation, which is the core problem in query optimization.","Mon, 3 Sep 2018 18:05:12 UTC (214 KB)"
"324","Deep learning for language understanding of mental health concepts derived from Cognitive Behavioural Therapy","Lina Rojas-Barahona, Bo-Hsiang Tseng, Yinpei Dai, Clare Mansfield, Osman Ramadan, Stefan Ultes, Michael Crawford, Milica Gasic","Computation and Language (cs.CL)","In recent years, we have seen deep learning and distributed representations of words and sentences make impact on a number of natural language processing tasks, such as similarity, entailment and sentiment analysis. Here we introduce a new task: understanding of mental health concepts derived from Cognitive Behavioural Therapy (CBT). We define a mental health ontology based on the CBT principles, annotate a large corpus where this phenomena is exhibited and perform understanding using deep learning and distributed representations. Our results show that the performance of deep learning models combined with word embeddings or sentence embeddings significantly outperform non-deep-learning models in this difficult task. This understanding module will be an essential component of a statistical dialogue system delivering therapy.","Mon, 3 Sep 2018 16:17:11 UTC (1,118 KB)"
"325","Deep Learning of Human Perception in Audio Event Classification","Yi Yu, Samuel Beuret, Donghuo Zeng, Keizo Oyama","Sound (cs.SD); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)","In this paper, we introduce our recent studies on human perception in audio event classification by different deep learning models. In particular, the pre-trained model VGGish is used as feature extractor to process audio data, and DenseNet is trained by and used as feature extractor for our electroencephalography (EEG) data. The correlation between audio stimuli and EEG is learned in a shared space. In the experiments, we record brain activities (EEG signals) of several subjects while they are listening to music events of 8 audio categories selected from Google AudioSet, using a 16-channel EEG headset with active electrodes. Our experimental results demonstrate that i) audio event classification can be improved by exploiting the power of human perception, and ii) the correlation between audio stimuli and EEG can be learned to complement audio event understanding.","Mon, 3 Sep 2018 08:47:32 UTC (203 KB)"
"326","Identifying Land Patterns from Satellite Imagery in Amazon Rainforest using Deep Learning","Somnath Rakshit, Soumyadeep Debnath, Dhiman Mondal","Computer Vision and Pattern Recognition (cs.CV)","The Amazon rainforests have been suffering widespread damage, both via natural and artificial means. Every minute, it is estimated that the world loses forest cover the size of 48 football fields. Deforestation in the Amazon rainforest has led to drastically reduced biodiversity, loss of habitat, climate change, and other biological losses. In this respect, it has become essential to track how the nature of these forests change over time. Image classification using deep learning can help speed up this process by removing the manual task of classifying each image. Here, it is shown how convolutional neural networks can be used to track changes in land patterns in the Amazon rainforests. In this work, a testing accuracy of 96.71% was obtained. This can help governments and other agencies to track changes in land patterns more effectively and accurately.","Sun, 2 Sep 2018 14:06:39 UTC (2,830 KB)"
"327","Car Monitoring System in Apartment Garages by Small Autonomous Car using Deep Learning","Leonardo Leon, Felipe Moreno, Renato Castro, Jose Navio, Marco Capcha","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)","Currently, there is an increase in the number of Peruvian families living in apartments instead of houses for the lots of advantage; however, in some cases there are troubles such as robberies of goods that are usually left at the parking lots or the entrance of strangers that use the tenants parking lots (this last trouble sometimes is related to kidnappings or robberies in building apartments). Due to these problems, the use of a self-driving mini-car is proposed to implement a monitoring system of license plates in an underground garage inside a building using a deep learning model with the aim of recording the vehicles and identifying their owners if they were tenants or not. In addition, the small robot has its own location system using beacons that allow us to identify the position of the parking lot corresponding to each tenant of the building while the mini-car is on its way. Finally, one of the objectives of this work is to build a low cost mini-robot that would replace expensive cameras or work together in order to keep safe the goods of tenants.","Sat, 1 Sep 2018 21:00:58 UTC (1,558 KB)[v2] Sat, 29 Sep 2018 01:00:32 UTC (2,852 KB)"
"328","A Simplified Approach to Deep Learning for Image Segmentation","Ishtar Nyawira, Kristi Bushman","Computer Vision and Pattern Recognition (cs.CV)","Leaping into the rapidly developing world of deep learning is an exciting and sometimes confusing adventure. All of the advice and tutorials available can be hard to organize and work through, especially when training specific models on specific datasets, different from those originally used to train the network. In this short guide, we aim to walk the reader through the techniques that we have used to successfully train two deep neural networks for pixel-wise classification, including some data management and augmentation approaches for working with image data that may be insufficiently annotated or relatively homogenous.","Fri, 31 Aug 2018 23:46:38 UTC (1,381 KB)"
"329","Understanding Neural Pathways in Zebrafish through Deep Learning and High Resolution Electron Microscope Data","Ishtar Nyawira, Kristi Bushman, Iris Qian, Annie Zhang","Computer Vision and Pattern Recognition (cs.CV)","The tracing of neural pathways through large volumes of image data is an incredibly tedious and time-consuming process that significantly encumbers progress in neuroscience. We are exploring deep learning's potential to automate segmentation of high-resolution scanning electron microscope (SEM) image data to remove that barrier. We have started with neural pathway tracing through 5.1GB of whole-brain serial-section slices from larval zebrafish collected by the Center for Brain Science at Harvard University. This kind of manual image segmentation requires years of careful work to properly trace the neural pathways in an organism as small as a zebrafish larva (approximately 5mm in total body length). In automating this process, we would vastly improve productivity, leading to faster data analysis and breakthroughs in understanding the complexity of the brain. We will build upon prior attempts to employ deep learning for automatic image segmentation extending methods for unconventional deep learning data.","Fri, 31 Aug 2018 23:42:11 UTC (1,326 KB)"
"330","Predicting protein inter-residue contacts using composite likelihood maximization and deep learning","Haicang Zhang, Qi Zhang, Fusong Ju, Jianwei Zhu, Shiwei Sun, Yujuan Gao, Ziwei Xie, Minghua Deng, Shiwei Sun, Wei-Mou Zheng, Dongbo Bu","Biomolecules (q-bio.BM); Machine Learning (cs.LG); Methodology (stat.ME)","Accurate prediction of inter-residue contacts of a protein is important to calcu- lating its tertiary structure. Analysis of co-evolutionary events among residues has been proved effective to inferring inter-residue contacts. The Markov ran- dom field (MRF) technique, although being widely used for contact prediction, suffers from the following dilemma: the actual likelihood function of MRF is accurate but time-consuming to calculate, in contrast, approximations to the actual likelihood, say pseudo-likelihood, are efficient to calculate but inaccu- rate. Thus, how to achieve both accuracy and efficiency simultaneously remains a challenge. In this study, we present such an approach (called clmDCA) for contact prediction. Unlike plmDCA using pseudo-likelihood, i.e., the product of conditional probability of individual residues, our approach uses composite- likelihood, i.e., the product of conditional probability of all residue pairs. Com- posite likelihood has been theoretically proved as a better approximation to the actual likelihood function than pseudo-likelihood. Meanwhile, composite likelihood is still efficient to maximize, thus ensuring the efficiency of clmDCA. We present comprehensive experiments on popular benchmark datasets, includ- ing PSICOV dataset and CASP-11 dataset, to show that: i) clmDCA alone outperforms the existing MRF-based approaches in prediction accuracy. ii) When equipped with deep learning technique for refinement, the prediction ac- curacy of clmDCA was further significantly improved, suggesting the suitability of clmDCA for subsequent refinement procedure. We further present successful application of the predicted contacts to accurately build tertiary structures for proteins in the PSICOV dataset. Accessibility: The software clmDCA and a server are publicly accessible through this http URL.","Fri, 31 Aug 2018 23:38:41 UTC (2,317 KB)"
"331","Automatic Lung Cancer Prediction from Chest X-ray Images Using Deep Learning Approach","Worawate Ausawalaithong, Sanparith Marukatat, Arjaree Thirach, Theerawit Wilaiprasitporn","Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)","Since, cancer is curable when diagnosed at an early stage, lung cancer screening plays an important role in preventive care. Although both low dose computed tomography (LDCT) and computed tomography (CT) scans provide more medical information than normal chest x-rays, there is very limited access to these technologies in rural areas. Recently, there is a trend in using computer-aided diagnosis (CADx) to assist in screening and diagnosing of cancer from biomedical images. In this study, the 121-layer convolutional neural network also known as DenseNet-121 by G. Huang et. al., along with the transfer learning scheme was explored as a means to classify lung cancer using chest X-ray images. The model was trained on a lung nodules dataset before training on the lung cancer dataset to alleviate the problem of a small dataset. The proposed model yields 74.43$\pm$6.01\% of mean accuracy, 74.96$\pm$9.85\% of mean specificity, and 74.68$\pm$15.33\% of mean sensitivity. The proposed model also provides a heatmap for identifying the location of the lung nodule. These findings are promising for further development of chest x-ray-based lung cancer diagnosis using the deep learning approach. Moreover, these findings solve the problem of small dataset.","Fri, 31 Aug 2018 17:36:59 UTC (6,837 KB)"
"332","Forecasting solar radiation during dust storms using deep learning","B. Ravindra","Atmospheric and Oceanic Physics (physics.ao-ph); Data Analysis, Statistics and Probability (physics.data-an)","Dust storms are common in arid zones on the earth and others planets such as Mars. The impact of dust storms on solar radiation has significant implications for solar power plants and autonomous vehicles powered by solar panels. This paper deals with the analysis of solar radiation and power output of a rooftop photovoltaic plant during a dust storm and proposes a forecasting methodology using deep learning network. The increased aerosol content due to dust storms increases the diffuse component of the solar radiation. This effect persists for a long duration and can impact the quality of forecasting of solar radiation. Deep learning networks that capture long range structure can improve the quality of solar radiation forecasting during dust storms. These results can help explain the sudden drop in power output of solar plants due to dust storms originating in another continent. They can shed light on mysterious cleaning events in autonomous vehicles powered by solar panels to be used in space missions.","Sat, 25 Aug 2018 02:35:47 UTC (606 KB)"
"333","Towards Asynchronous Motor Imagery-Based Brain-Computer Interfaces: a joint training scheme using deep learning","Patcharin Cheng, Phairot Autthasan, Boriwat Pijarana, Ekapol Chuangsuwanich, Theerawit Wilaiprasitporn","Signal Processing (eess.SP); Human-Computer Interaction (cs.HC); Neurons and Cognition (q-bio.NC)","In this paper, the deep learning (DL) approach is applied to a joint training scheme for asynchronous motor imagery-based Brain-Computer Interface (BCI). The proposed DL approach is a cascade of one-dimensional convolutional neural networks and fully-connected neural networks (CNN-FC). The focus is mainly on three types of brain responses: non-imagery EEG (\textit{background EEG}), (\textit{pure imagery}) EEG, and EEG during the transitional period between background EEG and pure imagery (\textit{transitional imagery}). The study of transitional imagery signals should provide greater insight into real-world scenarios. It may be inferred that pure imagery and transitional EEG are high and low power EEG imagery, respectively. Moreover, the results from the CNN-FC are compared to the conventional approach for motor imagery-BCI, namely the common spatial pattern (CSP) for feature extraction and support vector machine (SVM) for classification (CSP-SVM). Under a joint training scheme, pure and transitional imagery are treated as the same class, while background EEG is another class. Ten-fold cross-validation is used to evaluate whether the joint training scheme significantly improves the performance task of classifying pure and transitional imagery signals from background EEG. Using sparse of just a few electrode channels ($C_{z}$, $C_{3}$ and $C_{4}$), mean accuracy reaches 71.52 % and 70.27 % for CNN-FC and CSP-SVM, respectively. On the other hand, mean accuracy without the joint training scheme achieve only 62.68 % and 52.41 % for CNN-FC and CSP-SVM, respectively.","Fri, 31 Aug 2018 17:30:05 UTC (999 KB)"
"334","Single Channel ECG for Obstructive Sleep Apnea Severity Detection using a Deep Learning Approach","Nannapas Banluesombatkul, Thanawin Rakthanmanon, Theerawit Wilaiprasitporn","Signal Processing (eess.SP)","Obstructive sleep apnea (OSA) is a common sleep disorder caused by abnormal breathing. The severity of OSA can lead to many symptoms such as sudden cardiac death (SCD). Polysomnography (PSG) is a gold standard for OSA diagnosis. It records many signals from the patient's body for at least one whole night and calculates the Apnea-Hypopnea Index (AHI) which is the number of apnea or hypopnea incidences per hour. This value is then used to classify patients into OSA severity levels. However, it has many disadvantages and limitations. Consequently, we proposed a novel methodology of OSA severity classification using a Deep Learning approach. We focused on the classification between normal subjects (AHI $<$ 5) and severe OSA patients (AHI $>$ 30). The 15-second raw ECG records with apnea or hypopnea events were used with a series of deep learning models. The main advantages of our proposed method include easier data acquisition, instantaneous OSA severity detection, and effective feature extraction without domain knowledge from expertise. To evaluate our proposed method, 545 subjects of which 364 were normal and 181 were severe OSA patients obtained from the MrOS sleep study (Visit 1) database were used with the k-fold cross-validation technique. The accuracy of 79.45\% for OSA severity classification with sensitivity, specificity, and F-score was achieved. This is significantly higher than the results from the SVM classifier with RR Intervals and ECG derived respiration (EDR) signal feature extraction. The promising result shows that this proposed method is a good start for the detection of OSA severity from a single channel ECG which can be obtained from wearable devices at home and can also be applied to near real-time alerting systems such as before SCD occurs.","Fri, 31 Aug 2018 17:14:22 UTC (2,088 KB)"
"335","Single-Microphone Speech Enhancement and Separation Using Deep Learning","Morten Kolbk","Sound (cs.SD); Audio and Speech Processing (eess.AS)","The cocktail party problem comprises the challenging task of understanding a speech signal in a complex acoustic environment, where multiple speakers and background noise signals simultaneously interfere with the speech signal of interest. A signal processing algorithm that can effectively increase the speech intelligibility and quality of speech signals in such complicated acoustic situations is highly desirable. Especially for applications involving mobile communication devices and hearing assistive devices. Due to the re-emergence of machine learning techniques, today, known as deep learning, the challenges involved with such algorithms might be overcome. In this PhD thesis, we study and develop deep learning-based techniques for two sub-disciplines of the cocktail party problem: single-microphone speech enhancement and single-microphone multi-talker speech separation. Specifically, we conduct in-depth empirical analysis of the generalizability capability of modern deep learning-based single-microphone speech enhancement algorithms. We show that performance of such algorithms is closely linked to the training data, and good generalizability can be achieved with carefully designed training data. Furthermore, we propose uPIT, a deep learning-based algorithm for single-microphone speech separation and we report state-of-the-art results on a speaker-independent multi-talker speech separation task. Additionally, we show that uPIT works well for joint speech separation and enhancement without explicit prior knowledge about the noise type or number of speakers. Finally, we show that deep learning-based speech enhancement algorithms designed to minimize the classical short-time spectral amplitude mean squared error leads to enhanced speech signals which are essentially optimal in terms of STOI, a state-of-the-art speech intelligibility estimator.","Fri, 31 Aug 2018 07:55:20 UTC (2,186 KB)"
"336","Deep learning, quantum chaos, and pseudorandom evolution","Daniel W.F. Alves, Michael O. Flynn","Quantum Physics (quant-ph); Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech); High Energy Physics - Theory (hep-th)","By modeling quantum chaotic dynamics with ensembles of random operators, we explore how a deep learning architecture known as a convolutional neural network (CNN) can be used to detect pseudorandom behavior in qubit systems. We analyze samples consisting of pieces of correlation functions and find that a CNN is capable of determining the degree of pseudorandomness which a system is subject to. This is done without computing any correlators explicitly. Interestingly, even samples drawn from two-point functions are found to be sufficient to solve this classification problem. This presents the possibility of using deep learning algorithms to explore late time behavior in chaotic quantum systems which have been inaccessible to simulation.","Thu, 30 Aug 2018 19:53:59 UTC (373 KB)"
"337","A Unified Analysis of Stochastic Momentum Methods for Deep Learning","Yan Yan, Tianbao Yang, Zhe Li, Qihang Lin, Yi Yang","Machine Learning (cs.LG); Machine Learning (stat.ML)","Stochastic momentum methods have been widely adopted in training deep neural networks. However, their theoretical analysis of convergence of the training objective and the generalization error for prediction is still under-explored. This paper aims to bridge the gap between practice and theory by analyzing the stochastic gradient (SG) method, and the stochastic momentum methods including two famous variants, i.e., the stochastic heavy-ball (SHB) method and the stochastic variant of Nesterov's accelerated gradient (SNAG) method. We propose a framework that unifies the three variants. We then derive the convergence rates of the norm of gradient for the non-convex optimization problem, and analyze the generalization performance through the uniform stability approach. Particularly, the convergence analysis of the training objective exhibits that SHB and SNAG have no advantage over SG. However, the stability analysis shows that the momentum term can improve the stability of the learned model and hence improve the generalization performance. These theoretical insights verify the common wisdom and are also corroborated by our empirical analysis on deep learning.","Thu, 30 Aug 2018 17:00:03 UTC (449 KB)"
"338","Deep Learning for Quality Control of Subcortical Brain 3D Shape Models","Dmitry Petrov, Boris A. Gutman Egor Kuznetsov, Theo G.M. van Erp, Jessica A. Turner, Lianne Schmaal, Dick Veltman, Lei Wang, Kathryn Alpert, Dmitry Isaev, Artemis Zavaliangos-Petropulu, Christopher R.K. Ching, Vince Calhoun, David Glahn, Theodore D. Satterthwaite, Ole Andreas Andreassen, Stefan Borgwardt, Fleur Howells, Nynke Groenewold, Aristotle Voineskos, Joaquim Radua, Steven G. Potkin, Benedicto Crespo-Facorro, Diana Tordesillas-Gutierrez, Li Shen, Irina Lebedeva, Gianfranco Spalletta, Gary Donohoe, Peter Kochunov, Pedro G.P. Rosa, Anthony James, Udo Dannlowski, Bernhard T. Baune, Andre Aleman, Ian H. Gotlib, Henrik Walter, Martin Walter, Jair C. Soares, Stefan Ehrlich, Ruben C. Gur, N. Trung Doan, Ingrid Agartz, Lars T. Westlye, Fabienne Harrisberger, Anita Riecher-Rossler, Anne Uhlmann, Dan J. Stein, Erin W. Dickie, Edith Pomarol-Clotet, Paola Fuentes-Claramonte, Erick Jorge Canales-Rodriguez, Raymond Salvador, Alexander J. Huang, Roberto Roiz-Santianez, Shan Cong, Alexander Tomyshev, Fabrizio Piras, Daniela Vecchio, Nerisa Banaj, Valentina Ciullo, Elliot Hong, Geraldo Busatto, Marcus V. Zanetti, Mauricio H. Serpa, Simon Cervenka, Sinead Kelly, Dominik Grotegerd, Matthew D. Sacchet, Ilya M. Veer, Meng Li, Mon-Ju Wu, Benson Irungu, Esther Walton, Paul M. Thompson","Neurons and Cognition (q-bio.NC)","We present several deep learning models for assessing the morphometric fidelity of deep grey matter region models extracted from brain MRI. We test three different convolutional neural net architectures (VGGNet, ResNet and Inception) over 2D maps of geometric features. Further, we present a novel geometry feature augmentation technique based on a parametric spherical mapping. Finally, we present an approach for model decision visualization, allowing human raters to see the areas of subcortical shapes most likely to be deemed of failing quality by the machine. Our training data is comprised of 5200 subjects from the ENIGMA Schizophrenia MRI cohorts, and our test dataset contains 1500 subjects from the ENIGMA Major Depressive Disorder cohorts. Our final models reduce human rater time by 46-70%. ResNet outperforms VGGNet and Inception for all of our predictive tasks.","Thu, 30 Aug 2018 14:31:48 UTC (4,555 KB)[v2] Tue, 4 Sep 2018 08:12:34 UTC (4,555 KB)"
"339","Iterative Deep Learning for Road Topology Extraction","Carles Ventura, Jordi Pont-Tuset, Sergi Caelles, Kevis-Kokitsi Maninis, Luc Van Gool","Computer Vision and Pattern Recognition (cs.CV)","This paper tackles the task of estimating the topology of road networks from aerial images. Building on top of a global model that performs a dense semantical classification of the pixels of the image, we design a Convolutional Neural Network (CNN) that predicts the local connectivity among the central pixel of an input patch and its border points. By iterating this local connectivity we sweep the whole image and infer the global topology of the road network, inspired by a human delineating a complex network with the tip of their finger. We perform an extensive and comprehensive qualitative and quantitative evaluation on the road network estimation task, and show that our method also generalizes well when moving to networks of retinal vessels.","Tue, 28 Aug 2018 14:32:44 UTC (4,844 KB)"
"340","Notes on Deep Learning for NLP","Antoine J.-P. Tixier","Computation and Language (cs.CL)","My notes on Deep Learning for NLP.","Wed, 29 Aug 2018 12:58:45 UTC (1,557 KB)[v2] Thu, 30 Aug 2018 17:44:54 UTC (1,557 KB)"
"341","Locating earthquakes with a network of seismic stations via a deep learning method","Xiong Zhang, Jie Zhang, Congcong Yuan, Sen Liu, Zhibo Chen, Weiping Li","Geophysics (physics.geo-ph)","The accurate and automated determination of earthquake locations is still a challenging endeavor. However, such information is critical for monitoring seismic activity and assessing potential hazards in real time. Recently, a convolutional neural network was applied to detect earthquakes from single-station waveforms and approximately map events across several large surface areas. In this study, we locate 194 earthquakes induced during oil and gas operations in Oklahoma, USA, within an error range of approximately 4.9 km on average to the epicenter and 1.0 km to the depth in catalogs with data from 30 network stations by applying the fully convolutional network. The network is trained by 1,013 historic events, and the output is a 3D volume of the event location probability in the Earth. The trained system requires approximately one hundredth of a second to locate an event without the need for any velocity model or human interference.","Wed, 29 Aug 2018 02:07:13 UTC (4,889 KB)"
"342","DLFuzz: Differential Fuzzing Testing of Deep Learning Systems","Jianmin Guo, Yu Jiang, Yue Zhao, Quan Chen, Jiaguang Sun","Software Engineering (cs.SE)","Deep learning (DL) systems are increasingly applied to safety-critical domains such as autonomous driving cars. It is of significant importance to ensure the reliability and robustness of DL systems. Existing testing methodologies always fail to include rare inputs in the testing dataset and exhibit low neuron coverage. In this paper, we propose DLFuzz, the frst differential fuzzing testing framework to guide DL systems exposing incorrect behaviors. DLFuzz keeps minutely mutating the input to maximize the neuron coverage and the prediction difference between the original input and the mutated input, without manual labeling effort or cross-referencing oracles from other DL systems with the same functionality. We present empirical evaluations on two well-known datasets to demonstrate its efficiency. Compared with DeepXplore, the state-of-the-art DL whitebox testing framework, DLFuzz does not require extra efforts to find similar functional DL systems for cross-referencing check, but could generate 338.59% more adversarial inputs with 89.82% smaller perturbations, averagely obtain 2.86% higher neuron coverage, and save 20.11% time consumption.","Tue, 28 Aug 2018 17:08:38 UTC (171 KB)"
"343","PhaseMAC: A 14 TOPS/W 8bit GRO based Phase Domain MAC Circuit for In-Sensor-Computed Deep Learning Accelerators","Kentaro Yoshioka, Yosuke Toyama, Koichiro Ban, Daisuke Yashima, Shigeru Maya, Akihide Sai, Kohei Onizuka","Other Computer Science (cs.OH)","PhaseMAC (PMAC), a phase domain Gated-Ring-Oscillator (GRO) based 8bit MAC circuit, is proposed to minimize both area and power consumption of deep learning accelerators. PMAC composes of only digital cells and consumes significantly smaller power than standard digital designs, owing to its efficient analog accumulation nature. It occupies 26.6 times smaller area than conventional analog designs, which is competitive to digital MAC circuits. PMAC achieves a peak efficiency of 14 TOPS/W, which is best reported and 48% higher than conventional arts. Results in anomaly detection tasks are demonstrated, which is the hottest application in the industrial IoT scene.","Thu, 23 Aug 2018 19:59:53 UTC (1,128 KB)"
"344","Deep Learning of Vortex Induced Vibrations","Maziar Raissi, Zhicheng Wang, Michael S. Triantafyllou, George Em Karniadakis","Fluid Dynamics (physics.flu-dyn); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG); Analysis of PDEs (math.AP); Machine Learning (stat.ML)","Vortex induced vibrations of bluff bodies occur when the vortex shedding frequency is close to the natural frequency of the structure. Of interest is the prediction of the lift and drag forces on the structure given some limited and scattered information on the velocity field. This is an inverse problem that is not straightforward to solve using standard computational fluid dynamics (CFD) methods, especially since no information is provided for the pressure. An even greater challenge is to infer the lift and drag forces given some dye or smoke visualizations of the flow field. Here we employ deep neural networks that are extended to encode the incompressible Navier-Stokes equations coupled with the structure's dynamic motion equation. In the first case, given scattered data in space-time on the velocity field and the structure's motion, we use four coupled deep neural networks to infer very accurately the structural parameters, the entire time-dependent pressure field (with no prior training data), and reconstruct the velocity vector field and the structure's dynamic motion. In the second case, given scattered data in space-time on a concentration field only, we use five coupled deep neural networks to infer very accurately the vector velocity field and all other quantities of interest as before. This new paradigm of inference in fluid mechanics for coupled multi-physics problems enables velocity and pressure quantification from flow snapshots in small subdomains and can be exploited for flow control applications and also for system identification.","Sun, 26 Aug 2018 20:54:33 UTC (2,931 KB)"
"345","Deep Learning for Stress Field Prediction Using Convolutional Neural Networks","Zhenguo Nie, Haoliang Jiang, Levent Burak Kara","Machine Learning (cs.LG); Machine Learning (stat.ML)","This research presents a deep learning based approach to predict stress fields in the solid material elastic deformation using convolutional neural networks (CNN). Two different architectures are proposed to solve the problem. One is Feature Representation embedded Convolutional Neural Network (FR-CNN) with a single input channel, and the other is Squeeze-and-Excitation Residual network modules embedded Fully Convolutional Neural network (SE-Res-FCN) with multiple input channels. Both the tow architectures are stable and converged reliably in training and testing on GPUs. Accuracy analysis shows that SE-Res-FCN has a significantly smaller mean squared error (MSE) and mean absolute error (MAE) than FR-CNN. Mean relative error (MRE) of the SE-Res-FCN model is about 0.25% with respect to the average ground truth. The validation results indicate that the SE-Res-FCN model can accurately predict the stress field. For stress field prediction, the hierarchical architecture becomes deeper within certain limits, and then its prediction becomes more accurate. Fully trained deep learning models have higher computational efficiency over conventional FEM models, so they have great foreground and potential in structural design and topology optimization.","Mon, 27 Aug 2018 16:34:51 UTC (1,289 KB)"
"346","Deep Learning: Computational Aspects","Nicholas Polson, Vadim Sokolov","Machine Learning (cs.LG); Computation (stat.CO); Machine Learning (stat.ML)","In this article we review computational aspects of Deep Learning (DL). Deep learning uses network architectures consisting of hierarchical layers of latent variables to construct predictors for high-dimensional input-output models. Training a deep learning architecture is computationally intensive, and efficient linear algebra libraries is the key for training and inference. Stochastic gradient descent (SGD) optimization and batch sampling are used to learn from massive data sets.","Sun, 26 Aug 2018 20:26:11 UTC (2,144 KB)"
"347","Automatic 3D bi-ventricular segmentation of cardiac images by a shape-constrained multi-task deep learning approach","Jinming Duan, Ghalib Bello, Jo Schlemper, Wenjia Bai, Timothy J W Dawes, Carlo Biffi, Antonio de Marvao, Georgia Doumou, Declan P O'Regan, Daniel Rueckert","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)","Deep learning approaches have achieved state-of-the-art performance in cardiac magnetic resonance (CMR) image segmentation. However, most approaches have focused on learning image intensity features for segmentation, whereas the incorporation of anatomical shape priors has received less attention. In this paper, we combine a multi-task deep learning approach with atlas propagation to develop a shape-constrained bi-ventricular segmentation pipeline for short-axis CMR volumetric images. The pipeline first employs a fully convolutional network (FCN) that learns segmentation and landmark localisation tasks simultaneously. The architecture of the proposed FCN uses a 2.5D representation, thus combining the computational advantage of 2D FCNs networks and the capability of addressing 3D spatial consistency without compromising segmentation accuracy. Moreover, the refinement step is designed to explicitly enforce a shape constraint and improve segmentation quality. This step is effective for overcoming image artefacts (e.g. due to different breath-hold positions and large slice thickness), which preclude the creation of anatomically meaningful 3D cardiac shapes. The proposed pipeline is fully automated, due to network's ability to infer landmarks, which are then used downstream in the pipeline to initialise atlas propagation. We validate the pipeline on 1831 healthy subjects and 649 subjects with pulmonary hypertension. Extensive numerical experiments on the two datasets demonstrate that our proposed method is robust and capable of producing accurate, high-resolution and anatomically smooth bi-ventricular 3D models, despite the artefacts in input CMR volumes.","Sun, 26 Aug 2018 15:42:50 UTC (7,335 KB)[v2] Tue, 28 Aug 2018 13:18:46 UTC (7,335 KB)"
"348","Deep-Learning Ensembles for Skin-Lesion Segmentation, Analysis, Classification: RECOD Titans at ISIC Challenge 2018","Alceu Bissoto, Fabio Perez, Vinicius Ribeiro, Michel Fornaciali, Sandra Avila, Eduardo Valle","Computer Vision and Pattern Recognition (cs.CV)","This extended abstract describes the participation of RECOD Titans in parts 1 to 3 of the ISIC Challenge 2018 ""Skin Lesion Analysis Towards Melanoma Detection"" (MICCAI 2018). Although our team has a long experience with melanoma classification and moderate experience with lesion segmentation, the ISIC Challenge 2018 was the very first time we worked on lesion attribute detection. For each task we submitted 3 different ensemble approaches, varying combinations of models and datasets. Our best results on the official testing set, regarding the official metric of each task, were: 0.728 (segmentation), 0.344 (attribute detection) and 0.803 (classification). Those submissions reached, respectively, the 56th, 14th and 9th places.","Sat, 25 Aug 2018 22:50:43 UTC (82 KB)"
"349","Guiding Deep Learning System Testing using Surprise Adequacy","Jinhan Kim, Robert Feldt, Shin Yoo","Software Engineering (cs.SE); Neural and Evolutionary Computing (cs.NE)","Deep Learning (DL) systems are rapidly being adopted in safety and security critical domains, urgently calling for ways to test their correctness and robustness. Testing of DL systems has traditionally relied on manual collection and labelling of data. Recently, a number of coverage criteria based on neuron activation values have been proposed. These criteria essentially count the number of neurons whose activation during the execution of a DL system satisfied certain properties, such as being above predefined thresholds. However, existing coverage criteria are not sufficiently fine grained to capture subtle behaviours exhibited by DL systems. Moreover, evaluations have focused on showing correlation between adversarial examples and proposed criteria rather than evaluating and guiding their use for actual testing of DL systems. We propose a novel test adequacy criterion for testing of DL systems, called Surprise Adequacy for Deep Learning Systems (SADL), which is based on the behaviour of DL systems with respect to their training data. We measure the surprise of an input as the difference in DL system's behaviour between the input and the training data (i.e., what was learnt during training), and subsequently develop this as an adequacy criterion: a good test input should be sufficiently but not overtly surprising compared to training data. Empirical evaluation using a range of DL systems from simple image classifiers to autonomous driving car platforms shows that systematic sampling of inputs based on their surprise can improve classification accuracy of DL systems against adversarial examples by up to 77.5% via retraining.","Sat, 25 Aug 2018 15:55:59 UTC (1,119 KB)"
"350","Reducing model bias in a deep learning classifier using domain adversarial neural networks in the MINERvA experiment","G. N. Perdue, A. Ghosh, M. Wospakrik, F. Akbar, D. A. Andrade, M. Ascencio, L. Bellantoni, A. Bercellie, M. Betancourt, G. F. R. Caceres Vera, T. Cai, M. F. Carneiro, J. Chaves, D. Coplowe, H. da Motta, G. A. Diaz, J. Felix, L. Fields, R. Fine, A. M. Gago, R. Galindo, T. Golan, R. Gran, J. Y. Han, D. A. Harris, D. Jena, J. Kleykamp, M. Kordosky, X. G. Lu, E. Maher, W. A. Mann, C. M. Marshall, K. S. McFarland, A. M. McGowan, B. Messerly, J. Miller, J. K. Nelson, C. Nguyen, A. Norrick, Nuruzzaman, A. Olivier, R. Patton, M. A. Ramirez, R. D. Ransome, H. Ray, L. Ren, D. Rimal, D. Ruterbories, H. Schellman, C. J. Solano Salinas, H. Su, S. Upadhyay, E. Valencia, J. Wolcott, B. Yaeggy, S. Young","Data Analysis, Statistics and Probability (physics.data-an)","We present a simulation-based study using deep convolutional neural networks (DCNNs) to identify neutrino interaction vertices in the MINERvA passive targets region, and illustrate the application of domain adversarial neural networks (DANNs) in this context. DANNs are designed to be trained in one domain (simulated data) but tested in a second domain (physics data) and utilize unlabeled data from the second domain so that during training only features which are unable to discriminate between the domains are promoted. MINERvA is a neutrino-nucleus scattering experiment using the NuMI beamline at Fermilab. $A$-dependent cross sections are an important part of the physics program, and these measurements require vertex finding in complicated events. To illustrate the impact of the DANN we used a modified set of simulation in place of physics data during the training of the DANN and then used the label of the modified simulation during the evaluation of the DANN. We find that deep learning based methods offer significant advantages over our prior track-based reconstruction for the task of vertex finding, and that DANNs are able to improve the performance of deep networks by leveraging available unlabeled data and by mitigating network performance degradation rooted in biases in the physics models used for training.","Fri, 24 Aug 2018 23:13:51 UTC (4,117 KB)[v2] Tue, 28 Aug 2018 22:26:01 UTC (4,115 KB)[v3] Mon, 12 Nov 2018 23:14:08 UTC (4,274 KB)"
"351","Brain Biomarker Interpretation in ASD Using Deep Learning and fMRI","Xiaoxiao Li, Nicha C. Dvornek, Juntang Zhuang, Pamela Ventola, James S. Duncan","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)","Autism spectrum disorder (ASD) is a complex neurodevelopmental disorder. Finding the biomarkers associated with ASD is extremely helpful to understand the underlying roots of the disorder and can lead to earlier diagnosis and more targeted treatment. Although Deep Neural Networks (DNNs) have been applied in functional magnetic resonance imaging (fMRI) to identify ASD, understanding the data-driven computational decision making procedure has not been previously explored. Therefore, in this work, we address the problem of interpreting reliable biomarkers associated with identifying ASD; specifically, we propose a 2-stage method that classifies ASD and control subjects using fMRI images and interprets the saliency features activated by the classifier. First, we trained an accurate DNN classifier. Then, for detecting the biomarkers, different from the DNN visualization works in computer vision, we take advantage of the anatomical structure of brain fMRI and develop a frequency-normalized sampling method to corrupt images. Furthermore, in the ASD vs. control subjects classification scenario, we provide a new approach to detect and characterize important brain features into three categories. The biomarkers we found by the proposed method are robust and consistent with previous findings in the literature. We also validate the detected biomarkers by neurological function decoding and comparing with the DNN activation maps.","Thu, 23 Aug 2018 06:24:56 UTC (1,422 KB)"
"352","Improving Breast Cancer Detection using Symmetry Information with Deep Learning","Yeman Brhane Hagos, Albert Gubern Merida, Jonas Teuwen","Computer Vision and Pattern Recognition (cs.CV)","Convolutional Neural Networks (CNN) have had a huge success in many areas of computer vision and medical image analysis. However, there is still an immense potential for performance improvement in mammogram breast cancer detection Computer-Aided Detection (CAD) systems by integrating all the information that the radiologist utilizes, such as symmetry and temporal data. In this work, we proposed a patch based multi-input CNN that learns symmetrical difference to detect breast masses. The network was trained on a large-scale dataset of 28294 mammogram images. The performance was compared to a baseline architecture without symmetry context using Area Under the ROC Curve (AUC) and Competition Performance Metric (CPM). At candidate level, AUC value of 0.933 with 95% confidence interval of [0.920, 0.954] was obtained when symmetry information is incorporated in comparison with baseline architecture which yielded AUC value of 0.929 with [0.919, 0.947] confidence interval. By incorporating symmetrical information, although there was no a significant candidate level performance again (p = 0.111), we have found a compelling result at exam level with CPM value of 0.733 (p = 0.001). We believe that including temporal data, and adding benign class to the dataset could improve the detection performance.","Fri, 17 Aug 2018 11:04:42 UTC (940 KB)"
"353","An Improvement of Data Classification Using Random Multimodel Deep Learning (RMDL)","Mojtaba Heidarysafa, Kamran Kowsari, Donald E. Brown, Kiana Jafari Meimandi, Laura E. Barnes","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","The exponential growth in the number of complex datasets every year requires more enhancement in machine learning methods to provide robust and accurate data classification. Lately, deep learning approaches have achieved surpassing results in comparison to previous machine learning algorithms. However, finding the suitable structure for these models has been a challenge for researchers. This paper introduces Random Multimodel Deep Learning (RMDL): a new ensemble, deep learning approach for classification. RMDL solves the problem of finding the best deep learning structure and architecture while simultaneously improving robustness and accuracy through ensembles of deep learning architectures. In short, RMDL trains multiple randomly generated models of Deep Neural Network (DNN), Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) in parallel and combines their results to produce better result of any of those models individually. In this paper, we describe RMDL model and compare the results for image and text classification as well as face recognition. We used MNIST and CIFAR-10 datasets as ground truth datasets for image classification and WOS, Reuters, IMDB, and 20newsgroup datasets for text classification. Lastly, we used ORL dataset to compare the model performance on face recognition task.","Thu, 23 Aug 2018 00:38:14 UTC (1,755 KB)"
"354","Multi-scenario deep learning for multi-speaker source separation","Jeroen Zegers, Hugo Van hamme","Machine Learning (cs.LG); Machine Learning (stat.ML)","Research in deep learning for multi-speaker source separation has received a boost in the last years. However, most studies are restricted to mixtures of a specific number of speakers, called a specific scenario. While some works included experiments for different scenarios, research towards combining data of different scenarios or creating a single model for multiple scenarios have been very rare. In this work it is shown that data of a specific scenario is relevant for solving another scenario. Furthermore, it is concluded that a single model, trained on different scenarios is capable of matching performance of scenario specific models.","Fri, 24 Aug 2018 11:29:07 UTC (19 KB)"
"355","Atherosclerotic carotid plaques on panoramic imaging: an automatic detection using deep learning with small dataset","Lazar Kats, Marilena Vered, Ayelet Zlotogorski-Hurvitz, Itai Harpaz","Computer Vision and Pattern Recognition (cs.CV)","Stroke is the second most frequent cause of death worldwide with a considerable economic burden on the health systems. In about 15% of strokes, atherosclerotic carotid plaques (ACPs) constitute the main etiological factor. Early detection of ACPs may have a key-role for preventing strokes by managing the patient a-priory to the occurrence of the damage. ACPs can be detected on panoramic images. As these are one of the most common images performed for routine dental practice, they can be used as a source of available data for computerized methods of automatic detection in order to significantly increase timely diagnosis of ACPs. Recently, there has been a definite breakthrough in the field of analysis of medical images due to the use of deep learning based on neural networks. These methods, however have been barely used in dentistry. In this study we used the Faster Region-based Convolutional Network (Faster R-CNN) for deep learning. We aimed to assess the operation of the algorithm on a small database of 65 panoramic images. Due to a small amount of available training data, we had to use data augmentation by changing the brightness and randomly flipping and rotating cropped regions of interest in multiple angles. Receiver Operating Characteristic (ROC) analysis was performed to calculate the accuracy of detection. ACP was detected with a sensitivity of 75%, specificity of 80% and an accuracy of 83%. The ROC analysis showed a significant Area Under Curve (AUC) difference from 0.5. Our novelty lies in that we have showed the efficiency of the Faster R-CNN algorithm in detecting ACPs on routine panoramic images based on a small database. There is a need to further improve the application of the algorithm to the level of introducing this methodology in routine dental practice in order to enable us to prevent stroke events.","Fri, 24 Aug 2018 11:25:36 UTC (327 KB)"
"356","From Hand-Crafted to Deep Learning-based Cancer Radiomics: Challenges and Opportunities","Parnian Afshar, Arash Mohammadi, Konstantinos N. Plataniotis, Anastasia Oikonomou, Habib Benali","Computer Vision and Pattern Recognition (cs.CV)","Recent advancements in signal processing and machine learning coupled with developments of electronic medical record keeping in hospitals and the availability of extensive set of medical images through internal/external communication systems, have resulted in a recent surge of significant interest in ""Radiomics"". Radiomics is an emerging and relatively new research field, which refers to extracting semi-quantitative and/or quantitative features from medical images with the goal of developing predictive and/or prognostic models, and is expected to become a critical component for integration of image-derived information for personalized treatment in the near future. The conventional Radiomics workflow is typically based on extracting pre-designed features (also referred to as hand-crafted or engineered features) from a segmented region of interest. Nevertheless, recent advancements in deep learning have caused trends towards deep learning-based Radiomics (also referred to as discovery Radiomics). Capitalizing on the advantageous of these two approaches, there are also hybrid solutions developed to exploit the potentials of multiple data sources. Considering the variety of approaches to Radiomics, further improvements require a comprehensive and integrated sketch, which is the goal of this article. This manuscript provides a unique interdisciplinary perspective on Radiomics by discussing state-of-the-art signal processing solutions in the context of cancer Radiomics.","Thu, 23 Aug 2018 21:39:12 UTC (1,534 KB)[v2] Mon, 27 Aug 2018 13:08:27 UTC (1,534 KB)"
"357","High frame-rate cardiac ultrasound imaging with deep learning","Ortal Senouf, Sanketh Vedula, Grigoriy Zurakhov, Alex M. Bronstein, Michael Zibulevsky, Oleg Michailovich, Dan Adam, David Blondheim","Computer Vision and Pattern Recognition (cs.CV)","Cardiac ultrasound imaging requires a high frame rate in order to capture rapid motion. This can be achieved by multi-line acquisition (MLA), where several narrow-focused received lines are obtained from each wide-focused transmitted line. This shortens the acquisition time at the expense of introducing block artifacts. In this paper, we propose a data-driven learning-based approach to improve the MLA image quality. We train an end-to-end convolutional neural network on pairs of real ultrasound cardiac data, acquired through MLA and the corresponding single-line acquisition (SLA). The network achieves a significant improvement in image quality for both $5-$ and $7-$line MLA resulting in a decorrelation measure similar to that of SLA while having the frame rate of MLA.","Thu, 23 Aug 2018 16:21:18 UTC (1,958 KB)"
"358","High quality ultrasonic multi-line transmission through deep learning","Sanketh Vedula, Ortal Senouf, Grigoriy Zurakhov, Alex M. Bronstein, Michael Zibulevsky, Oleg Michailovich, Dan Adam, Diana Gaitini","Computer Vision and Pattern Recognition (cs.CV)","Frame rate is a crucial consideration in cardiac ultrasound imaging and 3D sonography. Several methods have been proposed in the medical ultrasound literature aiming at accelerating the image acquisition. In this paper, we consider one such method called \textit{multi-line transmission} (MLT), in which several evenly separated focused beams are transmitted simultaneously. While MLT reduces the acquisition time, it comes at the expense of a heavy loss of contrast due to the interactions between the beams (cross-talk artifact). In this paper, we introduce a data-driven method to reduce the artifacts arising in MLT. To this end, we propose to train an end-to-end convolutional neural network consisting of correction layers followed by a constant apodization layer. The network is trained on pairs of raw data obtained through MLT and the corresponding \textit{single-line transmission} (SLT) data. Experimental evaluation demonstrates significant improvement both in the visual image quality and in objective measures such as contrast ratio and contrast-to-noise ratio, while preserving resolution unlike traditional apodization-based methods. We show that the proposed method is able to generalize well across different patients and anatomies on real and phantom data.","Thu, 23 Aug 2018 16:07:59 UTC (3,122 KB)"
"359","Adversarial Attacks on Deep-Learning Based Radio Signal Classification","Meysam Sadeghi, Erik G. Larsson","Information Theory (cs.IT); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Signal Processing (eess.SP); Machine Learning (stat.ML)","Deep learning (DL), despite its enormous success in many computer vision and language processing applications, is exceedingly vulnerable to adversarial attacks. We consider the use of DL for radio signal (modulation) classification tasks, and present practical methods for the crafting of white-box and universal black-box adversarial attacks in that application. We show that these attacks can considerably reduce the classification performance, with extremely small perturbations of the input. In particular, these attacks are significantly more powerful than classical jamming attacks, which raises significant security and robustness concerns in the use of DL-based algorithms for the wireless physical layer.","Thu, 23 Aug 2018 12:12:10 UTC (138 KB)"
"360","Generating Magnetic Resonance Spectroscopy Imaging Data of Brain Tumours from Linear, Non-Linear and Deep Learning Models","Nathan J Olliverre, Guang Yang, Gregory Slabaugh, Constantino Carlos Reyes-Aldasoro, Eduardo Alonso","Computer Vision and Pattern Recognition (cs.CV)","Magnetic Resonance Spectroscopy (MRS) provides valuable information to help with the identification and understanding of brain tumors, yet MRS is not a widely available medical imaging modality. Aiming to counter this issue, this research draws on the advancements in machine learning techniques in other fields for the generation of artificial data. The generated methods were tested through the evaluation of their output against that of a real-world labelled MRS brain tumor data-set. Furthermore the resultant output from the generative techniques were each used to train separate traditional classifiers which were tested on a subset of the real MRS brain tumor dataset. The results suggest that there exist methods capable of producing accurate, ground truth based MRS voxels. These findings indicate that through generative techniques, large datasets can be made available for training deep, learning models for the use in brain tumor diagnosis.","Thu, 23 Aug 2018 00:02:31 UTC (1,052 KB)"
"361","DeepCorr: Strong Flow Correlation Attacks on Tor Using Deep Learning","Milad Nasr, Alireza Bahramali, Amir Houmansadr","Cryptography and Security (cs.CR); Machine Learning (cs.LG)","Flow correlation is the core technique used in a multitude of deanonymization attacks on Tor. Despite the importance of flow correlation attacks on Tor, existing flow correlation techniques are considered to be ineffective and unreliable in linking Tor flows when applied at a large scale, i.e., they impose high rates of false positive error rates or require impractically long flow observations to be able to make reliable correlations. In this paper, we show that, unfortunately, flow correlation attacks can be conducted on Tor traffic with drastically higher accuracies than before by leveraging emerging learning mechanisms. We particularly design a system, called DeepCorr, that outperforms the state-of-the-art by significant margins in correlating Tor connections. DeepCorr leverages an advanced deep learning architecture to learn a flow correlation function tailored to Tor's complex network this is in contrast to previous works' use of generic statistical correlation metrics to correlated Tor flows. We show that with moderate learning, DeepCorr can correlate Tor connections (and therefore break its anonymity) with accuracies significantly higher than existing algorithms, and using substantially shorter lengths of flow observations. For instance, by collecting only about 900 packets of each target Tor flow (roughly 900KB of Tor data), DeepCorr provides a flow correlation accuracy of 96% compared to 4% by the state-of-the-art system of RAPTOR using the same exact setting. We hope that our work demonstrates the escalating threat of flow correlation attacks on Tor given recent advances in learning algorithms, calling for the timely deployment of effective countermeasures by the Tor community.","Wed, 22 Aug 2018 09:02:53 UTC (1,691 KB)"
"362","A Survey of Modern Object Detection Literature using Deep Learning","Karanbir Singh Chahal, Kuntal Dey","Computer Vision and Pattern Recognition (cs.CV)","Object detection is the identification of an object in the image along with its localisation and classification. It has wide spread applications and is a critical component for vision based software systems. This paper seeks to perform a rigorous survey of modern object detection algorithms that use deep learning. As part of the survey, the topics explored include various algorithms, quality metrics, speed/size trade offs and training methodologies. This paper focuses on the two types of object detection algorithms- the SSD class of single step detectors and the Faster R-CNN class of two step detectors. Techniques to construct detectors that are portable and fast on low powered devices are also addressed by exploring new lightweight convolutional base architectures. Ultimately, a rigorous review of the strengths and weaknesses of each detector leads us to the present state of the art.","Wed, 22 Aug 2018 07:43:50 UTC (1,170 KB)"
"363","Approximating Poker Probabilities with Deep Learning","Brandon Da Silva","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","Many poker systems, whether created with heuristics or machine learning, rely on the probability of winning as a key input. However calculating the precise probability using combinatorics is an intractable problem, so instead we approximate it. Monte Carlo simulation is an effective technique that can be used to approximate the probability that a player will win and/or tie a hand. However, without the use of a memory-intensive lookup table or a supercomputer, it becomes infeasible to run millions of times when training an agent with self-play. To combat the space-time tradeoff, we use deep learning to approximate the probabilities obtained from the Monte Carlo simulation with high accuracy. The learned model proves to be a lightweight alternative to Monte Carlo simulation, which ultimately allows us to use the probabilities as inputs during self-play efficiently. The source code and optimized neural network can be found at this https URL","Wed, 22 Aug 2018 05:14:41 UTC (199 KB)[v2] Thu, 23 Aug 2018 02:21:56 UTC (199 KB)"
"364","Searching for Sub-Second Stellar Variability with Wide-Field Star Trails and Deep Learning","David Thomas, Steven M Kahn","Instrumentation and Methods for Astrophysics (astro-ph.IM)","We present a method that enables wide field ground-based telescopes to scan the sky for sub-second stellar variability. The method has operational and image processing components. The operational component is to take star trail images. Each trail serves as a light curve for its corresponding source and facilitates sub-exposure photometry. We train a deep neural network to identify stellar variability in wide-field star trail images. We use the Large Synoptic Survey Telescope (LSST) Photon Simulator to generate simulated star trail images and include transient bursts as a proxy for variability. The network identifies transient bursts on timescales down to 10 milliseconds. We argue that there are multiple fields of astrophysics that can be advanced by the unique combination of time resolution and observing throughput that our method offers.","Tue, 21 Aug 2018 15:53:28 UTC (2,429 KB)[v2] Tue, 9 Oct 2018 21:25:57 UTC (658 KB)"
"365","Deep Learned Full-3D Object Completion from Single View","Dario Rethage, Federico Tombari, Felix Achilles, Nassir Navab","Computer Vision and Pattern Recognition (cs.CV)","3D geometry is a very informative cue when interacting with and navigating an environment. This writing proposes a new approach to 3D reconstruction and scene understanding, which implicitly learns 3D geometry from depth maps pairing a deep convolutional neural network architecture with an auto-encoder. A data set of synthetic depth views and voxelized 3D representations is built based on ModelNet, a large-scale collection of CAD models, to train networks. The proposed method offers a significant advantage over current, explicit reconstruction methods in that it learns key geometric features offline and makes use of those to predict the most probable reconstruction of an unseen object. The relatively small network, consisting of roughly 4 million weights, achieves a 92.9% reconstruction accuracy at a 30x30x30 resolution through the use of a pre-trained decompression layer. This is roughly 1/4 the weights of the current leading network. The fast execution time of the model makes it suitable for real-time applications.","Tue, 21 Aug 2018 11:07:08 UTC (393 KB)"
"366","Synthetic Patient Generation: A Deep Learning Approach Using Variational Autoencoders","Ally Salim Jr","Machine Learning (cs.LG); Machine Learning (stat.ML)","Artificial Intelligence in healthcare is a new and exciting frontier and the possibilities are endless. With deep learning approaches beating human performances in many areas, the logical next step is to attempt their application in the health space. For these and other Machine Learning approaches to produce good results and have their potential realized, the need for, and importance of, large amounts of accurate data is second to none. This is a challenge faced by many industries and more so in the healthcare space. We present an approach of using Variational Autoencoders (VAE's) as an approach to generating more data for training deeper networks, as well as uncovering underlying patterns in diagnoses and the patients suffering from them. By training a VAE, on available data, it was able to learn the latent distribution of the patient features given the diagnosis. It is then possible, after training, to sample from the learnt latent distribution to generate new accurate patient records given the patient diagnosis.","Mon, 20 Aug 2018 13:36:07 UTC (760 KB)"
"367","Deep learning, deep change? Mapping the development of the Artificial Intelligence General Purpose Technology","J. Klinger, J. Mateos-Garcia, K. Stathoulopoulos","Computers and Society (cs.CY); Econometrics (econ.EM)","General Purpose Technologies (GPTs) that can be applied in many industries are an important driver of economic growth and national and regional competitiveness. In spite of this, the geography of their development and diffusion has not received significant attention in the literature. We address this with an analysis of Deep Learning (DL), a core technique in Artificial Intelligence (AI) increasingly being recognized as the latest GPT. We identify DL papers in a novel dataset from ArXiv, a popular preprints website, and use CrunchBase, a technology business directory to measure industrial capabilities related to it. After showing that DL conforms with the definition of a GPT, having experienced rapid growth and diffusion into new fields where it has generated an impact, we describe changes in its geography. Our analysis shows China's rise in AI rankings and relative decline in several European countries. We also find that initial volatility in the geography of DL has been followed by consolidation, suggesting that the window of opportunity for new entrants might be closing down as new DL research hubs become dominant. Finally, we study the regional drivers of DL clustering. We find that competitive DL clusters tend to be based in regions combining research and industrial activities related to it. This could be because GPT developers and adopters located close to each other can collaborate and share knowledge more easily, thus overcoming coordination failures in GPT deployment. Our analysis also reveals a Chinese comparative advantage in DL after we control for other explanatory factors, perhaps underscoring the importance of access to data and supportive policies for the successful development of this complex, `omni-use' technology.","Mon, 20 Aug 2018 09:14:54 UTC (5,285 KB)"
"368","Neural Body Fitting: Unifying Deep Learning and Model-Based Human Pose and Shape Estimation","Mohamed Omran, Christoph Lassner, Gerard Pons-Moll, Peter V. Gehler, Bernt Schiele","Computer Vision and Pattern Recognition (cs.CV)","Direct prediction of 3D body pose and shape remains a challenge even for highly parameterized deep learning models. Mapping from the 2D image space to the prediction space is difficult: perspective ambiguities make the loss function noisy and training data is scarce. In this paper, we propose a novel approach (Neural Body Fitting (NBF)). It integrates a statistical body model within a CNN, leveraging reliable bottom-up semantic body part segmentation and robust top-down body model constraints. NBF is fully differentiable and can be trained using 2D and 3D annotations. In detailed experiments, we analyze how the components of our model affect performance, especially the use of part segmentations as an explicit intermediate representation, and present a robust, efficiently trainable framework for 3D human pose estimation from 2D images with competitive results on standard benchmarks. Code will be made available at this http URL","Fri, 17 Aug 2018 17:56:10 UTC (7,557 KB)"
"369","Epithelium segmentation using deep learning in H&E-stained prostate specimens with immunohistochemistry as reference standard","Wouter Bulten, Peter Bandi, Jeffrey Hoven, Rob van de Loo, Johannes Lotz, Nick Weiss, Jeroen van der Laak, Bram van Ginneken, Christina Hulsbergen-van de Kaa, Geert Litjens","Computer Vision and Pattern Recognition (cs.CV)","Prostate cancer (PCa) is graded by pathologists by examining the architectural pattern of cancerous epithelial tissue on hematoxylin and eosin (H&E) stained slides. Given the importance of gland morphology, automatically differentiating between glandular epithelial tissue and other tissues is an important prerequisite for the development of automated methods for detecting PCa. We propose a new method, using deep learning, for automatically segmenting epithelial tissue in digitized prostatectomy slides. We employed immunohistochemistry (IHC) to render the ground truth less subjective and more precise compared to manual outlining on H&E slides, especially in areas with high-grade and poorly differentiated PCa. Our dataset consisted of 102 tissue blocks, including both low and high grade PCa. From each block a single new section was cut, stained with H&E, scanned, restained using P63 and CK8/18 to highlight the epithelial structure, and scanned again. The H&E slides were co-registered to the IHC slides. On a subset of the IHC slides we applied color deconvolution, corrected stain errors manually, and trained a U-Net to perform segmentation of epithelial structures. Whole-slide segmentation masks generated by the IHC U-Net were used to train a second U-Net on H&E. Our system makes precise cell-level segmentations and segments both intact glands as well as individual (tumor) epithelial cells. We achieved an F1-score of 0.895 on a hold-out test set and 0.827 on an external reference set from a different center. We envision this segmentation as being the first part of a fully automated prostate cancer detection and grading pipeline.","Fri, 17 Aug 2018 14:36:43 UTC (6,821 KB)"
"370","Deep Learning Architecture for Voltage Stability Evaluation in Smart Grid based on Variational Autoencoders","Haosen Yang, Robert C.Qiu, Xin Shi, Xing He","Signal Processing (eess.SP)","Deep learning, as one of the most popular rising technology, is being applied in power industry widely and gradually. This study explored a novel application of deep learning in voltage stability assessment based on variational autoencoder (VAE). VAE is a novel application of variational inference which have clear mathematical formula, it regularize latent variables in a expected stochastic distribution. VAE have distinctive ability to obtain near P-V curve by mere voltage data. An indicator based on VAE is proposed. For comparison and testing, multiple data-driven indicators based on sparse stacked autoencoder (SSAE) and adversarial autoencoder (AAE) are proposed. All of them extract important low-dimension expression of whole sampling data, showing the distinctive advantages of unsupervised learning [1]. A deep neural network based on proposed index is constructed to estimate voltage stability margin (VSM). Our methods are tested in IEEE-14, IEEE-57 and IEEE-118 bus standard system, and compared mutually. Other experimental cases show the effect of our approach in power grids state awareness, and the effects by limited field data. These testing case illustrate the accuracy and effectiveness of our approach.","Fri, 17 Aug 2018 05:44:07 UTC (787 KB)"
"371","Optimization of photonic crystal nanocavities based on deep learning","Takashi Asano, Susumu Noda","Computational Physics (physics.comp-ph); Applied Physics (physics.app-ph)","An approach to optimizing the Q factors of two-dimensional photonic crystal (2D-PC) nanocavities based on deep learning is proposed and demonstrated. We prepare a dataset consisting of 1000 nanocavities generated by randomly displacing the positions of many air holes of a base nanocavity and their Q factors calculated by a first-principle method. We train a four-layer neural network including a convolutional layer to recognize the relationship between the air holes' displacements and the Q factors using the prepared dataset. After the training, the neural network becomes able to estimate the Q factors from the air holes' displacements with an error of 13% in standard deviation. Crucially, the trained neural network can estimate the gradient of the Q factor with respect to the air holes' displacements very quickly based on back-propagation. A nanocavity structure with an extremely high Q factor of 1.58 x 10^9 is successfully obtained by optimizing the positions of 50 air holes over ~10^6 iterations, having taken advantage of the very fast evaluation of the gradient in high-dimensional parameter space. The obtained Q factor is more than one order of magnitude higher than that of the base cavity and more than twice that of the highest Q factors reported so far for cavities with similar modal volumes. This approach can optimize 2D-PC structures over a parameter space of a size unfeasibly large for previous optimization methods based solely on direct calculations. We believe this approach is also useful for improving other optical characteristics.","Fri, 17 Aug 2018 01:15:36 UTC (1,192 KB)"
"372","Statistical Analysis Driven Optimized Deep Learning System for Intrusion Detection","Cosimo Ieracitano, Ahsan Adeel, Mandar Gogate, Kia Dashtipour, Francesco Carlo Morabito, Hadi Larijani, Ali Raza, Amir Hussain","Cryptography and Security (cs.CR)","Attackers have developed ever more sophisticated and intelligent ways to hack information and communication technology systems. The extent of damage an individual hacker can carry out upon infiltrating a system is well understood. A potentially catastrophic scenario can be envisaged where a nation-state intercepting encrypted financial data gets hacked. Thus, intelligent cybersecurity systems have become inevitably important for improved protection against malicious threats. However, as malware attacks continue to dramatically increase in volume and complexity, it has become ever more challenging for traditional analytic tools to detect and mitigate threat. Furthermore, a huge amount of data produced by large networks has made the recognition task even more complicated and challenging. In this work, we propose an innovative statistical analysis driven optimized deep learning system for intrusion detection. The proposed intrusion detection system (IDS) extracts optimized and more correlated features using big data visualization and statistical analysis methods (human-in-the-loop), followed by a deep autoencoder for potential threat detection. Specifically, a pre-processing module eliminates the outliers and converts categorical variables into one-hot-encoded vectors. The feature extraction module discard features with null values and selects the most significant features as input to the deep autoencoder model (trained in a greedy-wise manner). The NSL-KDD dataset from the Canadian Institute for Cybersecurity is used as a benchmark to evaluate the feasibility and effectiveness of the proposed architecture. Simulation results demonstrate the potential of our proposed system and its outperformance as compared to existing state-of-the-art methods and recently published novel approaches. Ongoing work includes further optimization and real-time evaluation of our proposed IDS.","Thu, 16 Aug 2018 18:24:12 UTC (5,194 KB)"
"373","Anatomy Of High-Performance Deep Learning Convolutions On SIMD Architectures","Evangelos Georganas, Sasikanth Avancha, Kunal Banerjee, Dhiraj Kalamkar, Greg Henry, Hans Pabst, Alexander Heinecke","Distributed, Parallel, and Cluster Computing (cs.DC)","Convolution layers are prevalent in many classes of deep neural networks, including Convolutional Neural Networks (CNNs) which provide state-of-the-art results for tasks like image recognition, neural machine translation and speech recognition. The computationally expensive nature of a convolution operation has led to the proliferation of implementations including matrix-matrix multiplication formulation, and direct convolution primarily targeting GPUs. In this paper, we introduce direct convolution kernels for x86 architectures, in particular for Xeon and XeonPhi systems, which are implemented via a dynamic compilation approach. Our JIT-based implementation shows close to theoretical peak performance, depending on the setting and the CPU architecture at hand. We additionally demonstrate how these JIT-optimized kernels can be integrated into a lightweight multi-node graph execution model. This illustrates that single- and multi-node runs yield high efficiencies and high image-throughputs when executing state-of-the-art image recognition tasks on CPUs.","Thu, 16 Aug 2018 16:18:44 UTC (397 KB)[v2] Mon, 20 Aug 2018 21:08:32 UTC (401 KB)"
"374","Combining time-series and textual data for taxi demand prediction in event areas: a deep learning approach","Filipe Rodrigues, Ioulia Markou, Francisco Pereira","Machine Learning (stat.ML); Computation and Language (cs.CL); Machine Learning (cs.LG)","Accurate time-series forecasting is vital for numerous areas of application such as transportation, energy, finance, economics, etc. However, while modern techniques are able to explore large sets of temporal data to build forecasting models, they typically neglect valuable information that is often available under the form of unstructured text. Although this data is in a radically different format, it often contains contextual explanations for many of the patterns that are observed in the temporal data. In this paper, we propose two deep learning architectures that leverage word embeddings, convolutional layers and attention mechanisms for combining text information with time-series data. We apply these approaches for the problem of taxi demand forecasting in event areas. Using publicly available taxi data from New York, we empirically show that by fusing these two complementary cross-modal sources of information, the proposed models are able to significantly reduce the error in the forecasts.","Thu, 16 Aug 2018 15:19:34 UTC (1,519 KB)"
"375","Deep Learning for Energy Markets","Michael Polson, Vadim Sokolov","Machine Learning (stat.ML); Machine Learning (cs.LG); Statistical Finance (q-fin.ST)","Deep Learning (DL) provides a methodology to predict extreme loads observed in energy grids. Forecasting energy loads and prices is challenging due to sharp peaks and troughs that arise from intraday system constraints due to supply and demand fluctuations. We propose deep spatio-temporal models and extreme value theory (DL-EVT) to capture the tail behavior of load spikes. Deep architectures, such as ReLU and LSTM can model generation trends and temporal dependencies while EVT captures highly volatile load spikes. To illustrate our methodology, we use hourly price and demand data from the PJM interconnection for 4719 nodes and we develop a deep predictor. DL-EVT outperforms traditional Fourier and time series methods, both in-and out-of-sample, by capturing the nonlinearities in prices. Finally, we conclude with directions for future research.","Thu, 16 Aug 2018 15:01:01 UTC (7,638 KB)[v2] Wed, 22 Aug 2018 12:50:41 UTC (7,638 KB)"
"376","DRLGENCERT: Deep Learning-based Automated Testing of Certificate Verification in SSL/TLS Implementations","Chao Chen, Wenrui Diao, Yingpei Zeng, Shanqing Guo, Chengyu Hu","Cryptography and Security (cs.CR)","The Secure Sockets Layer (SSL) and Transport Layer Security (TLS) protocols are the foundation of network security. The certificate verification in SSL/TLS implementations is vital and may become the weak link in the whole network ecosystem. In previous works, some research focused on the automated testing of certificate verification, and the main approaches rely on generating massive certificates through randomly combining parts of seed certificates for fuzzing. Although the generated certificates could meet the semantic constraints, the cost is quite heavy, and the performance is limited due to the randomness. To fill this gap, in this paper, we propose DRLGENCERT, the first framework of applying deep reinforcement learning to the automated testing of certificate verification in SSL/TLS implementations. DRLGENCERT accepts ordinary certificates as input and outputs newly generated certificates which could trigger discrepancies with high efficiency. Benefited by the deep reinforcement learning, when generating certificates, our framework could choose the best next action according to the result of a previous modification, instead of simple random combinations. At the same time, we developed a set of new techniques to support the overall design, like new feature extraction method for X.509 certificates, fine-grained differential testing, and so forth. Also, we implemented a prototype of DRLGENCERT and carried out a series of real-world experiments. The results show DRLGENCERT is quite efficient, and we obtained 84,661 discrepancy-triggering certificates from 181,900 certificate seeds, say around 46.5% effectiveness. Also, we evaluated six popular SSL/TLS implementations, including GnuTLS, MatrixSSL, MbedTLS, NSS, OpenSSL, and wolfSSL. DRLGENCERT successfully discovered 23 serious certificate verification flaws, and most of them were previously unknown.","Thu, 16 Aug 2018 12:30:52 UTC (628 KB)"
"377","Conceptual Domain Adaptation Using Deep Learning","Behrang Mehrparvar, Ricardo Vilalta","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning has recently been shown to be instrumental in the problem of domain adaptation, where the goal is to learn a model on a target domain using a similar --but not identical-- source domain. The rationale for coupling both techniques is the possibility of extracting common concepts across domains. Considering (strictly) local representations, traditional deep learning assumes common concepts must be captured in the same hidden units. We contend that jointly training a model with source and target data using a single deep network is prone to failure when there is inherently lower-level representational discrepancy between the two domains; such discrepancy leads to a misalignment of corresponding concepts in separate hidden units. We introduce a search framework to correctly align high-level representations when training deep networks; such framework leads to the notion of conceptual --as opposed to representational-- domain adaptation.","Thu, 16 Aug 2018 06:25:24 UTC (154 KB)"
"378","Tool Breakage Detection using Deep Learning","Guang Li, Xin Yang, Duanbing Chen, Anxing Song, Yuke Fang, Junlin Zhou","Machine Learning (cs.LG); Machine Learning (stat.ML)","In manufacture, steel and other metals are mainly cut and shaped during the fabrication process by computer numerical control (CNC) machines. To keep high productivity and efficiency of the fabrication process, engineers need to monitor the real-time process of CNC machines, and the lifetime management of machine tools. In a real manufacturing process, breakage of machine tools usually happens without any indication, this problem seriously affects the fabrication process for many years. Previous studies suggested many different approaches for monitoring and detecting the breakage of machine tools. However, there still exists a big gap between academic experiments and the complex real fabrication processes such as the high demands of real-time detections, the difficulty in data acquisition and transmission. In this work, we use the spindle current approach to detect the breakage of machine tools, which has the high performance of real-time monitoring, low cost, and easy to install. We analyze the features of the current of a milling machine spindle through tools wearing processes, and then we predict the status of tool breakage by a convolutional neural network(CNN). In addition, we use a BP neural network to understand the reliability of the CNN. The results show that our CNN approach can detect tool breakage with an accuracy of 93%, while the best performance of BP is 80%.","Thu, 16 Aug 2018 04:45:15 UTC (500 KB)"
"379","Sequential Behavioral Data Processing Using Deep Learning and the Markov Transition Field in Online Fraud Detection","Ruinan Zhang, Fanglan Zheng, Wei Min","Machine Learning (cs.LG); Information Retrieval (cs.IR); Machine Learning (stat.ML)","Due to the popularity of the Internet and smart mobile devices, more and more financial transactions and activities have been digitalized. Compared to traditional financial fraud detection strategies using credit-related features, customers are generating a large amount of unstructured behavioral data every second. In this paper, we propose an Recurrent Neural Netword (RNN) based deep-learning structure integrated with Markov Transition Field (MTF) for predicting online fraud behaviors using customer's interactions with websites or smart-phone apps as a series of states. In practice, we tested and proved that the proposed network structure for processing sequential behavioral data could significantly boost fraud predictive ability comparing with the multilayer perceptron network and distance based classifier with Dynamic Time Warping(DTW) as distance metric.","Thu, 16 Aug 2018 02:58:54 UTC (505 KB)"
"380","DeepDownscale: a Deep Learning Strategy for High-Resolution Weather Forecast","Eduardo R. Rodrigues, Igor Oliveira, Renato L. F. Cunha, Marco A. S. Netto","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Running high-resolution physical models is computationally expensive and essential for many disciplines. Agriculture, transportation, and energy are sectors that depend on high-resolution weather models, which typically consume many hours of large High Performance Computing (HPC) systems to deliver timely results. Many users cannot afford to run the desired resolution and are forced to use low resolution output. One simple solution is to interpolate results for visualization. It is also possible to combine an ensemble of low resolution models to obtain a better prediction. However, these approaches fail to capture the redundant information and patterns in the low-resolution input that could help improve the quality of prediction. In this paper, we propose and evaluate a strategy based on a deep neural network to learn a high-resolution representation from low-resolution predictions using weather forecast as a practical use case. We take a supervised learning approach, since obtaining labeled data can be done automatically. Our results show significant improvement when compared with standard practices and the strategy is still lightweight enough to run on modest computer systems.","Wed, 15 Aug 2018 19:22:15 UTC (772 KB)"
"381","AnatomyNet: Deep Learning for Fast and Fully Automated Whole-volume Segmentation of Head and Neck Anatomy","Wentao Zhu, Yufang Huang, Liang Zeng, Xuming Chen, Yong Liu, Zhen Qian, Nan Du, Wei Fan, Xiaohui Xie","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Methods: Our deep learning model, called AnatomyNet, segments OARs from head and neck CT images in an end-to-end fashion, receiving whole-volume HaN CT images as input and generating masks of all OARs of interest in one shot. AnatomyNet is built upon the popular 3D U-net architecture, but extends it in three important ways: 1) a new encoding scheme to allow auto-segmentation on whole-volume CT images instead of local patches or subsets of slices, 2) incorporating 3D squeeze-and-excitation residual blocks in encoding layers for better feature representation, and 3) a new loss function combining Dice scores and focal loss to facilitate the training of the neural model. These features are designed to address two main challenges in deep-learning-based HaN segmentation: a) segmenting small anatomies (i.e., optic chiasm and optic nerves) occupying only a few slices, and b) training with inconsistent data annotations with missing ground truth for some anatomical structures. Results: We collected 261 HaN CT images to train AnatomyNet, and used MICCAI Head and Neck Auto Segmentation Challenge 2015 as a benchmark dataset to evaluate the performance of AnatomyNet. The objective is to segment nine anatomies: brain stem, chiasm, mandible, optic nerve left, optic nerve right, parotid gland left, parotid gland right, submandibular gland left, and submandibular gland right. Compared to previous state-of-the-art results from the MICCAI 2015 competition, AnatomyNet increases Dice similarity coefficient by 3.3% on average. AnatomyNet takes about 0.12 seconds to fully segment a head and neck CT image of dimension 178 x 302 x 225, significantly faster than previous methods. In addition, the model is able to process whole-volume CT images and delineate all OARs in one pass, requiring little pre- or post-processing. this https URL.","Wed, 15 Aug 2018 18:03:12 UTC (2,922 KB)[v2] Fri, 9 Nov 2018 00:23:48 UTC (1,901 KB)"
"382","Deep Learning using K-space Based Data Augmentation for Automated Cardiac MR Motion Artefact Detection","Ilkay Oksuz, Bram Ruijsink, Esther Puyol-Anton, Aurelien Bustin, Gastao Cruz, Claudia Prieto, Daniel Rueckert, Julia A. Schnabel, Andrew P. King","Computer Vision and Pattern Recognition (cs.CV)","Quality assessment of medical images is essential for complete automation of image processing pipelines. For large population studies such as the UK Biobank, artefacts such as those caused by heart motion are problematic and manual identification is tedious and time-consuming. Therefore, there is an urgent need for automatic image quality assessment techniques. In this paper, we propose a method to automatically detect the presence of motion-related artefacts in cardiac magnetic resonance (CMR) images. As this is a highly imbalanced classification problem (due to the high number of good quality images compared to the low number of images with motion artefacts), we propose a novel k-space based training data augmentation approach in order to address this problem. Our method is based on 3D spatio-temporal Convolutional Neural Networks, and is able to detect 2D+time short axis images with motion artefacts in less than 1ms. We test our algorithm on a subset of the UK Biobank dataset consisting of 3465 CMR images and achieve not only high accuracy in detection of motion artefacts, but also high precision and recall. We compare our approach to a range of state-of-the-art quality assessment methods.","Wed, 15 Aug 2018 15:22:21 UTC (336 KB)[v2] Fri, 31 Aug 2018 09:14:46 UTC (324 KB)"
"383","Exploiting Deep Learning for Persian Sentiment Analysis","Kia Dashtipour, Mandar Gogate, Ahsan Adeel, Cosimo Ieracitano, Hadi Larijani, Amir Hussain","Computation and Language (cs.CL)","The rise of social media is enabling people to freely express their opinions about products and services. The aim of sentiment analysis is to automatically determine subject's sentiment (e.g., positive, negative, or neutral) towards a particular aspect such as topic, product, movie, news etc. Deep learning has recently emerged as a powerful machine learning technique to tackle a growing demand of accurate sentiment analysis. However, limited work has been conducted to apply deep learning algorithms to languages other than English, such as Persian. In this work, two deep learning models (deep autoencoders and deep convolutional neural networks (CNNs)) are developed and applied to a novel Persian movie reviews dataset. The proposed deep learning models are analyzed and compared with the state-of-the-art shallow multilayer perceptron (MLP) based machine learning model. Simulation results demonstrate the enhanced performance of deep learning over state-of-the-art MLP.","Wed, 15 Aug 2018 13:46:54 UTC (782 KB)"
"384","Treepedia 2.0: Applying Deep Learning for Large-scale Quantification of Urban Tree Cover","Bill Yang Cai, Xiaojiang Li, Ian Seiferling, Carlo Ratti","Computer Vision and Pattern Recognition (cs.CV)","Recent advances in deep learning have made it possible to quantify urban metrics at fine resolution, and over large extents using street-level images. Here, we focus on measuring urban tree cover using Google Street View (GSV) images. First, we provide a small-scale labelled validation dataset and propose standard metrics to compare the performance of automated estimations of street tree cover using GSV. We apply state-of-the-art deep learning models, and compare their performance to a previously established benchmark of an unsupervised method. Our training procedure for deep learning models is novel; we utilize the abundance of openly available and similarly labelled street-level image datasets to pre-train our model. We then perform additional training on a small training dataset consisting of GSV images. We find that deep learning models significantly outperform the unsupervised benchmark method. Our semantic segmentation model increased mean intersection-over-union (IoU) from 44.10% to 60.42% relative to the unsupervised method and our end-to-end model decreased Mean Absolute Error from 10.04% to 4.67%. We also employ a recently developed method called gradient-weighted class activation map (Grad-CAM) to interpret the features learned by the end-to-end model. This technique confirms that the end-to-end model has accurately learned to identify tree cover area as key features for predicting percentage tree cover. Our paper provides an example of applying advanced deep learning techniques on a large-scale, geo-tagged and image-based dataset to efficiently estimate important urban metrics. The results demonstrate that deep learning models are highly accurate, can be interpretable, and can also be efficient in terms of data-labelling effort and computational resources.","Tue, 14 Aug 2018 15:34:22 UTC (8,197 KB)"
"385","CosmoFlow: Using Deep Learning to Learn the Universe at Scale","Amrita Mathuriya, Deborah Bard, Peter Mendygral, Lawrence Meadows, James Arnemann, Lei Shao, Siyu He, Tuomas Karna, Daina Moise, Simon J. Pennycook, Kristyn Maschoff, Jason Sewall, Nalini Kumar, Shirley Ho, Mike Ringenburg, Prabhat, Victor Lee","Cosmology and Nongalactic Astrophysics (astro-ph.CO); Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)","Deep learning is a promising tool to determine the physical model that describes our universe. To handle the considerable computational cost of this problem, we present CosmoFlow: a highly scalable deep learning application built on top of the TensorFlow framework. CosmoFlow uses efficient implementations of 3D convolution and pooling primitives, together with improvements in threading for many element-wise operations, to improve training performance on Intel(C) Xeon Phi(TM) processors. We also utilize the Cray PE Machine Learning Plugin for efficient scaling to multiple nodes. We demonstrate fully synchronous data-parallel training on 8192 nodes of Cori with 77% parallel efficiency, achieving 3.5 Pflop/s sustained performance. To our knowledge, this is the first large-scale science application of the TensorFlow framework at supercomputer scale with fully-synchronous training. These enhancements enable us to process large 3D dark matter distribution and predict the cosmological parameters $ヘ_M$, $ヲ_8$ and n$_s$ with unprecedented accuracy.","Tue, 14 Aug 2018 14:54:37 UTC (758 KB)[v2] Fri, 9 Nov 2018 20:15:11 UTC (749 KB)"
"386","Deep Learning Framework for Digital Breast Tomosynthesis Reconstruction","Nikita Moriakov, Koen Michielsen, Jonas Adler, Ritse Mann, Ioannis Sechopoulos, Jonas Teuwen","Medical Physics (physics.med-ph); Computer Vision and Pattern Recognition (cs.CV)","Digital breast tomosynthesis is rapidly replacing digital mammography as the basic x-ray technique for evaluation of the breasts. However, the sparse sampling and limited angular range gives rise to different artifacts, which manufacturers try to solve in several ways. In this study we propose an extension of the Learned Primal-Dual algorithm for digital breast tomosynthesis. The Learned Primal-Dual algorithm is a deep neural network consisting of several `reconstruction blocks', which take in raw sinogram data as the initial input, perform a forward and a backward pass by taking projections and back-projections, and use a convolutional neural network to produce an intermediate reconstruction result which is then improved further by the successive reconstruction block. We extend the architecture by providing breast thickness measurements as a mask to the neural network and allow it to learn how to use this thickness mask. We have trained the algorithm on digital phantoms and the corresponding noise-free/noisy projections, and then tested the algorithm on digital phantoms for varying level of noise. Reconstruction performance of the algorithms was compared visually, using MSE loss and Structural Similarity Index. Results indicate that the proposed algorithm outperforms the baseline iterative reconstruction algorithm in terms of reconstruction quality for both breast edges and internal structures and is robust to noise.","Tue, 14 Aug 2018 11:41:32 UTC (327 KB)"
"387","DeepNeuro: an open-source deep learning toolbox for neuroimaging","Andrew Beers, James Brown, Ken Chang, Katharina Hoebel, Elizabeth Gerstner, Bruce Rosen, Jayashree Kalpathy-Cramer","Computer Vision and Pattern Recognition (cs.CV)","Translating neural networks from theory to clinical practice has unique challenges, specifically in the field of neuroimaging. In this paper, we present DeepNeuro, a deep learning framework that is best-suited to putting deep learning algorithms for neuroimaging in practical usage with a minimum of friction. We show how this framework can be used to both design and train neural network architectures, as well as modify state-of-the-art architectures in a flexible and intuitive way. We display the pre- and postprocessing functions common in the medical imaging community that DeepNeuro offers to ensure consistent performance of networks across variable users, institutions, and scanners. And we show how pipelines created in DeepNeuro can be concisely packaged into shareable Docker containers and command-line interfaces using DeepNeuro's pipeline resources.","Tue, 14 Aug 2018 09:03:39 UTC (1,708 KB)"
"388","A Density Functional Tight Binding Layer for Deep Learning of Chemical Hamiltonians","Haichen Li, Christopher Collins, Matteus Tanha, Geoffrey J. Gordon, David J. Yaron","Chemical Physics (physics.chem-ph)","Current neural networks for predictions of molecular properties use quantum chemistry only as a source of training data. This paper explores models that use quantum chemistry as an integral part of the prediction process. This is done by implementing self-consistent-charge Density-Functional-Tight-Binding (DFTB) theory as a layer for use in deep learning models. The DFTB layer takes, as input, Hamiltonian matrix elements generated from earlier layers and produces, as output, electronic properties from self-consistent field solutions of the corresponding DFTB Hamiltonian. Backpropagation enables efficient training of the model to target electronic properties. Two types of input to the DFTB layer are explored, splines and feed-forward neural networks. Because overfitting can cause models trained on smaller molecules to perform poorly on larger molecules, regularizations are applied that penalize non-monotonic behavior and deviation of the Hamiltonian matrix elements from those of the published DFTB model used to initialize the model. The approach is evaluated on 15,700 hydrocarbons by comparing the root mean square error in energy and dipole moment, on test molecules with 8 heavy atoms, to the error from the initial DFTB model. When trained on molecules with up to 7 heavy atoms, the spline model reduces the test error in energy by 60% and in dipole moments by 42%. The neural network model performs somewhat better, with error reductions of 67% and 59% respectively. Training on molecules with up to 4 heavy atoms reduces performance, with both the spline and neural net models reducing the test error in energy by about 53% and in dipole by about 25%.","Tue, 14 Aug 2018 05:16:05 UTC (4,934 KB)[v2] Mon, 20 Aug 2018 21:01:26 UTC (5,203 KB)"
"389","Deep Learning Based Natural Language Processing for End to End Speech Translation","Sarvesh Patil","Computation and Language (cs.CL)","Deep Learning methods employ multiple processing layers to learn hierarchial representations of data. They have already been deployed in a humongous number of applications and have produced state-of-the-art results. Recently with the growth in processing power of computers to be able to do high dimensional tensor calculations, Natural Language Processing (NLP) applications have been given a significant boost in terms of efficiency as well as accuracy. In this paper, we will take a look at various signal processing techniques and then application of them to produce a speech-to-text system using Deep Recurrent Neural Networks.","Thu, 9 Aug 2018 14:21:35 UTC (499 KB)"
"390","Deep Learning Super-Resolution Enables Rapid Simultaneous Morphological and Quantitative Magnetic Resonance Imaging","Akshay Chaudhari, Zhongnan Fang, Jin Hyung Lee, Garry Gold, Brian Hargreaves","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Obtaining magnetic resonance images (MRI) with high resolution and generating quantitative image-based biomarkers for assessing tissue biochemistry is crucial in clinical and research applications. How- ever, acquiring quantitative biomarkers requires high signal-to-noise ratio (SNR), which is at odds with high-resolution in MRI, especially in a single rapid sequence. In this paper, we demonstrate how super-resolution can be utilized to maintain adequate SNR for accurate quantification of the T2 relaxation time biomarker, while simultaneously generating high- resolution images. We compare the efficacy of resolution enhancement using metrics such as peak SNR and structural similarity. We assess accuracy of cartilage T2 relaxation times by comparing against a standard reference method. Our evaluation suggests that SR can successfully maintain high-resolution and generate accurate biomarkers for accelerating MRI scans and enhancing the value of clinical and research MRI.","Tue, 7 Aug 2018 05:09:11 UTC (17,239 KB)"
"391","Deep learning of multi-element abundances from high-resolution spectroscopic data","Henry W. Leung, Jo Bovy","Astrophysics of Galaxies (astro-ph.GA); Instrumentation and Methods for Astrophysics (astro-ph.IM)","Deep learning with artificial neural networks is increasingly gaining attention, because of its potential for data-driven astronomy. However, this methodology usually does not provide uncertainties and does not deal with incompleteness and noise in the training data. In this work, we design a neural network for high-resolution spectroscopic analysis using APOGEE data that mimics the methodology of standard spectroscopic analyses: stellar parameters are determined using the full wavelength range, but individual element abundances use censored portions of the spectrum. We train this network with a customized objective function that deals with incomplete and noisy training data and apply dropout variational inference to derive uncertainties on our predictions. We determine parameters and abundances for 18 individual elements at the $\approx 0.03$ dex level, even at low signal-to-noise ratio. We demonstrate that the uncertainties returned by our method are a realistic estimate of the precision and they automatically blow up when inputs or outputs outside of the training set are encountered, thus shielding users from unwanted extrapolation. By using standard deep-learning tools for GPU acceleration, our method is extremely fast, allowing analysis of the entire APOGEE data set of $\approx250,000$ spectra in ten minutes on a singe, low-cost GPU. We release the stellar parameters and 18 individual-element abundances with associated uncertainty for the entire APOGEE DR14 dataset. Simultaneously, we release astroNN, a well-tested, open-source python package developed for this work, but that is also designed to be a general package for deep learning in astronomy. astroNN is available at this https URL with extensive documentation at this http URL.","Mon, 13 Aug 2018 20:01:45 UTC (4,600 KB)"
"392","RedSync : Reducing Synchronization Traffic for Distributed Deep Learning","Jiarui Fang, Haohuan Fu, Guangwen Yang, Cho-Jui Hsieh","Distributed, Parallel, and Cluster Computing (cs.DC); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Data parallelism has already become a dominant method to scale Deep Neural Network (DNN) training to multiple computation nodes. Considering that the synchronization of local model or gradient between iterations can be a bottleneck for large-scale distributed training, compressing communication traffic has gained widespread attention recently. Among several recent proposed compression algorithms, Residual Gradient Compression (RGC) is one of the most successful approaches---it can significantly compress the message size (0.1% of the original size) and still preserve accuracy. However, the literature on compressing deep networks focuses almost exclusively on finding good compression rate, while the efficiency of RGC in real implementation has been less investigated. In this paper, we explore the potential of application RGC method in the real distributed system. Targeting the widely adopted multi-GPU system, we proposed an RGC system design call RedSync, which includes a set of optimizations to reduce communication bandwidth while introducing limited overhead. We examine the performance of RedSync on two different multiple GPU platforms, including a supercomputer and a multi-card server. Our test cases include image classification and language modeling tasks on Cifar10, ImageNet, Penn Treebank and Wiki2 datasets. For DNNs featured with high communication to computation ratio, which have long been considered with poor scalability, RedSync shows significant performance improvement.","Mon, 13 Aug 2018 19:02:47 UTC (775 KB)"
"393","Hidden Fluid Mechanics: A Navier-Stokes Informed Deep Learning Framework for Assimilating Flow Visualization Data","Maziar Raissi, Alireza Yazdani, George Em Karniadakis","Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG); Fluid Dynamics (physics.flu-dyn); Machine Learning (stat.ML)","We present hidden fluid mechanics (HFM), a physics informed deep learning framework capable of encoding an important class of physical laws governing fluid motions, namely the Navier-Stokes equations. In particular, we seek to leverage the underlying conservation laws (i.e., for mass, momentum, and energy) to infer hidden quantities of interest such as velocity and pressure fields merely from spatio-temporal visualizations of a passive scaler (e.g., dye or smoke), transported in arbitrarily complex domains (e.g., in human arteries or brain aneurysms). Our approach towards solving the aforementioned data assimilation problem is unique as we design an algorithm that is agnostic to the geometry or the initial and boundary conditions. This makes HFM highly flexible in choosing the spatio-temporal domain of interest for data acquisition as well as subsequent training and predictions. Consequently, the predictions made by HFM are among those cases where a pure machine learning strategy or a mere scientific computing approach simply cannot reproduce. The proposed algorithm achieves accurate predictions of the pressure and velocity fields in both two and three dimensional flows for several benchmark problems motivated by real-world applications. Our results demonstrate that this relatively simple methodology can be used in physical and biomedical problems to extract valuable quantitative information (e.g., lift and drag forces or wall shear stresses in arteries) for which direct measurements may not be possible.","Mon, 13 Aug 2018 16:37:56 UTC (8,738 KB)"
"394","What is Unique in Individual Gait Patterns? Understanding and Interpreting Deep Learning in Gait Analysis","Fabian Horst, Sebastian Lapuschkin, Wojciech Samek, Klaus-Robert Muller, Wolfgang I. Schollhorn","Machine Learning (cs.LG); Machine Learning (stat.ML)","Machine learning (ML) techniques such as (deep) artificial neural networks (DNN) are solving very successfully a plethora of tasks and provide new predictive models for complex physical, chemical, biological and social systems. However, in most cases this comes with the disadvantage of acting as a black box, rarely providing information about what made them arrive at a particular prediction. This black box aspect of ML techniques can be problematic especially in medical diagnoses, so far hampering a clinical acceptance. The present paper studies the uniqueness of individual gait patterns in clinical biomechanics using DNNs. By attributing portions of the model predictions back to the input variables (ground reaction forces and full-body joint angles), the Layer-Wise Relevance Propagation (LRP) technique reliably demonstrates which variables at what time windows of the gait cycle are most relevant for the characterisation of gait patterns from a certain individual. By measuring the timeresolved contribution of each input variable to the prediction of ML techniques such as DNNs, our method describes the first general framework that enables to understand and interpret non-linear ML methods in (biomechanical) gait analysis and thereby supplies a powerful tool for analysis, diagnosis and treatment of human gait.","Mon, 13 Aug 2018 16:04:34 UTC (5,124 KB)"
"395","Understanding training and generalization in deep learning by Fourier analysis","Zhiqin John Xu","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Statistics Theory (math.ST); Machine Learning (stat.ML)","Background: It is still an open research area to theoretically understand why Deep Neural Networks (DNNs)---equipped with many more parameters than training data and trained by (stochastic) gradient-based methods---often achieve remarkably low generalization error. Contribution: We study DNN training by Fourier analysis. Our theoretical framework explains: i) DNN with (stochastic) gradient-based methods endows low-frequency components of the target function with a higher priority during the training; ii) Small initialization leads to good generalization ability of DNN while preserving the DNN's ability of fitting any function. These results are further confirmed by experiments of DNNs fitting the following datasets, i.e., natural images, one-dimensional functions and MNIST dataset.","Mon, 13 Aug 2018 15:40:41 UTC (4,180 KB)[v2] Tue, 21 Aug 2018 21:01:43 UTC (5,650 KB)[v3] Tue, 18 Sep 2018 01:14:01 UTC (5,732 KB)"
"396","Learning from our neighbours: a novel approach on sinogram completion using bin-sharing and deep learning to reconstruct high quality 4DCBCT","Joel Beaudry, Pedro L. Esquinas","Medical Physics (physics.med-ph)","Inspired by the success of deep learning applications on restoration of low-dose and sparse CT images, we propose a novel method to reconstruct high-quality 4D cone-beam CT (4DCBCT) images from sparse datasets. Our approach combines the idea of 'bin-sharing' with a deep convolutional neural network (CNN) model. More specifically, for each respiratory bin, an initial estimate of the patient sinogram is obtained by taking projections from adjacent bins and performing linear interpolation. Subsequently, the estimated sinogram is propagated through a CNN that predicts a full, high-quality sinogram. Lastly, the predicted sinogram is reconstructed with traditional CBCT algorithms such as the Feldkamp, Davis and Kress (FDK) method. The CNN model, which we referred to as the Sino-Net, was trained under different loss functions. We assessed the performance of the proposed method in terms of image quality metrics (mean square error, mean absolute error, peak signal-to-noise ratio and structural similarity) and tumor motion accuracy (tumor centroid deviation with respect to the ground truth). Overall, the presented prototype model was able to substantially improve the quality of 4DCBCT images, removing most of the streak artifacts and decreasing the noise with respect to the standard FDK reconstructions. The tumor centroid deviations with respect to the ground truth predicted by our method were approximately 0.5 mm, on average (maximum deviation was approximately 2 mm). These preliminary results are promising and encourage us to further investigate the performance of our model under more challenging imaging conditions and compare it against the state-of-the-art CBCT reconstruction algorithms.","Fri, 10 Aug 2018 20:24:57 UTC (1,640 KB)"
"397","Detection of Hard Exudates in Retinal Fundus Images using Deep Learning","Avula Benzamin, Chandan Chakraborty","Image and Video Processing (eess.IV)","Diabetic Retinopathy (DR) is a retinal disorder that affects the people having diabetes mellitus for a long time (20 years). DR is one of the main reasons for the preventable blindness all over the world. If not detected early the patient may progress to severe stages of irreversible blindness. Lack of Ophthalmologists poses a serious problem for the growing diabetes patients. It is advised to develop an automated DR screening system to assist the Ophthalmologist in decision making. Hard exudates develop when DR is present. It is important to detect hard exudates in order to detect DR in an early stage. Research has been done to detect hard exudates using regular image processing techniques and Machine Learning techniques. Here, a deep learning algorithm has been presented in this paper that detects hard exudates in fundus images of the retina.","Fri, 10 Aug 2018 18:01:09 UTC (427 KB)"
"398","Dropout is a special case of the stochastic delta rule: faster and more accurate deep learning","Noah Frazier-Logue, Stephen Jose Hanson","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Multi-layer neural networks have lead to remarkable performance on many kinds of benchmark tasks in text, speech and image processing. Nonlinear parameter estimation in hierarchical models is known to be subject to overfitting. One approach to this overfitting and related problems (local minima, colinearity, feature discovery etc.) is called dropout (Srivastava, et al 2014, Baldi et al 2016). This method removes hidden units with a Bernoulli random variable with probability $p$ over updates. In this paper we will show that Dropout is a special case of a more general model published originally in 1990 called the stochastic delta rule ( SDR, Hanson, 1990). SDR parameterizes each weight in the network as a random variable with mean $レ_{w_{ij}}$ and standard deviation $ヲ_{w_{ij}}$. These random variables are sampled on each forward activation, consequently creating an exponential number of potential networks with shared weights. Both parameters are updated according to prediction error, thus implementing weight noise injections that reflect a local history of prediction error and efficient model averaging. SDR therefore implements a local gradient-dependent simulated annealing per weight converging to a bayes optimal network. Tests on standard benchmarks (CIFAR) using a modified version of DenseNet shows the SDR outperforms standard dropout in error by over 50% and in loss by over 50%. Furthermore, the SDR implementation converges on a solution much faster, reaching a training error of 5 in just 15 epochs with DenseNet-40 compared to standard DenseNet-40's 94 epochs.","Fri, 10 Aug 2018 15:06:05 UTC (509 KB)"
"399","Deep Learning Based Speed Estimation for Constraining Strapdown Inertial Navigation on Smartphones","Santiago Cortes, Arno Solin, Juho Kannala","Computer Vision and Pattern Recognition (cs.CV)","Strapdown inertial navigation systems are sensitive to the quality of the data provided by the accelerometer and gyroscope. Low-grade IMUs in handheld smart-devices pose a problem for inertial odometry on these devices. We propose a scheme for constraining the inertial odometry problem by complementing non-linear state estimation by a CNN-based deep-learning model for inferring the momentary speed based on a window of IMU samples. We show the feasibility of the model using a wide range of data from an iPhone, and present proof-of-concept results for how the model can be combined with an inertial navigation system for three-dimensional inertial navigation.","Fri, 10 Aug 2018 11:03:58 UTC (498 KB)"
"400","Error Forward-Propagation: Reusing Feedforward Connections to Propagate Errors in Deep Learning","Adam A. Kohan, Edward A. Rietman, Hava T. Siegelmann","Neural and Evolutionary Computing (cs.NE); Neurons and Cognition (q-bio.NC)","We introduce Error Forward-Propagation, a biologically plausible mechanism to propagate error feedback forward through the network. Architectural constraints on connectivity are virtually eliminated for error feedback in the brain; systematic backward connectivity is not used or needed to deliver error feedback. Feedback as a means of assigning credit to neurons earlier in the forward pathway for their contribution to the final output is thought to be used in learning in the brain. How the brain solves the credit assignment problem is unclear. In machine learning, error backpropagation is a highly successful mechanism for credit assignment in deep multilayered networks. Backpropagation requires symmetric reciprocal connectivity for every neuron. From a biological perspective, there is no evidence of such an architectural constraint, which makes backpropagation implausible for learning in the brain. This architectural constraint is reduced with the use of random feedback weights. Models using random feedback weights require backward connectivity patterns for every neuron, but avoid symmetric weights and reciprocal connections. In this paper, we practically remove this architectural constraint, requiring only a backward loop connection for effective error feedback. We propose reusing the forward connections to deliver the error feedback by feeding the outputs into the input receiving layer. This mechanism, Error Forward-Propagation, is a plausible basis for how error feedback occurs deep in the brain independent of and yet in support of the functionality underlying intricate network architectures. We show experimentally that recurrent neural networks with two and three hidden layers can be trained using Error Forward-Propagation on the MNIST and Fashion MNIST datasets, achieving $1.90\%$ and $11\%$ generalization errors respectively.","Thu, 9 Aug 2018 21:52:10 UTC (185 KB)"
"401","Deep Learning for Single Image Super-Resolution: A Brief Review","Wenming Yang, Xuechen Zhang, Yapeng Tian, Wei Wang, Jing-Hao Xue","Computer Vision and Pattern Recognition (cs.CV)","Single image super-resolution (SISR) is a notoriously challenging ill-posed problem, which aims to obtain a high- resolution (HR) output from one of its low-resolution (LR) versions. To solve the SISR problem, recently powerful deep learning algorithms have been employed and achieved the state- of-the-art performance. In this survey, we review representative deep learning-based SISR methods, and group them into two categories according to their major contributions to two essential aspects of SISR: the exploration of efficient neural network archi- tectures for SISR, and the development of effective optimization objectives for deep SISR learning. For each category, a baseline is firstly established and several critical limitations of the baseline are summarized. Then representative works on overcoming these limitations are presented based on their original contents as well as our critical understandings and analyses, and relevant comparisons are conducted from a variety of perspectives. Finally we conclude this review with some vital current challenges and future trends in SISR leveraging deep learning algorithms.","Thu, 9 Aug 2018 20:51:51 UTC (2,973 KB)"
"402","Radon Inversion via Deep Learning","Ji He, Jianhua Ma","Computer Vision and Pattern Recognition (cs.CV)","Radon transform is widely used in physical and life sciences and one of its major applications is the X-ray computed tomography (X-ray CT), which is significant in modern health examination. The Radon inversion or image reconstruction is challenging due to the potentially defective radon projections. Conventionally, the reconstruction process contains several ad hoc stages to approximate the corresponding Radon inversion. Each of the stages is highly dependent on the results of the previous stage. In this paper, we propose a novel unified framework for Radon inversion via deep learning (DL). The Radon inversion can be approximated by the proposed framework with an end-to-end fashion instead of processing step-by-step with multiple stages. For simplicity, the proposed framework is short as iRadonMap (inverse Radon transform approximation). Specifically, we implement the iRadonMap as an appropriative neural network, of which the architecture can be divided into two segments. In the first segment, a learnable fully-connected filtering layer is used to filter the radon projections along the view-angle direction, which is followed by a learnable sinusoidal back-projection layer to transfer the filtered radon projections into an image. The second segment is a common neural network architecture to further improve the reconstruction performance in the image domain. The iRadonMap is overall optimized by training a large number of generic images from ImageNet database. To evaluate the performance of the iRadonMap, clinical patient data is used. Qualitative results show promising reconstruction performance of the iRadonMap.","Thu, 9 Aug 2018 04:19:08 UTC (1,870 KB)"
"403","Unsupervised/Semi-supervised Deep Learning for Low-dose CT Enhancement","Mingrui Geng, Yun Deng, Qian Zhao, Qi Xie, Dong Zeng, Dong Zeng, Wangmeng Zuo, Deyu Meng","Computer Vision and Pattern Recognition (cs.CV)","Recently, deep learning(DL) methods have been proposed for the low-dose computed tomography(LdCT) enhancement, and obtain good trade-off between computational efficiency and image quality. Most of them need large number of pre-collected ground-truth/high-dose sinograms with less noise, and train the network in a supervised end-to-end manner. This may bring major limitations on these methods because the number of such low-dose/high-dose training sinogram pairs would affect the network's capability and sometimes the ground-truth sinograms are hard to be obtained in large scale. Since large number of low-dose ones are relatively easy to obtain, it should be critical to make these sources play roles in network training in an unsupervised learning manner. To address this issue, we propose an unsupervised DL method for LdCT enhancement that incorporates unlabeled LdCT sinograms directly into the network training. The proposed method effectively considers the structure characteristics and noise distribution in the measured LdCT sinogram, and then learns the proper gradient of the LdCT sinogram in a pure unsupervised manner. Similar to the labeled ground-truth, the gradient information in an unlabeled LdCT sinogram can be used for sufficient network training. The experiments on the patient data show effectiveness of the proposed method.","Wed, 8 Aug 2018 02:23:37 UTC (3,533 KB)"
"404","Deep learning of dynamics and signal-noise decomposition with time-stepping constraints","Samuel H. Rudy, J. Nathan Kutz, Steven L. Brunton","Numerical Analysis (math.NA)","A critical challenge in the data-driven modeling of dynamical systems is producing methods robust to measurement error, particularly when data is limited. Many leading methods either rely on denoising prior to learning or on access to large volumes of data to average over the effect of noise. We propose a novel paradigm for data-driven modeling that simultaneously learns the dynamics and estimates the measurement noise at each observation. By constraining our learning algorithm, our method explicitly accounts for measurement error in the map between observations, treating both the measurement error and the dynamics as unknowns to be identified, rather than assuming idealized noiseless trajectories. We model the unknown vector field using a deep neural network, imposing a Runge-Kutta integrator structure to isolate this vector field, even when the data has a non-uniform timestep, thus constraining and focusing the modeling effort. We demonstrate the ability of this framework to form predictive models on a variety of canonical test problems of increasing complexity and show that it is robust to substantial amounts of measurement error. We also discuss issues with the generalizability of neural network models for dynamical systems and provide open-source code for all examples.","Tue, 7 Aug 2018 23:05:13 UTC (4,975 KB)[v2] Wed, 22 Aug 2018 21:21:18 UTC (4,975 KB)"
"405","Application of End-to-End Deep Learning in Wireless Communications Systems","Woongsup Lee, Ohyun Jo, Minhoe Kim","Information Theory (cs.IT); Machine Learning (cs.LG); Signal Processing (eess.SP)","Deep learning is a potential paradigm changer for the design of wireless communications systems (WCS), from conventional handcrafted schemes based on sophisticated mathematical models with assumptions to autonomous schemes based on the end-to-end deep learning using a large number of data. In this article, we present a basic concept of the deep learning and its application to WCS by investigating the resource allocation (RA) scheme based on a deep neural network (DNN) where multiple goals with various constraints can be satisfied through the end-to-end deep learning. Especially, the optimality and feasibility of the DNN based RA are verified through simulation. Then, we discuss the technical challenges regarding the application of deep learning in WCS.","Tue, 7 Aug 2018 14:20:10 UTC (370 KB)"
"406","A novel topology design approach using an integrated deep learning network architecture","Sharad Rawat, M.H. Herman Shen","Machine Learning (stat.ML); Machine Learning (cs.LG)","Topology design optimization offers tremendous opportunity in design and manufacturing freedoms by designing and producing a part from the ground-up without a meaningful initial design as required by conventional shape design optimization approaches. Ideally, with adequate problem statements, to formulate and solve the topology design problem using a standard topology optimization process, such as SIMP (Simplified Isotropic Material with Penalization) is possible. In reality, an estimated over thousands of design iterations is often required for just a few design variables, the conventional optimization approach is in general impractical or computationally unachievable for real world applications significantly diluting the development of the topology optimization technology. There is, therefore, a need for a different approach that will be able to optimize the initial design topology effectively and rapidly. Therefore, this work presents a new topology design procedure to generate optimal structures using an integrated Generative Adversarial Networks (GANs) and convolutional neural network architecture.","Fri, 3 Aug 2018 19:10:39 UTC (552 KB)"
"407","Engagement Recognition using Deep Learning and Facial Expression","Omid Mohamad Nezami, Len Hamey, Deborah Richards, Mark Dras","Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)","Engagement is a key indicator of the quality of learning experience, and one that plays a major role in developing intelligent educational interfaces. Any such interface requires the ability to recognise the level of engagement in order to respond appropriately; however, there is very little existing data to learn from, and new data is expensive and difficult to acquire. This paper presents a deep learning model to improve engagement recognition from face images captured in the wild that overcomes the data sparsity challenge by pre-training on readily available basic facial expression data, before training on specialised engagement data. In the first of two steps, a facial expression recognition model is trained to provide a rich face representation using deep learning. In the second step, we use the model's weights to initialize our deep learning based model to recognize engagement; we term this the Transfer model. We train the model on our new engagement recognition (ER) dataset with 4627 engaged and disengaged samples. We find that the Transfer model outperforms effective deep learning architectures that we apply for the first time to engagement recognition, as well as approaches using histogram of oriented gradients and support vector machines.","Tue, 7 Aug 2018 12:38:20 UTC (858 KB)[v2] Mon, 19 Nov 2018 11:32:39 UTC (1,670 KB)[v3] Sat, 24 Nov 2018 09:01:53 UTC (1,667 KB)"
"408","Grassmannian Learning: Embedding Geometry Awareness in Shallow and Deep Learning","Jiayao Zhang, Guangxu Zhu, Robert W. Heath Jr., Kaibin Huang","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Information Theory (cs.IT); Signal Processing (eess.SP); Machine Learning (stat.ML)","Modern machine learning algorithms have been adopted in a range of signal-processing applications spanning computer vision, natural language processing, and artificial intelligence. Many relevant problems involve subspace-structured features, orthogonality constrained or low-rank constrained objective functions, or subspace distances. These mathematical characteristics are expressed naturally using the Grassmann manifold. Unfortunately, this fact is not yet explored in many traditional learning algorithms. In the last few years, there have been growing interests in studying Grassmann manifold to tackle new learning problems. Such attempts have been reassured by substantial performance improvements in both classic learning and learning using deep neural networks. We term the former as shallow and the latter deep Grassmannian learning. The aim of this paper is to introduce the emerging area of Grassmannian learning by surveying common mathematical problems and primary solution approaches, and overviewing various applications. We hope to inspire practitioners in different fields to adopt the powerful tool of Grassmannian learning in their research.","Tue, 7 Aug 2018 06:54:06 UTC (6,509 KB)[v2] Mon, 13 Aug 2018 02:19:08 UTC (6,509 KB)"
"409","Deep Learning with Predictive Control for Human Motion Tracking","Don Joven Agravante, Giovanni De Magistris, Asim Munawar, Phongtharin Vinayavekhin, Ryuki Tachibana","Robotics (cs.RO)","We propose to combine model predictive control with deep learning for the task of accurate human motion tracking with a robot. We design the MPC to allow switching between the learned and a conservative prediction. We also explored online learning with a DyBM model. We applied this method to human handwriting motion tracking with a UR-5 robot. The results show that the framework significantly improves tracking performance.","Tue, 7 Aug 2018 03:48:52 UTC (404 KB)"
"410","3D Conceptual Design Using Deep Learning","Zhangsihao Yang, Haoliang Jiang, Zou Lan","Computer Vision and Pattern Recognition (cs.CV)","This article proposes a data-driven methodology to achieve a fast design support, in order to generate or develop novel designs covering multiple object categories. This methodology implements two state-of-the-art Variational Autoencoder dealing with 3D model data. Our methodology constructs a self-defined loss function. The loss function, containing the outputs of certain layers in the autoencoder, obtains combination of different latent features from different 3D model categories. Additionally, this article provide detail explanation to utilize the Princeton ModelNet40 database, a comprehensive clean collection of 3D CAD models for objects. After convert the original 3D mesh file to voxel and point cloud data type, we enable to feed our autoencoder with data of the same size of dimension. The novelty of this work is to leverage the power of deep learning methods as an efficient latent feature extractor to explore unknown designing areas. Through this project, we expect the output can show a clear and smooth interpretation of model from different categories to develop a fast design support to generate novel shapes. This final report will explore 1) the theoretical ideas, 2) the progresses to implement Variantional Autoencoder to attain implicit features from input shapes, 3) the results of output shapes during training in selected domains of both 3D voxel data and 3D point cloud data, and 4) our conclusion and future work to achieve the more outstanding goal.","Sun, 5 Aug 2018 19:09:12 UTC (2,055 KB)"
"411","Classification of Dermoscopy Images using Deep Learning","Nithin D Reddy","Computer Vision and Pattern Recognition (cs.CV)","Skin cancer is one of the most common forms of cancer and its incidence is projected to rise over the next decade. Artificial intelligence is a viable solution to the issue of providing quality care to patients in areas lacking access to trained dermatologists. Considerable progress has been made in the use of automated applications for accurate classification of skin lesions from digital images. In this manuscript, we discuss the design and implementation of a deep learning algorithm for classification of dermoscopy images from the HAM10000 Dataset. We trained a convolutional neural network based on the ResNet50 architecture to accurately classify dermoscopy images of skin lesions into one of seven disease categories. Using our custom model, we obtained a balanced accuracy of 91% on the validation dataset.","Sun, 5 Aug 2018 12:40:23 UTC (2,592 KB)"
"412","DELIMIT PyTorch - An extension for Deep Learning in Diffusion Imaging","Simon Koppers, Dorit Merhof","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","DELIMIT is a framework extension for deep learning in diffusion imaging, which extends the basic framework PyTorch towards spherical signals. Based on several novel layers, deep learning can be applied to spherical diffusion imaging data in a very convenient way. First, two spherical harmonic interpolation layers are added to the extension, which allow to transform the signal from spherical surface space into the spherical harmonic space, and vice versa. In addition, a local spherical convolution layer is introduced that adds the possibility to include gradient neighborhood information within the network. Furthermore, these extensions can also be utilized for the preprocessing of diffusion signals.","Sat, 4 Aug 2018 18:26:24 UTC (436 KB)"
"413","Spatial Deep Learning for Wireless Scheduling","Wei Cui (1), Kaiming Shen (1), Wei Yu (1) ((1) University of Toronto)","Signal Processing (eess.SP); Information Theory (cs.IT); Machine Learning (cs.LG)","The optimal scheduling of interfering links in a dense wireless network with full frequency reuse is a challenging task. The traditional method involves first estimating all the interfering channel strengths then optimizing the scheduling based on the model. This model-based method is however resource and computationally intensive, because channel estimation is expensive in dense networks; further, finding even a locally optimal solution of the resulting optimization problem may be computationally complex. This paper shows that by using a deep learning approach, it is possible to bypass channel estimation and to schedule links efficiently based solely on the geographic locations of transmitters and receivers. This is accomplished by using locally optimal schedules generated using a fractional programming method for randomly deployed device-to-device networks as training data, and by using a novel neural network architecture that takes the geographic spatial convolutions of the interfering or interfered neighboring nodes as input over multiple feedback stages to learn the optimum solution. The resulting neural network gives near-optimal performance for sum-rate maximization and is capable of generalizing to larger deployment areas and to deployments of different link densities. Finally, this paper proposes a novel scheduling approach that utilizes the sum-rate optimal scheduling heuristics over judiciously chosen subsets of links to provide fair scheduling across the network.","Sat, 4 Aug 2018 14:03:10 UTC (1,280 KB)"
"414","Deep Learning Advances on Different 3D Data Representations: A Survey","Eman Ahmed, Alexandre Saint, Abd El Rahman Shabayek, Kseniya Cherenkova, Rig Das, Gleb Gusev, Djamila Aouada, Bjorn Ottersten","Computer Vision and Pattern Recognition (cs.CV)","3D data is a valuable asset in the field of computer vision as it provides rich information about the full geometry of sensed objects and scenes. With the recent availability of large 3D datasets and the increase in computational power, it is today possible to consider applying deep learning to learn specific tasks on 3D data such as segmentation, recognition and correspondence. Depending on the considered 3D data representation, different challenges may be foreseen in using existent deep learning architectures. In this paper, we provide a comprehensive overview of various 3D data representations highlighting the difference between Euclidean and non-Euclidean ones. We also discuss how deep learning methods are applied on each representation, analyzing the challenges to overcome.","Sat, 4 Aug 2018 10:18:55 UTC (5,013 KB)"
"415","Deep Learning-Based Multiple Object Visual Tracking on Embedded System for IoT and Mobile Edge Computing Applications","Beatriz Blanco-Filgueira, Daniel Garcia-Lesta, Mauro Fernandez-Sanjurjo, Victor M. Brea, Paula Lopez","Computer Vision and Pattern Recognition (cs.CV)","Compute and memory demands of state-of-the-art deep learning methods are still a shortcoming that must be addressed to make them useful at IoT end-nodes. In particular, recent results depict a hopeful prospect for image processing using Convolutional Neural Netwoks, CNNs, but the gap between software and hardware implementations is already considerable for IoT and mobile edge computing applications due to their high power consumption. This proposal performs low-power and real time deep learning-based multiple object visual tracking implemented on an NVIDIA Jetson TX2 development kit. It includes a camera and wireless connection capability and it is battery powered for mobile and outdoor applications. A collection of representative sequences captured with the on-board camera, dETRUSC video dataset, is used to exemplify the performance of the proposed algorithm and to facilitate benchmarking. The results in terms of power consumption and frame rate demonstrate the feasibility of deep learning algorithms on embedded platforms although more effort to joint algorithm and hardware design of CNNs is needed.","Tue, 31 Jul 2018 10:33:09 UTC (5,286 KB)"
"416","A Deep Learning based Joint Segmentation and Classification Framework for Glaucoma Assesment in Retinal Color Fundus Images","Arunava Chakravarty, Jayanthi Sivswamy","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Automated Computer Aided diagnostic tools can be used for the early detection of glaucoma to prevent irreversible vision loss. In this work, we present a Multi-task Convolutional Neural Network (CNN) that jointly segments the Optic Disc (OD), Optic Cup (OC) and predicts the presence of glaucoma in color fundus images. The CNN utilizes a combination of image appearance features and structural features obtained from the OD-OC segmentation to obtain a robust prediction. The use of fewer network parameters and the sharing of the CNN features for multiple related tasks ensures the good generalizability of the architecture, allowing it to be trained on small training sets. The cross-testing performance of the proposed method on an independent validation set acquired using a different camera and image resolution was found to be good with an average dice score of 0.92 for OD, 0.84 for OC and AUC of 0.95 on the task of glaucoma classification illustrating its potential as a mass screening tool for the early detection of glaucoma.","Sun, 29 Jul 2018 09:12:37 UTC (548 KB)"
"417","Enabling Trust in Deep Learning Models: A Digital Forensics Case Study","Aditya K, Slawomir Grzonkowski, Nhien An Lekhac","Cryptography and Security (cs.CR)","Today, the volume of evidence collected per case is growing exponentially, to address this problem forensics investigators are looking for investigation process with tools built on new technologies like big data, cloud services, and Deep Learning (DL) techniques. Consequently, the accuracy of artifacts found also relies on the performance of techniques used, especially DL models. Recently, \textbf{D}eep \textbf{N}eural \textbf{N}ets (\textbf{DNN}) have achieved state of the art performance in the tasks of classification and recognition. In the context of digital forensics, DNN has been applied to the domains of cybercrime investigation such as child abuse investigations, malware classification, steganalysis and image forensics. However, the robustness of DNN models in the context of digital forensics is never studied before. Hence, in this research, we design and implement a domain-independent Adversary Testing Framework (ATF) to test the security robustness of black-box DNN's. By using ATF, we also methodically test a commercially available DNN service used in forensic investigations and bypass the detection, where published methods fail in control settings.","Fri, 3 Aug 2018 14:08:40 UTC (402 KB)"
"418","Generalization Error in Deep Learning","Daniel Jakubovitz, Raja Giryes, Miguel R. D. Rodrigues","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Deep learning models have lately shown great performance in various fields such as computer vision, speech recognition, speech translation, and natural language processing. However, alongside their state-of-the-art performance, it is still generally unclear what is the source of their generalization ability. Thus, an important question is what makes deep neural networks able to generalize well from the training set to new data. In this article, we provide an overview of the existing theory and bounds for the characterization of the generalization error of deep neural networks, combining both classical and more recent theoretical and empirical results.","Fri, 3 Aug 2018 12:57:12 UTC (100 KB)"
"419","PHI Scrubber: A Deep Learning Approach","Abhai Kollara Dilip, Kamal Raj K, Malaikannan Sankarasubbu","Machine Learning (cs.LG); Machine Learning (stat.ML)","Confidentiality of patient information is an essential part of Electronic Health Record System. Patient information, if exposed, can cause a serious damage to the privacy of individuals receiving healthcare. Hence it is important to remove such details from physician notes. A system is proposed which consists of a deep learning model where a de-convolutional neural network and bi-directional LSTM-CNN is used along with regular expressions to recognize and eliminate the individually identifiable information. This information is then removed from a medical practitioner's data which further allows the fair usage of such information among researchers and in clinical trials.","Fri, 3 Aug 2018 09:34:20 UTC (705 KB)"
"420","Dynamic Detection of False Data Injection Attack in Smart Grid using Deep Learning","Xiangyu Niu Jiangnan Li, Jinyuan Sun","Cryptography and Security (cs.CR)","Modern advances in sensor, computing, and communication technologies enable various smart grid applications. The heavy dependence on communication technology has highlighted the vulnerability of the electricity grid to false data injection (FDI) attacks that can bypass bad data detection mechanisms. Existing mitigation in the power system either focus on redundant measurements or protect a set of basic measurements. These methods make specific assumptions about FDI attacks, which are often restrictive and inadequate to deal with modern cyber threats. In the proposed approach, a deep learning based framework is used to detect injected data measurement. Our time-series anomaly detector adopts a Convolutional Neural Network (CNN) and a Long Short Term Memory (LSTM) network. To effectively estimate system variables, our approach observes both data measurements and network level features to jointly learn system states. The proposed system is tested on IEEE 39-bus system. Experimental analysis shows that the deep learning algorithm can identify anomalies which cannot be detected by traditional state estimation bad data detection.","Fri, 3 Aug 2018 05:57:31 UTC (1,031 KB)[v2] Fri, 14 Sep 2018 21:47:36 UTC (1,032 KB)"
"421","Evaluating the Readability of Force Directed Graph Layouts: A Deep Learning Approach","Hammad Haleem, Yong Wang, Abishek Puri, Sahil Wadhwa, Huamin Qu","Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Human-Computer Interaction (cs.HC)","Existing graph layout algorithms are usually not able to optimize all the aesthetic properties desired in a graph layout. To evaluate how well the desired visual features are reflected in a graph layout, many readability metrics have been proposed in the past decades. However, the calculation of these readability metrics often requires access to the node and edge coordinates and is usually computationally inefficient, especially for dense graphs. Importantly, when the node and edge coordinates are not accessible, it becomes impossible to evaluate the graph layouts quantitatively. In this paper, we present a novel deep learning-based approach to evaluate the readability of graph layouts by directly using graph images. A convolutional neural network architecture is proposed and trained on a benchmark dataset of graph images, which is composed of synthetically-generated graphs and graphs created by sampling from real large networks. Multiple representative readability metrics (including edge crossing, node spread, and group overlap) are considered in the proposed approach. We quantitatively compare our approach to traditional methods and qualitatively evaluate our approach using a case study and visualizing convolutional layers. This work is a first step towards using deep learning based methods to evaluate images from the visualization field quantitatively.","Thu, 2 Aug 2018 07:57:59 UTC (15,263 KB)[v2] Wed, 14 Nov 2018 23:20:45 UTC (947 KB)"
"422","Linguistic Search Optimization for Deep Learning Based LVCSR","Zhehuai Chen","Computation and Language (cs.CL)","Recent advances in deep learning based large vocabulary con- tinuous speech recognition (LVCSR) invoke growing demands in large scale speech transcription. The inference process of a speech recognizer is to find a sequence of labels whose corresponding acoustic and language models best match the input feature [1]. The main computation includes two stages: acoustic model (AM) inference and linguistic search (weighted finite-state transducer, WFST). Large computational overheads of both stages hamper the wide application of LVCSR. Benefit from stronger classifiers, deep learning, and more powerful computing devices, we propose general ideas and some initial trials to solve these fundamental problems.","Thu, 2 Aug 2018 06:47:23 UTC (1,174 KB)"
"423","Deep Learning for Radio Resource Allocation in Multi-Cell Networks","K. I. Ahmed, H. Tabassum, E. Hossain","Networking and Internet Architecture (cs.NI); Machine Learning (cs.LG); Signal Processing (eess.SP)","Increased complexity and heterogeneity of emerging 5G and beyond 5G (B5G) wireless networks will require a paradigm shift from traditional resource allocation mechanisms. Deep learning (DL) is a powerful tool where a multi-layer neural network can be trained to model a resource management algorithm using network data.Therefore, resource allocation decisions can be obtained without intensive online computations which would be required otherwise for the solution of resource allocation problems. In this context, this article focuses on the application of DL to obtain solutions for the radio resource allocation problems in multi-cell networks. Starting with a brief overview of a deep neural network (DNN) as a DL model, relevant DNN architectures and the data training procedure, we provide an overview of existing state-of-the-art applying DL in the context of radio resource allocation. A qualitative comparison is provided in terms of their objectives, inputs/outputs, learning and data training methods. Then, we present a supervised DL model to solve the sub-band and power allocation problem in a multi-cell network. Using the data generated by a genetic algorithm, we first train the model and then test the accuracy of the proposed model in predicting the resource allocation solutions. Simulation results show that the trained DL model is able to provide the desired optimal solution 86.3% of time.","Thu, 2 Aug 2018 04:55:25 UTC (199 KB)"
"424","Sequence Discriminative Training for Deep Learning based Acoustic Keyword Spotting","Zhehuai Chen, Yanmin Qian, Kai Yu","Computation and Language (cs.CL)","Speech recognition is a sequence prediction problem. Besides employing various deep learning approaches for framelevel classification, sequence-level discriminative training has been proved to be indispensable to achieve the state-of-the-art performance in large vocabulary continuous speech recognition (LVCSR). However, keyword spotting (KWS), as one of the most common speech recognition tasks, almost only benefits from frame-level deep learning due to the difficulty of getting competing sequence hypotheses. The few studies on sequence discriminative training for KWS are limited for fixed vocabulary or LVCSR based methods and have not been compared to the state-of-the-art deep learning based KWS approaches. In this paper, a sequence discriminative training framework is proposed for both fixed vocabulary and unrestricted acoustic KWS. Sequence discriminative training for both sequence-level generative and discriminative models are systematically investigated. By introducing word-independent phone lattices or non-keyword blank symbols to construct competing hypotheses, feasible and efficient sequence discriminative training approaches are proposed for acoustic KWS. Experiments showed that the proposed approaches obtained consistent and significant improvement in both fixed vocabulary and unrestricted KWS tasks, compared to previous frame-level deep learning based acoustic KWS methods.","Thu, 2 Aug 2018 02:26:53 UTC (4,786 KB)"
"425","Classification of Building Information Model (BIM) Structures with Deep Learning","Francesco Lomio, Ricardo Farinha, Mauri Laasonen, Heikki Huttunen","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","In this work we study an application of machine learning to the construction industry and we use classical and modern machine learning methods to categorize images of building designs into three classes: Apartment building, Industrial building or Other. No real images are used, but only images extracted from Building Information Model (BIM) software, as these are used by the construction industry to store building designs. For this task, we compared four different methods: the first is based on classical machine learning, where Histogram of Oriented Gradients (HOG) was used for feature extraction and a Support Vector Machine (SVM) for classification; the other three methods are based on deep learning, covering common pre-trained networks as well as ones designed from scratch. To validate the accuracy of the models, a database of 240 images was used. The accuracy achieved is 57% for the HOG + SVM model, and above 89% for the neural networks.","Wed, 1 Aug 2018 23:56:28 UTC (556 KB)"
"426","Stock Chart Pattern recognition with Deep Learning","Marc Velay, Fabrice Daniel","Machine Learning (cs.LG); Machine Learning (stat.ML)","This study evaluates the performances of CNN and LSTM for recognizing common charts patterns in a stock historical data. It presents two common patterns, the method used to build the training set, the neural networks architectures and the accuracies obtained.","Wed, 1 Aug 2018 17:00:43 UTC (378 KB)"
"427","Lip-Reading Driven Deep Learning Approach for Speech Enhancement","Ahsan Adeel, Mandar Gogate, Amir Hussain, William M. Whitmer","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)","This paper proposes a novel lip-reading driven deep learning framework for speech enhancement. The proposed approach leverages the complementary strengths of both deep learning and analytical acoustic modelling (filtering based approach) as compared to recently published, comparatively simpler benchmark approaches that rely only on deep learning. The proposed audio-visual (AV) speech enhancement framework operates at two levels. In the first level, a novel deep learning-based lip-reading regression model is employed. In the second level, lip-reading approximated clean-audio features are exploited, using an enhanced, visually-derived Wiener filter (EVWF), for the clean audio power spectrum estimation. Specifically, a stacked long-short-term memory (LSTM) based lip-reading regression model is designed for clean audio features estimation using only temporal visual features considering different number of prior visual frames. For clean speech spectrum estimation, a new filterbank-domain EVWF is formulated, which exploits estimated speech features. The proposed EVWF is compared with conventional Spectral Subtraction and Log-Minimum Mean-Square Error methods using both ideal AV mapping and LSTM driven AV mapping. The potential of the proposed speech enhancement framework is evaluated under different dynamic real-world commercially-motivated scenarios (e.g. cafe, public transport, pedestrian area) at different SNR levels (ranging from low to high SNRs) using benchmark Grid and ChiME3 corpora. For objective testing, perceptual evaluation of speech quality is used to evaluate the quality of restored speech. For subjective testing, the standard mean-opinion-score method is used with inferential statistics. Comparative simulation results demonstrate significant lip-reading and speech enhancement improvement in terms of both speech quality and speech intelligibility.","Tue, 31 Jul 2018 19:50:13 UTC (3,652 KB)"
"428","End-to-End Physics Event Classification with the CMS Open Data: Applying Image-based Deep Learning on Detector Data to Directly Classify Collision Events at the LHC","Michael Andrews, Manfred Paulini, Sergei Gleyzer, Barnabas Poczos","High Energy Physics - Experiment (hep-ex); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)","We describe the construction of a class of general, end-to-end, image-based physics event classifiers that directly use simulated raw detector data to discriminate signal and background processes in collision events at the LHC. To better understand what such classifiers are able to learn and to address some of the challenges associated with their use, we attempt to distinguish the Standard Model Higgs Boson decaying to two photons from its leading backgrounds using high-fidelity simulated detector data from the 2012 CMS Open Data. We demonstrate the ability of end-to-end classifiers to learn from the angular distribution of the electromagnetic showers, their shape, and the energy scale of their constituent hits, even when the underlying particles are not fully resolved.","Tue, 31 Jul 2018 16:52:07 UTC (527 KB)"
"429","Fast Sketch Segmentation and Labeling with Deep Learning","Lei Li, Hongbo Fu, Chiew-Lan Tai","Graphics (cs.GR)","We present a simple and efficient method based on deep learning to automatically decompose sketched objects into semantically valid parts. We train a deep neural network to transfer existing segmentations and labelings from 3D models to freehand sketches without requiring numerous well-annotated sketches as training data. The network takes the binary image of a sketched object as input and produces a corresponding segmentation map with per-pixel labelings as output. A subsequent post-process procedure with multi-label graph cuts further refines the segmentation and labeling result. We validate our proposed method on two sketch datasets. Experiments show that our method outperforms the state-of-the-art method in terms of segmentation and labeling accuracy and is significantly faster, enabling further integration in interactive drawing systems. We demonstrate the efficiency of our method in a sketch-based modeling application that automatically transforms input sketches into 3D models by part assembly.","Tue, 31 Jul 2018 14:56:02 UTC (3,432 KB)"
"430","Deep learning in agriculture: A survey","Andreas Kamilaris, Francesc X. Prenafeta-Boldu","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Deep learning constitutes a recent, modern technique for image processing and data analysis, with promising results and large potential. As deep learning has been successfully applied in various domains, it has recently entered also the domain of agriculture. In this paper, we perform a survey of 40 research efforts that employ deep learning techniques, applied to various agricultural and food production challenges. We examine the particular agricultural problems under study, the specific models and frameworks employed, the sources, nature and pre-processing of data used, and the overall performance achieved according to the metrics used at each work under study. Moreover, we study comparisons of deep learning with other existing popular techniques, in respect to differences in classification or regression performance. Our findings indicate that deep learning provides high accuracy, outperforming existing commonly used image processing techniques.","Tue, 31 Jul 2018 13:30:03 UTC (930 KB)"
"431","Disaster Monitoring using Unmanned Aerial Vehicles and Deep Learning","Andreas Kamilaris, Francesc X. Prenafeta-Boldu","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Monitoring of disasters is crucial for mitigating their effects on the environment and human population, and can be facilitated by the use of unmanned aerial vehicles (UAV), equipped with camera sensors that produce aerial photos of the areas of interest. A modern technique for recognition of events based on aerial photos is deep learning. In this paper, we present the state of the art work related to the use of deep learning techniques for disaster identification. We demonstrate the potential of this technique in identifying disasters with high accuracy, by means of a relatively simple deep learning model. Based on a dataset of 544 images (containing disaster images such as fires, earthquakes, collapsed buildings, tsunami and flooding, as well as non-disaster scenes), our results show an accuracy of 91% achieved, indicating that deep learning, combined with UAV equipped with camera sensors, have the potential to predict disasters with high accuracy.","Tue, 31 Jul 2018 13:24:31 UTC (503 KB)[v2] Wed, 8 Aug 2018 09:29:37 UTC (504 KB)"
"432","Deep Learning in Physical Layer Communications","Zhijin Qin, Hao Ye, Geoffrey Ye Li, Biing-Hwang Fred Juang","Information Theory (cs.IT)","Deep learning (DL) has shown the great potentials to break the bottleneck of communication systems. This article provides an overview on the recent advancements in DL-based physical layer communications. DL can improve the performance of each individual block in communication systems or optimize the whole transmitter/receiver. Therefore, we categorize the applications of DL in physical layer communications into systems with and without block structures. For DL-based communication systems with block structures, we demonstrate the power of DL in signal compression and signal detection. We also discuss the recent endeavors in developing end-to-end communication systems. Finally, the potential research directions are identified to boost the intelligent physical layer communications with DL.","Tue, 31 Jul 2018 09:22:14 UTC (963 KB)[v2] Mon, 24 Sep 2018 09:31:00 UTC (2,139 KB)"
"433","Deep Learning-based CSI Feedback Approach for Time-varying Massive MIMO Channels","Tianqi Wang, Chao-Kai Wen, Shi Jin, Geoffrey Ye Li","Information Theory (cs.IT)","Massive multiple-input multiple-output (MIMO) systems rely on channel state information (CSI) feedback to perform precoding and achieve performance gain in frequency division duplex (FDD) networks. However, the huge number of antennas poses a challenge to conventional CSI feedback reduction methods and leads to excessive feedback overhead. In this article, we develop a real-time CSI feedback architecture, called CsiNet-long short-term memory (LSTM), by extending a novel deep learning (DL)-based CSI sensing and recovery network. CsiNet-LSTM considerably enhances recovery quality and improves trade-off between compression ratio (CR) and complexity by directly learning spatial structures combined with time correlation from training samples of time-varying massive MIMO channels. Simulation results demonstrate that CsiNet- LSTM outperforms existing compressive sensing-based and DLbased methods and is remarkably robust to CR reduction.","Tue, 31 Jul 2018 05:58:33 UTC (859 KB)"
"434","Security and Privacy Issues in Deep Learning","Ho Bae, Jaehee Jang, Dahuin Jung, Hyemi Jang, Heonseok Ha, Sungroh Yoon","Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)","With the development of machine learning, expectations for artificial intelligence (AI) technology are increasing day by day. In particular, deep learning has shown enriched performance results in a variety of fields. There are many applications that are closely related to our daily life, such as making significant decisions in application area based on predictions or classifications, in which a deep learning (DL) model could be relevant. Hence, if a DL model causes mispredictions or misclassifications due to malicious external influences, it can cause very large difficulties in real life. Moreover, training deep learning models involves relying on an enormous amount of data and the training data often includes sensitive information. Therefore, deep learning models should not expose the privacy of such data. In this paper, we reviewed the threats and developed defense methods on the security of the models and the data privacy under the notion of SPAI: Secure and Private AI. We also discuss current challenges and open issues.","Tue, 31 Jul 2018 04:18:26 UTC (6,175 KB)"
"435","State-of-the-art and gaps for deep learning on limited training data in remote sensing","John E. Ball, Derek T. Anderson, Pan Wei","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning usually requires big data, with respect to both volume and variety. However, most remote sensing applications only have limited training data, of which a small subset is labeled. Herein, we review three state-of-the-art approaches in deep learning to combat this challenge. The first topic is transfer learning, in which some aspects of one domain, e.g., features, are transferred to another domain. The next is unsupervised learning, e.g., autoencoders, which operate on unlabeled data. The last is generative adversarial networks, which can generate realistic looking data that can fool the likes of both a deep learning network and human. The aim of this article is to raise awareness of this dilemma, to direct the reader to existing work and to highlight current gaps that need solving.","Wed, 11 Jul 2018 23:44:50 UTC (79 KB)"
"436","Weakly-Supervised Deep Learning of Heat Transport via Physics Informed Loss","Rishi Sharma, Amir Barati Farimani, Joe Gomes, Peter Eastman, Vijay Pande","Machine Learning (stat.ML); Machine Learning (cs.LG)","In typical machine learning tasks and applications, it is necessary to obtain or create large labeled datasets in order to to achieve high performance. Unfortunately, large labeled datasets are not always available and can be expensive to source, creating a bottleneck towards more widely applicable machine learning. The paradigm of weak supervision offers an alternative that allows for integration of domain-specific knowledge by enforcing constraints that a correct solution to the learning problem will obey over the output space. In this work, we explore the application of this paradigm to 2-D physical systems governed by non-linear differential equations. We demonstrate that knowledge of the partial differential equations governing a system can be encoded into the loss function of a neural network via an appropriately chosen convolutional kernel. We demonstrate this by showing that the steady-state solution to the 2-D heat equation can be learned directly from initial conditions by a convolutional neural network, in the absence of labeled training data. We also extend recent work in the progressive growing of fully convolutional networks to achieve high accuracy (< 1.5% error) at multiple scales of the heat-flow problem, including at the very large scale (1024x1024). Finally, we demonstrate that this method can be used to speed up exact calculation of the solution to the differential equations via finite difference.","Tue, 24 Jul 2018 17:58:56 UTC (1,791 KB)[v2] Tue, 21 Aug 2018 18:40:09 UTC (1,791 KB)"
"437","Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four Minutes","Xianyan Jia, Shutao Song, Wei He, Yangzihao Wang, Haidong Rong, Feihu Zhou, Liqiang Xie, Zhenyu Guo, Yuanzhou Yang, Liwei Yu, Tiegang Chen, Guangxiao Hu, Shaohuai Shi, Xiaowen Chu","Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (stat.ML)","Synchronized stochastic gradient descent (SGD) optimizers with data parallelism are widely used in training large-scale deep neural networks. Although using larger mini-batch sizes can improve the system scalability by reducing the communication-to-computation ratio, it may hurt the generalization ability of the models. To this end, we build a highly scalable deep learning training system for dense GPU clusters with three main contributions: (1) We propose a mixed-precision training method that significantly improves the training throughput of a single GPU without losing accuracy. (2) We propose an optimization approach for extremely large mini-batch size (up to 64k) that can train CNN models on the ImageNet dataset without losing accuracy. (3) We propose highly optimized all-reduce algorithms that achieve up to 3x and 11x speedup on AlexNet and ResNet-50 respectively than NCCL-based training on a cluster with 1024 Tesla P40 GPUs. On training ResNet-50 with 90 epochs, the state-of-the-art GPU-based system with 1024 Tesla P100 GPUs spent 15 minutes and achieved 74.9\% top-1 test accuracy, and another KNL-based system with 2048 Intel KNLs spent 20 minutes and achieved 75.4\% accuracy. Our training system can achieve 75.8\% top-1 test accuracy in only 6.6 minutes using 2048 Tesla P40 GPUs. When training AlexNet with 95 epochs, our system can achieve 58.7\% top-1 test accuracy within 4 minutes, which also outperforms all other existing systems.","Mon, 30 Jul 2018 07:40:44 UTC (1,261 KB)"
"438","Towards End-to-End Acoustic Localization using Deep Learning: from Audio Signal to Source Position Coordinates","Juan Manuel Vera-Diaz, Daniel Pizarro, Javier Macias-Guarasa","Sound (cs.SD); Audio and Speech Processing (eess.AS)","This paper presents a novel approach for indoor acoustic source localization using microphone arrays and based on a Convolutional Neural Network (CNN). The proposed solution is, to the best of our knowledge, the first published work in which the CNN is designed to directly estimate the three dimensional position of an acoustic source, using the raw audio signal as the input information avoiding the use of hand crafted audio features. Given the limited amount of available localization data, we propose in this paper a training strategy based on two steps. We first train our network using semi-synthetic data, generated from close talk speech recordings, and where we simulate the time delays and distortion suffered in the signal that propagates from the source to the array of microphones. We then fine tune this network using a small amount of real data. Our experimental results show that this strategy is able to produce networks that significantly improve existing localization methods based on \textit{SRP-PHAT} strategies. In addition, our experiments show that our CNN method exhibits better resistance against varying gender of the speaker and different window sizes compared with the other methods.","Sun, 29 Jul 2018 18:22:38 UTC (1,469 KB)"
"439","A Survey of Machine and Deep Learning Methods for Internet of Things (IoT) Security","Mohammed Ali Al-Garadi, Amr Mohamed, Abdulla Al-Ali, Xiaojiang Du, Mohsen Guizani","Cryptography and Security (cs.CR); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)","The Internet of Things (IoT) integrates billions of smart devices that can communicate with one another with minimal human intervention. It is one of the fastest developing fields in the history of computing, with an estimated 50 billion devices by the end of 2020. On the one hand, IoT play a crucial role in enhancing several real-life smart applications that can improve life quality. On the other hand, the crosscutting nature of IoT systems and the multidisciplinary components involved in the deployment of such systems introduced new security challenges. Implementing security measures, such as encryption, authentication, access control, network security and application security, for IoT devices and their inherent vulnerabilities is ineffective. Therefore, existing security methods should be enhanced to secure the IoT system effectively. Machine learning and deep learning (ML/DL) have advanced considerably over the last few years, and machine intelligence has transitioned from laboratory curiosity to practical machinery in several important applications. Consequently, ML/DL methods are important in transforming the security of IoT systems from merely facilitating secure communication between devices to security-based intelligence systems. The goal of this work is to provide a comprehensive survey of ML /DL methods that can be used to develop enhanced security methods for IoT systems. IoT security threats that are related to inherent or newly introduced threats are presented, and various potential IoT system attack surfaces and the possible threats related to each surface are discussed. We then thoroughly review ML/DL methods for IoT security and present the opportunities, advantages and shortcomings of each method. We discuss the opportunities and challenges involved in applying ML/DL to IoT security. These opportunities and challenges can serve as potential future research directions.","Sun, 29 Jul 2018 08:58:38 UTC (3,957 KB)"
"440","Bridge the Gap Between VQA and Human Behavior on Omnidirectional Video: A Large-Scale Dataset and a Deep Learning Model","Chen Li, Mai Xu, Xinzhe Du, Zulin Wang","Computer Vision and Pattern Recognition (cs.CV)","Omnidirectional video enables spherical stimuli with the $360 \times 180^ \circ$ viewing range. Meanwhile, only the viewport region of omnidirectional video can be seen by the observer through head movement (HM), and an even smaller region within the viewport can be clearly perceived through eye movement (EM). Thus, the subjective quality of omnidirectional video may be correlated with HM and EM of human behavior. To fill in the gap between subjective quality and human behavior, this paper proposes a large-scale visual quality assessment (VQA) dataset of omnidirectional video, called VQA-OV, which collects 60 reference sequences and 540 impaired sequences. Our VQA-OV dataset provides not only the subjective quality scores of sequences but also the HM and EM data of subjects. By mining our dataset, we find that the subjective quality of omnidirectional video is indeed related to HM and EM. Hence, we develop a deep learning model, which embeds HM and EM, for objective VQA on omnidirectional video. Experimental results show that our model significantly improves the state-of-the-art performance of VQA on omnidirectional video.","Sun, 29 Jul 2018 02:03:14 UTC (2,454 KB)"
"441","A Survey of the Usages of Deep Learning in Natural Language Processing","Daniel W. Otter, Julian R. Medina, Jugal K. Kalita","Computation and Language (cs.CL)","Over the last several years, the field of natural language processing has been propelled forward by an explosion in the use of deep learning models. This survey provides a brief introduction to the field and a quick overview of deep learning architectures and methods. It then sifts through the plethora of recent studies and summarizes a large assortment of relevant contributions. Analyzed research areas include several core linguistic processing issues in addition to a number of applications of computational linguistics. A discussion of the current state of the art is then provided along with recommendations for future research in the field.","Fri, 27 Jul 2018 23:11:39 UTC (1,492 KB)"
"442","End-to-end Deep Learning from Raw Sensor Data: Atrial Fibrillation Detection using Wearables","Igor Gotlibovych, Stuart Crawford, Dileep Goyal, Jiaqi Liu, Yaniv Kerem, David Benaron, Defne Yilmaz, Gregory Marcus, Yihan Li","Machine Learning (stat.ML); Machine Learning (cs.LG)","We present a convolutional-recurrent neural network architecture with long short-term memory for real-time processing and classification of digital sensor data. The network implicitly performs typical signal processing tasks such as filtering and peak detection, and learns time-resolved embeddings of the input signal. We use a prototype multi-sensor wearable device to collect over 180h of photoplethysmography (PPG) data sampled at 20Hz, of which 36h are during atrial fibrillation (AFib). We use end-to-end learning to achieve state-of-the-art results in detecting AFib from raw PPG data. For classification labels output every 0.8s, we demonstrate an area under ROC curve of 0.9999, with false positive and false negative rates both below $2\times 10^{-3}$. This constitutes a significant improvement on previous results utilising domain-specific feature engineering, such as heart rate extraction, and brings large-scale atrial fibrillation screenings within imminent reach.","Fri, 27 Jul 2018 16:17:31 UTC (268 KB)"
"443","On the overfly algorithm in deep learning of neural networks","Alexei Tsygvintsev","Machine Learning (cs.LG); Dynamical Systems (math.DS); Machine Learning (stat.ML)","In this paper we investigate the supervised backpropagation training of multilayer neural networks from a dynamical systems point of view. We discuss some links with the qualitative theory of differential equations and introduce the overfly algorithm to tackle the local minima problem. Our approach is based on the existence of first integrals of the generalised gradient system with build-in dissipation.","Fri, 27 Jul 2018 15:06:26 UTC (190 KB)[v2] Mon, 30 Jul 2018 12:28:26 UTC (191 KB)[v3] Thu, 9 Aug 2018 15:05:34 UTC (191 KB)[v4] Thu, 27 Sep 2018 21:07:14 UTC (191 KB)[v5] Wed, 7 Nov 2018 15:56:07 UTC (212 KB)"
"444","Deep Learning Hyperspectral Image Classification Using Multiple Class-based Denoising Autoencoders, Mixed Pixel Training Augmentation, and Morphological Operations","John E. Ball, Pan Wei","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Herein, we present a system for hyperspectral image segmentation that utilizes multiple class--based denoising autoencoders which are efficiently trained. Moreover, we present a novel hyperspectral data augmentation method for labelled HSI data using linear mixtures of pixels from each class, which helps the system with edge pixels which are almost always mixed pixels. Finally, we utilize a deep neural network and morphological hole-filling to provide robust image classification. Results run on the Salinas dataset verify the high performance of the proposed algorithm.","Wed, 11 Jul 2018 23:49:30 UTC (128 KB)"
"445","Embedded Implementation of a Deep Learning Smile Detector","Pedram Ghazi, Antti P. Happonen, Jani Boutellier, Heikki Huttunen","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","In this paper we study the real time deployment of deep learning algorithms in low resource computational environments. As the use case, we compare the accuracy and speed of neural networks for smile detection using different neural network architectures and their system level implementation on NVidia Jetson embedded platform. We also propose an asynchronous multithreading scheme for parallelizing the pipeline. Within this framework, we experimentally compare thirteen widely used network topologies. The experiments show that low complexity architectures can achieve almost equal performance as larger ones, with a fraction of computation required.","Tue, 10 Jul 2018 07:37:37 UTC (302 KB)"
"446","DeepLink: A Novel Link Prediction Framework based on Deep Learning","Mohammad Mehdi Keikha, Maseud Rahgozar, Masoud Asadpour","Social and Information Networks (cs.SI); Machine Learning (cs.LG); Machine Learning (stat.ML)","Recently, link prediction has attracted more attentions from various disciplines such as computer science, bioinformatics and economics. In this problem, unknown links between nodes are discovered based on numerous information such as network topology, profile information and user generated contents. Most of the previous researchers have focused on the structural features of the networks. While the recent researches indicate that contextual information can change the network topology. Although, there are number of valuable researches which combine structural and content information, but they face with the scalability issue due to feature engineering. Because, majority of the extracted features are obtained by a supervised or semi supervised algorithm. Moreover, the existing features are not general enough to indicate good performance on different networks with heterogeneous structures. Besides, most of the previous researches are presented for undirected and unweighted networks. In this paper, a novel link prediction framework called ""DeepLink"" is presented based on deep learning techniques. In contrast to the previous researches which fail to automatically extract best features for the link prediction, deep learning reduces the manual feature engineering. In this framework, both the structural and content information of the nodes are employed. The framework can use different structural feature vectors, which are prepared by various link prediction methods. It considers all proximity orders that are presented in a network during the structural feature learning. We have evaluated the performance of DeepLink on two real social network datasets including Telegram and irBlogs. On both datasets, the proposed framework outperforms several structural and hybrid approaches for link prediction problem.","Fri, 27 Jul 2018 08:50:13 UTC (1,183 KB)"
"447","A Deep Learning Framework for Automatic Diagnosis in Lung Cancer","Nikolay Burlutskiy, Feng Gu, Lena Kajland Wilen, Max Backman, Patrick Micke","Computer Vision and Pattern Recognition (cs.CV)","We developed a deep learning framework that helps to automatically identify and segment lung cancer areas in patients' tissue specimens. The study was based on a cohort of lung cancer patients operated at the Uppsala University Hospital. The tissues were reviewed by lung pathologists and then the cores were compiled to tissue micro-arrays (TMAs). For experiments, hematoxylin-eosin stained slides from 712 patients were scanned and then manually annotated. Then these scans and annotations were used to train segmentation models of the developed framework. The performance of the developed deep learning framework was evaluated on fully annotated TMA cores from 178 patients reaching pixel-wise precision of 0.80 and recall of 0.86. Finally, publicly available Stanford TMA cores were used to demonstrate high performance of the framework qualitatively.","Fri, 27 Jul 2018 07:32:46 UTC (1,571 KB)"
"448","DeepSPINE: Automated Lumbar Vertebral Segmentation, Disc-level Designation, and Spinal Stenosis Grading Using Deep Learning","Jen-Tang Lu, Stefano Pedemonte, Bernardo Bizzo, Sean Doyle, Katherine P. Andriole, Mark H. Michalski, R. Gilberto Gonzalez, Stuart R. Pomerantz","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","The high prevalence of spinal stenosis results in a large volume of MRI imaging, yet interpretation can be time-consuming with high inter-reader variability even among the most specialized radiologists. In this paper, we develop an efficient methodology to leverage the subject-matter-expertise stored in large-scale archival reporting and image data for a deep-learning approach to fully-automated lumbar spinal stenosis grading. Specifically, we introduce three major contributions: (1) a natural-language-processing scheme to extract level-by-level ground-truth labels from free-text radiology reports for the various types and grades of spinal stenosis (2) accurate vertebral segmentation and disc-level localization using a U-Net architecture combined with a spine-curve fitting method, and (3) a multi-input, multi-task, and multi-class convolutional neural network to perform central canal and foraminal stenosis grading on both axial and sagittal imaging series inputs with the extracted report-derived labels applied to corresponding imaging level segments. This study uses a large dataset of 22796 disc-levels extracted from 4075 patients. We achieve state-of-the-art performance on lumbar spinal stenosis classification and expect the technique will increase both radiology workflow efficiency and the perceived value of radiology reports for referring clinicians and patients.","Thu, 26 Jul 2018 15:59:49 UTC (4,232 KB)"
"449","Fusing numerical relativity and deep learning to detect higher-order multipole waveforms from eccentric binary black hole mergers","Adam Rebei, E. A. Huerta, Sibo Wang, Sarah Habib, Roland Haas, Daniel Johnson, Daniel George","General Relativity and Quantum Cosmology (gr-qc); High Energy Astrophysical Phenomena (astro-ph.HE); Computational Physics (physics.comp-ph)","Motivated by recent electromagnetic observations which suggest the existence of compact binary populations in the Galactic Cluster M22 [Nature 490, 71 (2012)] and in the Galactic center [Nature 556, 70 (2018)], and considering that eccentricity provides one of the cleanest signatures to identify these compact binary populations, in this article we study the importance of including higher-order waveform multipoles to enable gravitational wave observations of eccentric binary black hole mergers. Using a catalog of Einstein Toolkit numerical relativity simulations that describe eccentric, non-spinning black holes mergers with mass-ratios $1\leq q \leq 10$, and eccentricities $e_0\lesssim0.2$ ten cycles before merger, we determine the mass-ratio, eccentricity and binary inclination angle combinations that maximize the contribution of the higher-order waveform multipoles $(\ell, \, |m|)= \{(2,\,2),\, (2,\,1),\, (3,\,3),\, (3,\,2), \, (3,\,1),\, (4,\,4),\,(4,\,3),$ $(4,\,2),\,(4,\,1)\}$ for gravitational wave detection. We then explore the implications of these results in the context of stellar mass black holes that are detectable by LIGO detectors at design sensitivity, and show that compared to models that only include the $(\ell, \, |m|)=(2,\,2)$ mode, the inclusion of higher-order waveform multipoles can increase the signal-to-noise ratio of eccentric binary black hole mergers by up to $\sim45\%$ for mass-ratio binaries $q\leq10$. Furthermore, building upon our pioneering deep learning work [George & Huerta Phys. Rev. D 97, 044039 (2018); George & Huerta Physics Letters B 778, 64 (2018)], we show for the first time that machine learning can accurately reconstruct higher-order waveform multipole signals from eccentric binary black hole mergers embedded in real LIGO data.","Wed, 25 Jul 2018 18:00:05 UTC (1,752 KB)"
"450","PADME: A Deep Learning-based Framework for Drug-Target Interaction Prediction","Qingyuan Feng, Evgenia Dueva, Artem Cherkasov, Martin Ester","Machine Learning (cs.LG); Machine Learning (stat.ML)","In silico drug-target interaction (DTI) prediction is an important and challenging problem in biomedical research with a huge potential benefit to the pharmaceutical industry and patients. Most existing methods for DTI prediction including deep learning models generally have binary endpoints, which could be an oversimplification of the problem, and those methods are typically unable to handle cold-target problems, i.e., problems involving target protein that never appeared in the training set. Towards this, we contrived PADME (Protein And Drug Molecule interaction prEdiction), a framework based on Deep Neural Networks, to predict real-valued interaction strength between compounds and proteins. PADME takes both compound and protein information as inputs, so it is capable of solving cold-target (and cold-drug) problems. To our knowledge, we are the first to combine Molecular Graph Convolution (MGC) for compound featurization with protein descriptors for DTI prediction. We used multiple cross-validation split schemes and evaluation metrics to measure the performance of PADME on multiple datasets, including the ToxCast dataset, which we believe should be a standard benchmark for DTI problems, and PADME consistently dominates baseline methods. The results of a case study, which predicts the interactions between various compounds and androgen receptor (AR), suggest PADME's potential in drug development. The scalability of PADME is another advantage in the age of Big Data.","Wed, 25 Jul 2018 17:46:47 UTC (774 KB)[v2] Wed, 24 Oct 2018 23:50:49 UTC (1,097 KB)"
"451","Scheduling Computation Graphs of Deep Learning Models on Manycore CPUs","Linpeng Tang, Yida Wang, Theodore L. Willke, Kai Li","Distributed, Parallel, and Cluster Computing (cs.DC)","For a deep learning model, efficient execution of its computation graph is key to achieving high performance. Previous work has focused on improving the performance for individual nodes of the computation graph, while ignoring the parallelization of the graph as a whole. However, we observe that running multiple operations simultaneously without interference is critical to efficiently perform parallelizable small operations. The attempt of executing the computation graph in parallel in deep learning frameworks usually involves much resource contention among concurrent operations, leading to inferior performance on manycore CPUs. To address these issues, in this paper, we propose Graphi, a generic and high-performance execution engine to efficiently execute a computation graph in parallel on manycore CPUs. Specifically, Graphi minimizes the interference on both software/hardware resources, discovers the best parallel setting with a profiler, and further optimizes graph execution with the critical-path first scheduling. Our experiments show that the parallel execution consistently outperforms the sequential one. The training times on four different neural networks with Graphi are 2.1x to 9.5x faster than those with TensorFlow on a 68-core Intel Xeon Phi processor.","Mon, 16 Jul 2018 16:28:38 UTC (4,491 KB)"
"452","Deep Learning Detection Networks in MIMO Decode-Forward Relay Channels","Xianglan Jin, Hyoung-Nam Kim","Machine Learning (stat.ML); Information Theory (cs.IT); Machine Learning (cs.LG)","In this paper, we consider signal detection algorithms in a multiple-input multiple-output (MIMO) decode-forward (DF) relay channel with one source, one relay, and one destination. The existing suboptimal near maximum likelihood (NML) detector and the NML with two-level pair-wise error probability (NMLw2PEP) detector achieve excellent performance with instantaneous channel state information (CSI) of the source-relay (SR) link and with statistical CSI of the SR link, respectively. However, the NML detectors require an exponentially increasing complexity as the number of transmit antennas increases. Using deep learning algorithms, NML-based detection networks (NMLDNs) are proposed with and without the CSI of the SR link at the destination. The NMLDNs detect signals in changing channels after a single training using a large number of randomly distributed channels. The detection networks require much lower detection complexity than the exhaustive search NML detectors while exhibiting good performance. To evaluate the performance, we introduce semidefinite relaxation detectors with polynomial complexity based on the NML detectors. Additionally, new linear detectors based on the zero gradient of the NML metrics are proposed. Applying various detection algorithms at the relay (DetR) and detection algorithms at the destination (DetD), we present some DetR-DetD methods in MIMO DF relay channels. An appropriate DetR-DetD method can be employed according to the required error probability and detection complexity. The complexity analysis and simulation results validate the arguments of this paper.","Thu, 12 Jul 2018 02:31:37 UTC (1,514 KB)"
"453","Deep Learning Network Based Spectrum Sensing Methods for OFDM Systems","Qingqing Cheng, Zhenguo Shi, Diep N. Nguyen, Eryk Dutkiewicz","Signal Processing (eess.SP)","Spectrum sensing plays a critical role in dynamic spectrum sharing, a promising technology to address the radio spectrum shortage. In particular, sensing of Orthogonal frequency division multiplexing (OFDM) signals, a widely accepted multi-carrier transmission paradigm, has received paramount interest. Despite various efforts, most conventional OFDM sensing methods suffer from noise uncertainty, timing delay and carrier frequency offset (CFO) that significantly degrade the sensing accuracy. To address these challenges, this work develops two novel OFDM sensing frameworks drawing support from deep learning networks. Specifically, we first propose a stacked autoencoder based spectrum sensing method (SAE-SS), in which a stacked autoencoder network is designed to extract the inherent features of OFDM signals. Using these features to classify the OFDM user's activities, SAE-SS is much more robust to noise uncertainty, timing delay, and CFO than the conventional OFDM sensing methods. Moreover, SAE-SS doesn't require any prior information of signals (e.g., signal structure, pilot tones, cyclic prefix) which are essential for the conventional feature-based OFDM sensing methods. To further improve the sensing accuracy of SAE-SS, especially under low SNR conditions, we propose a stacked autoencoder based spectrum sensing method using time-frequency domain signals (SAE-TF). SAE-TF achieves higher sensing accuracy than SAW-SS at the cost of higher computational complexity. Extensive simulation results show that both SAE-SS and SAE-TF can achieve significantly higher sensing accuracy, compared with state of the art approaches that suffer from noise uncertainty, timing delay and CFO.","Wed, 25 Jul 2018 01:59:59 UTC (3,239 KB)[v2] Mon, 30 Jul 2018 22:45:12 UTC (3,217 KB)[v3] Sat, 18 Aug 2018 00:51:25 UTC (3,011 KB)"
"454","Deep learning the high variability and randomness inside multimode fibres","Pengfei Fan, Tianrui Zhao, Lei Su","Optics (physics.optics); Machine Learning (cs.LG)","Multimode fibres (MMF) are remarkable high-capacity information channels owing to the large number of transmitting fibre modes, and have recently attracted significant renewed interest in applications such as optical communication, imaging, and optical trapping. At the same time, the optical transmitting modes inside MMFs are highly sensitive to external perturbations and environmental changes, resulting in MMF transmission channels being highly variable and random. This largely limits the practical application of MMFs and hinders the full exploitation of their information capacity. Despite great research efforts made to overcome the high variability and randomness inside MMFs, any geometric change to the MMF leads to completely different transmission matrices, which unavoidably fails at the information recovery. Here, we show the successful binary image transmission using deep learning through a single MMF, which is stationary or subject to dynamic shape variations. We found that a single convolutional neural network has excellent generalisation capability with various MMF transmission states. This deep neural network can be trained by multiple MMF transmission states to accurately predict unknown information at the other end of the MMF at any of these states, without knowing which state is present. Our results demonstrate that deep learning is a promising solution to address the variability and randomness challenge of MMF based information channels. This deep-learning approach is the starting point of developing future high-capacity MMF optical systems and devices, and is applicable to optical systems concerning other diffusing media.","Wed, 18 Jul 2018 21:32:03 UTC (3,426 KB)"
"455","Deep Learning on Retina Images as Screening Tool for Diagnostic Decision Support","Maria Camila Alvarez Trivino (1), Jeremie Despraz (2), Jesus Alfonso Lopez Sotelo (1), Carlos Andres Pena (2) ((1) Universidad Autonoma de Occidente, (2) School of Business and Engineering Vaud (HEIG-VD))","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)","In this project, we developed a deep learning system applied to human retina images for medical diagnostic decision support. The retina images were provided by EyePACS. These images were used in the framework of a Kaggle contest, whose purpose to identify diabetic retinopathy signs through an automatic detection system. Using as inspiration one of the solutions proposed in the contest, we implemented a model that successfully detects diabetic retinopathy from retina images. After a carefully designed preprocessing, the images were used as input to a deep convolutional neural network (CNN). The CNN performed a feature extraction process followed by a classification stage, which allowed the system to differentiate between healthy and ill patients using five categories. Our model was able to identify diabetic retinopathy in the patients with an agreement rate of 76.73% with respect to the medical expert's labels for the test data.","Tue, 24 Jul 2018 16:59:06 UTC (419 KB)"
"456","Deep learning techniques applied to the physics of extensive air showers","A. Guillen, A. Bueno, J. M. Carceller, J. C. Martinez-Velazquez, G. Rubio, C. J. Todero Peixoto, P. Sanchez-Lucas","Instrumentation and Methods for Astrophysics (astro-ph.IM); High Energy Astrophysical Phenomena (astro-ph.HE)","Deep neural networks are a powerful technique that have found ample applications in several branches of Physics. In this work, we apply machine learning algorithms to a specific problem of Cosmic Ray Physics: the estimation of the muon content of extensive air showers when measured at the ground. As a working case, we explore the performance of a deep neural network applied to the signals recorded by the water-Cherenkov detectors of the Surface Detector Array of the Pierre Auger Observatory. We apply deep learning architectures to large sets of simulated data. The inner structure of the neural network is optimized through the use of genetic algorithms. To obtain a prediction of the recorded muon signal in each individual detector, we train neural networks with a mixed sample of light, intermediate and heavy nuclei. When true and predicted signals are compared at detector level, the primary values of the Pearson correlation coefficients are above 95\%. The relative errors of the predicted muon signals are below 10\% and do not depend on the event energy, zenith angle, total signal size, distance range or the hadronic model used to generate the events.","Tue, 24 Jul 2018 10:39:46 UTC (6,663 KB)"
"457","Cosmological constraints from noisy convergence maps through deep learning","Janis Fluri, Tomasz Kacprzak, Aurelien Lucchi, Alexandre Refregier, Adam Amara, Thomas Hofmann (ETH Zurich)","Cosmology and Nongalactic Astrophysics (astro-ph.CO)","Deep learning is a powerful analysis technique that has recently been proposed as a method to constrain cosmological parameters from weak lensing mass maps. Due to its ability to learn relevant features from the data, it is able to extract more information from the mass maps than the commonly used power spectrum, and thus achieve better precision for cosmological parameter measurement. We explore the advantage of Convolutional Neural Networks (CNN) over the power spectrum for varying levels of shape noise and different smoothing scales applied to the maps. We compare the cosmological constraints from the two methods in the $ヘ_M-ヲ_8$ plane for sets of 400 deg$^2$ convergence maps. We find that, for a shape noise level corresponding to 8.53 galaxies/arcmin$^2$ and the smoothing scale of $ヲ_s = 2.34$ arcmin, the network is able to generate 45% tighter constraints. For smaller smoothing scale of $ヲ_s = 1.17$ the improvement can reach $\sim 50 \%$, while for larger smoothing scale of $ヲ_s = 5.85$, the improvement decreases to 19%. The advantage generally decreases when the noise level and smoothing scales increase. We present a new training strategy to train the neural network with noisy data, as well as considerations for practical applications of the deep learning approach.","Mon, 23 Jul 2018 17:30:03 UTC (4,731 KB)"
"458","Deep Learning from Label Proportions for Emphysema Quantification","Gerda Bortsova, Florian Dubost, Silas ┴rting, Ioannis Katramados, Laurens Hogeweg, Laura Thomsen, Mathilde Wille, Marleen de Bruijne","Computer Vision and Pattern Recognition (cs.CV)","We propose an end-to-end deep learning method that learns to estimate emphysema extent from proportions of the diseased tissue. These proportions were visually estimated by experts using a standard grading system, in which grades correspond to intervals (label example: 1-5% of diseased tissue). The proposed architecture encodes the knowledge that the labels represent a volumetric proportion. A custom loss is designed to learn with intervals. Thus, during training, our network learns to segment the diseased tissue such that its proportions fit the ground truth intervals. Our architecture and loss combined improve the performance substantially (8% ICC) compared to a more conventional regression network. We outperform traditional lung densitometry and two recently published methods for emphysema quantification by a large margin (at least 7% AUC and 15% ICC), and achieve near-human-level performance. Moreover, our method generates emphysema segmentations that predict the spatial distribution of emphysema at human level.","Mon, 23 Jul 2018 13:34:01 UTC (496 KB)"
"459","Real-Time Patient-Specific Lung Radiotherapy Targeting using Deep Learning","Markus D. Foote (1), Blake Zimmerman (1), Amit Sawant (2), Sarang Joshi (1) ((1) Scientific Computing and Imaging Institute, Department of Bioengineering, University of Utah, (2) Department of Radiation Oncology, The University of Maryland School of Medicine)","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Radiation therapy has presented a need for dynamic tracking of a target tumor volume. Fiducial markers such as implanted gold seeds have been used to gate radiation delivery but the markers are invasive and gating significantly increases treatment time. Pretreatment acquisition of a 4DCT allows for the development of accurate motion estimation for treatment planning. A deep convolutional neural network and subspace motion tracking is used to recover anatomical positions from a single radiograph projection in real-time. We approximate the nonlinear inverse of a diffeomorphic transformation composed with radiographic projection as a deep network that produces subspace coordinates to define the patient-specific deformation of the lungs from a baseline anatomic position. The geometric accuracy of the subspace projections on real patient data is similar to accuracy attained by original image registration between individual respiratory-phase image volumes.","Sun, 22 Jul 2018 23:45:34 UTC (540 KB)"
"460","Skin Lesion Analysis Towards Melanoma Detection via End-to-end Deep Learning of Convolutional Neural Networks","Katherine M. Li, Evelyn C. Li","Computer Vision and Pattern Recognition (cs.CV)","This article presents the design, experiments and results of our solution submitted to the 2018 ISIC challenge: Skin Lesion Analysis Towards Melanoma Detection. We design a pipeline using state-of-the-art Convolutional Neural Network (CNN) models for a Lesion Boundary Segmentation task and a Lesion Diagnosis task.","Sun, 22 Jul 2018 18:07:50 UTC (188 KB)"
"461","Deep Learning Parametrization for B-Spline Curve Approximation","Pascal Laube, Matthias O. Franz, Georg Umlauf","Computational Geometry (cs.CG); Graphics (cs.GR)","In this paper we present a method using deep learning to compute parametrizations for B-spline curve approximation. Existing methods consider the computation of parametric values and a knot vector as separate problems. We propose to train interdependent deep neural networks to predict parametric values and knots. We show that it is possible to include B-spline curve approximation directly into the neural network architecture. The resulting parametrizations yield tight approximations and are able to outperform state-of-the-art methods.","Sun, 22 Jul 2018 15:41:21 UTC (1,450 KB)"
"462","Correlation Net : spatio temporal multimodal deep learning","Novanto Yudistira, Takio Kurita","Computer Vision and Pattern Recognition (cs.CV)","This letter describes a network that is able to capture spatiotemporal correlations over arbitrary timestamps. The proposed scheme operates as a complementary, extended network over spatiotemporal regions. Recently, multimodal fusion has been extensively researched in deep learning. For action recognition, the spatial and temporal streams are vital components of deep Convolutional Neural Network (CNNs), but reducing the occurrence of overfitting and fusing these two streams remain open problems. The existing fusion approach is to average the two streams. To this end, we propose a correlation network with a Shannon fusion to learn a CNN that has already been trained. Long-range video may consist of spatiotemporal correlation over arbitrary times. This correlation can be captured using simple fully connected layers to form the correlation network. This is found to be complementary to the existing network fusion methods. We evaluate our approach on the UCF-101 and HMDB-51 datasets, and the resulting improvement in accuracy demonstrates the importance of multimodal correlation.","Sun, 22 Jul 2018 14:48:32 UTC (718 KB)[v2] Sat, 6 Oct 2018 06:59:46 UTC (354 KB)"
"463","Deep learning at the shallow end: Malware classification for non-domain experts","Quan Le, Oisin Boydell, Brian Mac Namee, Mark Scanlon","Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","Current malware detection and classification approaches generally rely on time consuming and knowledge intensive processes to extract patterns (signatures) and behaviors from malware, which are then used for identification. Moreover, these signatures are often limited to local, contiguous sequences within the data whilst ignoring their context in relation to each other and throughout the malware file as a whole. We present a Deep Learning based malware classification approach that requires no expert domain knowledge and is based on a purely data driven approach for complex pattern and feature identification.","Sun, 22 Jul 2018 10:07:57 UTC (1,319 KB)"
"464","Recent Advances in Deep Learning: An Overview","Matiur Rahman Minar, Jibon Naher","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Deep Learning is one of the newest trends in Machine Learning and Artificial Intelligence research. It is also one of the most popular scientific research trends now-a-days. Deep learning methods have brought revolutionary advances in computer vision and machine learning. Every now and then, new and new deep learning techniques are being born, outperforming state-of-the-art machine learning and even existing deep learning techniques. In recent years, the world has seen many major breakthroughs in this field. Since deep learning is evolving at a huge speed, its kind of hard to keep track of the regular advances especially for new researchers. In this paper, we are going to briefly discuss about recent advances in Deep Learning for past few years.","Sat, 21 Jul 2018 15:40:10 UTC (38 KB)"
"465","What is not where: the challenge of integrating spatial representations into deep learning architectures","John D. Kelleher, Simon Dobnik","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","This paper examines to what degree current deep learning architectures for image caption generation capture spatial language. On the basis of the evaluation of examples of generated captions from the literature we argue that systems capture what objects are in the image data but not where these objects are located: the captions generated by these systems are the output of a language model conditioned on the output of an object detector that cannot capture fine-grained location information. Although language models provide useful knowledge for image captions, we argue that deep learning image captioning architectures should also model geometric relations between objects.","Sat, 21 Jul 2018 11:55:17 UTC (2,330 KB)"
"466","Ensemble of Deep Learned Features for Melanoma Classification","Loris Nanni, Alessandra Lumini, Stefano Ghidoni","Computer Vision and Pattern Recognition (cs.CV)","The aim of this work is to propose an ensemble of descriptors for Melanoma Classification, whose performance has been evaluated on validation and test datasets of the melanoma challenge 2018. The system proposed here achieves a strong discriminative power thanks to the combination of multiple descriptors. The proposed system represents a very simple yet effective way of boosting the performance of trained CNNs by composing multiple CNNs into an ensemble and combining scores by sum rule. Several types of ensembles are considered, with different CNN architectures along with different learning parameter sets. Moreover CNN are used as feature extractors: an input image is processed by a trained CNN and the response of a particular layer (usually the classification layer, but also internal layers can be employed) is treated as a descriptor for the image and used for training a set of Support Vector Machines (SVM).","Fri, 20 Jul 2018 19:25:22 UTC (166 KB)"
"467","Deep Learning","Nicholas G. Polson, Vadim O. Sokolov","Machine Learning (stat.ML); Machine Learning (cs.LG)","Deep learning (DL) is a high dimensional data reduction technique for constructing high-dimensional predictors in input-output models. DL is a form of machine learning that uses hierarchical layers of latent features. In this article, we review the state-of-the-art of deep learning from a modeling and algorithmic perspective. We provide a list of successful areas of applications in Artificial Intelligence (AI), Image Processing, Robotics and Automation. Deep learning is predictive in its nature rather then inferential and can be viewed as a black-box methodology for high-dimensional function estimation.","Fri, 20 Jul 2018 18:20:34 UTC (667 KB)[v2] Fri, 3 Aug 2018 11:27:28 UTC (667 KB)"
"468","PhaseStain: Digital staining of label-free quantitative phase microscopy images using deep learning","Yair Rivenson, Tairan Liu, Zhensong Wei, Yibo Zhang, Aydogan Ozcan","Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)","Using a deep neural network, we demonstrate a digital staining technique, which we term PhaseStain, to transform quantitative phase images (QPI) of labelfree tissue sections into images that are equivalent to brightfield microscopy images of the same samples that are histochemically stained. Through pairs of image data (QPI and the corresponding brightfield images, acquired after staining) we train a generative adversarial network (GAN) and demonstrate the effectiveness of this virtual staining approach using sections of human skin, kidney and liver tissue, matching the brightfield microscopy images of the same samples stained with Hematoxylin and Eosin, Jones' stain, and Masson's trichrome stain, respectively. This digital staining framework might further strengthen various uses of labelfree QPI techniques in pathology applications and biomedical research in general, by eliminating the need for chemical staining, reducing sample preparation related costs and saving time. Our results provide a powerful example of some of the unique opportunities created by data driven image transformations enabled by deep learning.","Fri, 20 Jul 2018 03:17:13 UTC (4,956 KB)"
"469","Data-Efficient Weakly Supervised Learning for Low-Resource Audio Event Detection Using Deep Learning","Veronica Morfi, Dan Stowell","Sound (cs.SD); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS); Machine Learning (stat.ML)","We propose a method to perform audio event detection under the common constraint that only limited training data are available. In training a deep learning system to perform audio event detection, two practical problems arise. Firstly, most datasets are ""weakly labelled"" having only a list of events present in each recording without any temporal information for training. Secondly, deep neural networks need a very large amount of labelled training data to achieve good quality performance, yet in practice it is difficult to collect enough samples for most classes of interest. In this paper, we propose a data-efficient training of a stacked convolutional and recurrent neural network. This neural network is trained in a multi instance learning setting for which we introduce a new loss function that leads to improved training compared to the usual approaches for weakly supervised learning. We successfully test our approach on two low-resource datasets that lack temporal labels.","Tue, 17 Jul 2018 14:03:55 UTC (359 KB)[v2] Fri, 26 Oct 2018 15:19:02 UTC (119 KB)"
"470","Learning Hybrid Sparsity Prior for Image Restoration: Where Deep Learning Meets Sparse Coding","Weisheng Dong, Zhangxi Yan, Xin Li, Guangming Shi","Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)","State-of-the-art approaches toward image restoration can be classified into model-based and learning-based. The former - best represented by sparse coding techniques - strive to exploit intrinsic prior knowledge about the unknown high-resolution images; while the latter - popularized by recently developed deep learning techniques - leverage external image prior from some training dataset. It is natural to explore their middle ground and pursue a hybrid image prior capable of achieving the best in both worlds. In this paper, we propose a systematic approach of achieving this goal called Structured Analysis Sparse Coding (SASC). Specifically, a structured sparse prior is learned from extrinsic training data via a deep convolutional neural network (in a similar way to previous learning-based approaches); meantime another structured sparse prior is internally estimated from the input observation image (similar to previous model-based approaches). Two structured sparse priors will then be combined to produce a hybrid prior incorporating the knowledge from both domains. To manage the computational complexity, we have developed a novel framework of implementing hybrid structured sparse coding processes by deep convolutional neural networks. Experimental results show that the proposed hybrid image restoration method performs comparably with and often better than the current state-of-the-art techniques.","Wed, 18 Jul 2018 13:33:02 UTC (5,494 KB)"
"471","Towards Automated Deep Learning: Efficient Joint Neural Architecture and Hyperparameter Search","Arber Zela, Aaron Klein, Stefan Falkner, Frank Hutter","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","While existing work on neural architecture search (NAS) tunes hyperparameters in a separate post-processing step, we demonstrate that architectural choices and other hyperparameter settings interact in a way that can render this separation suboptimal. Likewise, we demonstrate that the common practice of using very few epochs during the main NAS and much larger numbers of epochs during a post-processing step is inefficient due to little correlation in the relative rankings for these two training regimes. To combat both of these problems, we propose to use a recent combination of Bayesian optimization and Hyperband for efficient joint neural architecture and hyperparameter search.","Wed, 18 Jul 2018 13:11:08 UTC (418 KB)"
"472","Fast approximate simulation of seismic waves with deep learning","Benjamin Moseley, Andrew Markham, Tarje Nissen-Meyer","Geophysics (physics.geo-ph); Computational Physics (physics.comp-ph)","We simulate the response of acoustic seismic waves in horizontally layered media using a deep neural network. In contrast to traditional finite-difference modelling techniques our network is able to directly approximate the recorded seismic response at multiple receiver locations in a single inference step, without needing to iteratively model the seismic wavefield through time. This results in an order of magnitude reduction in simulation time from the order of 1 s for FD modelling to the order of 0.1 s using our approach. Such a speed improvement could lead to real-time seismic simulation applications and benefit seismic inversion algorithms based on forward modelling, such as full waveform inversion. Our proof of concept deep neural network is trained using 50,000 synthetic examples of seismic waves propagating through different 2D horizontally layered velocity models. We discuss how our approach could be extended to arbitrary velocity models. Our deep neural network design is inspired by the WaveNet architecture used for speech synthesis. We also investigate using deep neural networks for simulating the full seismic wavefield and for carrying out seismic inversion directly.","Wed, 18 Jul 2018 11:46:42 UTC (1,100 KB)"
"473","SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities","Zhen Li, Deqing Zou, Shouhuai Xu, Hai Jin, Yawei Zhu, Zhaoxuan Chen","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (stat.ML)","The detection of software vulnerabilities (or vulnerabilities for short) is an important problem that has yet to be tackled, as manifested by many vulnerabilities reported on a daily basis. This calls for machine learning methods to automate vulnerability detection. Deep learning is attractive for this purpose because it does not require human experts to manually define features. Despite the tremendous success of deep learning in other domains, its applicability to vulnerability detection is not systematically understood. In order to fill this void, we propose the first systematic framework for using deep learning to detect vulnerabilities. The framework, dubbed Syntax-based, Semantics-based, and Vector Representations (SySeVR), focuses on obtaining program representations that can accommodate syntax and semantic information pertinent to vulnerabilities. Our experiments with 4 software products demonstrate the usefulness of the framework: we detect 15 vulnerabilities that are not reported in the National Vulnerability Database. Among these 15 vulnerabilities, 7 are unknown and have been reported to the vendors, and the other 8 have been ""silently"" patched by the vendors when releasing newer versions of the products.","Wed, 18 Jul 2018 03:26:39 UTC (1,625 KB)[v2] Fri, 21 Sep 2018 01:41:57 UTC (1,297 KB)"
"474","Integrating Algorithmic Planning and Deep Learning for Partially Observable Navigation","Peter Karkus, David Hsu, Wee Sun Lee","Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","We propose to take a novel approach to robot system design where each building block of a larger system is represented as a differentiable program, i.e. a deep neural network. This representation allows for integrating algorithmic planning and deep learning in a principled manner, and thus combine the benefits of model-free and model-based methods. We apply the proposed approach to a challenging partially observable robot navigation task. The robot must navigate to a goal in a previously unseen 3-D environment without knowing its initial location, and instead relying on a 2-D floor map and visual observations from an onboard camera. We introduce the Navigation Networks (NavNets) that encode state estimation, planning and acting in a single, end-to-end trainable recurrent neural network. In preliminary simulation experiments we successfully trained navigation networks to solve the challenging partially observable navigation task.","Tue, 17 Jul 2018 22:51:14 UTC (1,856 KB)"
"475","Efficient Deep Learning on Multi-Source Private Data","Nick Hynes, Raymond Cheng, Dawn Song","Machine Learning (cs.LG); Machine Learning (stat.ML)","Machine learning models benefit from large and diverse datasets. Using such datasets, however, often requires trusting a centralized data aggregator. For sensitive applications like healthcare and finance this is undesirable as it could compromise patient privacy or divulge trade secrets. Recent advances in secure and privacy-preserving computation, including trusted hardware enclaves and differential privacy, offer a way for mutually distrusting parties to efficiently train a machine learning model without revealing the training data. In this work, we introduce Myelin, a deep learning framework which combines these privacy-preservation primitives, and use it to establish a baseline level of performance for fully private machine learning.","Tue, 17 Jul 2018 22:18:19 UTC (308 KB)"
"476","Parallel Restarted SGD with Faster Convergence and Less Communication: Demystifying Why Model Averaging Works for Deep Learning","Hao Yu, Sen Yang, Shenghuo Zhu","Optimization and Control (math.OC); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","In distributed training of deep neural networks, parallel mini-batch SGD is widely used to speed up the training process by using multiple workers. It uses multiple workers to sample local stochastic gradient in parallel, aggregates all gradients in a single server to obtain the average, and update each worker's local model using a SGD update with the averaged gradient. Ideally, parallel mini-batch SGD can achieve a linear speed-up of the training time (with respect to the number of workers) compared with SGD over a single worker. However, such linear scalability in practice is significantly limited by the growing demand for gradient communication as more workers are involved. Model averaging, which periodically averages individual models trained over parallel workers, is another common practice used for distributed training of deep neural networks since (Zinkevich et al. 2010) (McDonald, Hall, and Mann 2010). Compared with parallel mini-batch SGD, the communication overhead of model averaging is significantly reduced. Impressively, tremendous experimental works have verified that model averaging can still achieve a good speed-up of the training time as long as the averaging interval is carefully controlled. However, it remains a mystery in theory why such a simple heuristic works so well. This paper provides a thorough and rigorous theoretical study on why model averaging can work as well as parallel mini-batch SGD with significantly less communication overhead.","Tue, 17 Jul 2018 19:14:17 UTC (505 KB)[v2] Mon, 12 Nov 2018 09:09:49 UTC (1,071 KB)[v3] Fri, 16 Nov 2018 07:57:46 UTC (1,643 KB)"
"477","Deep Learning-Based BSDE Solver for Libor Market Model with Application to Bermudan Swaption Pricing and Hedging","Haojie Wang, Han Chen, Agus Sudjianto, Richard Liu, Qi Shen","Computational Finance (q-fin.CP); Numerical Analysis (math.NA)","The Libor market model is a mainstay term structure model of interest rates for derivatives pricing, especially for Bermudan swaptions, and other exotic Libor callable derivatives. For numerical implementation the pricing of derivatives with Libor market models is mainly carried out with Monte Carlo simulation. The PDE grid approach is not particularly feasible due to Curse of Dimensionality. The standard Monte Carlo method for American/Bermudan swaption pricing more or less uses regression to estimate expected value as a linear combination of basis functions (Longstaff and Schwartz). However, Monte Carlo method only provides the lower bound for American option price. Another complexity is the computation of the sensitivities of the option, the so-called Greeks, which are fundamental for a trader's hedging activity. Recently, an alternative numerical method based on deep learning and backward stochastic differential equations appeared in quite a few researches. For European style options the feedforward deep neural networks (DNN) show not only feasibility but also efficiency to obtain both prices and numerical Greeks. In this paper, a new backward DNN solver is proposed for Bermudan swaptions. Our approach is representing financial pricing problems in the form of high dimensional stochastic optimal control problems, FBSDEs, or equivalent PDEs. We demonstrate that using backward DNN the high-dimension Bermudan swaption pricing and hedging can be solved effectively and efficiently. A comparison between Monte Carlo simulation and the new method for pricing vanilla interest rate options manifests the superior performance of the new method. We then use this method to calculate prices and Greeks of Bermudan swaptions as a prelude for other Libor callable derivatives.","Tue, 17 Jul 2018 18:53:20 UTC (374 KB)[v2] Sat, 22 Sep 2018 17:05:56 UTC (605 KB)"
"478","A Deep Learning Driven Active Framework for Segmentation of Large 3D Shape Collections","David George, Xianguha Xie, Yu-Kun Lai, Gary KL Tam","Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)","High-level shape understanding and technique evaluation on large repositories of 3D shapes often benefit from additional information known about the shapes. One example of such information is the semantic segmentation of a shape into functional or meaningful parts. Generating accurate segmentations with meaningful segment boundaries is, however, a costly process, typically requiring large amounts of user time to achieve high quality results. In this paper we present an active learning framework for large dataset segmentation, which iteratively provides the user with new predictions by training new models based on already segmented shapes. Our proposed pipeline consists of three novel components. First, we a propose a fast and relatively accurate feature-based deep learning model to provide dataset-wide segmentation predictions. Second, we propose an information theory measure to estimate the prediction quality and for ordering subsequent fast and meaningful shape selection. Our experiments show that such suggestive ordering helps reduce users time and effort, produce high quality predictions, and construct a model that generalizes well. Finally, we provide effective segmentation refinement features to help the user quickly correct any incorrect predictions. We show that our framework is more accurate and in general more efficient than state-of-the-art, for massive dataset segmentation with while also providing consistent segment boundaries.","Tue, 17 Jul 2018 16:58:06 UTC (7,941 KB)"
"479","Icing on the Cake: An Easy and Quick Post-Learnig Method You Can Try After Deep Learning","Tomohiko Konno, Michiaki Iwazume","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","We found an easy and quick post-learning method named ""Icing on the Cake"" to enhance a classification performance in deep learning. The method is that we train only the final classifier again after an ordinary training is done.","Tue, 17 Jul 2018 16:35:51 UTC (1,444 KB)"
"480","Pseudo-Feature Generation for Imbalanced Data Analysis in Deep Learning","Tomohiko Konno, Michiaki Iwazume","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","We generate pseudo-features by multivariate probability distributions obtained from feature maps in a low layer of trained deep neural networks. Then, we virtually augment the data of minor classes by the pseudo-features in order to overcome imbalanced data problems. Because all the wild data are imbalanced, the proposed method has the possibility to improve the ability of DNN in a broad range of problems","Tue, 17 Jul 2018 16:34:47 UTC (595 KB)[v2] Wed, 18 Jul 2018 02:37:09 UTC (1,129 KB)[v3] Wed, 12 Sep 2018 01:22:27 UTC (1,120 KB)"
"481","A framework for remote sensing images processing using deep learning technique","Remi Cresson","Computer Vision and Pattern Recognition (cs.CV)","Deep learning techniques are becoming increasingly important to solve a number of image processing tasks. Among common algorithms, Convolutional Neural Networks and Recurrent Neural Networks based systems achieve state of the art results on satellite and aerial imagery in many applications. While these approaches are subject to scientific interest, there is currently no operational and generic implementation available at user-level for the remote sensing community. In this paper, we presents a framework enabling the use of deep learning techniques with remote sensing images and geospatial data. Our solution takes roots in two extensively used open-source libraries, the remote sensing image processing library Orfeo ToolBox, and the high performance numerical computation library TensorFlow. It can apply deep nets without restriction on images size and is computationally efficient, regardless hardware configuration.","Tue, 17 Jul 2018 16:32:08 UTC (18 KB)[v2] Wed, 5 Sep 2018 11:13:47 UTC (18 KB)"
"482","Weakly Supervised Deep Learning for Thoracic Disease Classification and Localization on Chest X-rays","Chaochao Yan, Jiawen Yao, Ruoyu Li, Zheng Xu, Junzhou Huang","Computer Vision and Pattern Recognition (cs.CV)","Chest X-rays is one of the most commonly available and affordable radiological examinations in clinical practice. While detecting thoracic diseases on chest X-rays is still a challenging task for machine intelligence, due to 1) the highly varied appearance of lesion areas on X-rays from patients of different thoracic disease and 2) the shortage of accurate pixel-level annotations by radiologists for model training. Existing machine learning methods are unable to deal with the challenge that thoracic diseases usually happen in localized disease-specific areas. In this article, we propose a weakly supervised deep learning framework equipped with squeeze-and-excitation blocks, multi-map transfer, and max-min pooling for classifying thoracic diseases as well as localizing suspicious lesion regions. The comprehensive experiments and discussions are performed on the ChestX-ray14 dataset. Both numerical and visual results have demonstrated the effectiveness of the proposed model and its better performance against the state-of-the-art pipelines.","Mon, 16 Jul 2018 19:19:38 UTC (3,118 KB)"
"483","A deep learning architecture to detect events in EEG signals during sleep","Stanislas Chambon, Valentin Thorey, Pierrick J. Arnal, Emmanuel Mignot, Alexandre Gramfort","Signal Processing (eess.SP); Machine Learning (cs.LG); Machine Learning (stat.ML)","Electroencephalography (EEG) during sleep is used by clinicians to evaluate various neurological disorders. In sleep medicine, it is relevant to detect macro-events (> 10s) such as sleep stages, and micro-events (<2s) such as spindles and K-complexes. Annotations of such events require a trained sleep expert, a time consuming and tedious process with a large inter-scorer variability. Automatic algorithms have been developed to detect various types of events but these are event-specific. We propose a deep learning method that jointly predicts locations, durations and types of events in EEG time series. It relies on a convolutional neural network that builds a feature representation from raw EEG signals. Numerical experiments demonstrate efficiency of this new approach on various event detection tasks compared to current state-of-the-art, event specific, algorithms.","Wed, 11 Jul 2018 14:29:55 UTC (155 KB)"
"484","Automatic acoustic detection of birds through deep learning: the first Bird Audio Detection challenge","Dan Stowell, Yannis Stylianou, Mike Wood, Hanna Pamua, Herve Glotin","Sound (cs.SD); Audio and Speech Processing (eess.AS)","Assessing the presence and abundance of birds is important for monitoring specific species as well as overall ecosystem health. Many birds are most readily detected by their sounds, and thus passive acoustic monitoring is highly appropriate. Yet acoustic monitoring is often held back by practical limitations such as the need for manual configuration, reliance on example sound libraries, low accuracy, low robustness, and limited ability to generalise to novel acoustic conditions. Here we report outcomes from a collaborative data challenge showing that with modern machine learning including deep learning, general-purpose acoustic bird detection can achieve very high retrieval rates in remote monitoring data --- with no manual recalibration, and no pre-training of the detector for the target species or the acoustic conditions in the target environment. Multiple methods were able to attain performance of around 88% AUC (area under the ROC curve), much higher performance than previous general-purpose methods. We present new acoustic monitoring datasets, summarise the machine learning techniques proposed by challenge teams, conduct detailed performance evaluation, and discuss how such approaches to detection can be integrated into remote monitoring projects.","Mon, 16 Jul 2018 12:06:13 UTC (578 KB)"
"485","Applications of deep learning to relativistic hydrodynamics","Hengfeng Huang, Bowen Xiao, Huixin Xiong, Zeming Wu, Yadong Mu, Huichao Song (Peking U)","Nuclear Theory (nucl-th); Disordered Systems and Neural Networks (cond-mat.dis-nn); High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph); Nuclear Experiment (nucl-ex)","In this proceeding, we will briefly review our recent progress on implementing deep learning to relativistic hydrodynamics. We will demonstrate that a successfully designed and trained deep neural network, called {\tt stacked U-net}, can capture the main features of the non-linear evolution of hydrodynamics, which could also rapidly predict the final profiles for various testing initial conditions.","Mon, 16 Jul 2018 08:39:55 UTC (2,562 KB)"
"486","Deep Learning for Semantic Segmentation on Minimal Hardware","Sander G. van Dijk, Marcus M. Scheunemann","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO); Machine Learning (stat.ML)","Deep learning has revolutionised many fields, but it is still challenging to transfer its success to small mobile robots with minimal hardware. Specifically, some work has been done to this effect in the RoboCup humanoid football domain, but results that are performant and efficient and still generally applicable outside of this domain are lacking. We propose an approach conceptually different from those taken previously. It is based on semantic segmentation and does achieve these desired properties. In detail, it is being able to process full VGA images in real-time on a low-power mobile processor. It can further handle multiple image dimensions without retraining, it does not require specific domain knowledge for achieving a high frame rate and it is applicable on a minimal mobile hardware.","Sun, 15 Jul 2018 19:15:41 UTC (2,305 KB)"
"487","DeepInf: Social Influence Prediction with Deep Learning","Jiezhong Qiu, Jian Tang, Hao Ma, Yuxiao Dong, Kuansan Wang, Jie Tang","Social and Information Networks (cs.SI); Machine Learning (cs.LG)","Social and information networking activities such as on Facebook, Twitter, WeChat, and Weibo have become an indispensable part of our everyday life, where we can easily access friends' behaviors and are in turn influenced by them. Consequently, an effective social influence prediction for each user is critical for a variety of applications such as online recommendation and advertising. Conventional social influence prediction approaches typically design various hand-crafted rules to extract user- and network-specific features. However, their effectiveness heavily relies on the knowledge of domain experts. As a result, it is usually difficult to generalize them into different domains. Inspired by the recent success of deep neural networks in a wide range of computing applications, we design an end-to-end framework, DeepInf, to learn users' latent feature representation for predicting social influence. In general, DeepInf takes a user's local network as the input to a graph neural network for learning her latent social representation. We design strategies to incorporate both network structures and user-specific features into convolutional neural and attention networks. Extensive experiments on Open Academic Graph, Twitter, Weibo, and Digg, representing different types of social and information networks, demonstrate that the proposed end-to-end model, DeepInf, significantly outperforms traditional feature engineering-based approaches, suggesting the effectiveness of representation learning for social applications.","Sun, 15 Jul 2018 15:11:09 UTC (996 KB)"
"488","Object Detection with Deep Learning: A Review","Zhong-Qiu Zhao, Peng Zheng, Shou-tao Xu, Xindong Wu","Computer Vision and Pattern Recognition (cs.CV)","Due to object detection's close relationship with video analysis and image understanding, it has attracted much research attention in recent years. Traditional object detection methods are built on handcrafted features and shallow trainable architectures. Their performance easily stagnates by constructing complex ensembles which combine multiple low-level image features with high-level context from object detectors and scene classifiers. With the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. These models behave differently in network architecture, training strategy and optimization function, etc. In this paper, we provide a review on deep learning based object detection frameworks. Our review begins with a brief introduction on the history of deep learning and its representative tool, namely Convolutional Neural Network (CNN). Then we focus on typical generic object detection architectures along with some modifications and useful tricks to improve detection performance further. As distinct specific detection tasks exhibit different characteristics, we also briefly survey several specific tasks, including salient object detection, face detection and pedestrian detection. Experimental analyses are also provided to compare various methods and draw some meaningful conclusions. Finally, several promising directions and tasks are provided to serve as guidelines for future work in both object detection and relevant neural network based learning systems.","Sun, 15 Jul 2018 08:16:03 UTC (3,939 KB)"
"489","Survey on Deep Learning Techniques for Person Re-Identification Task","Bahram Lavi, Mehdi Fatan Serj, Ihsan Ullah","Computer Vision and Pattern Recognition (cs.CV)","Intelligent video-surveillance is currently an active research field in computer vision and machine learning techniques. It provides useful tools for surveillance operators and forensic video investigators. Person re-identification (PReID) is one among these tools. It consists of recognizing whether an individual has already been observed over a camera in a network or not. This tool can also be employed in various possible applications such as off-line retrieval of all the video-sequences showing an individual of interest whose image is given a query, and online pedestrian tracking over multiple camera views. To this aim, many techniques have been proposed to increase the performance of PReID. Among the systems, many researchers utilized deep neural networks (DNNs) because of their better performance and fast execution at test time. Our objective is to provide for future researchers the work being done on PReID to date. Therefore, we summarized state-of-the-art DNN models being used for this task. A brief description of each model along with their evaluation on a set of benchmark datasets is given. Finally, a detailed comparison is provided among these models followed by some limitations that can work as guidelines for future research.","Fri, 13 Jul 2018 21:18:54 UTC (2,792 KB)[v2] Tue, 17 Jul 2018 14:27:22 UTC (2,948 KB)[v3] Thu, 19 Jul 2018 20:58:50 UTC (2,948 KB)"
"490","Deep Learning in the Wild","Thilo Stadelmann, Mohammadreza Amirian, Ismail Arabaci, Marek Arnold, Gilbert Francois Duivesteijn, Ismail Elezi, Melanie Geiger, Stefan Lorwald, Benjamin Bruno Meier, Katharina Rombach, Lukas Tuggener","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Deep learning with neural networks is applied by an increasing number of people outside of classic research environments, due to the vast success of the methodology on a wide range of machine perception tasks. While this interest is fueled by beautiful success stories, practical work in deep learning on novel tasks without existing baselines remains challenging. This paper explores the specific challenges arising in the realm of real world tasks, based on case studies from research \& development in conjunction with industry, and extracts lessons learned from them. It thus fills a gap between the publication of latest algorithmic and methodical developments, and the usually omitted nitty-gritty of how to make them work. Specifically, we give insight into deep learning projects on face matching, print media monitoring, industrial quality control, music scanning, strategy game playing, and automated machine learning, thereby providing best practices for deep learning in practice.","Fri, 13 Jul 2018 07:22:45 UTC (7,154 KB)"
"491","Automatic segmentation of skin lesions using deep learning","Joshua Peter Ebenezer, Jagath C. Rajapakse","Computer Vision and Pattern Recognition (cs.CV)","This paper summarizes the method used in our submission to Task 1 of the International Skin Imaging Collaboration's (ISIC) Skin Lesion Analysis Towards Melanoma Detection challenge held in 2018. We used a fully automated method to accurately segment lesion boundaries from dermoscopic images. A U-net deep learning network is trained on publicly available data from ISIC. We introduce the use of intensity, color, and texture enhancement operations as pre-processing steps and morphological operations and contour identification as post-processing steps.","Fri, 13 Jul 2018 02:34:24 UTC (22 KB)"
"492","When deep learning meets security","Majd Latah","Cryptography and Security (cs.CR); Machine Learning (cs.LG)","Deep learning is an emerging research field that has proven its effectiveness towards deploying more efficient intelligent systems. Security, on the other hand, is one of the most essential issues in modern communication systems. Recently many papers have shown that using deep learning models can achieve promising results when applied to the security domain. In this work, we provide an overview for the recent studies that apply deep learning techniques to the field of security.","Thu, 12 Jul 2018 17:44:42 UTC (729 KB)"
"493","Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures","Sergey Bartunov, Adam Santoro, Blake A. Richards, Luke Marris, Geoffrey E. Hinton, Timothy Lillicrap","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","The backpropagation of error algorithm (BP) is impossible to implement in a real brain. The recent success of deep networks in machine learning and AI, however, has inspired proposals for understanding how the brain might learn across multiple layers, and hence how it might approximate BP. As of yet, none of these proposals have been rigorously evaluated on tasks where BP-guided deep learning has proved critical, or in architectures more structured than simple fully-connected networks. Here we present results on scaling up biologically motivated models of deep learning on datasets which need deep networks with appropriate architectures to achieve good performance. We present results on the MNIST, CIFAR-10, and ImageNet datasets and explore variants of target-propagation (TP) and feedback alignment (FA) algorithms, and explore performance in both fully- and locally-connected architectures. We also introduce weight-transport-free variants of difference target propagation (DTP) modified to remove backpropagation from the penultimate layer. Many of these algorithms perform well for MNIST, but for CIFAR and ImageNet we find that TP and FA variants perform significantly worse than BP, especially for networks composed of locally connected units, opening questions about whether new architectures and algorithms are required to scale these approaches. Our results and implementation details help establish baselines for biologically motivated deep learning schemes going forward.","Thu, 12 Jul 2018 12:53:50 UTC (277 KB)[v2] Tue, 20 Nov 2018 14:26:44 UTC (316 KB)"
"494","Deep Learning for Imbalance Data Classification using Class Expert Generative Adversarial Network","Fanny, Tjeng Wawan Cenggoro","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Without any specific way for imbalance data classification, artificial intelligence algorithm cannot recognize data from minority classes easily. In general, modifying the existing algorithm by assuming that the training data is imbalanced, is the only way to handle imbalance data. However, for a normal data handling, this way mostly produces a deficient result. In this research, we propose a class expert generative adversarial network (CE-GAN) as the solution for imbalance data classification. CE-GAN is a modification in deep learning algorithm architecture that does not have an assumption that the training data is imbalance data. Moreover, CE-GAN is designed to identify more detail about the character of each class before classification step. CE-GAN has been proved in this research to give a good performance for imbalance data classification.","Thu, 12 Jul 2018 12:51:24 UTC (2,813 KB)[v2] Fri, 13 Jul 2018 03:11:44 UTC (1,609 KB)"
"495","VTA: An Open Hardware-Software Stack for Deep Learning","Thierry Moreau, Tianqi Chen, Ziheng Jiang, Luis Ceze, Carlos Guestrin, Arvind Krishnamurthy","Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (stat.ML)","Hardware acceleration is an enabler for ubiquitous and efficient deep learning. With hardware accelerators being introduced in datacenter and edge devices, it is time to acknowledge that hardware specialization is central to the deep learning system stack. This technical report presents the Versatile Tensor Accelerator (VTA), an open, generic, and customizable deep learning accelerator design. VTA is a programmable accelerator that exposes a RISC-like programming abstraction to describe operations at the tensor level. We designed VTA to expose the most salient and common characteristics of mainstream deep learning accelerators, such as tensor operations, DMA load/stores, and explicit compute/memory arbitration. VTA is more than a standalone accelerator design: it's an end-to-end solution that includes drivers, a JIT runtime, and an optimizing compiler stack based on TVM. The current release of VTA includes a behavioral hardware simulator, as well as the infrastructure to deploy VTA on low-cost FPGA development boards for fast prototyping. By extending the TVM stack with a customizable, and open source deep learning hardware accelerator design, we are exposing a transparent end-to-end deep learning stack from the high-level deep learning framework, down to the actual hardware design and implementation. This forms a truly end-to-end, from software-to-hardware open source stack for deep learning systems.","Wed, 11 Jul 2018 15:19:30 UTC (1,824 KB)"
"496","Recognising Cardiac Abnormalities in Wearable Device Photoplethysmography (PPG) with Deep Learning","Stewart Whiting, Samuel Moreland, Jason Costello, Glen Colopy, Christopher McCann","Signal Processing (eess.SP)","Cardiac abnormalities affecting heart rate and rhythm are commonly observed in both healthy and acutely unwell people. Although many of these are benign, they can sometimes indicate a serious health risk. ECG monitors are typically used to detect these events in electrical heart activity, however they are impractical for continuous long-term use. In contrast, current-generation wearables with optical photoplethysmography (PPG) have gained popularity with their low-cost, lack of wires and tiny size. Many cardiac abnormalities such as ectopic beats and AF can manifest as both obvious and subtle anomalies in a PPG waveform as they disrupt blood flow. We propose an automatic method for recognising these anomalies in PPG signal alone, without the need for ECG. We train an LSTM deep neural network on 400,000 clean PPG samples to learn typical PPG morphology and rhythm, and flag PPG signal diverging from this as cardiac abnormalities. We compare the cardiac abnormalities our approach recognises with the ectopic beats recorded by a bedside ECG monitor for 29 patients over 47.6 hours of gold standard observations. Our proposed cardiac abnormality recognition approach recognises 60%+ of ECG-detected PVCs in PPG signal, with a false positive rate of 23% - demonstrating the compelling power and value of this novel approach. Finally we examine how cardiac abnormalities manifest in PPG signal for in- and out-of-hospital patient populations using a wearable device during standard care.","Wed, 11 Jul 2018 11:31:50 UTC (290 KB)"
"497","DeepDiff: Deep-learning for predicting Differential gene expression from histone modifications","Arshdeep Sekhon, Ritambhara Singh, Yanjun Qi","Machine Learning (cs.LG); Computers and Society (cs.CY); Machine Learning (stat.ML)","Computational methods that predict differential gene expression from histone modification signals are highly desirable for understanding how histone modifications control the functional heterogeneity of cells through influencing differential gene regulation. Recent studies either failed to capture combinatorial effects on differential prediction or primarily only focused on cell type-specific analysis. In this paper, we develop a novel attention-based deep learning architecture, DeepDiff, that provides a unified and end-to-end solution to model and to interpret how dependencies among histone modifications control the differential patterns of gene regulation. DeepDiff uses a hierarchy of multiple Long short-term memory (LSTM) modules to encode the spatial structure of input signals and to model how various histone modifications cooperate automatically. We introduce and train two levels of attention jointly with the target prediction, enabling DeepDiff to attend differentially to relevant modifications and to locate important genome positions for each modification. Additionally, DeepDiff introduces a novel deep-learning based multi-task formulation to use the cell-type-specific gene expression predictions as auxiliary tasks, encouraging richer feature embeddings in our primary task of differential expression prediction. Using data from Roadmap Epigenomics Project (REMC) for ten different pairs of cell types, we show that DeepDiff significantly outperforms the state-of-the-art baselines for differential gene expression prediction. The learned attention weights are validated by observations from previous studies about how epigenetic mechanisms connect to differential gene expression. Codes and results are available at \url{deepchrome.org}","Tue, 10 Jul 2018 21:45:47 UTC (956 KB)"
"498","Deep learning for comprehensive forecasting of Alzheimer's Disease progression","Charles K. Fisher, Aaron M. Smith, Jonathan R. Walsh, the Coalition Against Major Diseases","Machine Learning (cs.LG); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)","Most approaches to machine learning from electronic health data can only predict a single endpoint. Here, we present an alternative that uses unsupervised deep learning to simulate detailed patient trajectories. We use data comprising 18-month trajectories of 44 clinical variables from 1908 patients with Mild Cognitive Impairment or Alzheimer's Disease to train a model for personalized forecasting of disease progression. We simulate synthetic patient data including the evolution of each sub-component of cognitive exams, laboratory tests, and their associations with baseline clinical characteristics, generating both predictions and their confidence intervals. Our unsupervised model predicts changes in total ADAS-Cog scores with the same accuracy as specifically trained supervised models and identifies sub-components associated with word recall as predictive of progression. The ability to simultaneously simulate dozens of patient characteristics is a crucial step towards personalized medicine for Alzheimer's Disease.","Tue, 10 Jul 2018 21:42:17 UTC (1,771 KB)[v2] Wed, 7 Nov 2018 18:57:03 UTC (1,783 KB)"
"499","Deep Learning for Image Sequence Classification of Astronomical Events","Rodrigo Carrasco-Davis, Guillermo Cabrera-Vives, Francisco Forster, Pablo A. Estevez, Pablo Huijse, Pavlos Protopapas, Ignacio Reyes, Jorge Martinez-Palomera, Cristobal Donoso","Instrumentation and Methods for Astrophysics (astro-ph.IM)","We propose a new sequential classification model for astronomical objects based on a recurrent convolutional neural network (RCNN) which uses sequences of images as inputs. This approach avoids the computation of light curves or difference images. This is the first time that sequences of images are used directly for the classification of variable objects in astronomy. The second contribution of this work is the image simulation process. We generate synthetic image sequences that take into account the instrumental and observing conditions, obtaining a realistic, set of movies for each astronomical object. The simulated dataset is used to train our RCNN classifier. This approach allows us to generate datasets to train and test our RCNN model for different astronomical surveys and telescopes. We aim at building a simulated dataset whose distribution is close enough to the real dataset, so that a fine tuning could match the distributions between real and simulated dataset. To test the RCNN classifier trained with the synthetic dataset, we used real-world data from the High cadence Transient Survey (HiTS) obtaining an average recall of 85%, improved to 94% after performing fine tuning with 10 real samples per class. We compare the results of our model with those of a light curve random forest classifier. The proposed RCNN with fine tuning has a similar performance on the HiTS dataset compared to the light curve classifier, trained on an augmented training set with 10 real samples per class. The RCNN approach presents several advantages in an alert stream classification scenario, such as a reduction of the data pre-processing, faster online evaluation and easier performance improvement using a few real data samples. These results encourage us to use this method for alert brokers systems that will process alert streams generated by new telescopes such as the Large Synoptic Survey Telescope.","Tue, 10 Jul 2018 21:27:13 UTC (501 KB)[v2] Tue, 6 Nov 2018 18:42:54 UTC (2,135 KB)[v3] Wed, 7 Nov 2018 16:59:13 UTC (2,135 KB)"
"500","Model-based free-breathing cardiac MRI reconstruction using deep learned \& STORM priors: MoDL-STORM","Sampurna Biswas, Hemant K. Aggarwal, Sunrita Poddar, Mathews Jacob","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","We introduce a model-based reconstruction framework with deep learned (DL) and smoothness regularization on manifolds (STORM) priors to recover free breathing and ungated (FBU) cardiac MRI from highly undersampled measurements. The DL priors enable us to exploit the local correlations, while the STORM prior enables us to make use of the extensive non-local similarities that are subject dependent. We introduce a novel model-based formulation that allows the seamless integration of deep learning methods with available prior information, which current deep learning algorithms are not capable of. The experimental results demonstrate the preliminary potential of this work in accelerating FBU cardiac MRI.","Tue, 10 Jul 2018 20:04:14 UTC (343 KB)"
"501","Deep Learning for Audio Transcription on Low-Resource Datasets","Veronica Morfi, Dan Stowell","Machine Learning (cs.LG); Machine Learning (stat.ML)","In training a deep learning system to perform audio transcription, two practical problems may arise. Firstly, most datasets are weakly labelled, having only a list of events present in each recording without any temporal information for training. Secondly, deep neural networks need a very large amount of labelled training data to achieve good quality performance, yet in practice it is difficult to collect enough samples for most classes of interest. In this paper, we propose factorising the final task of audio transcription into multiple intermediate tasks in order to improve the training performance when dealing with this kind of low-resource datasets. We evaluate three data-efficient approaches of training a stacked convolutional and recurrent neural network for the intermediate tasks. Our results show that different methods of training have different advantages and disadvantages.","Tue, 10 Jul 2018 15:12:23 UTC (319 KB)[v2] Wed, 11 Jul 2018 11:59:36 UTC (319 KB)"
"502","Deep Learning as a Parton Shower","James William Monk","High Energy Physics - Phenomenology (hep-ph)","We make the connection between certain deep learning architectures and the renormalisation group explicit in the context of QCD by using a deep learning network to construct a toy parton shower model. The model aims to describe proton-proton collisions at the Large Hadron Collider. A convolutional autoencoder learns a set of kernels that efficiently encode the behaviour of fully showered QCD collision events. The network is structured recursively so as to ensure self-similarity, and the number of trained network parameters is low. Randomness is introduced via a novel custom masking layer, which also preserves existing parton splittings by using layer-skipping connections. By applying a shower merging procedure, the network can be evaluated on unshowered events produced by a matrix element calculation. The trained network behaves as a parton shower that qualitatively reproduces jet-based observables.","Tue, 10 Jul 2018 14:49:10 UTC (4,139 KB)[v2] Thu, 2 Aug 2018 12:02:01 UTC (4,147 KB)[v3] Mon, 8 Oct 2018 14:29:30 UTC (4,739 KB)[v4] Wed, 31 Oct 2018 11:27:23 UTC (4,738 KB)"
"503","Window Opening Model using Deep Learning Methods","Romana Markovic, Eva Grintal, Daniel Wolki, Jerome Frisch, Christoph van Treeck","Machine Learning (cs.LG); Machine Learning (stat.ML)","Occupant behavior (OB) and in particular window openings need to be considered in building performance simulation (BPS), in order to realistically model the indoor climate and energy consumption for heating ventilation and air conditioning (HVAC). However, the proposed OB window opening models are often biased towards the over-represented class where windows remained closed. In addition, they require tuning for each occupant which can not be efficiently scaled to the increased number of occupants. This paper presents a window opening model for commercial buildings using deep learning methods. The model is trained using data from occupants from an office building in Germany. In total the model is evaluated using almost 20 mio. data points from 3 independent buildings, located in Aachen, Frankfurt and Philadelphia. Eventually, the results of 3100 core hours of model development are summarized, which makes this study the largest of its kind in window states modeling. Additionally, the practical potential of the proposed model was tested by incorporating it in the Modelica-based thermal building simulation. The resulting evaluation accuracy and F1 scores on the office buildings ranged between 86-89 % and 0.53-0.65 respectively. The performance dropped around 15 % points in case of sparse input data, while the F1 score remained high.","Tue, 10 Jul 2018 13:17:08 UTC (464 KB)[v2] Mon, 17 Sep 2018 11:12:00 UTC (433 KB)[v3] Thu, 20 Sep 2018 08:21:21 UTC (362 KB)"
"504","DLOPT: Deep Learning Optimization Library","Andres Camero, Jamal Toutouh, Enrique Alba","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","Deep learning hyper-parameter optimization is a tough task. Finding an appropriate network configuration is a key to success, however most of the times this labor is roughly done. In this work we introduce a novel library to tackle this problem, the Deep Learning Optimization Library: DLOPT. We briefly describe its architecture and present a set of use examples. This is an open source project developed under the GNU GPL v3 license and it is freely available at this https URL","Tue, 10 Jul 2018 08:34:25 UTC (61 KB)"
"505","SceneEDNet: A Deep Learning Approach for Scene Flow Estimation","Ravi Kumar Thakur, Snehasis Mukherjee","Computer Vision and Pattern Recognition (cs.CV); Computational Geometry (cs.CG); Machine Learning (cs.LG); Robotics (cs.RO)","Estimating scene flow in RGB-D videos is attracting much interest of the computer vision researchers, due to its potential applications in robotics. The state-of-the-art techniques for scene flow estimation, typically rely on the knowledge of scene structure of the frame and the correspondence between frames. However, with the increasing amount of RGB-D data captured from sophisticated sensors like Microsoft Kinect, and the recent advances in the area of sophisticated deep learning techniques, introduction of an efficient deep learning technique for scene flow estimation, is becoming important. This paper introduces a first effort to apply a deep learning method for direct estimation of scene flow by presenting a fully convolutional neural network with an encoder-decoder (ED) architecture. The proposed network SceneEDNet involves estimation of three dimensional motion vectors of all the scene points from sequence of stereo images. The training for direct estimation of scene flow is done using consecutive pairs of stereo images and corresponding scene flow ground truth. The proposed architecture is applied on a huge dataset and provides meaningful results.","Tue, 10 Jul 2018 03:26:55 UTC (1,523 KB)"
"506","Predicting property damage from tornadoes with deep learning","Jeremy Diaz, Maxwell Joseph","Machine Learning (stat.ML); Machine Learning (cs.LG); Applications (stat.AP)","Tornadoes are the most violent of all atmospheric storms. In a typical year, the United States experiences hundreds of tornadoes with associated damages on the order of one billion dollars. Community preparation and resilience would benefit from accurate predictions of these economic losses, particularly as populations in tornado-prone areas continue to increase in density and extent. Here, we use artificial neural networks to predict tornado-induced property damage using publicly available data. We find that the large number of tornadoes which cause zero property damage (30.6% of the data) poses a challenge for predictive models. We developed a model that predicts whether a tornado will cause property damage to a high degree of accuracy (out of sample accuracy = 0.829 and AUROC = 0.873). Conditional on a tornado causing damage, another model predicts the amount of damage. When combined, these two models yield an expected value for the amount of property damage caused by a tornado event. From the best-performing models (out of sample mean squared error = 0.089 and R2 = 0.473), we provide an interactive, gridded map of monthly expected values for the year 2018. One major weakness is that the model predictive power is optimized with log-transformed, mean-normalized property damages, however this leads to large natural-scale residuals for the most destructive tornadoes. The predictive capacity of this model along with an interactive interface may provide an opportunity for science-informed tornado disaster planning.","Tue, 10 Jul 2018 02:39:33 UTC (833 KB)"
"507","Developing Brain Atlas through Deep Learning","Asim Iqbal, Romesa Khan, Theofanis Karayannis","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","To uncover the organizational principles governing the human brain, neuroscientists are in need of developing high-throughput methods that can explore the structure and function of distinct brain regions using animal models. The first step towards this goal is to accurately register the regions of interest in a mouse brain, against a standard reference atlas, with minimum human supervision. The second step is to scale this approach to different animal ages, so as to also allow insights into normal and pathological brain development and aging. We introduce here a fully automated convolutional neural network-based method (SeBRe) for registration through Segmenting Brain Regions of interest in mice at different ages. We demonstrate the validity of our method on different mouse brain post-natal (P) developmental time points, across a range of neuronal markers. Our method outperforms the existing brain registration methods, and provides the minimum mean squared error (MSE) score on a mouse brain dataset. We propose that our deep learning-based registration method can (i) accelerate brain-wide exploration of region-specific changes in brain development and (ii) replace the existing complex brain registration methodology, by simply segmenting brain regions of interest for high-throughput brain-wide analysis.","Tue, 10 Jul 2018 01:28:44 UTC (4,243 KB)"
"508","Exploring Brain-wide Development of Inhibition through Deep Learning","Asim Iqbal, Asfandyar Sheikh, Theofanis Karayannis","Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC); Quantitative Methods (q-bio.QM)","We introduce here a fully automated convolutional neural network-based method for brain image processing to Detect Neurons in different brain Regions during Development (DeNeRD). Our method takes a developing mouse brain as input and i) registers the brain sections against a developing mouse reference atlas, ii) detects various types of neurons, and iii) quantifies the neural density in many unique brain regions at different postnatal (P) time points. Our method is invariant to the shape, size and expression of neurons and by using DeNeRD, we compare the brain-wide neural density of all GABAergic neurons in developing brains of ages P4, P14 and P56. We discover and report 6 different clusters of regions in the mouse brain in which GABAergic neurons develop in a differential manner from early age (P4) to adulthood (P56). These clusters reveal key steps of GABAergic cell development that seem to track with the functional development of diverse brain regions as the mouse transitions from a passive receiver of sensory information (<P14) to an active seeker (>P14).","Mon, 9 Jul 2018 15:39:09 UTC (5,354 KB)"
"509","Efficient Decentralized Deep Learning by Dynamic Model Averaging","Michael Kamp, Linara Adilova, Joachim Sicking, Fabian Huger, Peter Schlicht, Tim Wirtz, Stefan Wrobel","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (stat.ML)","We propose an efficient protocol for decentralized training of deep neural networks from distributed data sources. The proposed protocol allows to handle different phases of model training equally well and to quickly adapt to concept drifts. This leads to a reduction of communication by an order of magnitude compared to periodically communicating state-of-the-art approaches. Moreover, we derive a communication bound that scales well with the hardness of the serialized learning problem. The reduction in communication comes at almost no cost, as the predictive performance remains virtually unchanged. Indeed, the proposed protocol retains loss bounds of periodically averaging schemes. An extensive empirical evaluation validates major improvement of the trade-off between model performance and communication which could be beneficial for numerous decentralized learning applications, such as autonomous driving, or voice recognition and image classification on mobile phones.","Mon, 9 Jul 2018 15:01:51 UTC (7,443 KB)[v2] Tue, 13 Nov 2018 18:45:10 UTC (7,832 KB)"
"510","Approximate k-space models and Deep Learning for fast photoacoustic reconstruction","Andreas Hauptmann, Ben Cox, Felix Lucka, Nam Huynh, Marta Betcke, Paul Beard, Simon Arridge","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS); Optimization and Control (math.OC)","We present a framework for accelerated iterative reconstructions using a fast and approximate forward model that is based on k-space methods for photoacoustic tomography. The approximate model introduces aliasing artefacts in the gradient information for the iterative reconstruction, but these artefacts are highly structured and we can train a CNN that can use the approximate information to perform an iterative reconstruction. We show feasibility of the method for human in-vivo measurements in a limited-view geometry. The proposed method is able to produce superior results to total variation reconstructions with a speed-up of 32 times.","Mon, 9 Jul 2018 14:32:18 UTC (1,690 KB)"
"511","YouTube for Patient Education: A Deep Learning Approach for Understanding Medical Knowledge from User-Generated Videos","Xiao Liu, Bin Zhang, Anjana Susarla, Rema Padman","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","YouTube presents an unprecedented opportunity to explore how machine learning methods can improve healthcare information dissemination. We propose an interdisciplinary lens that synthesizes machine learning methods with healthcare informatics themes to address the critical issue of developing a scalable algorithmic solution to evaluate videos from a health literacy and patient education perspective. We develop a deep learning method to understand the level of medical knowledge encoded in YouTube videos. Preliminary results suggest that we can extract medical knowledge from YouTube videos and classify videos according to the embedded knowledge with satisfying performance. Deep learning methods show great promise in knowledge extraction, natural language understanding, and image classification, especially in an era of patient-centric care and precision medicine.","Fri, 6 Jul 2018 17:19:26 UTC (530 KB)"
"512","Data Augmentation for Detection of Architectural Distortion in Digital Mammography using Deep Learning Approach","Arthur C. Costa, Helder C. R. Oliveira, Juliana H. Catani, Nestor de Barros, Carlos F. E. Melo, Marcelo A. C. Vieira","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Early detection of breast cancer can increase treatment efficiency. Architectural Distortion (AD) is a very subtle contraction of the breast tissue and may represent the earliest sign of cancer. Since it is very likely to be unnoticed by radiologists, several approaches have been proposed over the years but none using deep learning techniques. To train a Convolutional Neural Network (CNN), which is a deep neural architecture, is necessary a huge amount of data. To overcome this problem, this paper proposes a data augmentation approach applied to clinical image dataset to properly train a CNN. Results using receiver operating characteristic analysis showed that with a very limited dataset we could train a CNN to detect AD in digital mammography with area under the curve (AUC = 0.74).","Fri, 6 Jul 2018 02:12:49 UTC (165 KB)"
"513","Deep Learning Based Sphere Decoding","Mostafa Mohammadkarimi, Mehrtash Mehrabi, Masoud Ardakani, Yindi Jing","Signal Processing (eess.SP); Machine Learning (cs.LG)","In this paper, a deep learning (DL)-based sphere decoding algorithm is proposed, where the radius of the decoding hypersphere is learnt by a deep neural network (DNN). The performance achieved by the proposed algorithm is very close to the optimal maximum likelihood decoding (MLD) over a wide range of signal-to-noise ratios (SNRs), while the computational complexity, compared to existing sphere decoding variants, is significantly reduced. This improvement is attributed to DNN's ability of intelligently learning the radius of the hypersphere used in decoding. The expected complexity of the proposed DL-based algorithm is analytically derived and compared with existing ones. It is shown that the number of lattice points inside the decoding hypersphere drastically reduces in the DL- based algorithm in both the average and worst-case senses. The effectiveness of the proposed algorithm is shown through simulation for high-dimensional multiple-input multiple-output (MIMO) systems, using high-order modulations.","Fri, 6 Jul 2018 03:18:35 UTC (202 KB)"
"514","Forecasting Disease Trajectories in Alzheimer's Disease Using Deep Learning","Bryan Lim, Mihaela van der Schaar","Machine Learning (stat.ML); Machine Learning (cs.LG)","Joint models for longitudinal and time-to-event data are commonly used in longitudinal studies to forecast disease trajectories over time. Despite the many advantages of joint modeling, the standard forms suffer from limitations that arise from a fixed model specification and computational difficulties when applied to large datasets. We adopt a deep learning approach to address these limitations, enhancing existing methods with the flexibility and scalability of deep neural networks while retaining the benefits of joint modeling. Using data from the Alzheimer's Disease Neuroimaging Institute, we show improvements in performance and scalability compared to traditional methods.","Fri, 6 Jul 2018 16:28:58 UTC (471 KB)"
"515","Affective EEG-Based Person Identification Using the Deep Learning Approach","Theerawit Wilaiprasitporn, Apiwat Ditthapron, Karis Matchaparn, Tanaboon Tongbuasirilai, Nannapas Banluesombatkul, Ekapol Chuangsuwanich","Signal Processing (eess.SP); Computer Vision and Pattern Recognition (cs.CV)","There are several reports available on affective electroencephalography-based personal identification (affective EEG-based PI), one of which uses a small dataset and another reaching less than 90% of the mean correct recognition rate \emph{CRR},. Thus, the aim of this paper is to improve and evaluate the performance of affective EEG-based PI using a deep learning approach. The state-of-the-art EEG dataset DEAP was used as the standard for affective recognition. Thirty-two healthy participants participated in the experiment. They were asked to watch affective elicited music videos and score subjective ratings for forty video clips during the EEG measurement. An EEG amplifier with thirty-two electrodes was used to record affective EEG measurements from the participants. To identify personal EEG, a cascade of deep learning architectures was proposed, using a combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). CNNs are used to handle the spatial information from the EEG while RNNs extract the temporal information. There has been a cascade of CNNs, with recurrent models known as Long Short-Term Memory (CNN-LSTM) and Gate Recurrent Unit (CNN-GRU) for comparison. Experimental results indicate that CNN-GRU and CNN-LSTM can deal with an EEG (4--40 Hz) rom different affective states and reach up to 99.90--100% mean \emph{CRR}. On the other hand, a traditional machine learning approach such as a support vector machine (SVM) using power spectral density (PSD) as a feature does not reach 50% mean \emph{CRR}. To reduce the number of EEG electrodes from thirty-two to five for more practical application, $F_{3}$, $F_{4}$, $F_{z}$, $F_{7}$ and $F_{8}$ were found to be the best five electrodes for application in similar scenarios to those in this study. CNN-GRU and CNN-LSTM reached up to 99.17% and 98.23% mean \emph{CRR}, respectively.","Thu, 5 Jul 2018 22:43:01 UTC (5,617 KB)[v2] Sun, 15 Jul 2018 09:43:12 UTC (5,063 KB)"
"516","Towards Radiologist-Level Accurate Deep Learning System for Pulmonary Screening","Mrinal Haloi, K. Raja Rajalakshmi, Pradeep Walia","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","In this work, we propose advanced pneumonia and Tuberculosis grading system for X-ray images. The proposed system is a very deep fully convolutional classification network with online augmentation that outputs confidence values for diseases prevalence. Its a fully automated system capable of disease feature understanding without any offline preprocessing step or manual feature extraction. We have achieved state- of-the- art performance on the public databases such as ChestXray-14, Mendeley, Shenzhen Hospital X-ray and Belarus X-ray set.","Mon, 25 Jun 2018 07:07:25 UTC (501 KB)"
"517","Deep Global-Connected Net With The Generalized Multi-Piecewise ReLU Activation in Deep Learning","Zhi Chen, Pin-han Ho","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Recent Progress has shown that exploitation of hidden layer neurons in convolution neural networks incorporating with a carefully designed activation function can yield better classification results in the field of computer vision. The paper firstly introduces a novel deep learning architecture aiming to mitigate the gradient-vanishing problem, in which the earlier hidden layer neurons could be directly connected with the last hidden layer and feed into the last layer for classification. We then design a generalized linear rectifier function as the activation function that can approximate arbitrary complex functions via training of the parameters. We will show that our design can achieve similar performance in a number of object recognition and video action benchmark tasks, under significantly less number of parameters and shallower network infrastructure, which is not only promising in training in terms of computation burden and memory usage, but is also applicable to low-computation, low-memory mobile scenarios.","Tue, 19 Jun 2018 22:53:48 UTC (270 KB)"
"518","A deep learning approach for understanding natural language commands for mobile service robots","Pedro Henrique Martins, Luis Custodio, Rodrigo Ventura","Computation and Language (cs.CL); Robotics (cs.RO)","Using natural language to give instructions to robots is challenging, since natural language understanding is still largely an open problem. In this paper we address this problem by restricting our attention to commands modeled as one action, plus arguments (also known as slots). For action detection (also called intent detection) and slot filling various architectures of Recurrent Neural Networks and Long Short Term Memory (LSTM) networks were evaluated, having LSTMs achieved a superior accuracy. As the action requested may not fall within the robots capabilities, a Support Vector Machine(SVM) is used to determine whether it is or not. For the input of the neural networks, several word embedding algorithms were compared. Finally, to implement the system in a robot, a ROS package is created using a SMACH state machine. The proposed system is then evaluated both using well-known datasets and benchmarks in the context of domestic service robots.","Mon, 9 Jul 2018 11:34:21 UTC (613 KB)"
"519","Deep Learning for Singing Processing: Achievements, Challenges and Impact on Singers and Listeners","Emilia Gomez, Merlijn Blaauw, Jordi Bonada, Pritish Chandna, Helena Cuesta","Sound (cs.SD); Information Retrieval (cs.IR); Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS); Machine Learning (stat.ML)","This paper summarizes some recent advances on a set of tasks related to the processing of singing using state-of-the-art deep learning techniques. We discuss their achievements in terms of accuracy and sound quality, and the current challenges, such as availability of data and computing resources. We also discuss the impact that these advances do and will have on listeners and singers when they are integrated in commercial applications.","Mon, 9 Jul 2018 11:19:42 UTC (36 KB)"
"520","Improving Deep Learning through Automatic Programming","The-Hien Dang-Ha","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning and deep architectures are emerging as the best machine learning methods so far in many practical applications such as reducing the dimensionality of data, image classification, speech recognition or object segmentation. In fact, many leading technology companies such as Google, Microsoft or IBM are researching and using deep architectures in their systems to replace other traditional models. Therefore, improving the performance of these models could make a strong impact in the area of machine learning. However, deep learning is a very fast-growing research domain with many core methodologies and paradigms just discovered over the last few years. This thesis will first serve as a short summary of deep learning, which tries to include all of the most important ideas in this research area. Based on this knowledge, we suggested, and conducted some experiments to investigate the possibility of improving the deep learning based on automatic programming (ADATE). Although our experiments did produce good results, there are still many more possibilities that we could not try due to limited time as well as some limitations of the current ADATE version. I hope that this thesis can promote future work on this topic, especially when the next version of ADATE comes out. This thesis also includes a short analysis of the power of ADATE system, which could be useful for other researchers who want to know what it is capable of.","Sun, 8 Jul 2018 13:38:21 UTC (4,115 KB)"
"521","Fringe pattern analysis using deep learning","Shijie Feng, Qian Chen, Guohua Gu, Tianyang Tao, Liang Zhang, Yan Hu, Wei Yin, Chao Zuo","Image and Video Processing (eess.IV)","In many optical metrology techniques, fringe pattern analysis is the central algorithm for recovering the underlying phase distribution from the recorded fringe patterns. Despite extensive research efforts for decades, how to extract the desired phase information, with the highest possible accuracy, from the minimum number of fringe patterns remains one of the most challenging open problems. Inspired by recent successes of deep learning techniques for computer vision and other applications, here, we demonstrate for the first time, to our knowledge, that the deep neural networks can be trained to perform fringe analysis, which substantially enhances the accuracy of phase demodulation from a single fringe pattern. The effectiveness of the proposed method is experimentally verified using carrier fringe patterns under the scenario of fringe projection profilometry. Experimental results demonstrate its superior performance in terms of high accuracy and edge-preserving over two representative single-frame techniques: Fourier transform profilometry and Windowed Fourier profilometry.","Sun, 8 Jul 2018 05:41:19 UTC (1,377 KB)"
"522","A Deep-Learning-Based Geological Parameterization for History Matching Complex Models","Yimin Liu, Wenyue Sun, Louis J. Durlofsky","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Geophysics (physics.geo-ph)","A new low-dimensional parameterization based on principal component analysis (PCA) and convolutional neural networks (CNN) is developed to represent complex geological models. The CNN-PCA method is inspired by recent developments in computer vision using deep learning. CNN-PCA can be viewed as a generalization of an existing optimization-based PCA (O-PCA) method. Both CNN-PCA and O-PCA entail post-processing a PCA model to better honor complex geological features. In CNN-PCA, rather than use a histogram-based regularization as in O-PCA, a new regularization involving a set of metrics for multipoint statistics is introduced. The metrics are based on summary statistics of the nonlinear filter responses of geological models to a pre-trained deep CNN. In addition, in the CNN-PCA formulation presented here, a convolutional neural network is trained as an explicit transform function that can post-process PCA models quickly. CNN-PCA is shown to provide both unconditional and conditional realizations that honor the geological features present in reference SGeMS geostatistical realizations for a binary channelized system. Flow statistics obtained through simulation of random CNN-PCA models closely match results for random SGeMS models for a demanding case in which O-PCA models lead to significant discrepancies. Results for history matching are also presented. In this assessment CNN-PCA is applied with derivative-free optimization, and a subspace randomized maximum likelihood method is used to provide multiple posterior models. Data assimilation and significant uncertainty reduction are achieved for existing wells, and physically reasonable predictions are also obtained for new wells. Finally, the CNN-PCA method is extended to a more complex non-stationary bimodal deltaic fan system, and is shown to provide high-quality realizations for this challenging example.","Sat, 7 Jul 2018 20:34:04 UTC (2,529 KB)"
"523","DeepSource: Point Source Detection using Deep Learning","A. Vafaei Sadr, Etienne. E. Vos, Bruce A. Bassett, Zafiirah Hosenie, N. Oozeer, Michelle Lochner","Instrumentation and Methods for Astrophysics (astro-ph.IM); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); High Energy Physics - Phenomenology (hep-ph); Machine Learning (stat.ML)","Point source detection at low signal-to-noise is challenging for astronomical surveys, particularly in radio interferometry images where the noise is correlated. Machine learning is a promising solution, allowing the development of algorithms tailored to specific telescope arrays and science cases. We present DeepSource - a deep learning solution - that uses convolutional neural networks to achieve these goals. DeepSource enhances the Signal-to-Noise Ratio (SNR) of the original map and then uses dynamic blob detection to detect sources. Trained and tested on two sets of 500 simulated 1 deg x 1 deg MeerKAT images with a total of 300,000 sources, DeepSource is essentially perfect in both purity and completeness down to SNR = 4 and outperforms PyBDSF in all metrics. For uniformly-weighted images it achieves a Purity x Completeness (PC) score at SNR = 3 of 0.73, compared to 0.31 for the best PyBDSF model. For natural-weighting we find a smaller improvement of ~40% in the PC score at SNR = 3. If instead we ask where either of the purity or completeness first drop to 90%, we find that DeepSource reaches this value at SNR = 3.6 compared to the 4.3 of PyBDSF (natural-weighting). A key advantage of DeepSource is that it can learn to optimally trade off purity and completeness for any science case under consideration. Our results show that deep learning is a promising approach to point source detection in astronomical images.","Sat, 7 Jul 2018 18:00:07 UTC (11,543 KB)"
"524","Deep Learning for Launching and Mitigating Wireless Jamming Attacks","Tugba Erpek, Yalin E. Sagduyu, Yi Shi","Networking and Internet Architecture (cs.NI); Machine Learning (cs.LG); Machine Learning (stat.ML)","An adversarial machine learning approach is introduced to launch jamming attacks on wireless communications and a defense strategy is provided. A cognitive transmitter uses a pre-trained classifier to predict current channel status based on recent sensing results and decides whether to transmit or not, whereas a jammer collects channel status and ACKs to build a deep learning classifier that reliably predicts whether there will be a successful transmission next and effectively jams these transmissions. This jamming approach is shown to reduce the performance of the transmitter much more severely compared with randomized or sensing-based jamming. Next, a generative adversarial network (GAN) is developed for the jammer to reduce the time to collect the training dataset by augmenting it with synthetic samples. Then, a defense scheme is introduced for the transmitter that prevents the jammer from building a reliable classifier by deliberately taking a small number of wrong actions (in form of a causative attack launched against the jammer) when it accesses the spectrum. The transmitter systematically selects when to take wrong actions and adapts the level of defense to machine learning-based or conventional jamming behavior in order to mislead the jammer into making prediction errors and consequently increase its throughput.","Tue, 3 Jul 2018 23:17:50 UTC (1,582 KB)"
"525","Blockchain as a Service: An Autonomous, Privacy Preserving, Decentralized Architecture for Deep Learning","Gihan J. Mendis, Moein Sabounchi, Jin Wei, Rigoberto Roche'","Cryptography and Security (cs.CR); Computers and Society (cs.CY); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning algorithms have recently gained attention due to their inherent capabilities and the application opportunities that they provide. Two of the main reasons for the success of deep learning methods are the availability of processing power and big data. Both of these two are expensive and rare commodities that present limitations to the usage and implementation of deep learning. Decentralization of the processing and data is one of the most prevalent solutions for these issues. This paper proposes a cooperative decentralized deep learning architecture. The contributors can train deep learning models with private data and share them to the cooperative data-driven applications initiated elsewhere. Shared models are fused together to obtain a better model. In this work, the contributors can both design their own models or train the models provided by the initiator. In order to utilize an efficient decentralized learning algorithm, blockchain technology is incorporated as a method of creating an incentive-compatible market. In the proposed method, Ethereum blockchain's scripting capabilities are employed to devise a decentralized deep learning mechanism, which provides much higher, collective processing power and grants access to large amounts of data, which would be otherwise inaccessible. The technical description of the mechanism is described and the simulation results are presented.","Thu, 5 Jul 2018 20:03:38 UTC (374 KB)"
"526","A Review of Different Word Embeddings for Sentiment Classification using Deep Learning","Debadri Dutta","Information Retrieval (cs.IR); Computation and Language (cs.CL); Machine Learning (cs.LG); Machine Learning (stat.ML)","The web is loaded with textual content, and Natural Language Processing is a standout amongst the most vital fields in Machine Learning. But when data is huge simple Machine Learning algorithms are not able to handle it and that is when Deep Learning comes into play which based on Neural Networks. However since neural networks cannot process raw text, we have to change over them through some diverse strategies of word embedding. This paper demonstrates those distinctive word embedding strategies implemented on an Amazon Review Dataset, which has two sentiments to be classified: Happy and Unhappy based on numerous customer reviews. Moreover we demonstrate the distinction in accuracy with a discourse about which word embedding to apply when.","Thu, 5 Jul 2018 07:17:21 UTC (5 KB)"
"527","Automatic deep learning-based normalization of breast dynamic contrast-enhanced magnetic resonance images","Jun Zhang, Ashirbani Saha, Brian J. Soher, Maciej A. Mazurowski","Computer Vision and Pattern Recognition (cs.CV)","Objective: To develop an automatic image normalization algorithm for intensity correction of images from breast dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) acquired by different MRI scanners with various imaging parameters, using only image information. Methods: DCE-MR images of 460 subjects with breast cancer acquired by different scanners were used in this study. Each subject had one T1-weighted pre-contrast image and three T1-weighted post-contrast images available. Our normalization algorithm operated under the assumption that the same type of tissue in different patients should be represented by the same voxel value. We used four tissue/material types as the anchors for the normalization: 1) air, 2) fat tissue, 3) dense tissue, and 4) heart. The algorithm proceeded in the following two steps: First, a state-of-the-art deep learning-based algorithm was applied to perform tissue segmentation accurately and efficiently. Then, based on the segmentation results, a subject-specific piecewise linear mapping function was applied between the anchor points to normalize the same type of tissue in different patients into the same intensity ranges. We evaluated the algorithm with 300 subjects used for training and the rest used for testing. Results: The application of our algorithm to images with different scanning parameters resulted in highly improved consistency in pixel values and extracted radiomics features. Conclusion: The proposed image normalization strategy based on tissue segmentation can perform intensity correction fully automatically, without the knowledge of the scanner parameters. Significance: We have thoroughly tested our algorithm and showed that it successfully normalizes the intensity of DCE-MR images. We made our software publicly available for others to apply in their analyses.","Thu, 5 Jul 2018 18:56:14 UTC (1,679 KB)"
"528","Calamari - A High-Performance Tensorflow-based Deep Learning Package for Optical Character Recognition","Christoph Wick, Christian Reul, Frank Puppe","Computer Vision and Pattern Recognition (cs.CV)","Optical Character Recognition (OCR) on contemporary and historical data is still in the focus of many researchers. Especially historical prints require book specific trained OCR models to achieve applicable results (Springmann and Ludeling, 2016, Reul et al., 2017a). To reduce the human effort for manually annotating ground truth (GT) various techniques such as voting and pretraining have shown to be very efficient (Reul et al., 2018a, Reul et al., 2018b). Calamari is a new open source OCR line recognition software that both uses state-of-the art Deep Neural Networks (DNNs) implemented in Tensorflow and giving native support for techniques such as pretraining and voting. The customizable network architectures constructed of Convolutional Neural Networks (CNNS) and Long-ShortTerm-Memory (LSTM) layers are trained by the so-called Connectionist Temporal Classification (CTC) algorithm of Graves et al. (2006). Optional usage of a GPU drastically reduces the computation times for both training and prediction. We use two different datasets to compare the performance of Calamari to OCRopy, OCRopus3, and Tesseract 4. Calamari reaches a Character Error Rate (CER) of 0.11% on the UW3 dataset written in modern English and 0.18% on the DTA19 dataset written in German Fraktur, which considerably outperforms the results of the existing softwares.","Thu, 5 Jul 2018 13:46:37 UTC (715 KB)[v2] Tue, 24 Jul 2018 08:18:26 UTC (715 KB)[v3] Mon, 6 Aug 2018 07:52:56 UTC (716 KB)"
"529","Deconvolution-Based Backproject-Filter (BPF) Computed Tomography Image Reconstruction Method Using Deep Learning Technique","Yongshuai Ge, Qiyang Zhang, Zhanli Hu, Jianwei Chen, Wei Shi, Hairong Zheng, Dong Liang","Medical Physics (physics.med-ph)","For conventional computed tomography (CT) image reconstruction tasks, the most popular method is the so-called filtered-back-projection (FBP) algorithm. In it, the acquired Radon projections are usually filtered first by a ramp kernel before back-projected to generate CT images. In this work, as a contrary, we realized the idea of image-domain backproject-filter (BPF) CT image reconstruction using the deep learning techniques for the first time. With a properly designed convolutional neural network (CNN), preliminary results demonstrate that it is feasible to reconstruct CT images with maintained high spatial resolution and accurate pixel values from the highly blurred back-projection image, i.e., laminogram. In addition, experimental results also show that this deconvolution-based CT image reconstruction network has the potential to reduce CT image noise (up to 20%), indicating that patient radiation dose may be reduced. Due to these advantages, this proposed CNN-based image-domain BPF type CT image reconstruction scheme provides promising prospects in generating high spatial resolution, low-noise CT images for future clinical applications.","Thu, 5 Jul 2018 03:15:19 UTC (2,339 KB)"
"530","Synthetic contrast enhancement in cardiac CT with Deep Learning","Gianmarco Santini, Lorena M. Zumbo, Nicola Martini, Gabriele Valvano, Andrea Leo, Andrea Ripoli, Francesco Avogliero, Dante Chiappino, Daniele Della Latta","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","In Europe the 20% of the CT scans cover the thoracic region. The acquired images contain information about the cardiovascular system that often remains latent due to the lack of contrast in the cardiac area. On the other hand, the contrast enhanced computed tomography (CECT) represents an imaging technique that allows to easily assess the cardiac chambers volumes and the contrast dynamics. With this work we aim to face the problem of extraction and presentation of these latent information, using a deep learning approach with convolutional neural networks. Starting from the extraction of relevant features from the image without contrast medium, we try to re-map them on features typical of CECT, to synthesize an image characterized by an attenuation in the cardiac chambers as if a virtually iodine contrast medium was injected. The purposes are to guarantee an estimation of the left cardiac chambers volume and to perform an evaluation of the contrast dynamics. Our approach is based on a deconvolutional network trained on a set of 120 patients who underwent both CT acquisitions in the same contrastographic arterial phase and the same cardiac phase. To ensure a reliable predicted CECT image, in terms of values and morphology, a custom loss function is defined by combining an error function to find a pixel-wise correspondence, which takes into account the similarity in term of Hounsfield units between the input and output images and by a cross-entropy computed on the binarized versions of the synthesized and of the real CECT image. The proposed method is finally tested on 20 subjects.","Mon, 2 Jul 2018 15:26:14 UTC (1,201 KB)"
"531","Deep Learning Based Damage Detection on Post-Hurricane Satellite Imagery","Quoc Dung Cao, Youngjun Choe","Computer Vision and Pattern Recognition (cs.CV)","After a hurricane, damage assessment is critical to emergency managers and first responders. To improve the efficiency and accuracy of damage assessment, instead of using windshield survey, we propose to automatically detect damaged buildings using image classification algorithms. The method is applied to the case study of 2017 Hurricane Harvey.","Wed, 4 Jul 2018 17:11:16 UTC (5,956 KB)"
"532","Multicolor localization microscopy by deep learning","Eran Hershko*, Lucien E. Weiss*, Tomer Michaeli, Yoav Shechtman","Optics (physics.optics)","Deep learning has become an extremely effective tool for image classification and image restoration problems. Here, we apply deep learning to microscopy, and demonstrate how neural networks can exploit the chromatic dependence of the point-spread function to classify the colors of single emitters imaged on a grayscale camera. While existing single-molecule methods for spectral classification require additional optical elements in the emission path, e.g. spectral filters, prisms, or phase masks, our neural net correctly identifies static as well as mobile emitters with high efficiency using a standard, unmodified single-channel configuration. Furthermore, we demonstrate how deep learning can be used to design phase-modulating elements that, when implemented into the imaging path, result in further improved color differentiation between species.","Wed, 4 Jul 2018 15:24:15 UTC (5,448 KB)"
"533","The SEN1-2 Dataset for Deep Learning in SAR-Optical Data Fusion","Michael Schmitt, Lloyd Haydn Hughes, Xiao Xiang Zhu","Computer Vision and Pattern Recognition (cs.CV)","While deep learning techniques have an increasing impact on many technical fields, gathering sufficient amounts of training data is a challenging problem in remote sensing. In particular, this holds for applications involving data from multiple sensors with heterogeneous characteristics. One example for that is the fusion of synthetic aperture radar (SAR) data and optical imagery. With this paper, we publish the SEN1-2 dataset to foster deep learning research in SAR-optical data fusion. SEN1-2 comprises 282,384 pairs of corresponding image patches, collected from across the globe and throughout all meteorological seasons. Besides a detailed description of the dataset, we show exemplary results for several possible applications, such as SAR image colorization, SAR-optical image matching, and creation of artificial optical images from SAR input data. Since SEN1-2 is the first large open dataset of this kind, we believe it will support further developments in the field of deep learning for remote sensing as well as multi-sensor data fusion.","Wed, 4 Jul 2018 13:29:14 UTC (6,661 KB)"
"534","Wideband Time-Domain Digital Backpropagation via Subband Processing and Deep Learning","Christian Hager, Henry D. Pfister","Information Theory (cs.IT); Machine Learning (stat.ML)","We propose a low-complexity sub-banded DSP architecture for digital backpropagation where the walk-off effect is compensated using simple delay elements. For a simulated 96-Gbaud signal and 2500 km optical link, our method achieves a 2.8 dB SNR improvement over linear equalization.","Wed, 4 Jul 2018 12:39:25 UTC (84 KB)"
"535","A Mean-Field Optimal Control Formulation of Deep Learning","Weinan E, Jiequn Han, Qianxiao Li","Optimization and Control (math.OC); Machine Learning (cs.LG)","Recent work linking deep neural networks and dynamical systems opened up new avenues to analyze deep learning. In particular, it is observed that new insights can be obtained by recasting deep learning as an optimal control problem on difference or differential equations. However, the mathematical aspects of such a formulation have not been systematically explored. This paper introduces the mathematical formulation of the population risk minimization problem in deep learning as a mean-field optimal control problem. Mirroring the development of classical optimal control, we state and prove optimality conditions of both the Hamilton-Jacobi-Bellman type and the Pontryagin type. These mean-field results reflect the probabilistic nature of the learning problem. In addition, by appealing to the mean-field Pontryagin's maximum principle, we establish some quantitative relationships between population and empirical learning problems. This serves to establish a mathematical foundation for investigating the algorithmic and theoretical connections between optimal control and deep learning.","Tue, 3 Jul 2018 11:05:13 UTC (65 KB)"
"536","Securing Input Data of Deep Learning Inference Systems via Partitioned Enclave Execution","Zhongshu Gu, Heqing Huang, Jialong Zhang, Dong Su, Ankita Lamba, Dimitrios Pendarakis, Ian Molloy","Cryptography and Security (cs.CR)","Deep learning systems have been widely deployed as backend engines of artificial intelligence (AI) services for their approaching-human performance in cognitive tasks. However, end users always have some concerns about the confidentiality of their provisioned input data, even for those reputable AI service providers. Accidental disclosures of sensitive user data might unexpectedly happen due to security breaches, exploited vulnerabilities, neglect, or insiders. In this paper, we systematically investigate the potential information exposure in deep learning based AI inference systems. Based on our observation, we develop DeepEnclave, a privacy-enhancing system to mitigate sensitive information disclosure in deep learning inference pipelines. The key innovation is to partition deep learning models and leverage secure enclave techniques on cloud infrastructures to cryptographically protect the confidentiality and integrity of user inputs. We formulate the information exposure problem as a reconstruction privacy attack and quantify the adversary's capabilities with different attack strategies. Our comprehensive security analysis and performance measurement can act as a guideline for end users to determine their principle of partitioning deep neural networks, thus to achieve maximum privacy guarantee with acceptable performance overhead.","Tue, 3 Jul 2018 04:00:15 UTC (1,452 KB)"
"537","Deep Learning Based Fast Multiuser Detection for Massive Machine-Type Communication","Yanna Bai, Bo Ai, Wei Chen","Signal Processing (eess.SP)","Massive machine-type communication (MTC) with sporadically transmitted small packets and low data rate requires new designs on the PHY and MAC layer with light transmission overhead. Compressive sensing based multiuser detection (CS-MUD) is designed to detect active users through random access with low overhead by exploiting sparsity, i.e., the nature of sporadic transmissions in MTC. However, the high computational complexity of conventional sparse reconstruction algorithms prohibits the implementation of CS-MUD in real communication systems. To overcome this drawback, in this paper, we propose a fast Deep learning based approach for CS-MUD in massive MTC systems. In particular, a novel block restrictive activation nonlinear unit, is proposed to capture the block sparse structure in wide-band wireless communication systems (or multi-antenna systems). Our simulation results show that the proposed approach outperforms various existing algorithms for CS-MUD and allows for ten-fold decrease of the computing time.","Tue, 3 Jul 2018 03:54:35 UTC (558 KB)"
"538","Knowledge transfer of Deep Learning for galaxy morphology from one survey to another","H. Dominguez Sanchez, M. Huertas-Company, M. Bernardi, S. Kaviraj, J. L. Fischer, T. M. C. Abbott, F. B. Abdalla, J. Annis, S. Avila, D. Brooks, E. Buckley-Geer, A. Carnero Rosell, M. Carrasco Kind, J. Carretero, C. E. Cunha, C. B. D'Andrea, L. N. da Costa, C. Davis, J. De Vicente, P. Doel, A. E. Evrard, P. Fosalba, J. Frieman, J. Garcia-Bellido, E. Gaztanaga, D. W. Gerdes, D. Gruen, R. A. Gruendl, J. Gschwend, G. Gutierrez, W. G. Hartley, D. L. Hollowood, K. Honscheid, B. Hoyle, D. J. James, K. Kuehn, N. Kuropatkin, O. Lahav, M. A. G. Maia, M. March, P. Melchior, F. Menanteau, R. Miquel, B. Nord, A. A. Plazas, E. Sanchez, V. Scarpine, R. Schindler, M. Schubnell, M. Smith, R. C. Smith, M. Soares-Santos, F. Sobreira, E. Suchyta, M. E. C. Swanson, G. Tarle, D. Thomas, A. R. Walker, J. Zuntz","Astrophysics of Galaxies (astro-ph.GA)","Deep Learning (DL) algorithms for morphological classification of galaxies have proven very successful, mimicking (or even improving) visual classifications. However, these algorithms rely on large training samples of labeled galaxies (typically thousands of them). A key question for using DL classifications in future Big Data surveys is how much of the knowledge acquired from an existing survey can be exported to a new dataset, i.e. if the features learned by the machines are meaningful for different data. We test the performance of DL models, trained with Sloan Digital Sky Survey (SDSS) data, on Dark Energy survey (DES) using images for a sample of 5000 galaxies with a similar redshift distribution to SDSS. Applying the models directly to DES data provides a reasonable global accuracy ($\sim$ 90%), but small completeness and purity values. A fast domain adaptation step, consisting in a further training with a small DES sample of galaxies ($\sim$ 500-300), is enough for obtaining an accuracy > 95% and a significant improvement in the completeness and purity values. This demonstrates that, once trained with a particular dataset, machines can quickly adapt to new instrument characteristics (e.g., PSF, seeing, depth), reducing by almost one order of magnitude the necessary training sample for morphological classification. Redshift evolution effects or significant depth differences are not taken into account in this study.","Mon, 2 Jul 2018 17:59:58 UTC (735 KB)[v2] Tue, 3 Jul 2018 11:35:10 UTC (735 KB)"
"539","Deepcode: Feedback Codes via Deep Learning","Hyeji Kim, Yihan Jiang, Sreeram Kannan, Sewoong Oh, Pramod Viswanath","Machine Learning (cs.LG); Information Theory (cs.IT); Machine Learning (stat.ML)","The design of codes for communicating reliably over a statistically well defined channel is an important endeavor involving deep mathematical research and wide-ranging practical applications. In this work, we present the first family of codes obtained via deep learning, which significantly beats state-of-the-art codes designed over several decades of research. The communication channel under consideration is the Gaussian noise channel with feedback, whose study was initiated by Shannon; feedback is known theoretically to improve reliability of communication, but no practical codes that do so have ever been successfully constructed. We break this logjam by integrating information theoretic insights harmoniously with recurrent-neural-network based encoders and decoders to create novel codes that outperform known codes by 3 orders of magnitude in reliability. We also demonstrate several desirable properties of the codes: (a) generalization to larger block lengths, (b) composability with known codes, (c) adaptation to practical constraints. This result also has broader ramifications for coding theory: even when the channel has a clear mathematical model, deep learning methodologies, when combined with channel-specific information-theoretic insights, can potentially beat state-of-the-art codes constructed over decades of mathematical research.","Mon, 2 Jul 2018 17:50:25 UTC (6,125 KB)"
"540","Online Label Recovery for Deep Learning-based Communication through Error Correcting Codes","Stefan Schibisch, Sebastian Cammerer, Sebastian Dorner, Jakob Hoydis, Stephan ten Brink","Information Theory (cs.IT); Signal Processing (eess.SP)","We demonstrate that error correcting codes (ECCs) can be used to construct a labeled data set for finetuning of ""trainable"" communication systems without sacrificing resources for the transmission of known symbols. This enables adaptive systems, which can be trained on-the-fly to compensate for slow fluctuations in channel conditions or varying hardware impairments. We examine the influence of corrupted training data and show that it is crucial to train based on correct labels. The proposed method can be applied to fully end-to-end trained communication systems (autoencoders) as well as systems with only some trainable components. This is exemplified by extending a conventional OFDM system with a trainable pre-equalizer neural network (NN) that can be optimized at run time.","Mon, 2 Jul 2018 15:36:31 UTC (277 KB)"
"541","Classifying neuromorphic data using a deep learning framework for image classification","Roshan Gopalakrishnan, Yansong Chua, Laxmi R Iyer","Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)","In the field of artificial intelligence, neuromorphic computing has been around for several decades. Deep learning has however made much recent progress such that it consistently outperforms neuromorphic learning algorithms in classification tasks in terms of accuracy. Specifically in the field of image classification, neuromorphic computing has been traditionally using either the temporal or rate code for encoding static images in datasets into spike trains. It is only till recently, that neuromorphic vision sensors are widely used by the neuromorphic research community, and provides an alternative to such encoding methods. Since then, several neuromorphic datasets as obtained by applying such sensors on image datasets (e.g. the neuromorphic CALTECH 101) have been introduced. These data are encoded in spike trains and hence seem ideal for benchmarking of neuromorphic learning algorithms. Specifically, we train a deep learning framework used for image classification on the CALTECH 101 and a collapsed version of the neuromorphic CALTECH 101 datasets. We obtained an accuracy of 91.66% and 78.01% for the CALTECH 101 and neuromorphic CALTECH 101 datasets respectively. For CALTECH 101, our accuracy is close to the best reported accuracy, while for neuromorphic CALTECH 101, it outperforms the last best reported accuracy by over 10%. This raises the question of the suitability of such datasets as benchmarks for neuromorphic learning algorithms.","Mon, 2 Jul 2018 10:18:37 UTC (281 KB)"
"542","Confounding variables can degrade generalization performance of radiological deep learning models","John R. Zech, Marcus A. Badgeley, Manway Liu, Anthony B. Costa, Joseph J. Titano, Eric K. Oermann","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Early results in using convolutional neural networks (CNNs) on x-rays to diagnose disease have been promising, but it has not yet been shown that models trained on x-rays from one hospital or one group of hospitals will work equally well at different hospitals. Before these tools are used for computer-aided diagnosis in real-world clinical settings, we must verify their ability to generalize across a variety of hospital systems. A cross-sectional design was used to train and evaluate pneumonia screening CNNs on 158,323 chest x-rays from NIH (n=112,120 from 30,805 patients), Mount Sinai (42,396 from 12,904 patients), and Indiana (n=3,807 from 3,683 patients). In 3 / 5 natural comparisons, performance on chest x-rays from outside hospitals was significantly lower than on held-out x-rays from the original hospital systems. CNNs were able to detect where an x-ray was acquired (hospital system, hospital department) with extremely high accuracy and calibrate predictions accordingly. The performance of CNNs in diagnosing diseases on x-rays may reflect not only their ability to identify disease-specific imaging findings on x-rays, but also their ability to exploit confounding information. Estimates of CNN performance based on test data from hospital systems used for model training may overstate their likely real-world performance.","Mon, 2 Jul 2018 01:57:38 UTC (2,252 KB)[v2] Fri, 13 Jul 2018 01:07:41 UTC (2,252 KB)"
"543","Autonomous Deep Learning: A Genetic DCNN Designer for Image Classification","Benteng Ma, Yong Xia","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Recent years have witnessed the breakthrough success of deep convolutional neural networks (DCNNs) in image classification and other vision applications. Although freeing users from the troublesome handcrafted feature extraction by providing a uniform feature extraction-classification framework, DCNNs still require a handcrafted design of their architectures. In this paper, we propose the genetic DCNN designer, an autonomous learning algorithm can generate a DCNN architecture automatically based on the data available for a specific image classification problem. We first partition a DCNN into multiple stacked meta convolutional blocks and fully connected blocks, each containing the operations of convolution, pooling, fully connection, batch normalization, activation and drop out, and thus convert the architecture into an integer vector. Then, we use refined evolutionary operations, including selection, mutation and crossover to evolve a population of DCNN architectures. Our results on the MNIST, Fashion-MNIST, EMNISTDigit, EMNIST-Letter, CIFAR10 and CIFAR100 datasets suggest that the proposed genetic DCNN designer is able to produce automatically DCNN architectures, whose performance is comparable to, if not better than, that of stateof- the-art DCNN models","Sun, 1 Jul 2018 07:11:54 UTC (753 KB)"
"544","Accurate Uncertainties for Deep Learning Using Calibrated Regression","Volodymyr Kuleshov, Nathan Fenner, Stefano Ermon","Machine Learning (cs.LG); Machine Learning (stat.ML)","Methods for reasoning under uncertainty are a key building block of accurate and reliable machine learning systems. Bayesian methods provide a general framework to quantify uncertainty. However, because of model misspecification and the use of approximate inference, Bayesian uncertainty estimates are often inaccurate -- for example, a 90% credible interval may not contain the true outcome 90% of the time. Here, we propose a simple procedure for calibrating any regression algorithm; when applied to Bayesian and probabilistic models, it is guaranteed to produce calibrated uncertainty estimates given enough data. Our procedure is inspired by Platt scaling and extends previous work on classification. We evaluate this approach on Bayesian linear regression, feedforward, and recurrent neural networks, and find that it consistently outputs well-calibrated credible intervals while improving performance on time series forecasting and model-based reinforcement learning tasks.","Sun, 1 Jul 2018 03:31:32 UTC (2,751 KB)"
"545","Topology classification with deep learning to improve real-time event selection at the LHC","Thong Q. Nguyen, Daniel Weitekamp III, Dustin Anderson, Roberto Castello, Olmo Cerri, Maurizio Pierini, Maria Spiropulu, Jean-Roch Vlimant","High Energy Physics - Experiment (hep-ex); Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)","We show how event topology classification based on deep learning could be used to improve the purity of data samples selected in real time at at the Large Hadron Collider. We consider different data representations, on which different kinds of multi-class classifiers are trained. Both raw data and high-level features are utilized. In the considered examples, a filter based on the classifier's score can be trained to retain ~99% of the interesting events and reduce the false-positive rate by as much as one order of magnitude for certain background processes. By operating such a filter as part of the online event selection infrastructure of the LHC experiments, one could benefit from a more flexible and inclusive selection strategy while reducing the amount of downstream resources wasted in processing false positives. The saved resources could be translated into a reduction of the detector operation cost or into an effective increase of storage and processing capabilities, which could be reinvested to extend the physics reach of the LHC experiments.","Fri, 29 Jun 2018 23:07:49 UTC (2,631 KB)[v2] Wed, 1 Aug 2018 23:44:59 UTC (5,134 KB)"
"546","Adversarial Examples in Deep Learning: Characterization and Divergence","Wenqi Wei, Ling Liu, Stacey Truex, Lei Yu, Mehmet Emre Gursoy, Yanzhao Wu","Machine Learning (cs.LG); Machine Learning (stat.ML)","The burgeoning success of deep learning has raised the security and privacy concerns as more and more tasks are accompanied with sensitive data. Adversarial attacks in deep learning have emerged as one of the dominating security threat to a range of mission-critical deep learning systems and applications. This paper takes a holistic and principled approach to perform statistical characterization of adversarial examples in deep learning. We provide a general formulation of adversarial examples and elaborate on the basic principle for adversarial attack algorithm design. We introduce easy and hard categorization of adversarial attacks to analyze the effectiveness of adversarial examples in terms of attack success rate, degree of change in adversarial perturbation, average entropy of prediction qualities, and fraction of adversarial examples that lead to successful attacks. We conduct extensive experimental study on adversarial behavior in easy and hard attacks under deep learning models with different hyperparameters and different deep learning frameworks. We show that the same adversarial attack behaves differently under different hyperparameters and across different frameworks due to the different features learned under different deep learning model training process. Our statistical characterization with strong empirical evidence provides a transformative enlightenment on mitigation strategies towards effective countermeasures against present and future adversarial attacks.","Fri, 29 Jun 2018 19:50:25 UTC (3,037 KB)[v2] Mon, 29 Oct 2018 02:43:04 UTC (3,037 KB)"
"547","Exploration of Low Numeric Precision Deep Learning Inference Using Intel FPGAs","Philip Colangelo, Nasibeh Nasiri, Asit Mishra, Eriko Nurvitadhi, Martin Margala, Kevin Nealis","Distributed, Parallel, and Cluster Computing (cs.DC); Hardware Architecture (cs.AR)","CNNs have been shown to maintain reasonable classification accuracy when quantized to lower precisions. Quantizing to sub 8-bit activations and weights can result in accuracy falling below an acceptable threshold. Techniques exist for closing the accuracy gap of limited numeric precision typically by increasing computation. This results in a trade-off between throughput and accuracy and can be tailored for different networks through various combinations of activation and weight data widths. Hardware architectures like FPGAs provide the opportunity for data width specific computation through unique logic configurations leading to highly optimized processing that is unattainable by full precision networks. Ternary and binary weighted networks offer an efficient method of inference for 2-bit and 1-bit data respectively. Most hardware architectures can take advantage of the memory storage and bandwidth savings that come along with smaller datapaths, but very few architectures can take advantage of limited numeric precision at the computation level. In this paper, we present a hardware design for FPGAs that takes advantage of bandwidth, memory, power, and computation savings of limited numerical precision data. We provide insights into the trade-offs between throughput and accuracy for various networks and how they map to our framework. Further, we show how limited numeric precision computation can be efficiently mapped onto FPGAs for both ternary and binary cases. Starting with Arria 10, we show a 2-bit activation and ternary weighted AlexNet running in hardware that achieves 3,700 images per second on the ImageNet dataset with a top-1 accuracy of 0.49. Using a hardware modeler designed for our low numeric precision framework we project performance most notably for a 55.5 TOPS Stratix 10 device running a modified ResNet-34 with only 3.7% accuracy degradation compared with single precision.","Tue, 12 Jun 2018 22:00:31 UTC (900 KB)"
"548","Deep Learning and its Application to LHC Physics","Dan Guest, Kyle Cranmer, Daniel Whiteson","High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph); Computational Physics (physics.comp-ph); Data Analysis, Statistics and Probability (physics.data-an)","Machine learning has played an important role in the analysis of high-energy physics data for decades. The emergence of deep learning in 2012 allowed for machine learning tools which could adeptly handle higher-dimensional and more complex problems than previously feasible. This review is aimed at the reader who is familiar with high energy physics but not machine learning. The connections between machine learning and high energy physics data analysis are explored, followed by an introduction to the core concepts of neural networks, examples of the key results demonstrating the power of deep learning for analysis of LHC data, and discussion of future prospects and concerns.","Fri, 29 Jun 2018 15:41:16 UTC (5,817 KB)"
"549","Bayesian Deep Learning on a Quantum Computer","Zhikuan Zhao, Alejandro Pozas-Kerstjens, Patrick Rebentrost, Peter Wittek","Quantum Physics (quant-ph); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Bayesian methods in machine learning, such as Gaussian processes, have great advantages compared to other techniques. In particular, they provide estimates of the uncertainty associated with a prediction. Extending the Bayesian approach to deep architectures has remained a major challenge. Recent results connected deep feedforward neural networks with Gaussian processes, allowing training without backpropagation. This connection enables us to leverage a quantum algorithm designed for Gaussian processes and develop a new algorithm for Bayesian deep learning on quantum computers. The properties of the kernel matrix in the Gaussian process ensure the efficient execution of the core component of the protocol, quantum matrix inversion, providing an at least polynomial speedup over the classical algorithm. Furthermore, we demonstrate the execution of the algorithm on contemporary quantum computers and analyze its robustness with respect to realistic noise models.","Fri, 29 Jun 2018 15:08:45 UTC (51 KB)[v2] Mon, 9 Jul 2018 12:13:47 UTC (51 KB)"
"550","MRFusion: A Deep Learning architecture to fuse PAN and MS imagery for land cover mapping","Raffaele Gaetano, Dino Ienco, Kenji Ose, Remi Cresson","Computer Vision and Pattern Recognition (cs.CV)","Nowadays, Earth Observation systems provide a multitude of heterogeneous remote sensing data. How to manage such richness leveraging its complementarity is a crucial chal- lenge in modern remote sensing analysis. Data Fusion techniques deal with this point proposing method to combine and exploit complementarity among the different data sensors. Considering optical Very High Spatial Resolution (VHSR) images, satellites obtain both Multi Spectral (MS) and panchro- matic (PAN) images at different spatial resolution. VHSR images are extensively exploited to produce land cover maps to deal with agricultural, ecological, and socioeconomic issues as well as assessing ecosystem status, monitoring biodiversity and provid- ing inputs to conceive food risk monitoring systems. Common techniques to produce land cover maps from such VHSR images typically opt for a prior pansharpening of the multi-resolution source for a full resolution processing. Here, we propose a new deep learning architecture to jointly use PAN and MS imagery for a direct classification without any prior image fusion or resampling process. By managing the spectral information at its native spatial resolution, our method, named MRFusion, aims at avoiding the possible infor- mation loss induced by pansharpening or any other hand-crafted preprocessing. Moreover, the proposed architecture is suitably designed to learn non-linear transformations of the sources with the explicit aim of taking as much as possible advantage of the complementarity of PAN and MS imagery. Experiments are carried out on two-real world scenarios depicting large areas with different land cover characteristics. The characteristics of the proposed scenarios underline the applicability and the generality of our method in operational settings.","Fri, 29 Jun 2018 14:43:48 UTC (6,791 KB)"
"551","Detecting Mammals in UAV Images: Best Practices to address a substantially Imbalanced Dataset with Deep Learning","Benjamin Kellenberger, Diego Marcos, Devis Tuia","Computer Vision and Pattern Recognition (cs.CV)","Knowledge over the number of animals in large wildlife reserves is a vital necessity for park rangers in their efforts to protect endangered species. Manual animal censuses are dangerous and expensive, hence Unmanned Aerial Vehicles (UAVs) with consumer level digital cameras are becoming a popular alternative tool to estimate livestock. Several works have been proposed that semi-automatically process UAV images to detect animals, of which some employ Convolutional Neural Networks (CNNs), a recent family of deep learning algorithms that proved very effective in object detection in large datasets from computer vision. However, the majority of works related to wildlife focuses only on small datasets (typically subsets of UAV campaigns), which might be detrimental when presented with the sheer scale of real study areas for large mammal census. Methods may yield thousands of false alarms in such cases. In this paper, we study how to scale CNNs to large wildlife census tasks and present a number of recommendations to train a CNN on a large UAV dataset. We further introduce novel evaluation protocols that are tailored to censuses and model suitability for subsequent human verification of detections. Using our recommendations, we are able to train a CNN reducing the number of false positives by an order of magnitude compared to previous state-of-the-art. Setting the requirements at 90% recall, our CNN allows to reduce the amount of data required for manual verification by three times, thus making it possible for rangers to screen all the data acquired efficiently and to detect almost all animals in the reserve automatically.","Fri, 29 Jun 2018 11:59:14 UTC (6,073 KB)"
"552","A hybrid deep learning approach for medical relation extraction","Veera Raghavendra Chikka, Kamalakar Karlapalem","Machine Learning (cs.LG); Information Retrieval (cs.IR); Machine Learning (stat.ML)","Mining relationships between treatment(s) and medical problem(s) is vital in the biomedical domain. This helps in various applications, such as decision support system, safety surveillance, and new treatment discovery. We propose a deep learning approach that utilizes both word level and sentence-level representations to extract the relationships between treatment and problem. While deep learning techniques demand a large amount of data for training, we make use of a rule-based system particularly for relationship classes with fewer samples. Our final relations are derived by jointly combining the results from deep learning and rule-based models. Our system achieved a promising performance on the relationship classes of I2b2 2010 relation extraction task.","Tue, 26 Jun 2018 06:38:01 UTC (72 KB)"
"553","Deep Learning Based Instance Segmentation in 3D Biomedical Images Using Weak Annotation","Zhuo Zhao, Lin Yang, Hao Zheng, Ian H. Guldner, Siyuan Zhang, Danny Z. Chen","Computer Vision and Pattern Recognition (cs.CV)","Instance segmentation in 3D images is a fundamental task in biomedical image analysis. While deep learning models often work well for 2D instance segmentation, 3D instance segmentation still faces critical challenges, such as insufficient training data due to various annotation difficulties in 3D biomedical images. Common 3D annotation methods (e.g., full voxel annotation) incur high workloads and costs for labeling enough instances for training deep learning 3D instance segmentation models. In this paper, we propose a new weak annotation approach for training a fast deep learning 3D instance segmentation model without using full voxel mask annotation. Our approach needs only 3D bounding boxes for all instances and full voxel annotation for a small fraction of the instances, and uses a novel two-stage 3D instance segmentation model utilizing these two kinds of annotation, respectively. We evaluate our approach on several biomedical image datasets, and the experimental results show that (1) with full annotated boxes and a small amount of masks, our approach can achieve similar performance as the best known methods using full annotation, and (2) with similar annotation time, our approach outperforms the best known methods that use full annotation.","Thu, 28 Jun 2018 18:22:52 UTC (3,729 KB)"
"554","Acceleration and Quantitation of Localized Correlated Spectroscopy using Deep Learning: A Pilot Simulation Study","Zohaib Iqbal, Dan Nguyen, M. Albert Thomas, Steve Jiang","Medical Physics (physics.med-ph)","Nuclear magnetic resonance spectroscopy (MRS) allows for the determination of atomic structures and concentrations of different chemicals in a biochemical sample of interest. MRS is used in vivo clinically to aid in the diagnosis of several pathologies that affect metabolic pathways in the body. Typically, this experiment produces a one dimensional (1D) 1H spectrum containing several peaks that are well associated with biochemicals, or metabolites. However, since many of these peaks overlap, distinguishing chemicals with similar atomic structures becomes much more challenging. One technique capable of overcoming this issue is the localized correlated spectroscopy (L-COSY) experiment, which acquires a second spectral dimension and spreads overlapping signal across this second dimension. Unfortunately, the acquisition of a two dimensional (2D) spectroscopy experiment is extremely time consuming. Furthermore, quantitation of a 2D spectrum is more complex. Recently, artificial intelligence has emerged in the field of medicine as a powerful force capable of diagnosing disease, aiding in treatment, and even predicting treatment outcome. In this study, we utilize deep learning to: 1) accelerate the L-COSY experiment and 2) quantify L-COSY spectra. We demonstrate that our deep learning model greatly outperforms compressed sensing based reconstruction of L-COSY spectra at higher acceleration factors. Specifically, at four-fold acceleration, our method has less than 5% normalized mean squared error, whereas compressed sensing yields 20% normalized mean squared error. We also show that at low SNR (25% noise compared to maximum signal), our deep learning model has less than 8% normalized mean squared error for quantitation of L-COSY spectra. These pilot simulation results appear promising and may help improve the efficiency and accuracy of L-COSY experiments in the future.","Thu, 28 Jun 2018 16:35:01 UTC (9,143 KB)"
"555","Deep learning for dehazing: Comparison and analysis","A Benoit (LISTIC), Leonel Cuevas, Jean-Baptiste Thomas (Le2i)","Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Image and Video Processing (eess.IV)","We compare a recent dehazing method based on deep learning, Dehazenet, with traditional state-of-the-art approaches , on benchmark data with reference. Dehazenet estimates the depth map from transmission factor on a single color image, which is used to inverse the Koschmieder model of imaging in the presence of haze. In this sense, the solution is still attached to the Koschmieder model. We demonstrate that the transmission is very well estimated by the network, but also that this method exhibits the same limitation than others due to the use of the same imaging model.","Thu, 28 Jun 2018 12:37:54 UTC (4,507 KB)"
"556","Deep learning in business analytics and operations research: Models, applications and managerial implications","Mathias Kraus, Stefan Feuerriegel, Asil Oztekin","Machine Learning (cs.LG); Machine Learning (stat.ML)","Business analytics refers to methods and practices that create value through data for individuals, firms, and organizations. This field is currently experiencing a radical shift due to the advent of deep learning: deep neural networks promise improvements in prediction performance as compared to models from traditional machine learning. However, our research into the existing body of literature reveals a scarcity of research works utilizing deep learning in our discipline. Accordingly, the objectives of this work are as follows: (1) we motivate why researchers and practitioners from business analytics should utilize deep neural networks and review potential use cases, necessary requirements, and benefits. (2) We investigate the added value to operations research in different case studies with real data from entrepreneurial undertakings. All such cases demonstrate a higher prediction performance in comparison to traditional machine learning and thus direct value gains. (3) We provide guidelines and implications for researchers, managers and practitioners in operations research who want to advance their capabilities for business analytics with regard to deep learning. (4) We finally discuss directions for future research in the field of business analytics.","Thu, 28 Jun 2018 11:48:36 UTC (389 KB)"
"557","Deep Learning-Aided Iterative Detector for Massive Overloaded MIMO Channels","Masayuki Imanishi, Satoshi Takabe, Tadashi Wadayama","Information Theory (cs.IT); Machine Learning (cs.LG)","The paper presents a deep learning-aided iterative detection algorithm for massive overloaded MIMO channels. The proposed algorithm is based on the iterative soft thresholding algorithm for sparse signal recovery. The notable feature of the proposed scheme is that the detector has a reasonably low computational cost and contains trainable parameters which can be optimized with standard deep learning techniques. The number of trainable parameters is constant to the channel size, which promotes fast and stable training processes for the detector. The numerical simulations show that the proposed detector achieves a comparable detection performance to the state-of-the-art IW-SOAV detector for massive overloaded MIMO channels.","Thu, 28 Jun 2018 08:34:06 UTC (44 KB)"
"558","Gradient Similarity: An Explainable Approach to Detect Adversarial Attacks against Deep Learning","Jasjeet Dhaliwal, Saurabh Shintre","Computer Vision and Pattern Recognition (cs.CV); Cryptography and Security (cs.CR); Machine Learning (cs.LG)","Deep neural networks are susceptible to small-but-specific adversarial perturbations capable of deceiving the network. This vulnerability can lead to potentially harmful consequences in security-critical applications. To address this vulnerability, we propose a novel metric called \emph{Gradient Similarity} that allows us to capture the influence of training data on test inputs. We show that \emph{Gradient Similarity} behaves differently for normal and adversarial inputs, and enables us to detect a variety of adversarial attacks with a near perfect ROC-AUC of 95-100\%. Even white-box adversaries equipped with perfect knowledge of the system cannot bypass our detector easily. On the MNIST dataset, white-box attacks are either detected with a high ROC-AUC of 87-96\%, or require very high distortion to bypass our detector.","Wed, 27 Jun 2018 22:47:37 UTC (1,320 KB)"
"559","Efficient representation and approximation of model predictive control laws via deep learning","Benjamin Karg, Sergio Lucia","Optimization and Control (math.OC)","We show that artificial neural networks with rectifier units as activation functions can exactly represent the piecewise affine function that results from the formulation of model predictive control of linear time-invariant systems. The choice of deep neural networks is particularly interesting as they can represent exponentially many more affine regions compared to networks with only one hidden layer. We provide theoretical bounds on the minimum number of hidden layers and neurons per layer that a neural network should have to exactly represent a given model predictive control law. The proposed approach has a strong potential as an approximation method of predictive control laws, leading to better approximation quality and significantly smaller memory requirements than previous approaches, as we illustrate via simulation examples. Since the online evaluation of neural networks is extremely simple, the proposed approach is a perfect candidate for embedded applications.","Wed, 27 Jun 2018 18:56:14 UTC (409 KB)"
"560","This looks like that: deep learning for interpretable image recognition","Chaofan Chen, Oscar Li, Alina Barnett, Jonathan Su, Cynthia Rudin","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","When we are faced with challenging image classification tasks, we often explain our reasoning by dissecting the image, and pointing out prototypical aspects of one class or another. The mounting evidence for each of the classes helps us make our final decision. In this work, we introduce a deep network architecture that reasons in a similar way: the network dissects the image by finding prototypical parts, and combines evidence from the prototypes to make a final classification. The algorithm thus reasons in a way that is qualitatively similar to the way ornithologists, physicians, geologists, architects, and others would explain to people on how to solve challenging image classification tasks. The network uses only image-level labels for training, meaning that there are no labels for parts of images. We demonstrate the method on the CIFAR-10 dataset and 10 classes from the CUB-200-2011 dataset.","Wed, 27 Jun 2018 17:18:03 UTC (4,351 KB)"
"561","A Generalized Data Representation and Training-Performance Analysis for Deep Learning-Based Communications Systems","Xiao Chen, Liang Wu, Zaichen Zhang","Information Theory (cs.IT)","Deep learning (DL)-based autoencoder is a potential architecture to implement end-to-end communication systems. In this letter, we first give a brief introduction to the autoencoder-represented communication system. Then, we propose a novel generalized data representation (GDR) aiming to improve the data rate of DL-based communication systems. Finally, simulation results show that the proposed GDR scheme has lower training complexity, comparable block error rate performance and higher channel capacity than the conventional one-hot vector scheme. Furthermore, we investigate the effect of signal-to-noise ratio (SNR) in DL-based communication systems and prove that training at a high SNR could produce a good training performance for autoencoder.","Wed, 27 Jun 2018 08:17:51 UTC (1,527 KB)[v2] Fri, 6 Jul 2018 07:47:10 UTC (1,527 KB)"
"562","Low Photon Count Phase Retrieval Using Deep Learning","Alexandre Goy, Kwabena Arthur, Shuai Li, George Barbastathis","Image and Video Processing (eess.IV); Optics (physics.optics)","Imaging systems' performance at low light intensity is affected by shot noise, which becomes increasingly strong as the power of the light source decreases. In this paper we experimentally demonstrate the use of deep neural networks to recover objects illuminated with weak light and demonstrate better performance than with the classical Gerchberg-Saxton phase retrieval algorithm for equivalent signal over noise ratio. Prior knowledge about the object is implicitly contained in the training data set and feature detection is possible for a signal over noise ratio close to one. We apply this principle to a phase retrieval problem and show successful recovery of the object's most salient features with as little as one photon per detector pixel on average in the illumination beam. We also show that the phase reconstruction is significantly improved by training the neural network with an initial estimate of the object, as opposed as training it with the raw intensity measurement.","Mon, 25 Jun 2018 16:59:23 UTC (3,805 KB)"
"563","A Universal Training Algorithm for Quantum Deep Learning","Guillaume Verdon, Jason Pye, Michael Broughton","Quantum Physics (quant-ph)","We introduce the Backwards Quantum Propagation of Phase errors (Baqprop) principle, a central theme upon which we construct multiple universal optimization heuristics for training both parametrized quantum circuits and classical deep neural networks on a quantum computer. Baqprop encodes error information in relative phases of a quantum wavefunction defined over the space of network parameters; it can be thought of as the unification of the phase kickback principle of quantum computation and of the backpropagation algorithm from classical deep learning. We propose two core heuristics which leverage Baqprop for quantum-enhanced optimization of network parameters: Quantum Dynamical Descent (QDD) and Momentum Measurement Gradient Descent (MoMGrad). QDD uses simulated quantum coherent dynamics for parameter optimization, allowing for quantum tunneling through the hypothesis space landscape. MoMGrad leverages Baqprop to estimate gradients and thereby perform gradient descent on the parameter landscape; it can be thought of as the quantum-classical analogue of QDD. In addition to these core optimization strategies, we propose various methods for parallelization, regularization, and meta-learning as augmentations to MoMGrad and QDD. We introduce several quantum-coherent adaptations of canonical classical feedforward neural networks, and study how Baqprop can be used to optimize such networks. We develop multiple applications of parametric circuit learning for quantum data, and show how to perform Baqprop in each case. One such application allows for the training of hybrid quantum-classical neural-circuit networks, via the seamless integration of Baqprop with classical backpropagation. Finally, for a representative subset of these proposed applications, we demonstrate the training of these networks via numerical simulations of implementations of QDD and MoMGrad.","Mon, 25 Jun 2018 23:55:24 UTC (7,624 KB)"
"564","Pushing the boundaries of parallel Deep Learning -- A practical approach","Paolo Viviani, Maurizio Drocco, Marco Aldinucci","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","This work aims to assess the state of the art of data parallel deep neural network training, trying to identify potential research tracks to be exploited for performance improvement. Beside, it presents a design for a practical C++ library dedicated at implementing and unifying the current state of the art methodologies for parallel training in a performance-conscious framework, allowing the user to explore novel strategies without departing significantly from its usual work-flow.","Mon, 25 Jun 2018 15:30:33 UTC (26 KB)"
"565","SkinNet: A Deep Learning Framework for Skin Lesion Segmentation","Sulaiman Vesal, Nishant Ravikumar, Andreas Maier","Computer Vision and Pattern Recognition (cs.CV)","There has been a steady increase in the incidence of skin cancer worldwide, with a high rate of mortality. Early detection and segmentation of skin lesions are crucial for timely diagnosis and treatment, necessary to improve the survival rate of patients. However, skin lesion segmentation is a challenging task due to the low contrast of lesions and their high similarity in terms of appearance, to healthy tissue. This underlines the need for an accurate and automatic approach for skin lesion segmentation. To tackle this issue, we propose a convolutional neural network (CNN) called SkinNet. The proposed CNN is a modified version of U-Net. We compared the performance of our approach with other state-of-the-art techniques, using the ISBI 2017 challenge dataset. Our approach outperformed the others in terms of the Dice coefficient, Jaccard index and sensitivity, evaluated on the held-out challenge test data set, across 5-fold cross validation experiments. SkinNet achieved an average value of 85.10, 76.67 and 93.0%, for the DC, JI, and SE, respectively.","Mon, 25 Jun 2018 15:14:31 UTC (314 KB)"
"566","A Hierarchical Deep Learning Natural Language Parser for Fashion","Jose Marcelino, Joao Faria, Luis Baia, Ricardo Gamelas Sousa","Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)","This work presents a hierarchical deep learning natural language parser for fashion. Our proposal intends not only to recognize fashion-domain entities but also to expose syntactic and morphologic insights. We leverage the usage of an architecture of specialist models, each one for a different task (from parsing to entity recognition). Such architecture renders a hierarchical model able to capture the nuances of the fashion language. The natural language parser is able to deal with textual ambiguities which are left unresolved by our currently existing solution. Our empirical results establish a robust baseline, which justifies the use of hierarchical architectures of deep learning models while opening new research avenues to explore.","Mon, 25 Jun 2018 14:57:52 UTC (525 KB)"
"567","Disease Classification in Metagenomics with 2D Embeddings and Deep Learning","Thanh Hai Nguyen, Edi Prifti, Yann Chevaleyre, Nataliya Sokolovska, Jean-Daniel Zucker","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Deep learning (DL) techniques have shown unprecedented success when applied to images, waveforms, and text. Generally, when the sample size ($N$) is much bigger than the number of features ($d$), DL often outperforms other machine learning (ML) techniques, often through the use of Convolutional Neural Networks (CNNs). However, in many bioinformatics fields (including metagenomics), we encounter the opposite situation where $d$ is significantly greater than $N$. In these situations, applying DL techniques would lead to severe overfitting. Here we aim to improve classification of various diseases with metagenomic data through the use of CNNs. For this we proposed to represent metagenomic data as images. The proposed Met2Img approach relies on taxonomic and t-SNE embeddings to transform abundance data into ""synthetic images"". We applied our approach to twelve benchmark data sets including more than 1400 metagenomic samples. Our results show significant improvements over the state-of-the-art algorithms (Random Forest (RF), Support Vector Machine (SVM)). We observe that the integration of phylogenetic information alongside abundance data improves classification. The proposed approach is not only important in classification setting but also allows to visualize complex metagenomic data. The Met2Img is implemented in Python.","Sat, 23 Jun 2018 22:01:27 UTC (1,186 KB)"
"568","The Foundations of Deep Learning with a Path Towards General Intelligence","Eray Ozkural","Artificial Intelligence (cs.AI)","Like any field of empirical science, AI may be approached axiomatically. We formulate requirements for a general-purpose, human-level AI system in terms of postulates. We review the methodology of deep learning, examining the explicit and tacit assumptions in deep learning research. Deep Learning methodology seeks to overcome limitations in traditional machine learning research as it combines facets of model richness, generality, and practical applicability. The methodology so far has produced outstanding results due to a productive synergy of function approximation, under plausible assumptions of irreducibility and the efficiency of back-propagation family of algorithms. We examine these winning traits of deep learning, and also observe the various known failure modes of deep learning. We conclude by giving recommendations on how to extend deep learning methodology to cover the postulates of general-purpose AI including modularity, and cognitive architecture. We also relate deep learning to advances in theoretical neuroscience research.","Fri, 22 Jun 2018 22:52:12 UTC (38 KB)"
"569","A deep learning framework for segmentation of retinal layers from OCT images","Karthik Gopinath, Samrudhdhi B Rangrej, Jayanthi Sivaswamy","Computer Vision and Pattern Recognition (cs.CV)","Segmentation of retinal layers from Optical Coherence Tomography (OCT) volumes is a fundamental problem for any computer aided diagnostic algorithm development. This requires preprocessing steps such as denoising, region of interest extraction, flattening and edge detection all of which involve separate parameter tuning. In this paper, we explore deep learning techniques to automate all these steps and handle the presence/absence of pathologies. A model is proposed consisting of a combination of Convolutional Neural Network (CNN) and Long Short Term Memory (LSTM). The CNN is used to extract layers of interest image and extract the edges, while the LSTM is used to trace the layer boundary. This model is trained on a mixture of normal and AMD cases using minimal data. Validation results on three public datasets show that the pixel-wise mean absolute error obtained with our system is 1.30 plus or minus 0.48 which is lower than the inter-marker error of 1.79 plus or minus 0.76. Our model's performance is also on par with the existing methods.","Fri, 22 Jun 2018 21:24:58 UTC (5,769 KB)"
"570","Combination of Domain Knowledge and Deep Learning for Sentiment Analysis","Khuong Vo, Dang Pham, Mao Nguyen, Trung Mai, Tho Quan","Computation and Language (cs.CL); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","The emerging technique of deep learning has been widely applied in many different areas. However, when adopted in a certain specific domain, this technique should be combined with domain knowledge to improve efficiency and accuracy. In particular, when analyzing the applications of deep learning in sentiment analysis, we found that the current approaches are suffering from the following drawbacks: (i) the existing works have not paid much attention to the importance of different types of sentiment terms, which is an important concept in this area; and (ii) the loss function currently employed does not well reflect the degree of error of sentiment misclassification. To overcome such problem, we propose to combine domain knowledge with deep learning. Our proposal includes using sentiment scores, learnt by regression, to augment training data; and introducing penalty matrix for enhancing the loss function of cross entropy. When experimented, we achieved a significant improvement in classification results.","Fri, 22 Jun 2018 16:39:37 UTC (1,030 KB)[v2] Tue, 26 Jun 2018 05:47:31 UTC (1,029 KB)"
"571","Towards safe deep learning: accurately quantifying biomarker uncertainty in neural network predictions","Zach Eaton-Rosen, Felix Bragman, Sotirios Bisdas, Sebastien Ourselin, M. Jorge Cardoso","Computer Vision and Pattern Recognition (cs.CV)","Automated medical image segmentation, specifically using deep learning, has shown outstanding performance in semantic segmentation tasks. However, these methods rarely quantify their uncertainty, which may lead to errors in downstream analysis. In this work we propose to use Bayesian neural networks to quantify uncertainty within the domain of semantic segmentation. We also propose a method to convert voxel-wise segmentation uncertainty into volumetric uncertainty, and calibrate the accuracy and reliability of confidence intervals of derived measurements. When applied to a tumour volume estimation application, we demonstrate that by using such modelling of uncertainty, deep learning systems can be made to report volume estimates with well-calibrated error-bars, making them safer for clinical use. We also show that the uncertainty estimates extrapolate to unseen data, and that the confidence intervals are robust in the presence of artificial noise. This could be used to provide a form of quality control and quality assurance, and may permit further adoption of deep learning tools in the clinic.","Fri, 22 Jun 2018 12:54:20 UTC (2,332 KB)"
"572","Shape-from-Mask: A Deep Learning Based Human Body Shape Reconstruction from Binary Mask Images","Zhongping Ji, Xiao Qi, Yigang Wang, Gang Xu, Peng Du, Qing Wu","Graphics (cs.GR); Computer Vision and Pattern Recognition (cs.CV)","3D content creation is referred to as one of the most fundamental tasks of computer graphics. And many 3D modeling algorithms from 2D images or curves have been developed over the past several decades. Designers are allowed to align some conceptual images or sketch some suggestive curves, from front, side, and top views, and then use them as references in constructing a 3D model automatically or manually. However, to the best of our knowledge, no studies have investigated on 3D human body reconstruction in a similar manner. In this paper, we propose a deep learning based reconstruction of 3D human body shape from 2D orthographic views. A novel CNN-based regression network, with two branches corresponding to frontal and lateral views respectively, is designed for estimating 3D human body shape from 2D mask images. We train our networks separately to decouple the feature descriptors which encode the body parameters from different views, and fuse them to estimate an accurate human body shape. In addition, to overcome the shortage of training data required for this purpose, we propose some significantly data augmentation schemes for 3D human body shapes, which can be used to promote further research on this topic. Extensive experimen- tal results demonstrate that visually realistic and accurate reconstructions can be achieved effectively using our algorithm. Requiring only binary mask images, our method can help users create their own digital avatars quickly, and also make it easy to create digital human body for 3D game, virtual reality, online fashion shopping.","Fri, 22 Jun 2018 04:00:37 UTC (5,423 KB)"
"573","Estimation of groundwater storage from seismic data using deep learning","Timo Lahivaara, Alireza Malehmir, Antti Pasanen, Leo Karkkainen, Janne M.J. Huttunen, Jan S. Hesthaven","Computational Physics (physics.comp-ph)","We investigate the feasibility of employing convolutional neural networks to estimate the amount of groundwater stored in an aquifer and delineate water-table level from active-source seismic data. The seismic data to train and test the neural networks are obtained by solving wave propagation in a coupled poroviscoelastic-elastic media. A discontinuous Galerkin method is used to model wave propagation whereas a deep convolutional neural network is used for the parameter estimation problem. In the numerical experiment, the primary unknowns, the amount of stored groundwater and water-table level, are estimated, while the remaining parameters, assumed to be of less of interest, are successfully marginalized in the convolutional neural networks-based solution. This study, through synthetic data, illustrates the potential of deep learning methods to extract additional aquifer information from seismic data, which otherwise would be impossible based on a set of reflection seismic sections or velocity tomograms.","Thu, 21 Jun 2018 18:11:00 UTC (5,037 KB)[v2] Wed, 29 Aug 2018 10:22:31 UTC (5,147 KB)"
"574","Can Deep Learning Relax Endomicroscopy Hardware Miniaturization Requirements?","Saeed Izadi, Kathleen P. Moriarty, Ghassan Hamarneh","Computer Vision and Pattern Recognition (cs.CV)","Confocal laser endomicroscopy (CLE) is a novel imaging modality that provides in vivo histological cross-sections of examined tissue. Recently, attempts have been made to develop miniaturized in vivo imaging devices, specifically confocal laser microscopes, for both clinical and research applications. However, current implementations of miniature CLE components, such as confocal lenses, compromise image resolution, signal-to-noise ratio, or both, which negatively impacts the utility of in vivo imaging. In this work, we demonstrate that software-based techniques can be used to recover lost information due to endomicroscopy hardware miniaturization and reconstruct images of higher resolution. Particularly, a densely connected convolutional neural network is used to reconstruct a high-resolution CLE image from a low-resolution input. In the proposed network, each layer is directly connected to all subsequent layers, which results in an effective combination of low-level and high-level features and efficient information flow throughout the network. To train and evaluate our network, we use a dataset of 181 high-resolution CLE images. Both quantitative and qualitative results indicate superiority of the proposed network compared to traditional interpolation techniques and competing learning-based methods. This work demonstrates that software-based super-resolution is a viable approach to compensate for loss of resolution due to endoscopic hardware miniaturization.","Thu, 21 Jun 2018 17:28:00 UTC (5,552 KB)"
"575","Layouts from Panoramic Images with Geometry and Deep Learning","Clara Fernandez-Labrador, Alejandro Perez-Yus, Gonzalo Lopez-Nicolas, Jose J. Guerrero","Computer Vision and Pattern Recognition (cs.CV)","In this paper, we propose a novel procedure for 3D layout recovery of indoor scenes from single 360 degrees panoramic images. With such images, all scene is seen at once, allowing to recover closed geometries. Our method combines strategically the accuracy provided by geometric reasoning (lines and vanishing points) with the higher level of data abstraction and pattern recognition achieved by deep learning techniques (edge and normal maps). Thus, we extract structural corners from which we generate layout hypotheses of the room assuming Manhattan world. The best layout model is selected, achieving good performance on both simple rooms (box-type) and complex shaped rooms (with more than four walls). Experiments of the proposed approach are conducted within two public datasets, SUN360 and Stanford (2D-3D-S) demonstrating the advantages of estimating layouts by combining geometry and deep learning and the effectiveness of our proposal with respect to the state of the art.","Thu, 21 Jun 2018 15:38:18 UTC (8,730 KB)"
"576","Como funciona o Deep Learning","Moacir Antonelli Ponti, Gabriel B. Paranhos da Costa","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Deep Learning methods are currently the state-of-the-art in many problems which can be tackled via machine learning, in particular classification problems. However there is still lack of understanding on how those methods work, why they work and what are the limitations involved in using them. In this chapter we will describe in detail the transition from shallow to deep networks, include examples of code on how to implement them, as well as the main issues one faces when training a deep network. Afterwards, we introduce some theoretical background behind the use of deep models, and discuss their limitations.","Wed, 20 Jun 2018 18:04:09 UTC (1,392 KB)"
"577","Edge Intelligence: On-Demand Deep Learning Model Co-Inference with Device-Edge Synergy","En Li, Zhi Zhou, Xu Chen","Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Networking and Internet Architecture (cs.NI)","As the backbone technology of machine learning, deep neural networks (DNNs) have have quickly ascended to the spotlight. Running DNNs on resource-constrained mobile devices is, however, by no means trivial, since it incurs high performance and energy overhead. While offloading DNNs to the cloud for execution suffers unpredictable performance, due to the uncontrolled long wide-area network latency. To address these challenges, in this paper, we propose Edgent, a collaborative and on-demand DNN co-inference framework with device-edge synergy. Edgent pursues two design knobs: (1) DNN partitioning that adaptively partitions DNN computation between device and edge, in order to leverage hybrid computation resources in proximity for real-time DNN inference. (2) DNN right-sizing that accelerates DNN inference through early-exit at a proper intermediate DNN layer to further reduce the computation latency. The prototype implementation and extensive evaluations based on Raspberry Pi demonstrate Edgent's effectiveness in enabling on-demand low-latency edge intelligence.","Wed, 20 Jun 2018 16:56:54 UTC (2,758 KB)[v2] Thu, 21 Jun 2018 03:36:27 UTC (2,746 KB)[v3] Fri, 14 Sep 2018 02:37:07 UTC (2,745 KB)"
"578","Identifying viruses from metagenomic data by deep learning","Jie Ren, Kai Song, Chao Deng, Nathan A. Ahlgren, Jed A. Fuhrman, Yi Li, Xiaohui Xie, Fengzhu Sun","Genomics (q-bio.GN)","The recent development of metagenomic sequencing makes it possible to sequence microbial genomes including viruses in an environmental sample. Identifying viral sequences from metagenomic data is critical for downstream virus analyses. The existing reference-based and gene homology-based methods are not efficient in identifying unknown viruses or short viral sequences. Here we have developed a reference-free and alignment-free machine learning method, DeepVirFinder, for predicting viral sequences in metagenomic data using deep learning techniques. DeepVirFinder was trained based on a large number of viral sequences discovered before May 2015. Evaluated on the sequences after that date, DeepVirFinder outperformed the state-of-the-art method VirFinder at all contig lengths. Enlarging the training data by adding millions of purified viral sequences from environmental metavirome samples significantly improves the accuracy for predicting under-represented viruses. Applying DeepVirFinder to real human gut metagenomic samples from patients with colorectal carcinoma (CRC) identified 51,138 viral sequences belonging to 175 bins. Ten bins were associated with the cancer status, indicating their potential use for non-invasive diagnosis of CRC. In summary, DeepVirFinder greatly improved the precision and recall rates of viral identification, and it will significantly accelerate the discovery rate of viruses.","Wed, 20 Jun 2018 15:55:51 UTC (2,338 KB)"
"579","Deep Learning Classification of 3.5 GHz Band Spectrograms with Applications to Spectrum Sensing","W. Max Lees, Adam Wunderlich, Peter Jeavons, Paul D. Hale, Michael R. Souryal","Signal Processing (eess.SP); Machine Learning (cs.LG)","In the United States, the Federal Communications Commission has adopted rules permitting commercial wireless networks to share spectrum with federal incumbents in the 3.5 GHz Citizens Broadband Radio Service band (3550-3700 MHz). These rules require commercial wireless systems to vacate the band when coastal sensor networks detect radars operated by the U.S. military; a key example being the SPN-43 air traffic control radar. For such coastal sensor networks to meet their operating requirements, they require highly-accurate detection algorithms. In addition to their use in sensor networks, detection algorithms can assist in the generation of descriptive statistics for libraries of spectrum recordings. In this paper, using a library of over 14,000 3.5 GHz band spectrograms collected by a recent measurement campaign, we investigate the performance of three different methods for SPN-43 radar detection. Namely, we compare classical energy detection to two deep learning algorithms: a convolutional neural network and a long short-term memory recurrent neural network. Performing a thorough evaluation, we demonstrate that deep learning algorithms appreciably outperform energy detection. Finally, we apply the best-performing classifier to generate descriptive statistics for the 3.5 GHz spectrogram library. Overall, our findings highlight potential weaknesses of energy detection as well as the strengths of modern deep learning algorithms for radar detection in the 3.5 GHz band.","Tue, 19 Jun 2018 01:26:00 UTC (1,773 KB)[v2] Thu, 13 Sep 2018 15:03:20 UTC (1,773 KB)"
"580","A large-scale evaluation framework for EEG deep learning architectures","Felix A. Heilmeyer, Robin T. Schirrmeister, Lukas D. J. Fiederer, Martin Volker, Joos Behncke, Tonio Ball","Signal Processing (eess.SP); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Neurons and Cognition (q-bio.NC); Machine Learning (stat.ML)","EEG is the most common signal source for noninvasive BCI applications. For such applications, the EEG signal needs to be decoded and translated into appropriate actions. A recently emerging EEG decoding approach is deep learning with Convolutional or Recurrent Neural Networks (CNNs, RNNs) with many different architectures already published. Here we present a novel framework for the large-scale evaluation of different deep-learning architectures on different EEG datasets. This framework comprises (i) a collection of EEG datasets currently including 100 examples (recording sessions) from six different classification problems, (ii) a collection of different EEG decoding algorithms, and (iii) a wrapper linking the decoders to the data as well as handling structured documentation of all settings and (hyper-) parameters and statistics, designed to ensure transparency and reproducibility. As an applications example we used our framework by comparing three publicly available CNN architectures: the Braindecode Deep4 ConvNet, Braindecode Shallow ConvNet, and two versions of EEGNet. We also show how our framework can be used to study similarities and differences in the performance of different decoding methods across tasks. We argue that the deep learning EEG framework as described here could help to tap the full potential of deep learning for BCI applications.","Mon, 18 Jun 2018 15:49:23 UTC (990 KB)[v2] Wed, 25 Jul 2018 15:25:46 UTC (1,408 KB)"
"581","Combinatorial Testing for Deep Learning Systems","Lei Ma, Fuyuan Zhang, Minhui Xue, Bo Li, Yang Liu, Jianjun Zhao, Yadong Wang","Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)","Deep learning (DL) has achieved remarkable progress over the past decade and been widely applied to many safety-critical applications. However, the robustness of DL systems recently receives great concerns, such as adversarial examples against computer vision systems, which could potentially result in severe consequences. Adopting testing techniques could help to evaluate the robustness of a DL system and therefore detect vulnerabilities at an early stage. The main challenge of testing such systems is that its runtime state space is too large: if we view each neuron as a runtime state for DL, then a DL system often contains massive states, rendering testing each state almost impossible. For traditional software, combinatorial testing (CT) is an effective testing technique to reduce the testing space while obtaining relatively high defect detection abilities. In this paper, we perform an exploratory study of CT on DL systems. We adapt the concept in CT and propose a set of coverage criteria for DL systems, as well as a CT coverage guided test generation technique. Our evaluation demonstrates that CT provides a promising avenue for testing DL systems. We further pose several open questions and interesting directions for combinatorial testing of DL systems.","Wed, 20 Jun 2018 13:42:37 UTC (288 KB)"
"582","Dynamic Risk Assessment for Vehicles of Higher Automation Levels by Deep Learning","Patrik Feth, Mohammed Naveed Akram, Rene Schuster, Oliver Wasenmuller","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)","Vehicles of higher automation levels require the creation of situation awareness. One important aspect of this situation awareness is an understanding of the current risk of a driving situation. In this work, we present a novel approach for the dynamic risk assessment of driving situations based on images of a front stereo camera using deep learning. To this end, we trained a deep neural network with recorded monocular images, disparity maps and a risk metric for diverse traffic scenes. Our approach can be used to create the aforementioned situation awareness of vehicles of higher automation levels and can serve as a heterogeneous channel to systems based on radar or lidar sensors that are used traditionally for the calculation of risk metrics.","Wed, 20 Jun 2018 09:41:14 UTC (1,383 KB)"
"583","DeepAffinity: Interpretable Deep Learning of Compound-Protein Affinity through Unified Recurrent and Convolutional Neural Networks","Mostafa Karimi, Di Wu, Zhangyang Wang, Yang Shen","Biomolecules (q-bio.BM); Machine Learning (cs.LG); Machine Learning (stat.ML)","Motivation: Drug discovery demands rapid quantification of compound-protein interaction (CPI). However, there is a lack of methods that can predict compound-protein affinity from sequences alone with high applicability, accuracy, and interpretability. Results: We present a seamless integration of domain knowledges and learning-based approaches. Under novel representations of structurally-annotated protein sequences, a semi-supervised deep learning model that unifies recurrent and convolutional neural networks has been proposed to exploit both unlabeled and labeled data, for jointly encoding molecular representations and predicting affinities. Our representations and models outperform conventional options in achieving relative error in IC50 within 5-fold for test cases and 10-fold for protein classes not included for training. Performances for new protein classes with few labeled data are further improved by transfer learning. Furthermore, an attention mechanism is embedded to our model to add to its interpretability, as illustrated in case studies for predicting and explaining selective drug-target interactions.","Wed, 20 Jun 2018 03:39:33 UTC (988 KB)"
"584","Quantitative MRI: Absolute T1, T2 and Proton Density Parameters from Deep Learning","Qing Lyu, Ge Wang","Medical Physics (physics.med-ph)","Quantitative MRI is highly desirable in terms of intrinsic tissue parameters such as T1, T2 and proton density. This approach promises to minimize diagnostic variability and differentiate normal and pathological tissues by comparing tissue parameters to the normal ranges. Also, absolute quantification can help segment MRI tissue images with better accuracy compared to traditional qualitative segmentation methods. Currently, there are several methods proposed to quantify tissue parameters; however, all of them require excessive scan time and thus are difficult to be applied in clinical applications. In this paper, we propose a novel machine learning approach for MRI quantification, which can dramatically decrease the scan time and improve image quality.","Tue, 19 Jun 2018 20:18:17 UTC (762 KB)"
"585","DeepTerramechanics: Terrain Classification and Slip Estimation for Ground Robots via Deep Learning","Ramon Gonzalez, Karl Iagnemma","Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","Terramechanics plays a critical role in the areas of ground vehicles and ground mobile robots since understanding and estimating the variables influencing the vehicle-terrain interaction may mean the success or the failure of an entire mission. This research applies state-of-the-art algorithms in deep learning to two key problems: estimating wheel slip and classifying the terrain being traversed by a ground robot. Three data sets collected by ground robotic platforms (MIT single-wheel testbed, MSL Curiosity rover, and tracked robot Fitorobot) are employed in order to compare the performance of traditional machine learning methods (i.e. Support Vector Machine (SVM) and Multi-layer Perceptron (MLP)) against Deep Neural Networks (DNNs) and Convolutional Neural Networks (CNNs). This work also shows the impact that certain tuning parameters and the network architecture (MLP, DNN and CNN) play on the performance of those methods. This paper also contributes a deep discussion with the lessons learned in the implementation of DNNs and CNNs and how these methods can be extended to solve other problems.","Tue, 12 Jun 2018 07:29:25 UTC (4,487 KB)"
"586","Magnetic Resonance Spectroscopy Quantification using Deep Learning","Nima Hatami, Michael Sdika, Helene Ratiney","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Magnetic resonance spectroscopy (MRS) is an important technique in biomedical research and it has the unique capability to give a non-invasive access to the biochemical content (metabolites) of scanned organs. In the literature, the quantification (the extraction of the potential biomarkers from the MRS signals) involves the resolution of an inverse problem based on a parametric model of the metabolite signal. However, poor signal-to-noise ratio (SNR), presence of the macromolecule signal or high correlation between metabolite spectral patterns can cause high uncertainties for most of the metabolites, which is one of the main reasons that prevents use of MRS in clinical routine. In this paper, quantification of metabolites in MR Spectroscopic imaging using deep learning is proposed. A regression framework based on the Convolutional Neural Networks (CNN) is introduced for an accurate estimation of spectral parameters. The proposed model learns the spectral features from a large-scale simulated data set with different variations of human brain spectra and SNRs. Experimental results demonstrate the accuracy of the proposed method, compared to state of the art standard quantification method (QUEST), on concentration of 20 metabolites and the macromolecule.","Tue, 19 Jun 2018 13:56:56 UTC (403 KB)"
"587","ASIC Implementation of Time-Domain Digital Backpropagation with Deep-Learned Chromatic Dispersion Filters","Christoffer Fougstedt, Christian Hager, Lars Svensson, Henry D. Pfister, Per Larsson-Edefors","Information Theory (cs.IT); Machine Learning (stat.ML)","We consider time-domain digital backpropagation with chromatic dispersion filters jointly optimized and quantized using machine-learning techniques. Compared to the baseline implementations, we show improved BER performance and >40% power dissipation reductions in 28-nm CMOS.","Tue, 19 Jun 2018 13:42:33 UTC (62 KB)[v2] Wed, 20 Jun 2018 00:35:46 UTC (62 KB)"
"588","Effect of Hyper-Parameter Optimization on the Deep Learning Model Proposed for Distributed Attack Detection in Internet of Things Environment","Md Mohaimenuzzaman, Zahraa Said Abdallah, Joarder Kamruzzaman, Bala Srinivasan","Machine Learning (cs.LG); Cryptography and Security (cs.CR); Machine Learning (stat.ML)","This paper studies the effect of various hyper-parameters and their selection for the best performance of the deep learning model proposed in [1] for distributed attack detection in the Internet of Things (IoT). The findings show that there are three hyper-parameters that have more influence on the best performance achieved by the model. As a consequence, this study shows that the model's accuracy as reported in the paper is not achievable, based on the best selections of parameters, which is also supported by another recent publication [2].","Tue, 19 Jun 2018 06:11:32 UTC (98 KB)"
"589","Pressure Predictions of Turbine Blades with Deep Learning","Cheng'an Bai, Chao Zhou","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning has been used in many areas, such as feature detections in images and the game of go. This paper presents a study that attempts to use the deep learning method to predict turbomachinery performance. Three different deep neural networks are built and trained to predict the pressure distributions of turbine airfoils. The performance of a library of turbine airfoils were firstly predicted using methods based on Euler equations, which were then used to train and validate the deep learning neural networks. The results show that network with four layers of convolutional neural network and two layers of fully connected neural network provides the best predictions. For the best neural network architecture, the pressure prediction on more than 99% locations are better than 3% and 90% locations are better than 1%.","Tue, 12 Jun 2018 03:17:08 UTC (1,339 KB)"
"590","Deep Learning based Estimation of Weaving Target Maneuvers","Vitaly Shalumov, Itzik Klein","Machine Learning (cs.LG); Machine Learning (stat.ML)","In target tracking, the estimation of an unknown weaving target frequency is crucial for improving the miss distance. The estimation process is commonly carried out in a Kalman framework. The objective of this paper is to examine the potential of using neural networks in target tracking applications. To that end, we propose estimating the weaving frequency using deep neural networks, instead of classical Kalman framework based estimation. Particularly, we focus on the case where a set of possible constant target frequencies is known. Several neural network architectures, requiring low computational resources were designed to estimate the unknown frequency out of the known set of frequencies. The proposed approach performance is compared with the multiple model adaptive estimation algorithm. Simulation results show that in the examined scenarios, deep neural network outperforms multiple model adaptive estimation in terms of accuracy and the amount of required measurements to convergence.","Wed, 13 Jun 2018 06:16:14 UTC (565 KB)"
"591","Towards an efficient deep learning model for musical onset detection","Rong Gong, Xavier Serra","Sound (cs.SD); Information Retrieval (cs.IR); Audio and Speech Processing (eess.AS)","In this paper, we propose an efficient and reproducible deep learning model for musical onset detection (MOD). We first review the state-of-the-art deep learning models for MOD, and identify their shortcomings and challenges: (i) the lack of hyper-parameter tuning details, (ii) the non-availability of code for training models on other datasets, and (iii) ignoring the network capability when comparing different architectures. Taking the above issues into account, we experiment with seven deep learning architectures. The most efficient one achieves equivalent performance to our implementation of the state-of-the-art architecture. However, it has only 28.3% of the total number of trainable parameters compared to the state-of-the-art. Our experiments are conducted using two different datasets: one mainly consists of instrumental music excerpts, and another developed by ourselves includes only solo singing voice excerpts. Further, inter-dataset transfer learning experiments are conducted. The results show that the model pre-trained on one dataset fails to detect onsets on another dataset, which denotes the importance of providing the implementation code to enable re-training the model for a different dataset. Datasets, code and a Jupyter notebook running on Google Colab are publicly available to make this research understandable and easy to reproduce.","Mon, 18 Jun 2018 15:30:35 UTC (169 KB)[v2] Tue, 19 Jun 2018 10:12:23 UTC (169 KB)"
"592","Detecting Zero-day Controller Hijacking Attacks on the Power-Grid with Enhanced Deep Learning","Zecheng He, Aswin Raghavan, Sek Chai, Ruby Lee","Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)","Attacks against the control processor of a power-grid system, especially zero-day attacks, can be catastrophic. Earlier detection of the attacks can prevent further damage. However, detecting zero-day attacks can be challenging because they have no known code and have unknown behavior. In order to address the zero-day attack problem, we propose a data-driven defense by training a temporal deep learning model, using only normal data from legitimate processes that run daily in these power-grid systems, to model the normal behavior of the power-grid controller. Then, we can quickly find malicious codes running on the processor, by estimating deviations from the normal behavior with a statistical test. Experimental results on a real power-grid controller show that we can detect anomalous behavior with over 99.9% accuracy and nearly zero false positives.","Mon, 18 Jun 2018 04:28:18 UTC (4,411 KB)[v2] Fri, 21 Sep 2018 03:20:39 UTC (4,411 KB)"
"593","How Could Polyhedral Theory Harness Deep Learning?","Thiago Serra, Christian Tjandraatmadja, Srikumar Ramalingam","Optimization and Control (math.OC); Machine Learning (cs.LG); Machine Learning (stat.ML)","The holy grail of deep learning is to come up with an automatic method to design optimal architectures for different applications. In other words, how can we effectively dimension and organize neurons along the network layers based on the computational resources, input size, and amount of training data? We outline promising research directions based on polyhedral theory and mixed-integer representability that may offer an analytical approach to this question, in contrast to the empirical techniques often employed.","Sun, 17 Jun 2018 11:18:49 UTC (4 KB)"
"594","Learning from deep learning: better cosmological parameter inference from weak lensing maps","Dezs<U+0151> Ribli, Balint Armin Pataki, Istvan Csabai","Cosmology and Nongalactic Astrophysics (astro-ph.CO)","Gravitational weak lensing is one of the most promising probes of cosmology. Due to nonlinearities on small scales, the traditional analysis with two-point statistics does not fully capture all the underlying information. Multiple inference methods were proposed to extract more details based on higher order statistics, peak statistics, Minkowski functionals and recently convolutional neural networks (CNN). Here we present an improved CNN that gives significantly better estimates of ヘm and ヲ8 cosmological parameters from simulated convergence maps than the state of art methods and also is free of systematic bias. Going beyond ""black box"" style predictions, the investigation of the features learned by a high performing CNN revealed interesting insights. Without direct human assistance, only from the training data, the CNN discovered two familiar convolutional operators: the discrete Laplace operator and a Roberts cross kernel, which both characterize the steepness of the peaks. Using this insight we constructed a new, easy-to-understand, and robust peak counting algorithm which uses these operators, instead of the heights of the peaks. The new scheme significantly reduced prediction errors, and turned out to be even more accurate than the neural network.","Fri, 15 Jun 2018 14:26:18 UTC (350 KB)"
"595","Three dimensional Deep Learning approach for remote sensing image classification","Amina Ben Hamida (LISTIC), A Benoit (LISTIC), Patrick Lambert (LISTIC), Chokri Ben Amar (REGIM)","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Recently, a variety of approaches has been enriching the field of Remote Sensing (RS) image processing and analysis. Unfortunately, existing methods remain limited faced to the rich spatio-spectral content of today's large datasets. It would seem intriguing to resort to Deep Learning (DL) based approaches at this stage with regards to their ability to offer accurate semantic interpretation of the data. However, the specificity introduced by the coexistence of spectral and spatial content in the RS datasets widens the scope of the challenges presented to adapt DL methods to these contexts. Therefore, the aim of this paper is firstly to explore the performance of DL architectures for the RS hyperspectral dataset classification and secondly to introduce a new three-dimensional DL approach that enables a joint spectral and spatial information process. A set of three-dimensional schemes is proposed and evaluated. Experimental results based on well knownhyperspectral datasets demonstrate that the proposed method is able to achieve a better classification rate than state of the art methods with lower computational costs.","Fri, 15 Jun 2018 06:35:47 UTC (6,431 KB)"
"596","Deep Learning with Convolutional Neural Network for Objective Skill Evaluation in Robot-assisted Surgery","Ziheng Wang, Ann Majewicz Fey","Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","With the advent of robot-assisted surgery, the role of data-driven approaches to integrate statistics and machine learning is growing rapidly with prominent interests in objective surgical skill assessment. However, most existing work requires translating robot motion kinematics into intermediate features or gesture segments that are expensive to extract, lack efficiency, and require significant domain-specific knowledge. We propose an analytical deep learning framework for skill assessment in surgical training. A deep convolutional neural network is implemented to map multivariate time series data of the motion kinematics to individual skill levels. We perform experiments on the public minimally invasive surgical robotic dataset, JHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS). Our proposed learning model achieved a competitive accuracy of 94.1%, 90.3%, and 86.8%, in the standard training tasks: Suturing, Needle-passing, and Knot-tying, respectively. Without the need of engineered features or carefully-tuned gesture segmentation, our model can successfully decode skill information from raw motion profiles via end-to-end learning. Meanwhile, the proposed model is able to reliably interpret skills within 1-3 second window, without needing an observation of entire training trial. This study highlights the potentials of deep architectures for an proficient online skill assessment in modern surgical training.","Fri, 15 Jun 2018 03:22:06 UTC (7,690 KB)"
"597","Deep Learning Approximation: Zero-Shot Neural Network Speedup","Michele Pratusevich","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Neural networks offer high-accuracy solutions to a range of problems, but are costly to run in production systems because of computational and memory requirements during a forward pass. Given a trained network, we propose a techique called Deep Learning Approximation to build a faster network in a tiny fraction of the time required for training by only manipulating the network structure and coefficients without requiring re-training or access to the training data. Speedup is achieved by by applying a sequential series of independent optimizations that reduce the floating-point operations (FLOPs) required to perform a forward pass. First, lossless optimizations are applied, followed by lossy approximations using singular value decomposition (SVD) and low-rank matrix decomposition. The optimal approximation is chosen by weighing the relative accuracy loss and FLOP reduction according to a single parameter specified by the user. On PASCAL VOC 2007 with the YOLO network, we show an end-to-end 2x speedup in a network forward pass with a 5% drop in mAP that can be re-gained by finetuning.","Fri, 15 Jun 2018 01:25:47 UTC (46 KB)"
"598","Interactive Classification for Deep Learning Interpretation","Angel Cabrera, Fred Hohman, Jason Lin, Duen Horng Chau","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)","We present an interactive system enabling users to manipulate images to explore the robustness and sensitivity of deep learning image classifiers. Using modern web technologies to run in-browser inference, users can remove image features using inpainting algorithms and obtain new classifications in real time, which allows them to ask a variety of ""what if"" questions by experimentally modifying images and seeing how the model reacts. Our system allows users to compare and contrast what image regions humans and machine learning models use for classification, revealing a wide range of surprising results ranging from spectacular failures (e.g., a ""water bottle"" image becomes a ""concert"" when removing a person) to impressive resilience (e.g., a ""baseball player"" image remains correctly classified even without a glove or base). We demonstrate our system at The 2018 Conference on Computer Vision and Pattern Recognition (CVPR) for the audience to try it live. Our system is open-sourced at this https URL. A video demo is available at this https URL.","Thu, 14 Jun 2018 17:36:02 UTC (875 KB)"
"599","Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam","Mohammad Emtiyaz Khan, Didrik Nielsen, Voot Tangkaratt, Wu Lin, Yarin Gal, Akash Srivastava","Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Computation (stat.CO)","Uncertainty computation in deep learning is essential to design robust and reliable systems. Variational inference (VI) is a promising approach for such computation, but requires more effort to implement and execute compared to maximum-likelihood methods. In this paper, we propose new natural-gradient algorithms to reduce such efforts for Gaussian mean-field VI. Our algorithms can be implemented within the Adam optimizer by perturbing the network weights during gradient evaluations, and uncertainty estimates can be cheaply obtained by using the vector that adapts the learning rate. This requires lower memory, computation, and implementation effort than existing VI methods, while obtaining uncertainty estimates of comparable quality. Our empirical results confirm this and further suggest that the weight-perturbation in our algorithm could be useful for exploration in reinforcement learning and stochastic optimization.","Wed, 13 Jun 2018 05:45:22 UTC (13,308 KB)[v2] Sat, 7 Jul 2018 12:19:00 UTC (5,499 KB)[v3] Thu, 2 Aug 2018 08:21:25 UTC (1,732 KB)"
"600","Deep learning to represent sub-grid processes in climate models","Stephan Rasp, Michael S. Pritchard, Pierre Gentine","Atmospheric and Oceanic Physics (physics.ao-ph); Machine Learning (cs.LG); Machine Learning (stat.ML)","The representation of nonlinear sub-grid processes, especially clouds, has been a major source of uncertainty in climate models for decades. Cloud-resolving models better represent many of these processes and can now be run globally but only for short-term simulations of at most a few years because of computational limitations. Here we demonstrate that deep learning can be used to capture many advantages of cloud-resolving modeling at a fraction of the computational cost. We train a deep neural network to represent all atmospheric sub-grid processes in a climate model by learning from a multi-scale model in which convection is treated explicitly. The trained neural network then replaces the traditional sub-grid parameterizations in a global general circulation model in which it freely interacts with the resolved dynamics and the surface-flux scheme. The prognostic multi-year simulations are stable and closely reproduce not only the mean climate of the cloud-resolving simulation but also key aspects of variability, including precipitation extremes and the equatorial wave spectrum. Furthermore, the neural network approximately conserves energy despite not being explicitly instructed to. Finally, we show that the neural network parameterization generalizes to new surface forcing patterns but struggles to cope with temperatures far outside its training manifold. Our results show the feasibility of using deep learning for climate model parameterization. In a broader context, we anticipate that data-driven Earth System Model development could play a key role in reducing climate prediction uncertainty in the coming decade.","Tue, 12 Jun 2018 19:29:25 UTC (2,212 KB)[v2] Thu, 14 Jun 2018 17:10:58 UTC (2,212 KB)[v3] Fri, 7 Sep 2018 08:28:05 UTC (2,472 KB)"
"601","A Question-Answering framework for plots using Deep learning","Revanth Reddy, Rahul Ramesh, Ameet Deshpande, Mitesh M. Khapra","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep Learning has managed to push boundaries in a wide variety of tasks. One area of interest is to tackle problems in reasoning and understanding, in an aim to emulate human intelligence. In this work, we describe a deep learning model that addresses the reasoning task of question-answering on bar graphs and pie charts. We introduce a novel architecture that learns to identify various plot elements, quantify the represented values and determine a relative ordering of these statistical values. We test our model on the recently released FigureQA dataset, which provides images and accompanying questions, for bar graphs and pie charts, augmented with rich annotations. Our approach outperforms the state-of-the-art Relation Networks baseline and traditional CNN-LSTM models when evaluated on this dataset. Our model also has a considerably faster training time of approximately 2 days on 1 GPU compared to the Relation Networks baseline","Tue, 12 Jun 2018 17:31:23 UTC (1,019 KB)"
"602","Deep Learning to Detect Redundant Method Comments","Annie Louis, Santanu Kumar Dash, Earl T. Barr, Charles Sutton","Software Engineering (cs.SE); Computation and Language (cs.CL)","Comments in software are critical for maintenance and reuse. But apart from prescriptive advice, there is little practical support or quantitative understanding of what makes a comment useful. In this paper, we introduce the task of identifying comments which are uninformative about the code they are meant to document. To address this problem, we introduce the notion of comment entailment from code, high entailment indicating that a comment's natural language semantics can be inferred directly from the code. Although not all entailed comments are low quality, comments that are too easily inferred, for example, comments that restate the code, are widely discouraged by authorities on software style. Based on this, we develop a tool called CRAIC which scores method-level comments for redundancy. Highly redundant comments can then be expanded or alternately removed by the developer. CRAIC uses deep language models to exploit large software corpora without requiring expensive manual annotations of entailment. We show that CRAIC can perform the comment entailment task with good agreement with human judgements. Our findings also have implications for documentation tools. For example, we find that common tags in Javadoc are at least two times more predictable from code than non-Javadoc sentences, suggesting that Javadoc tags are less informative than more free-form comments","Tue, 12 Jun 2018 15:49:14 UTC (76 KB)"
"603","Deep Learning-based Intelligent Dual Connectivity for Mobility Management in Dense Network","Chujie Wang, Zhifeng Zhao, Qi Sun, Honggang Zhang","Networking and Internet Architecture (cs.NI)","Ultra-dense network deployment has been proposed as a key technique for achieving capacity goals in the fifth-generation (5G) mobile communication system. However, the deployment of smaller cells inevitably leads to more frequent handovers, thus making mobility management more challenging and reducing the capacity gains offered by the dense network deployment. In order to fully reap the gains for mobile users in such a network environment, we propose an intelligent dual connectivity mechanism for mobility management through deep learning-based mobility prediction. We first use LSTM (Long Short Term Memory) algorithm, one of deep learning algorithms, to learn every user equipment's (UE's) mobility pattern from its historical trajectories and predict its movement trends in the future. Based on the corresponding prediction results, the network will judge whether a handover is required for the UE. For the handover case, a dual connection will be established for the related UE. Thus, the UE can get the radio signal from two base stations in the handover process. Simulation results verify that the proposed intelligent dual connectivity mechanism can significantly improve the quality of service of mobile users in the handover process while guaranteeing the network energy efficiency.","Wed, 30 May 2018 07:59:12 UTC (581 KB)"
"604","Deep speckle correlation: a deep learning approach towards scalable imaging through scattering media","Yunzhe Li, Yujia Xue, Lei Tian","Image and Video Processing (eess.IV); Optics (physics.optics)","Imaging through scattering is an important, yet challenging problem. Tremendous progress has been made by exploiting the deterministic input-output ""transmission matrix"" for a fixed medium. However, this ""one-to-one"" mapping is highly susceptible to speckle decorrelations - small perturbations to the scattering medium lead to model errors and severe degradation of the imaging performance. Our goal here is to develop a new framework that is highly scalable to both medium perturbations and measurement requirement. To do so, we propose a statistical ""one-to-all"" deep learning technique that encapsulates a wide range of statistical variations for the model to be resilient to speckle decorrelations. Specifically, we develop a convolutional neural network (CNN) that is able to learn the statistical information contained in the speckle intensity patterns captured on a set of diffusers having the same macroscopic parameter. We then show for the first time, to the best of our knowledge, that the trained CNN is able to generalize and make high-quality object predictions through an entirely different set of diffusers of the same class. Our work paves the way to a highly scalable deep learning approach for imaging through scattering media.","Mon, 11 Jun 2018 16:27:19 UTC (16,393 KB)[v2] Wed, 26 Sep 2018 14:40:55 UTC (7,838 KB)"
"605","Writing Style Invariant Deep Learning Model for Historical Manuscripts Alignment","Majeed Kassis, Jumana Nassour, Jihad El-Sana","Computer Vision and Pattern Recognition (cs.CV)","Historical manuscript alignment is a widely known problem in document analysis. Finding the differences between manuscript editions is mostly done manually. In this paper, we present a writer independent deep learning model which is trained on several writing styles, and able to achieve high detection accuracy when tested on writing styles not present in training data. We test our model using cross validation, each time we train the model on five manuscripts, and test it on the other two manuscripts, never seen in the training data. We've applied cross validation on seven manuscripts, netting 21 different tests, achieving average accuracy of $\%92.17$. We also present a new alignment algorithm based on dynamic sized sliding window, which is able to successfully handle complex cases.","Thu, 7 Jun 2018 11:13:39 UTC (9,073 KB)"
"606","A Multi-task Deep Learning Architecture for Maritime Surveillance using AIS Data Streams","Duong Nguyen, Rodolphe Vadaine, Guillaume Hajduch, Rene Garello, Ronan Fablet","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","In a world of global trading, maritime safety, security and efficiency are crucial issues. We propose a multi-task deep learning framework for vessel monitoring using Automatic Identification System (AIS) data streams. We combine recurrent neural networks with latent variable modeling and an embedding of AIS messages to a new representation space to jointly address key issues to be dealt with when considering AIS data streams: massive amount of streaming data, noisy data and irregular timesampling. We demonstrate the relevance of the proposed deep learning framework on real AIS datasets for a three-task setting, namely trajectory reconstruction, anomaly detection and vessel type identification.","Wed, 6 Jun 2018 19:21:09 UTC (5,718 KB)[v2] Wed, 13 Jun 2018 08:25:33 UTC (5,718 KB)[v3] Tue, 7 Aug 2018 21:12:20 UTC (7,384 KB)"
"607","End to End Brain Fiber Orientation Estimation using Deep Learning","Nandakishore Puttashamachar, Ulas Bagci","Computer Vision and Pattern Recognition (cs.CV)","In this work, we explore the various Brain Neuron tracking techniques, which is one of the most significant applications of Diffusion Tensor Imaging. Tractography provides us with a non-invasive method to analyze underlying tissue micro-structure. Understanding the structure and organization of the tissues facilitates us with a diagnosis method to identify any aberrations and provide acute information on the occurrences of brain ischemia or stroke, the mutation of neurological diseases such as Alzheimer, multiple sclerosis and so on. Time if of essence and accurate localization of the aberrations can help save or change a diseased life. Following up with the limitations introduced by the current Tractography techniques such as computational complexity, reconstruction errors during tensor estimation and standardization, we aim to elucidate these limitations through our research findings. We introduce an end to end Deep Learning framework which can accurately estimate the most probable likelihood orientation at each voxel along a neuronal pathway. We use Probabilistic Tractography as our baseline model to obtain the training data and which also serve as a Tractography Gold Standard for our evaluations. Through experiments we show that our Deep Network can do a significant improvement over current Tractography implementations by reducing the run-time complexity to a significant new level. Our architecture also allows for variable sized input DWI signals eliminating the need to worry about memory issues as seen with the traditional techniques. The advantage of this architecture is that it is perfectly desirable to be processed on a cloud setup and utilize the existing multi GPU frameworks to perform whole brain Tractography in minutes rather than hours. We evaluate our network with Gold Standard and benchmark its performance across several parameters.","Mon, 4 Jun 2018 18:07:25 UTC (3,518 KB)"
"608","Deep Learning for Classification Tasks on Geospatial Vector Polygons","Rein van 't Veer, Peter Bloem, Erwin Folmer","Machine Learning (stat.ML); Machine Learning (cs.LG)","In this paper, we evaluate the accuracy of deep learning approaches on geospatial vector geometry classification tasks. The purpose of this evaluation is to investigate the ability of deep learning models to learn from geometry coordinates directly. Previous machine learning research applied to geospatial polygon data did not use geometries directly, but derived properties thereof. These are produced by way of extracting geometry properties such as Fourier descriptors. Instead, our introduced deep neural net architectures are able to learn on sequences of coordinates mapped directly from polygons. In three classification tasks we show that the deep learning architectures are competitive with common learning algorithms that require extracted features.","Mon, 11 Jun 2018 08:33:04 UTC (218 KB)"
"609","Synthetic Perfusion Maps: Imaging Perfusion Deficits in DSC-MRI with Deep Learning","Andreas Hess, Raphael Meier, Johannes Kaesmacher, Simon Jung, Fabien Scalzo, David Liebeskind, Roland Wiest, Richard McKinley","Computer Vision and Pattern Recognition (cs.CV)","In this work, we present a novel convolutional neural net- work based method for perfusion map generation in dynamic suscepti- bility contrast-enhanced perfusion imaging. The proposed architecture is trained end-to-end and solely relies on raw perfusion data for inference. We used a dataset of 151 acute ischemic stroke cases for evaluation. Our method generates perfusion maps that are comparable to the target maps used for clinical routine, while being model-free, fast, and less noisy.","Mon, 11 Jun 2018 07:52:36 UTC (2,617 KB)"
"610","Compression of phase-only holograms with JPEG standard and deep learning","Shuming Jiao, Zhi Jin, Chenliang Chang, Changyuan Zhou, Wenbin Zou, Xia Li","Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)","It is a critical issue to reduce the enormous amount of data in the processing, storage and transmission of a hologram in digital format. In photograph compression, the JPEG standard is commonly supported by almost every system and device. It will be favorable if JPEG standard is applicable to hologram compression, with advantages of universal compatibility. However, the reconstructed image from a JPEG compressed hologram suffers from severe quality degradation since some high frequency features in the hologram will be lost during the compression process. In this work, we employ a deep convolutional neural network to reduce the artifacts in a JPEG compressed hologram. Simulation and experimental results reveal that our proposed ""JPEG + deep learning"" hologram compression scheme can achieve satisfactory reconstruction results for a computer-generated phase-only hologram after compression.","Mon, 11 Jun 2018 05:11:58 UTC (632 KB)"
"611","Deep learning based inverse method for layout design","Yujie Zhang, Wenjing Ye","Signal Processing (eess.SP); Machine Learning (cs.LG); Machine Learning (stat.ML)","Layout design with complex constraints is a challenging problem to solve due to the non-uniqueness of the solution and the difficulties in incorporating the constraints into the conventional optimization-based methods. In this paper, we propose a design method based on the recently developed machine learning technique, Variational Autoencoder (VAE). We utilize the learning capability of the VAE to learn the constraints and the generative capability of the VAE to generate design candidates that automatically satisfy all the constraints. As such, no constraints need to be imposed during the design stage. In addition, we show that the VAE network is also capable of learning the underlying physics of the design problem, leading to an efficient design tool that does not need any physical simulation once the network is constructed. We demonstrated the performance of the method on two cases: inverse design of surface diffusion induced morphology change and mask design for optical microlithography.","Thu, 7 Jun 2018 01:55:06 UTC (1,293 KB)"
"612","A Systematic Evaluation of Recent Deep Learning Architectures for Fine-Grained Vehicle Classification","Krassimir Valev, Arne Schumann, Lars Sommer, Jurgen Beyerer","Computer Vision and Pattern Recognition (cs.CV)","Fine-grained vehicle classification is the task of classifying make, model, and year of a vehicle. This is a very challenging task, because vehicles of different types but similar color and viewpoint can often look much more similar than vehicles of same type but differing color and viewpoint. Vehicle make, model, and year in com- bination with vehicle color - are of importance in several applications such as vehicle search, re-identification, tracking, and traffic analysis. In this work we investigate the suitability of several recent landmark convolutional neural network (CNN) architectures, which have shown top results on large scale image classification tasks, for the task of fine-grained classification of vehicles. We compare the performance of the networks VGG16, several ResNets, Inception architectures, the recent DenseNets, and MobileNet. For classification we use the Stanford Cars-196 dataset which features 196 different types of vehicles. We investigate several aspects of CNN training, such as data augmentation and training from scratch vs. fine-tuning. Importantly, we introduce no aspects in the architectures or training process which are specific to vehicle classification. Our final model achieves a state-of-the-art classification accuracy of 94.6% outperforming all related works, even approaches which are specifically tailored for the task, e.g. by including vehicle part detections.","Fri, 8 Jun 2018 06:55:16 UTC (4,526 KB)"
"613","Fast Distributed Deep Learning via Worker-adaptive Batch Sizing","Chen Chen, Qizhen Weng, Wei Wang, Baochun Li, Bo Li","Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Performance (cs.PF)","Deep neural network models are usually trained in cluster environments, where the model parameters are iteratively refined by multiple worker machines in parallel. One key challenge in this regard is the presence of stragglers, which significantly degrades the learning performance. In this paper, we propose to eliminate stragglers by adapting each worker's training load to its processing capability; that is, slower workers receive a smaller batch of data to process. Following this idea, we develop a new synchronization scheme called LB-BSP (Load-balanced BSP). It works by coordinately setting the batch size of each worker so that they can finish batch processing at around the same time. A prerequisite for deciding the workers' batch sizes is to know their processing speeds before each iteration starts. For the best prediction accuracy, we adopt NARX, an extended recurrent neural network that accounts for both the historical speeds and the driving factors such as CPU and memory in prediction. We have implemented LB-BSP for both TensorFlow and MXNet. EC2 experiments against popular benchmarks show that LB-BSP can effectively accelerate the training of deep models, with up to 2x speedup.","Thu, 7 Jun 2018 04:15:58 UTC (1,496 KB)"
"614","Spectral Inference Networks: Unifying Spectral Methods With Deep Learning","David Pfau, Stig Petersen, Ashish Agarwal, David Barrett, Kim Stachenfeld","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","We present Spectral Inference Networks, a framework for learning eigenfunctions of linear operators by stochastic optimization. Spectral Inference Networks generalize Slow Feature Analysis to generic symmetric operators, and are closely related to Variational Monte Carlo methods from computational physics. As such, they can be a powerful tool for unsupervised representation learning from video or pairs of data. We derive a training algorithm for Spectral Inference Networks that addresses the bias in the gradients due to finite batch size and allows for online learning of multiple eigenfunctions. We show results of training Spectral Inference Networks on problems in quantum mechanics and feature learning for videos on synthetic datasets as well as the Arcade Learning Environment. Our results demonstrate that Spectral Inference Networks accurately recover eigenfunctions of linear operators, can discover interpretable representations from video and find meaningful subgoals in reinforcement learning environments.","Wed, 6 Jun 2018 14:28:03 UTC (8,670 KB)"
"615","Probabilistic Deep Learning using Random Sum-Product Networks","Robert Peharz, Antonio Vergari, Karl Stelzner, Alejandro Molina, Martin Trapp, Kristian Kersting, Zoubin Ghahramani","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","The need for consistent treatment of uncertainty has recently triggered increased interest in probabilistic deep learning methods. However, most current approaches have severe limitations when it comes to inference, since many of these models do not even permit to evaluate exact data likelihoods. Sum-product networks (SPNs), on the other hand, are an excellent architecture in that regard, as they allow to efficiently evaluate likelihoods, as well as arbitrary marginalization and conditioning tasks. Nevertheless, SPNs have not been fully explored as serious deep learning models, likely due to their special structural requirements, which complicate learning. In this paper, we make a drastic simplification and use random SPN structures which are trained in a ""classical deep learning manner"", i.e. employing automatic differentiation, SGD, and GPU support. The resulting models, called RAT-SPNs, yield prediction results comparable to deep neural networks, while still being interpretable as generative model and maintaining well-calibrated uncertainties. This property makes them highly robust under missing input features and enables them to naturally detect outliers and peculiar samples.","Tue, 5 Jun 2018 19:44:44 UTC (189 KB)[v2] Fri, 22 Jun 2018 14:46:45 UTC (188 KB)"
"616","Performance Evaluation of Deep Learning Networks for Semantic Segmentation of Traffic Stereo-Pair Images","Vlad Taran, Nikita Gordienko, Yuriy Kochura, Yuri Gordienko, Alexandr Rokovyi, Oleg Alienin, Sergii Stirenko","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Semantic image segmentation is one the most demanding task, especially for analysis of traffic conditions for self-driving cars. Here the results of application of several deep learning architectures (PSPNet and ICNet) for semantic image segmentation of traffic stereo-pair images are presented. The images from Cityscapes dataset and custom urban images were analyzed as to the segmentation accuracy and image inference time. For the models pre-trained on Cityscapes dataset, the inference time was equal in the limits of standard deviation, but the segmentation accuracy was different for various cities and stereo channels even. The distributions of accuracy (mean intersection over union - mIoU) values for each city and channel are asymmetric, long-tailed, and have many extreme outliers, especially for PSPNet network in comparison to ICNet network. Some statistical properties of these distributions (skewness, kurtosis) allow us to distinguish these two networks and open the question about relations between architecture of deep learning networks and statistical distribution of the predicted results (mIoU here). The results obtained demonstrated the different sensitivity of these networks to: (1) the local street view peculiarities in different cities that should be taken into account during the targeted fine tuning the models before their practical applications, (2) the right and left data channels in stereo-pairs. For both networks, the difference in the predicted results (mIoU here) for the right and left data channels in stereo-pairs is out of the limits of statistical error in relation to mIoU values. It means that the traffic stereo pairs can be effectively used not only for depth calculations (as it is usually used), but also as an additional data channel that can provide much more information about scene objects than simple duplication of the same street view images.","Tue, 5 Jun 2018 19:00:35 UTC (612 KB)"
"617","LSTM Benchmarks for Deep Learning Frameworks","Stefan Braun","Machine Learning (cs.LG); Machine Learning (stat.ML)","This study provides benchmarks for different implementations of LSTM units between the deep learning frameworks PyTorch, TensorFlow, Lasagne and Keras. The comparison includes cuDNN LSTMs, fused LSTM variants and less optimized, but more flexible LSTM implementations. The benchmarks reflect two typical scenarios for automatic speech recognition, notably continuous speech recognition and isolated digit recognition. These scenarios cover input sequences of fixed and variable length as well as the loss functions CTC and cross entropy. Additionally, a comparison between four different PyTorch versions is included. The code is available online this https URL.","Tue, 5 Jun 2018 17:15:41 UTC (1,473 KB)"
"618","Evidential Deep Learning to Quantify Classification Uncertainty","Murat Sensoy, Lance Kaplan, Melih Kandemir","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deterministic neural nets have been shown to learn effective predictors on a wide range of machine learning problems. However, as the standard approach is to train the network to minimize a prediction loss, the resultant model remains ignorant to its prediction confidence. Orthogonally to Bayesian neural nets that indirectly infer prediction uncertainty through weight uncertainties, we propose explicit modeling of the same using the theory of subjective logic. By placing a Dirichlet distribution on the class probabilities, we treat predictions of a neural net as subjective opinions and learn the function that collects the evidence leading to these opinions by a deterministic neural net from data. The resultant predictor for a multi-class classification problem is another Dirichlet distribution whose parameters are set by the continuous output of a neural net. We provide a preliminary analysis on how the peculiarities of our new loss function drive improved uncertainty estimation. We observe that our method achieves unprecedented success on detection of out-of-distribution queries and endurance against adversarial perturbations.","Tue, 5 Jun 2018 16:07:27 UTC (1,521 KB)[v2] Wed, 6 Jun 2018 19:41:22 UTC (1,141 KB)[v3] Wed, 31 Oct 2018 23:49:45 UTC (1,230 KB)"
"619","Concept-Oriented Deep Learning","Daniel T Chang","Artificial Intelligence (cs.AI)","Concepts are the foundation of human deep learning, understanding, and knowledge integration and transfer. We propose concept-oriented deep learning (CODL) which extends (machine) deep learning with concept representations and conceptual understanding capability. CODL addresses some of the major limitations of deep learning: interpretability, transferability, contextual adaptation, and requirement for lots of labeled training data. We discuss the major aspects of CODL including concept graph, concept representations, concept exemplars, and concept representation learning systems supporting incremental and continual learning.","Tue, 5 Jun 2018 15:50:30 UTC (181 KB)"
"620","Forecasting Crime with Deep Learning","Alexander Stec, Diego Klabjan","Machine Learning (stat.ML); Machine Learning (cs.LG)","The objective of this work is to take advantage of deep neural networks in order to make next day crime count predictions in a fine-grain city partition. We make predictions using Chicago and Portland crime data, which is augmented with additional datasets covering weather, census data, and public transportation. The crime counts are broken into 10 bins and our model predicts the most likely bin for a each spatial region at a daily level. We train this data using increasingly complex neural network structures, including variations that are suited to the spatial and temporal aspects of the crime prediction problem. With our best model we are able to predict the correct bin for overall crime count with 75.6% and 65.3% accuracy for Chicago and Portland, respectively. The results show the efficacy of neural networks for the prediction problem and the value of using external datasets in addition to standard crime data.","Tue, 5 Jun 2018 04:08:12 UTC (995 KB)"
"621","An Explainable Adversarial Robustness Metric for Deep Learning Neural Networks","Chirag Agarwal, Bo Dong, Dan Schonfeld, Anthony Hoogs","Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep Neural Networks(DNN) have excessively advanced the field of computer vision by achieving state of the art performance in various vision tasks. These results are not limited to the field of vision but can also be seen in speech recognition and machine translation tasks. Recently, DNNs are found to poorly fail when tested with samples that are crafted by making imperceptible changes to the original input images. This causes a gap between the validation and adversarial performance of a DNN. An effective and generalizable robustness metric for evaluating the performance of DNN on these adversarial inputs is still missing from the literature. In this paper, we propose Noise Sensitivity Score (NSS), a metric that quantifies the performance of a DNN on a specific input under different forms of fix-directional attacks. An insightful mathematical explanation is provided for deeply understanding the proposed metric. By leveraging the NSS, we also proposed a skewness based dataset robustness metric for evaluating a DNN's adversarial performance on a given dataset. Extensive experiments using widely used state of the art architectures along with popular classification datasets, such as MNIST, CIFAR-10, CIFAR-100, and ImageNet, are used to validate the effectiveness and generalization of our proposed metrics. Instead of simply measuring a DNN's adversarial robustness in the input domain, as previous works, the proposed NSS is built on top of insightful mathematical understanding of the adversarial attack and gives a more explicit explanation of the robustness.","Tue, 5 Jun 2018 03:07:56 UTC (2,169 KB)[v2] Wed, 6 Jun 2018 04:08:21 UTC (2,201 KB)"
"622","OpenTag: Open Attribute Value Extraction from Product Profiles [Deep Learning, Active Learning, Named Entity Recognition]","Guineng Zheng, Subhabrata Mukherjee, Xin Luna Dong, Feifei Li","Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (stat.ML)","Extraction of missing attribute values is to find values describing an attribute of interest from a free text input. Most past related work on extraction of missing attribute values work with a closed world assumption with the possible set of values known beforehand, or use dictionaries of values and hand-crafted features. How can we discover new attribute values that we have never seen before? Can we do this with limited human annotation or supervision? We study this problem in the context of product catalogs that often have missing values for many attributes of interest. In this work, we leverage product profile information such as titles and descriptions to discover missing values of product attributes. We develop a novel deep tagging model OpenTag for this extraction problem with the following contributions: (1) we formalize the problem as a sequence tagging task, and propose a joint model exploiting recurrent neural networks (specifically, bidirectional LSTM) to capture context and semantics, and Conditional Random Fields (CRF) to enforce tagging consistency, (2) we develop a novel attention mechanism to provide interpretable explanation for our model's decisions, (3) we propose a novel sampling strategy exploring active learning to reduce the burden of human annotation. OpenTag does not use any dictionary or hand-crafted features as in prior works. Extensive experiments in real-life datasets in different domains show that OpenTag with our active learning strategy discovers new attribute values from as few as 150 annotated samples (reduction in 3.3x amount of annotation effort) with a high F-score of 83%, outperforming state-of-the-art models.","Fri, 1 Jun 2018 19:41:07 UTC (2,918 KB)[v2] Sat, 6 Oct 2018 17:29:28 UTC (2,918 KB)"
"623","Relational inductive biases, deep learning, and graph networks","Peter W. Battaglia, Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, Caglar Gulcehre, Francis Song, Andrew Ballard, Justin Gilmer, George Dahl, Ashish Vaswani, Kelsey Allen, Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan Wierstra, Pushmeet Kohli, Matt Botvinick, Oriol Vinyals, Yujia Li, Razvan Pascanu","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between ""hand-engineering"" and ""end-to-end"" learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization, laying the foundation for more sophisticated, interpretable, and flexible patterns of reasoning. As a companion to this paper, we have released an open-source software library for building graph networks, with demonstrations of how to use them in practice.","Mon, 4 Jun 2018 17:58:18 UTC (11,795 KB)[v2] Mon, 11 Jun 2018 13:33:54 UTC (5,897 KB)[v3] Wed, 17 Oct 2018 17:51:36 UTC (6,725 KB)"
"624","Performance tuning for deep learning on a many-core processor (master thesis)","Philippos Papaphilippou","Distributed, Parallel, and Cluster Computing (cs.DC)","Convolutional neural networks (CNNs) are becoming very successful and popular for a variety of applications. The Loki many-core processor architecture is very promising for achieving specialised hardware performance and efficiency while being a general purpose solution. Loki combines many simple cores with increased control for the programmer. This freedom can be exploited to produce much more efficient code than in conventional multiprocessors but it also creates a very big design space for possible optimisations. In this project, I explore possible optimisations for a CNN application, their portability on different Loki-specific configurations, convolution parameters and inputs. Finally, I investigate the potential for adaptive algorithms for further performance increase.","Fri, 4 May 2018 11:01:28 UTC (5,525 KB)"
"625","Infrastructure Quality Assessment in Africa using Satellite Imagery and Deep Learning","Barak Oshri, Annie Hu, Peter Adelson, Xiao Chen, Pascaline Dupas, Jeremy Weinstein, Marshall Burke, David Lobell, Stefano Ermon","Computers and Society (cs.CY); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","The UN Sustainable Development Goals allude to the importance of infrastructure quality in three of its seventeen goals. However, monitoring infrastructure quality in developing regions remains prohibitively expensive and impedes efforts to measure progress toward these goals. To this end, we investigate the use of widely available remote sensing data for the prediction of infrastructure quality in Africa. We train a convolutional neural network to predict ground truth labels from the Afrobarometer Round 6 survey using Landsat 8 and Sentinel 1 satellite imagery. Our best models predict infrastructure quality with AUROC scores of 0.881 on Electricity, 0.862 on Sewerage, 0.739 on Piped Water, and 0.786 on Roads using Landsat 8. These performances are significantly better than models that leverage OpenStreetMap or nighttime light intensity on the same tasks. We also demonstrate that our trained model can accurately make predictions in an unseen country after fine-tuning on a small sample of images. Furthermore, the model can be deployed in regions with limited samples to predict infrastructure outcomes with higher performance than nearest neighbor spatial interpolation.","Sun, 3 Jun 2018 23:30:01 UTC (7,840 KB)"
"626","k-Space Deep Learning for Parallel MRI: Application to Time-Resolved MR Angiography","Eunju Cha, Eung Yeop Kim, Jong Chul Ye","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","Time-resolved angiography with interleaved stochastic trajectories (TWIST) has been widely used for dynamic contrast enhanced MRI (DCE-MRI). To achieve highly accelerated acquisitions, TWIST combines the periphery of the k-space data from several adjacent frames to reconstruct one temporal frame. However, this view-sharing scheme limits the true temporal resolution of TWIST. Moreover, the k-space sampling patterns have been specially designed for a specific generalized autocalibrating partial parallel acquisition (GRAPPA) factor so that it is not possible to reduce the number of view-sharing once the k-data is acquired. To address these issues, this paper proposes a novel k-space deep learning approach for parallel MRI. In particular, we have designed our neural network so that accurate k-space interpolations are performed simultaneously for multiple coils by exploiting the redundancies along the coils and images. Reconstruction results using in vivo TWIST data set confirm that the proposed method can immediately generate high-quality reconstruction results with various choices of view- sharing, allowing us to exploit the trade-off between spatial and temporal resolution in time-resolved MR angiography.","Sun, 3 Jun 2018 14:56:46 UTC (4,788 KB)[v2] Sun, 10 Jun 2018 06:51:12 UTC (7,258 KB)"
"627","Eye in the Sky: Real-time Drone Surveillance System (DSS) for Violent Individuals Identification using ScatterNet Hybrid Deep Learning Network","Amarjot Singh, Devendra Patil, SN Omkar","Computer Vision and Pattern Recognition (cs.CV)","Drone systems have been deployed by various law enforcement agencies to monitor hostiles, spy on foreign drug cartels, conduct border control operations, etc. This paper introduces a real-time drone surveillance system to identify violent individuals in public areas. The system first uses the Feature Pyramid Network to detect humans from aerial images. The image region with the human is used by the proposed ScatterNet Hybrid Deep Learning (SHDL) network for human pose estimation. The orientations between the limbs of the estimated pose are next used to identify the violent individuals. The proposed deep network can learn meaningful representations quickly using ScatterNet and structural priors with relatively fewer labeled examples. The system detects the violent individuals in real-time by processing the drone images in the cloud. This research also introduces the aerial violent individual dataset used for training the deep network which hopefully may encourage researchers interested in using deep learning for aerial surveillance. The pose estimation and violent individuals identification performance is compared with the state-of-the-art techniques.","Sun, 3 Jun 2018 07:44:11 UTC (6,300 KB)"
"628","BoxNet: Deep Learning Based Biomedical Image Segmentation Using Boxes Only Annotation","Lin Yang, Yizhe Zhang, Zhuo Zhao, Hao Zheng, Peixian Liang, Michael T. C. Ying, Anil T. Ahuja, Danny Z. Chen","Computer Vision and Pattern Recognition (cs.CV)","In recent years, deep learning (DL) methods have become powerful tools for biomedical image segmentation. However, high annotation efforts and costs are commonly needed to acquire sufficient biomedical training data for DL models. To alleviate the burden of manual annotation, in this paper, we propose a new weakly supervised DL approach for biomedical image segmentation using boxes only annotation. First, we develop a method to combine graph search (GS) and DL to generate fine object masks from box annotation, in which DL uses box annotation to compute a rough segmentation for GS and then GS is applied to locate the optimal object boundaries. During the mask generation process, we carefully utilize information from box annotation to filter out potential errors, and then use the generated masks to train an accurate DL segmentation network. Extensive experiments on gland segmentation in histology images, lymph node segmentation in ultrasound images, and fungus segmentation in electron microscopy images show that our approach attains superior performance over the best known state-of-the-art weakly supervised DL method and is able to achieve (1) nearly the same accuracy compared to fully supervised DL methods with far less annotation effort, (2) significantly better results with similar annotation time, and (3) robust performance in various applications.","Sat, 2 Jun 2018 07:10:30 UTC (18,320 KB)"
"629","Surgical Activity Recognition in Robot-Assisted Radical Prostatectomy using Deep Learning","Aneeq Zia, Andrew Hung, Irfan Essa, Anthony Jarc","Computer Vision and Pattern Recognition (cs.CV)","Adverse surgical outcomes are costly to patients and hospitals. Approaches to benchmark surgical care are often limited to gross measures across the entire procedure despite the performance of particular tasks being largely responsible for undesirable outcomes. In order to produce metrics from tasks as opposed to the whole procedure, methods to recognize automatically individual surgical tasks are needed. In this paper, we propose several approaches to recognize surgical activities in robot-assisted minimally invasive surgery using deep learning. We collected a clinical dataset of 100 robot-assisted radical prostatectomies (RARP) with 12 tasks each and propose `RP-Net', a modified version of InceptionV3 model, for image based surgical activity recognition. We achieve an average precision of 80.9% and average recall of 76.7% across all tasks using RP-Net which out-performs all other RNN and CNN based models explored in this paper. Our results suggest that automatic surgical activity recognition during RARP is feasible and can be the foundation for advanced analytics.","Fri, 1 Jun 2018 17:55:38 UTC (800 KB)"
"630","Solving stochastic differential equations and Kolmogorov equations by means of deep learning","Christian Beck, Sebastian Becker, Philipp Grohs, Nor Jaafari, Arnulf Jentzen","Numerical Analysis (math.NA); Machine Learning (cs.LG); Probability (math.PR); Machine Learning (stat.ML)","Stochastic differential equations (SDEs) and the Kolmogorov partial differential equations (PDEs) associated to them have been widely used in models from engineering, finance, and the natural sciences. In particular, SDEs and Kolmogorov PDEs, respectively, are highly employed in models for the approximative pricing of financial derivatives. Kolmogorov PDEs and SDEs, respectively, can typically not be solved explicitly and it has been and still is an active topic of research to design and analyze numerical methods which are able to approximately solve Kolmogorov PDEs and SDEs, respectively. Nearly all approximation methods for Kolmogorov PDEs in the literature suffer under the curse of dimensionality or only provide approximations of the solution of the PDE at a single fixed space-time point. In this paper we derive and propose a numerical approximation method which aims to overcome both of the above mentioned drawbacks and intends to deliver a numerical approximation of the Kolmogorov PDE on an entire region $[a,b]^d$ without suffering from the curse of dimensionality. Numerical results on examples including the heat equation, the Black-Scholes model, the stochastic Lorenz equation, and the Heston model suggest that the proposed approximation algorithm is quite effective in high dimensions in terms of both accuracy and speed.","Fri, 1 Jun 2018 16:18:57 UTC (76 KB)"
"631","k-Space Deep Learning for Reference-free EPI Ghost Correction","Juyoung Lee, Yoseob Han, Jong Chul Ye","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","Nyquist ghost artifacts in EPI images are originated from phase mismatch between the even and odd echoes. However, conventional correction methods using reference scans often produce erroneous results especially in high-field MRI due to the non-linear and time-varying local magnetic field changes. Recently, it was shown that the problem of ghost correction can be transformed into k-space data interpolation problem that can be solved using the annihilating filter-based low-rank Hankel structured matrix completion approach (ALOHA). Another recent discovery has shown that the deep convolutional neural network is closely related to the data-driven Hankel matrix decomposition. By synergistically combining these findings, here we propose a k-space deep learning approach that immediately corrects the k-space phase mismatch without a reference scan. Reconstruction results using 7T in vivo data showed that the proposed reference-free k-space deep learning approach for EPI ghost correction significantly improves the image quality compared to the existing methods, and the computing time is several orders of magnitude faster.","Fri, 1 Jun 2018 01:01:27 UTC (4,610 KB)[v2] Sun, 10 Jun 2018 07:17:27 UTC (4,613 KB)"
"632","Interpreting Deep Learning: The Machine Learning Rorschach Test?","Adam S. Charles","Machine Learning (stat.ML); Machine Learning (cs.LG)","Theoretical understanding of deep learning is one of the most important tasks facing the statistics and machine learning communities. While deep neural networks (DNNs) originated as engineering methods and models of biological networks in neuroscience and psychology, they have quickly become a centerpiece of the machine learning toolbox. Unfortunately, DNN adoption powered by recent successes combined with the open-source nature of the machine learning community, has outpaced our theoretical understanding. We cannot reliably identify when and why DNNs will make mistakes. In some applications like text translation these mistakes may be comical and provide for fun fodder in research talks, a single error can be very costly in tasks like medical imaging. As we utilize DNNs in increasingly sensitive applications, a better understanding of their properties is thus imperative. Recent advances in DNN theory are numerous and include many different sources of intuition, such as learning theory, sparse signal analysis, physics, chemistry, and psychology. An interesting pattern begins to emerge in the breadth of possible interpretations. The seemingly limitless approaches are mostly constrained by the lens with which the mathematical operations are viewed. Ultimately, the interpretation of DNNs appears to mimic a type of Rorschach test --- a psychological test wherein subjects interpret a series of seemingly ambiguous ink-blots. Validation for DNN theory requires a convergence of the literature. We must distinguish between universal results that are invariant to the analysis perspective and those that are specific to a particular network configuration. Simultaneously we must deal with the fact that many standard statistical tools for quantifying generalization or empirically assessing important network features are difficult to apply to DNNs.","Fri, 1 Jun 2018 00:35:32 UTC (256 KB)"
"633","Deep Learning with unsupervised data labeling for weeds detection on UAV images","M.Dian. Bah, Adel Hafiane, Raphael Canals","Computer Vision and Pattern Recognition (cs.CV)","In modern agriculture, usually weeds control consists in spraying herbicides all over the agricultural field. This practice involves significant waste and cost of herbicide for farmers and environmental pollution. One way to reduce the cost and environmental impact is to allocate the right doses of herbicide at the right place and at the right time (Precision Agriculture). Nowadays, Unmanned Aerial Vehicle (UAV) is becoming an interesting acquisition system for weeds localization and management due to its ability to obtain the images of the entire agricultural field with a very high spatial resolution and at low cost. Despite the important advances in UAV acquisition systems, automatic weeds detection remains a challenging problem because of its strong similarity with the crops. Recently Deep Learning approach has shown impressive results in different complex classification problem. However, this approach needs a certain amount of training data but, creating large agricultural datasets with pixel-level annotations by expert is an extremely time consuming task. In this paper, we propose a novel fully automatic learning method using Convolutional Neuronal Networks (CNNs) with unsupervised training dataset collection for weeds detection from UAV images. The proposed method consists in three main phases. First we automatically detect the crop lines and using them to identify the interline weeds. In the second phase, interline weeds are used to constitute the training dataset. Finally, we performed CNNs on this dataset to build a model able to detect the crop and weeds in the images. The results obtained are comparable to the traditional supervised training data labeling. The accuracy gaps are 1.5% in the spinach field and 6% in the bean field.","Thu, 31 May 2018 09:43:40 UTC (6,569 KB)"
"634","Collaborative Multi-modal deep learning for the personalized product retrieval in Facebook Marketplace","Lu Zheng, Zhao Tan, Kun Han, Ren Mao","Information Retrieval (cs.IR)","Facebook Marketplace is quickly gaining momentum among consumers as a favored customer-to-customer (C2C) product trading platform. The recommendation system behind it helps to significantly improve the user experience. Building the recommendation system for Facebook Marketplace is challenging for two reasons: 1) Scalability: the number of products in Facebook Marketplace is huge. Tens of thousands of products need to be scored and recommended within a couple hundred milliseconds for millions of users every day; 2) Cold start: the life span of the C2C products is very short and the user activities on the products are sparse. Thus it is difficult to accumulate enough product level signals for recommendation and we are facing a significant cold start issue. In this paper, we propose to address both the scalability and the cold-start issue by building a collaborative multi-modal deep learning based retrieval system where the compact embeddings for the users and the products are trained with the multi-modal content information. This system shows significant improvement over the benchmark in online and off-line experiments: In the online experiment, it increases the number of messages initiated by the buyer to the seller by +26.95%; in the off-line experiment, it improves the prediction accuracy by +9.58%.","Thu, 31 May 2018 03:41:41 UTC (693 KB)"
"635","On Consensus-Optimality Trade-offs in Collaborative Deep Learning","Zhanhong Jiang, Aditya Balu, Chinmay Hegde, Soumik Sarkar","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","In distributed machine learning, where agents collaboratively learn from diverse private data sets, there is a fundamental tension between consensus and optimality. In this paper, we build on recent algorithmic progresses in distributed deep learning to explore various consensus-optimality trade-offs over a fixed communication topology. First, we propose the incremental consensus-based distributed SGD (i-CDSGD) algorithm, which involves multiple consensus steps (where each agent communicates information with its neighbors) within each SGD iteration. Second, we propose the generalized consensus-based distributed SGD (g-CDSGD) algorithm that enables us to navigate the full spectrum from complete consensus (all agents agree) to complete disagreement (each agent converges to individual model parameters). We analytically establish convergence of the proposed algorithms for strongly convex and nonconvex objective functions; we also analyze the momentum variants of the algorithms for the strongly convex case. We support our algorithms via numerical experiments, and demonstrate significant improvements over existing methods for collaborative deep learning.","Wed, 30 May 2018 17:59:24 UTC (2,726 KB)"
"636","Counterstrike: Defending Deep Learning Architectures Against Adversarial Samples by Langevin Dynamics with Supervised Denoising Autoencoder","Vignesh Srinivasan, Arturo Marban, Klaus-Robert Muller, Wojciech Samek, Shinichi Nakajima","Machine Learning (cs.LG); Machine Learning (stat.ML)","Adversarial attacks on deep learning models have been demonstrated to be imperceptible to a human, while decreasing the model performance considerably. Attempts to provide invariance against such attacks have denoised adversarial samples to only send cleaned samples to the classifier. In a similar spirit this paper proposes a novel effective strategy that allows to relax adversarial samples onto the underlying manifold of the (unknown) target class distribution. Specifically, given an off-manifold adversarial example, our Metroplis-adjusted Langevin algorithm (Mala) guided through a supervised denoising autoencoder network (sDAE) allows to drive the adversarial samples towards high density regions of the data generating distribution. So, in a nutshell the adversarial example is transformed back from off-manifold onto the data manifold for which the learning model was originally trained and where it can perform well and robustly. Experiments on various benchmark datasets show that our novel Malade method exhibits a high robustness against blackbox and whitebox attacks and outperforms state-of-the-art defense algorithms.","Wed, 30 May 2018 15:01:38 UTC (895 KB)"
"637","Radio Galaxy Zoo: ClaRAN - A Deep Learning Classifier for Radio Morphologies","Chen Wu, O. Ivy Wong, Lawrence Rudnick, Stanislav S. Shabala, Matthew J. Alger, Julie K. Banfield, Cheng Soon Ong, Sarah V. White, Avery F. Garon, Ray P. Norris, Heinz Andernach, Jean Tate, Vesna Lukic, Hongming Tang, Kevin Schawinski, Foivos I. Diakogiannis","Instrumentation and Methods for Astrophysics (astro-ph.IM)","The upcoming next-generation large area radio continuum surveys can expect tens of millions of radio sources, rendering the traditional method for radio morphology classification through visual inspection unfeasible. We present ClaRAN - Classifying Radio sources Automatically with Neural networks - a proof-of-concept radio source morphology classifier based upon the Faster Region-based Convolutional Neutral Networks (Faster R-CNN) method. Specifically, we train and test ClaRAN on the FIRST and WISE images from the Radio Galaxy Zoo Data Release 1 catalogue. ClaRAN provides end users with automated identification of radio source morphology classifications from a simple input of a radio image and a counterpart infrared image of the same region. ClaRAN is the first open-source, end-to-end radio source morphology classifier that is capable of locating and associating discrete and extended components of radio sources in a fast (< 200 milliseconds per image) and accurate (>= 90 %) fashion. Future work will improve ClaRAN's relatively lower success rates in dealing with multi-source fields and will enable ClaRAN to identify sources on much larger fields without loss in classification accuracy.","Wed, 30 May 2018 14:42:51 UTC (7,141 KB)[v2] Mon, 29 Oct 2018 14:06:58 UTC (6,613 KB)"
"638","Automatic Large-Scale Data Acquisition via Crowdsourcing for Crosswalk Classification: A Deep Learning Approach","Rodrigo F. Berriel, Franco Schmidt Rossi, Alberto F. de Souza, Thiago Oliveira-Santos","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Correctly identifying crosswalks is an essential task for the driving activity and mobility autonomy. Many crosswalk classification, detection and localization systems have been proposed in the literature over the years. These systems use different perspectives to tackle the crosswalk classification problem: satellite imagery, cockpit view (from the top of a car or behind the windshield), and pedestrian perspective. Most of the works in the literature are designed and evaluated using small and local datasets, i.e. datasets that present low diversity. Scaling to large datasets imposes a challenge for the annotation procedure. Moreover, there is still need for cross-database experiments in the literature because it is usually hard to collect the data in the same place and conditions of the final application. In this paper, we present a crosswalk classification system based on deep learning. For that, crowdsourcing platforms, such as OpenStreetMap and Google Street View, are exploited to enable automatic training via automatic acquisition and annotation of a large-scale database. Additionally, this work proposes a comparison study of models trained using fully-automatic data acquisition and annotation against models that were partially annotated. Cross-database experiments were also included in the experimentation to show that the proposed methods enable use with real world applications. Our results show that the model trained on the fully-automatic database achieved high overall accuracy (94.12%), and that a statistically significant improvement (to 96.30%) can be achieved by manually annotating a specific part of the database. Finally, the results of the cross-database experiments show that both models are robust to the many variations of image and scenarios, presenting a consistent behavior.","Wed, 30 May 2018 13:55:14 UTC (1,940 KB)"
"639","Learn to Combine Modalities in Multimodal Deep Learning","Kuan Liu, Yanen Li, Ning Xu, Prem Natarajan","Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","Combining complementary information from multiple modalities is intuitively appealing for improving the performance of learning-based approaches. However, it is challenging to fully leverage different modalities due to practical challenges such as varying levels of noise and conflicts between modalities. Existing methods do not adopt a joint approach to capturing synergies between the modalities while simultaneously filtering noise and resolving conflicts on a per sample basis. In this work we propose a novel deep neural network based technique that multiplicatively combines information from different source modalities. Thus the model training process automatically focuses on information from more reliable modalities while reducing emphasis on the less reliable modalities. Furthermore, we propose an extension that multiplicatively combines not only the single-source modalities, but a set of mixtured source modalities to better capture cross-modal signal correlations. We demonstrate the effectiveness of our proposed technique by presenting empirical results on three multimodal classification tasks from different domains. The results show consistent accuracy improvements on all three tasks.","Tue, 29 May 2018 22:24:48 UTC (862 KB)"
"640","Deep Learning under Privileged Information Using Heteroscedastic Dropout","John Lambert, Ozan Sener, Silvio Savarese","Machine Learning (cs.LG); Machine Learning (stat.ML)","Unlike machines, humans learn through rapid, abstract model-building. The role of a teacher is not simply to hammer home right or wrong answers, but rather to provide intuitive comments, comparisons, and explanations to a pupil. This is what the Learning Under Privileged Information (LUPI) paradigm endeavors to model by utilizing extra knowledge only available during training. We propose a new LUPI algorithm specifically designed for Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). We propose to use a heteroscedastic dropout (i.e. dropout with a varying variance) and make the variance of the dropout a function of privileged information. Intuitively, this corresponds to using the privileged information to control the uncertainty of the model output. We perform experiments using CNNs and RNNs for the tasks of image classification and machine translation. Our method significantly increases the sample efficiency during learning, resulting in higher accuracy with a large margin when the number of training examples is limited. We also theoretically justify the gains in sample efficiency by providing a generalization error bound decreasing with $O(\frac{1}{n})$, where $n$ is the number of training examples, in an oracle case.","Tue, 29 May 2018 17:58:12 UTC (7,155 KB)"
"641","Adversarial Noise Attacks of Deep Learning Architectures - Stability Analysis via Sparse Modeled Signals","Yaniv Romano, Aviad Aberdam, Jeremias Sulam, Michael Elad","Machine Learning (stat.ML); Information Theory (cs.IT); Machine Learning (cs.LG)","Despite their impressive performance, deep convolutional neural networks (CNNs) have been shown to be sensitive to small adversarial perturbations. These nuisances, which one can barely notice, are powerful enough to fool sophisticated and well performing classifiers, leading to ridiculous misclassification results. In this paper we analyze the stability of state-of-the-art deep-learning classification machines to adversarial perturbations, where we assume that the signals belong to the (possibly multi-layer) sparse representation model. We start with convolutional sparsity and then proceed to its multi-layered version, which is tightly connected to CNNs. Our analysis links between the stability of the classification to noise and the underlying structure of the signal, quantified by the sparsity of its representation under a fixed dictionary. In addition, we offer similar stability theorems for two practical pursuit algorithms, which are posed as two different deep-learning architectures - the layered Thresholding and the layered Basis Pursuit. Our analysis establishes the better robustness of the later to adversarial attacks. We corroborate these theoretical results by numerical experiments on three datasets: MNIST, CIFAR-10 and CIFAR-100.","Tue, 29 May 2018 17:25:11 UTC (210 KB)[v2] Thu, 22 Nov 2018 06:01:52 UTC (469 KB)"
"642","NengoDL: Combining deep learning and neuromorphic modelling methods","Daniel Rasmussen","Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI)","NengoDL is a software framework designed to combine the strengths of neuromorphic modelling and deep learning. NengoDL allows users to construct biologically detailed neural models, intermix those models with deep learning elements (such as convolutional networks), and then efficiently simulate those models in an easy-to-use, unified framework. In addition, NengoDL allows users to apply deep learning training methods to optimize the parameters of biological neural models. In this paper we present basic usage examples, benchmarking, and details on the key implementation elements of NengoDL. More details can be found at this https URL .","Mon, 28 May 2018 19:36:45 UTC (161 KB)[v2] Wed, 30 May 2018 00:13:05 UTC (161 KB)"
"643","Deep learning for the R-parity violating supersymmetry searches at the LHC","Jun Guo, Jinmian Li, Tianjun Li, Fangzhou Xu, Wenxing Zhang","High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Experiment (hep-ex)","Supersymmetry with hadronic R-parity violation in which the lightest neutralino decays into three quarks is still weakly constrained. This work aims to further improve the current search for this scenario by the boosted decision tree method with additional information from jet substructure. In particular, we find a deep neural network turns out to perform well in characterizing the neutralino jet substructure. We first construct a Convolutional Neutral Network (CNN) which is capable of tagging the neutralino jet in any signal process by using the idea of jet image. When applied to pure jet samples, such a CNN outperforms the N-subjettiness variable by a factor of a few in tagging efficiency. Moreover, we find the method, which combines the CNN output and jet invariant mass, can perform better and is applicable to a wider range of neutralino mass than the CNN alone. Finally, the ATLAS search for the signal of gluino pair production with subsequent decay $\tilde{g} \to q q \tildeヶ^0_1 (\to q q q)$ is recasted as an application. In contrast to the pure sample, the heavy contamination among jets in this complex final state renders the discriminating powers of the CNN and N-subjettiness similar. By analyzing the jets substructure in events which pass the ATLAS cuts with our CNN method, the exclusion limit on gluino mass can be pushed up by $\sim200$ GeV for neutralino mass $\sim 100$ GeV.","Mon, 28 May 2018 01:56:11 UTC (944 KB)[v2] Mon, 15 Oct 2018 02:14:44 UTC (1,064 KB)"
"644","Legal Document Retrieval using Document Vector Embeddings and Deep Learning","Keet Sugathadasa, Buddhi Ayesha, Nisansa de Silva, Amal Shehan Perera, Vindula Jayawardana, Dimuthu Lakmal, Madhavi Perera","Information Retrieval (cs.IR)","Domain specific information retrieval process has been a prominent and ongoing research in the field of natural language processing. Many researchers have incorporated different techniques to overcome the technical and domain specificity and provide a mature model for various domains of interest. The main bottleneck in these studies is the heavy coupling of domain experts, that makes the entire process to be time consuming and cumbersome. In this study, we have developed three novel models which are compared against a golden standard generated via the on line repositories provided, specifically for the legal domain. The three different models incorporated vector space representations of the legal domain, where document vector generation was done in two different mechanisms and as an ensemble of the above two. This study contains the research being carried out in the process of representing legal case documents into different vector spaces, whilst incorporating semantic word measures and natural language processing techniques. The ensemble model built in this study, shows a significantly higher accuracy level, which indeed proves the need for incorporation of domain specific semantic similarity measures into the information retrieval process. This study also shows, the impact of varying distribution of the word similarity measures, against varying document vector dimensions, which can lead to improvements in the process of legal information retrieval.","Sun, 27 May 2018 20:55:50 UTC (1,943 KB)"
"645","Deployment of Customized Deep Learning based Video Analytics On Surveillance Cameras","Pratik Dubal, Rohan Mahadev, Suraj Kothawade, Kunal Dargan, Rishabh Iyer","Computer Vision and Pattern Recognition (cs.CV); Discrete Mathematics (cs.DM)","This paper demonstrates the effectiveness of our customized deep learning based video analytics system in various applications focused on security, safety, customer analytics and process compliance. We describe our video analytics system comprising of Search, Summarize, Statistics and real-time alerting, and outline its building blocks. These building blocks include object detection, tracking, face detection and recognition, human and face sub-attribute analytics. In each case, we demonstrate how custom models trained using data from the deployment scenarios provide considerably superior accuracies than off-the-shelf models. Towards this end, we describe our data processing and model training pipeline, which can train and fine-tune models from videos with a quick turnaround time. Finally, since most of these models are deployed on-site, it is important to have resource constrained models which do not require GPUs. We demonstrate how we custom train resource constrained models and deploy them on embedded devices without significant loss in accuracy. To our knowledge, this is the first work which provides a comprehensive evaluation of different deep learning models on various real-world customer deployment scenarios of surveillance video analytics. By sharing our implementation details and the experiences learned from deploying customized deep learning models for various customers, we hope that customized deep learning based video analytics is widely incorporated in commercial products around the world.","Sun, 27 May 2018 11:01:30 UTC (251 KB)[v2] Wed, 27 Jun 2018 14:04:07 UTC (251 KB)"
"646","Deep Learning Topological Invariants of Band Insulators","Ning Sun, Jinmin Yi, Pengfei Zhang, Huitao Shen, Hui Zhai","Strongly Correlated Electrons (cond-mat.str-el); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)","In this work we design and train deep neural networks to predict topological invariants for one-dimensional four-band insulators in AIII class whose topological invariant is the winding number, and two-dimensional two-band insulators in A class whose topological invariant is the Chern number. Given Hamiltonians in the momentum space as the input, neural networks can predict topological invariants for both classes with accuracy close to or higher than 90%, even for Hamiltonians whose invariants are beyond the training data set. Despite the complexity of the neural network, we find that the output of certain intermediate hidden layers resembles either the winding angle for models in AIII class or the solid angle (Berry curvature) for models in A class, indicating that neural networks essentially capture the mathematical formula of topological invariants. Our work demonstrates the ability of neural networks to predict topological invariants for complicated models with local Hamiltonians as the only input, and offers an example that even a deep neural network is understandable.","Sat, 26 May 2018 16:10:47 UTC (1,241 KB)[v2] Sat, 9 Jun 2018 10:48:10 UTC (1,241 KB)"
"647","L1-(2D)2PCANet: A Deep Learning Network for Face Recognition","YunKun Li, XiaoJun Wu, Josef Kittler","Computer Vision and Pattern Recognition (cs.CV)","In this paper, we propose a novel deep learning network L1-(2D)2PCANet for face recognition, which is based on L1-norm-based two-directional two-dimensional principal component analysis (L1-(2D)2PCA). In our network, the role of L1-(2D)2PCA is to learn the filters of multiple convolution layers. After the convolution layers, we deploy binary hashing and block-wise histogram for pooling. We test our network on some benchmark facial datasets YALE, AR, Extended Yale B, LFW-a and FERET with CNN, PCANet, 2DPCANet and L1-PCANet as comparison. The results show that the recognition performance of L1-(2D)2PCANet in all tests is better than baseline networks, especially when there are outliers in the test data. Owing to the L1-norm, L1-2D2PCANet is robust to outliers and changes of the training images.","Sat, 26 May 2018 12:56:21 UTC (685 KB)"
"648","Geometric Understanding of Deep Learning","Na Lei, Zhongxuan Luo, Shing-Tung Yau, David Xianfeng Gu","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning is the mainstream technique for many machine learning tasks, including image recognition, machine translation, speech recognition, and so on. It has outperformed conventional methods in various fields and achieved great successes. Unfortunately, the understanding on how it works remains unclear. It has the central importance to lay down the theoretic foundation for deep learning. In this work, we give a geometric view to understand deep learning: we show that the fundamental principle attributing to the success is the manifold structure in data, namely natural high dimensional data concentrates close to a low-dimensional manifold, deep learning learns the manifold and the probability distribution on it. We further introduce the concepts of rectified linear complexity for deep neural network measuring its learning capability, rectified linear complexity of an embedding manifold describing the difficulty to be learned. Then we show for any deep neural network with fixed architecture, there exists a manifold that cannot be learned by the network. Finally, we propose to apply optimal mass transportation theory to control the probability distribution in the latent space.","Sat, 26 May 2018 09:15:53 UTC (7,003 KB)[v2] Thu, 31 May 2018 00:30:35 UTC (6,460 KB)"
"649","Three-Dimensional Radiotherapy Dose Prediction on Head and Neck Cancer Patients with a Hierarchically Densely Connected U-net Deep Learning Architecture","Dan Nguyen, Xun Jia, David Sher, Mu-Han Lin, Zohaib Iqbal, Hui Liu, Steve Jiang","Medical Physics (physics.med-ph); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","The treatment planning process for patients with head and neck (H&N) cancer is regarded as one of the most complicated due large target volume, multiple prescription dose levels, and many radiation-sensitive critical structures near the target. Treatment planning for this site requires a high level of human expertise and a tremendous amount of effort to produce personalized high quality plans, taking as long as a week, which deteriorates the chances of tumor control and patient survival. To solve this problem, we propose to investigate a deep learning-based dose prediction model, Hierarchically Densely Connected U-net, based on two highly popular network architectures: U-net and DenseNet. We find that this new architecture is able to accurately and efficiently predict the dose distribution, outperforming the other two models, the Standard U-net and DenseNet, in homogeneity, dose conformity, and dose coverage on the test data. On average, our proposed model is capable of predicting the OAR max dose within 6.3% and mean dose within 5.1% of the prescription dose on the test data. The other models, the Standard U-net and DenseNet, performed worse, having an OAR max dose prediction error of 8.2% and 9.3%, respectively, and mean dose prediction error of 6.4% and 6.8%, respectively. In addition, our proposed model used 12 times less trainable parameters than the Standard U-net, and predicted the patient dose 4 times faster than DenseNet.","Fri, 25 May 2018 23:40:32 UTC (1,715 KB)"
"650","Underwater Fish Species Classification using Convolutional Neural Network and Deep Learning","Dhruv Rathi, Sushant Jain, Dr. S. Indu","Computer Vision and Pattern Recognition (cs.CV)","The target of this paper is to recommend a way for Automated classification of Fish species. A high accuracy fish classification is required for greater understanding of fish behavior in Ichthyology and by marine biologists. Maintaining a ledger of the number of fishes per species and marking the endangered species in large and small water bodies is required by concerned institutions. Majority of available methods focus on classification of fishes outside of water because underwater classification poses challenges such as background noises, distortion of images, the presence of other water bodies in images, image quality and occlusion. This method uses a novel technique based on Convolutional Neural Networks, Deep Learning and Image Processing to achieve an accuracy of 96.29%. This method ensures considerably discrimination accuracy improvements than the previously proposed methods.","Fri, 25 May 2018 12:34:10 UTC (553 KB)"
"651","Cautious Deep Learning","Yotam Hechtlinger, Barnabas Poczos, Larry Wasserman","Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Methodology (stat.ME)","Most classifiers operate by selecting the maximum of an estimate of the conditional distribution $p(y|x)$ where $x$ stands for the features of the instance to be classified and $y$ denotes its label. This often results in a hubristic bias: overconfidence in the assignment of a definite label. Usually, the observations are concentrated on a small volume but the classifier provides definite predictions for the entire space. We propose constructing conformal prediction sets [vovk2005algorithmic] which contain a set of labels rather than a single label. These conformal prediction sets contain the true label with probability $1-メ$. Our construction is based on $p(x|y)$ rather than $p(y|x)$ which results in a classifier that is very cautious: it outputs the null set - meaning `I don't know' --- when the object does not resemble the training examples. An important property of our approach is that classes can be added or removed without having to retrain the classifier. We demonstrate the performance on the ImageNet ILSVRC dataset using high dimensional features obtained from state of the art convolutional neural networks.","Thu, 24 May 2018 00:17:24 UTC (2,131 KB)"
"652","Communication Algorithms via Deep Learning","Hyeji Kim, Yihan Jiang, Ranvir Rana, Sreeram Kannan, Sewoong Oh, Pramod Viswanath","Machine Learning (stat.ML); Machine Learning (cs.LG)","Coding theory is a central discipline underpinning wireline and wireless modems that are the workhorses of the information age. Progress in coding theory is largely driven by individual human ingenuity with sporadic breakthroughs over the past century. In this paper we study whether it is possible to automate the discovery of decoding algorithms via deep learning. We study a family of sequential codes parameterized by recurrent neural network (RNN) architectures. We show that creatively designed and trained RNN architectures can decode well known sequential codes such as the convolutional and turbo codes with close to optimal performance on the additive white Gaussian noise (AWGN) channel, which itself is achieved by breakthrough algorithms of our times (Viterbi and BCJR decoders, representing dynamic programing and forward-backward algorithms). We show strong generalizations, i.e., we train at a specific signal to noise ratio and block length but test at a wide range of these quantities, as well as robustness and adaptivity to deviations from the AWGN setting.","Wed, 23 May 2018 17:58:37 UTC (7,707 KB)"
"653","Deep Learning Estimation of Absorbed Dose for Nuclear Medicine Diagnostics","Luciano Melodia","Machine Learning (stat.ML); Machine Learning (cs.LG)","The distribution of energy dose from Lu$^{177}$ radiotherapy can be estimated by convolving an image of a time-integrated activity distribution with a dose voxel kernel (dvk) consisting of different types of tissues. This fast and inacurate approximation is inappropriate for personalized dosimetry as it neglects tissue heterogenity. The latter can be calculated using different imaging techniques such as CT and SPECT combined with a time consuming monte-carlo simulation. The aim of this study is, for the first time, an estimation of DVKs from CT-derived density kernels (dk) via deep learning in convolutional neural networks (cnns). The proposed cnn achieved, on the test set, a mean intersection over union (iou) of $= 0.86$ after $308$ epochs and a corresponding mean squared error (mse) $= 1.24 \cdot 10^{-4}$. This generalization ability shows that the trained cnn can indeed learn the complex transfer function from dk to dvk. Future work will evaluate dvks estimated by cnns with full monte-carlo simulations of a whole body CT to predict patient specific voxel dose maps. Keywords: Deep Learning, Nuclear Medicine, Diagnostics, Machine Learning, Statistics","Wed, 23 May 2018 13:54:00 UTC (1,456 KB)[v2] Thu, 24 May 2018 11:45:48 UTC (1,470 KB)[v3] Sun, 10 Jun 2018 12:45:11 UTC (1,197 KB)"
"654","Toward a Thinking Microscope: Deep Learning in Optical Microscopy and Image Reconstruction","Yair Rivenson, Aydogan Ozcan","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Optics (physics.optics); Machine Learning (stat.ML)","We discuss recently emerging applications of the state-of-art deep learning methods on optical microscopy and microscopic image reconstruction, which enable new transformations among different modes and modalities of microscopic imaging, driven entirely by image data. We believe that deep learning will fundamentally change both the hardware and image reconstruction methods used in optical microscopy in a holistic manner.","Wed, 23 May 2018 05:54:51 UTC (3,259 KB)"
"655","Step Size Matters in Deep Learning","Kamil Nar, S. Shankar Sastry","Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)","Training a neural network with the gradient descent algorithm gives rise to a discrete-time nonlinear dynamical system. Consequently, behaviors that are typically observed in these systems emerge during training, such as convergence to an orbit but not to a fixed point or dependence of convergence on the initialization. Step size of the algorithm plays a critical role in these behaviors: it determines the subset of the local optima that the algorithm can converge to, and it specifies the magnitude of the oscillations if the algorithm converges to an orbit. To elucidate the effects of the step size on training of neural networks, we study the gradient descent algorithm as a discrete-time dynamical system, and by analyzing the Lyapunov stability of different solutions, we show the relationship between the step size of the algorithm and the solutions that can be obtained with this algorithm. The results provide an explanation for several phenomena observed in practice, including the deterioration in the training error with increased depth, the hardness of estimating linear mappings with large singular values, and the distinct performance of deep residual networks.","Tue, 22 May 2018 22:35:50 UTC (101 KB)[v2] Tue, 9 Oct 2018 06:10:32 UTC (193 KB)"
"656","Sparse Binary Compression: Towards Distributed Deep Learning with minimal Communication","Felix Sattler, Simon Wiedemann, Klaus-Robert Muller, Wojciech Samek","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (stat.ML)","Currently, progressively larger deep neural networks are trained on ever growing data corpora. As this trend is only going to increase in the future, distributed training schemes are becoming increasingly relevant. A major issue in distributed training is the limited communication bandwidth between contributing nodes or prohibitive communication cost in general. These challenges become even more pressing, as the number of computation nodes increases. To counteract this development we propose sparse binary compression (SBC), a compression framework that allows for a drastic reduction of communication cost for distributed training. SBC combines existing techniques of communication delay and gradient sparsification with a novel binarization method and optimal weight update encoding to push compression gains to new limits. By doing so, our method also allows us to smoothly trade-off gradient sparsity and temporal sparsity to adapt to the requirements of the learning task. Our experiments show, that SBC can reduce the upstream communication on a variety of convolutional and recurrent neural network architectures by more than four orders of magnitude without significantly harming the convergence speed in terms of forward-backward passes. For instance, we can train ResNet50 on ImageNet in the same number of iterations to the baseline accuracy, using $\times 3531$ less bits or train it to a $1\%$ lower accuracy using $\times 37208$ less bits. In the latter case, the total upstream communication required is cut from 125 terabytes to 3.35 gigabytes for every participating client.","Tue, 22 May 2018 17:54:13 UTC (2,087 KB)"
"657","Image Based Fashion Product Recommendation with Deep Learning","Hessel Tuinhof, Clemens Pirker, Markus Haltmeier","Computer Vision and Pattern Recognition (cs.CV)","We develop a two-stage deep learning framework that recommends fashion images based on other input images of similar style. For that purpose, a neural network classifier is used as a data-driven, visually-aware feature extractor. The latter then serves as input for similarity-based recommendations using a ranking algorithm. Our approach is tested on the publicly available Fashion dataset. Initialization strategies using transfer learning from larger product databases are presented. Combined with more traditional content-based recommendation systems, our framework can help to increase robustness and performance, for example, by better matching a particular customer style.","Sun, 6 May 2018 18:14:51 UTC (1,024 KB)[v2] Tue, 17 Jul 2018 21:05:33 UTC (1,025 KB)"
"658","High throughput quantitative metallography for complex microstructures using deep learning: A case study in ultrahigh carbon steel","Brian L. DeCost, Toby Francis, Elizabeth A. Holm","Computer Vision and Pattern Recognition (cs.CV)","We apply a deep convolutional neural network segmentation model to enable novel automated microstructure segmentation applications for complex microstructures typically evaluated manually and subjectively. We explore two microstructure segmentation tasks in an openly-available ultrahigh carbon steel microstructure dataset: segmenting cementite particles in the spheroidized matrix, and segmenting larger fields of view featuring grain boundary carbide, spheroidized particle matrix, particle-free grain boundary denuded zone, and Widmanstatten cementite. We also demonstrate how to combine these data-driven microstructure segmentation models to obtain empirical cementite particle size and denuded zone width distributions from more complex micrographs containing multiple microconstituents. The full annotated dataset is available on materialsdata.nist.gov (this https URL).","Fri, 4 May 2018 17:22:34 UTC (7,958 KB)"
"659","Assessing a mobile-based deep learning model for plant disease surveillance","Amanda Ramcharan, Peter McCloskey, Kelsee Baranowski, Neema Mbilinyi, Latifa Mrisho, Mathias Ndalahwa, James Legg, David Hughes","Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)","Convolutional neural network models (CNNs) have made major advances in computer vision tasks in the last five years. Given the challenge in collecting real world datasets, most studies report performance metrics based on available research datasets. In scenarios where CNNs are to be deployed on images or videos from mobile devices, models are presented with new challenges due to lighting, angle, and camera specifications, which are not accounted for in research datasets. It is essential for assessment to also be conducted on real world datasets if such models are to be reliably integrated with products and services in society. Plant disease datasets can be used to test CNNs in real time and gain insight into real world performance. We train a CNN object detection model to identify foliar symptoms of diseases (or lack thereof) in cassava (Manihot esculenta Crantz). We then deploy the model on a mobile app and test its performance on mobile images and video of 720 diseased leaflets in an agricultural field in Tanzania. Within each disease category we test two levels of severity of symptoms - mild and pronounced, to assess the model performance for early detection of symptoms. In both severities we see a decrease in the F-1 score for real world images and video. The F-1 score dropped by 32% for pronounced symptoms in real world images (the closest data to the training data) due to a drop in model recall. If the potential of smartphone CNNs are to be realized our data suggest it is crucial to consider tuning precision and recall performance in order to achieve the desired performance in real world settings. In addition, the varied performance related to different input data (image or video) is an important consideration for the design of CNNs in real world applications.","Fri, 4 May 2018 15:07:29 UTC (1,724 KB)"
"660","Deep Learning Inference on Embedded Devices: Fixed-Point vs Posit","Seyed H. F. Langroudi, Tej Pandit, Dhireesha Kudithipudi","Computer Vision and Pattern Recognition (cs.CV)","Performing the inference step of deep learning in resource constrained environments, such as embedded devices, is challenging. Success requires optimization at both software and hardware levels. Low precision arithmetic and specifically low precision fixed-point number systems have become the standard for performing deep learning inference. However, representing non-uniform data and distributed parameters (e.g. weights) by using uniformly distributed fixed-point values is still a major drawback when using this number system. Recently, the posit number system was proposed, which represents numbers in a non-uniform manner. Therefore, in this paper we are motivated to explore using the posit number system to represent the weights of Deep Convolutional Neural Networks. However, we do not apply any quantization techniques and hence the network weights do not require re-training. The results of this exploration show that using the posit number system outperformed the fixed point number system in terms of accuracy and memory utilization.","Tue, 22 May 2018 14:31:27 UTC (1,662 KB)"
"661","Deep learning generalizes because the parameter-function map is biased towards simple functions","Guillermo Valle-Perez, Chico Q. Camargo, Ard A. Louis","Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Deep neural networks generalize remarkably well without explicit regularization even in the strongly over-parametrized regime. This success suggests that some form of implicit regularization must be at work. In this paper we argue that a strong intrinsic bias in the parameter-function map helps explain the success of deep neural networks. We provide evidence that the parameter-function map results in a heavily biased prior over functions, if we assume that the training algorithm samples parameters close to uniformly within the zero-error region. The PAC-Bayes theorem then guarantees good expected generalization for target functions producing high-likelihood training sets. We exploit connections between deep neural networks and Gaussian processes to estimate the marginal likelihood, finding remarkably good agreement between Gaussian processes and neural networks for small input sets. Using approximate marginal likelihood calculations we produce nontrivial generalization PAC-Bayes error bounds which correlate well with the true error on realistic datasets such as MNIST and CIFAR and for architectures including convolutional and fully connected networks. As predicted by recent arguments based on algorithmic information theory, we find that the prior probability drops exponentially with linear increases in several measures of descriptional complexity of the target function. As target functions in many real problems are expected to be highly structured, this simplicity bias offers an insight into why deep networks generalize well on real world problems, but badly on randomized data.","Tue, 22 May 2018 11:51:36 UTC (3,068 KB)[v2] Wed, 23 May 2018 10:55:36 UTC (3,067 KB)[v3] Fri, 28 Sep 2018 18:22:18 UTC (3,285 KB)"
"662","RPC Considered Harmful: Fast Distributed Deep Learning on RDMA","Jilong Xue, Youshan Miao, Cheng Chen, Ming Wu, Lintao Zhang, Lidong Zhou","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","Deep learning emerges as an important new resource-intensive workload and has been successfully applied in computer vision, speech, natural language processing, and so on. Distributed deep learning is becoming a necessity to cope with growing data and model sizes. Its computation is typically characterized by a simple tensor data abstraction to model multi-dimensional matrices, a data-flow graph to model computation, and iterative executions with relatively frequent synchronizations, thereby making it substantially different from Map/Reduce style distributed big data computation. RPC, commonly used as the communication primitive, has been adopted by popular deep learning frameworks such as TensorFlow, which uses gRPC. We show that RPC is sub-optimal for distributed deep learning computation, especially on an RDMA-capable network. The tensor abstraction and data-flow graph, coupled with an RDMA network, offers the opportunity to reduce the unnecessary overhead (e.g., memory copy) without sacrificing programmability and generality. In particular, from a data access point of view, a remote machine is abstracted just as a ""device"" on an RDMA channel, with a simple memory interface for allocating, reading, and writing memory regions. Our graph analyzer looks at both the data flow graph and the tensors to optimize memory allocation and remote data access using this interface. The result is up to 25 times speedup in representative deep learning benchmarks against the standard gRPC in TensorFlow and up to 169% improvement even against an RPC implementation optimized for RDMA, leading to faster convergence in the training process.","Tue, 22 May 2018 07:42:33 UTC (2,182 KB)"
"663","Deep Learning with Cinematic Rendering: Fine-Tuning Deep Neural Networks Using Photorealistic Medical Images","Faisal Mahmood, Richard Chen, Sandra Sudarsky, Daphne Yu, Nicholas J. Durr","Computer Vision and Pattern Recognition (cs.CV)","Deep learning has emerged as a powerful artificial intelligence tool to interpret medical images for a growing variety of applications. However, the paucity of medical imaging data with high-quality annotations that is necessary for training such methods ultimately limits their performance. Medical data is challenging to acquire due to privacy issues, shortage of experts available for annotation, limited representation of rare conditions and cost. This problem has previously been addressed by using synthetically generated data. However, networks trained on synthetic data often fail to generalize to real data. Cinematic rendering simulates the propagation and interaction of light passing through tissue models reconstructed from CT data, enabling the generation of photorealistic images. In this paper, we present one of the first applications of cinematic rendering in deep learning, in which we propose to fine-tune synthetic data-driven networks using cinematically rendered CT data for the task of monocular depth estimation in endoscopy. Our experiments demonstrate that: (a) Convolutional Neural Networks (CNNs) trained on synthetic data and fine-tuned on photorealistic cinematically rendered data adapt better to real medical images and demonstrate more robust performance when compared to networks with no fine-tuning, (b) these fine-tuned networks require less training data to converge to an optimal solution, and (c) fine-tuning with data from a variety of photorealistic rendering conditions of the same scene prevents the network from learning patient-specific information and aids in generalizability of the model. Our empirical evaluation demonstrates that networks fine-tuned with cinematically rendered data predict depth with 56.87% less error for rendered endoscopy images and 27.49% less error for real porcine colon endoscopy images.","Tue, 22 May 2018 05:24:41 UTC (4,482 KB)[v2] Thu, 31 May 2018 01:41:37 UTC (6,327 KB)[v3] Sat, 29 Sep 2018 19:09:43 UTC (5,593 KB)"
"664","Opening the black box of deep learning","Dian Lei, Xiaoxiao Chen, Jianfei Zhao","Machine Learning (cs.LG); Machine Learning (stat.ML)","The great success of deep learning shows that its technology contains profound truth, and understanding its internal mechanism not only has important implications for the development of its technology and effective application in various fields, but also provides meaningful insights into the understanding of human brain mechanism. At present, most of the theoretical research on deep learning is based on mathematics. This dissertation proposes that the neural network of deep learning is a physical system, examines deep learning from three different perspectives: microscopic, macroscopic, and physical world views, answers multiple theoretical puzzles in deep learning by using physics principles. For example, from the perspective of quantum mechanics and statistical physics, this dissertation presents the calculation methods for convolution calculation, pooling, normalization, and Restricted Boltzmann Machine, as well as the selection of cost functions, explains why deep learning must be deep, what characteristics are learned in deep learning, why Convolutional Neural Networks do not have to be trained layer by layer, and the limitations of deep learning, etc., and proposes the theoretical direction and basis for the further development of deep learning now and in the future. The brilliance of physics flashes in deep learning, we try to establish the deep learning technology based on the scientific theory of physics.","Tue, 22 May 2018 02:12:33 UTC (167 KB)"
"665","Small steps and giant leaps: Minimal Newton solvers for Deep Learning","Joao F. Henriques, Sebastien Ehrhardt, Samuel Albanie, Andrea Vedaldi","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Numerical Analysis (cs.NA); Machine Learning (stat.ML)","We propose a fast second-order method that can be used as a drop-in replacement for current deep learning solvers. Compared to stochastic gradient descent (SGD), it only requires two additional forward-mode automatic differentiation operations per iteration, which has a computational cost comparable to two standard forward passes and is easy to implement. Our method addresses long-standing issues with current second-order solvers, which invert an approximate Hessian matrix every iteration exactly or by conjugate-gradient methods, a procedure that is both costly and sensitive to noise. Instead, we propose to keep a single estimate of the gradient projected by the inverse Hessian matrix, and update it once per iteration. This estimate has the same size and is similar to the momentum variable that is commonly used in SGD. No estimate of the Hessian is maintained. We first validate our method, called CurveBall, on small problems with known closed-form solutions (noisy Rosenbrock function and degenerate 2-layer linear networks), where current deep learning solvers seem to struggle. We then train several large models on CIFAR and ImageNet, including ResNet and VGG-f networks, where we demonstrate faster convergence with no hyperparameter tuning. Code is available.","Mon, 21 May 2018 14:54:28 UTC (1,865 KB)"
"666","Variational based Mixed Noise Removal with CNN Deep Learning Regularization","Faqiang Wang, Haiyang Huang, Jun Liu","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","In this paper, the traditional model based variational method and learning based algorithms are naturally integrated to address mixed noise removal problem. To be different from single type noise (e.g. Gaussian) removal, it is a challenge problem to accurately discriminate noise types and levels for each pixel. We propose a variational method to iteratively estimate the noise parameters, and then the algorithm can automatically classify the noise according to the different statistical parameters. The proposed variational problem can be separated into regularization, synthesis, parameter estimation and noise classification four steps with the operator splitting scheme. Each step is related to an optimization subproblem. To enforce the regularization, the deep learning method is employed to learn the natural images priori. Compared with some model based regularizations, the CNN regularizer can significantly improve the quality of the restored images. Compared with some learning based methods, the synthesis step can produce better reconstructions by analyzing the recognized noise types and levels. In our method, the convolution neutral network (CNN) can be regarded as an operator which associated to a variational functional. From this viewpoint, the proposed method can be extended to many image reconstruction and inverse problems. Numerical experiments in the paper show that our method can achieve some state-of-the-art results for mixed noise removal.","Mon, 21 May 2018 14:52:06 UTC (3,931 KB)"
"667","SmoothOut: Smoothing Out Sharp Minima to Improve Generalization in Deep Learning","Wei Wen, Yandan Wang, Feng Yan, Cong Xu, Chunpeng Wu, Yiran Chen, Hai Li","Machine Learning (cs.LG); Machine Learning (stat.ML)","In Deep Learning, Stochastic Gradient Descent (SGD) is usually selected as the training method because of its efficiency and scalability; however, recently, a problem in SGD gains research interest: sharp minima in Deep Neural Networks (DNNs) have poor generalization [1][2]; especially, large-batch SGD tends to converge to sharp minima. It becomes an open question whether escaping sharp minima can improve the generalization. To answer this question, we proposed SmoothOut to smooth out sharp minima in DNNs and thereby improve generalization. In a nutshell, SmoothOut perturbs multiple copies of the DNN by noise injection and averages these copies. Injecting noises to SGD is widely for exploration, but SmoothOut differs in lots of ways: (1) de-noising process is applied before parameter updating; (2) uniform noises are injected instead of Gaussian noises; (3) the goal is to obtain an auxiliary function without sharp minima for better generalization, instead of higher exploration. We prove that SmoothOut can eliminate sharp minima. Training multiple DNN copies is inefficient, we further propose a stochastic version of SmoothOut which only introduces the overhead of noise injecting and de-noising per batch. We prove that the Stochastic SmoothOut is an unbiased approximation of the original SmoothOut. In experiments on a variety of DNNs and datasets, SmoothOut consistently improve generalization in both small-batch and large-batch training on the top of state-of-the-art solutions. Our source code is in this https URL","Mon, 21 May 2018 05:28:22 UTC (3,734 KB)[v2] Sat, 1 Sep 2018 20:44:05 UTC (2,696 KB)"
"668","DLBI: Deep learning guided Bayesian inference for structure reconstruction of super-resolution fluorescence microscopy","Yu Li, Fan Xu, Fa Zhang, Pingyong Xu, Mingshu Zhang, Ming Fan, Lihua Li, Xin Gao, Renmin Han","Computer Vision and Pattern Recognition (cs.CV); Applications (stat.AP); Machine Learning (stat.ML)","Super-resolution fluorescence microscopy, with a resolution beyond the diffraction limit of light, has become an indispensable tool to directly visualize biological structures in living cells at a nanometer-scale resolution. Despite advances in high-density super-resolution fluorescent techniques, existing methods still have bottlenecks, including extremely long execution time, artificial thinning and thickening of structures, and lack of ability to capture latent structures. Here we propose a novel deep learning guided Bayesian inference approach, DLBI, for the time-series analysis of high-density fluorescent images. Our method combines the strength of deep learning and statistical inference, where deep learning captures the underlying distribution of the fluorophores that are consistent with the observed time-series fluorescent images by exploring local features and correlation along time-axis, and statistical inference further refines the ultrastructure extracted by deep learning and endues physical meaning to the final image. Comprehensive experimental results on both real and simulated datasets demonstrate that our method provides more accurate and realistic local patch and large-field reconstruction than the state-of-the-art method, the 3B analysis, while our method is more than two orders of magnitude faster. The main program is available at this https URL","Sun, 20 May 2018 15:28:56 UTC (6,175 KB)[v2] Tue, 22 May 2018 05:32:56 UTC (6,175 KB)[v3] Sat, 1 Sep 2018 20:07:42 UTC (6,175 KB)"
"669","Long-term face tracking in the wild using deep learning","Kunlei Zhang, Elaheh Rashedi, Elaheh Barati, Xue-wen Chen","Computer Vision and Pattern Recognition (cs.CV)","This paper investigates long-term face tracking of a specific person given his/her face image in a single frame as a query in a video stream. Through taking advantage of pre-trained deep learning models on big data, a novel system is developed for accurate video face tracking in the unconstrained environments depicting various people and objects moving in and out of the frame. In the proposed system, we present a detection-verification-tracking method (dubbed as 'DVT') which accomplishes the long-term face tracking task through the collaboration of face detection, face verification, and (short-term) face tracking. An offline trained detector based on cascaded convolutional neural networks localizes all faces appeared in the frames, and an offline trained face verifier based on deep convolutional neural networks and similarity metric learning decides if any face or which face corresponds to the queried person. An online trained tracker follows the face from frame to frame. When validated on a sitcom episode and a TV show, the DVT method outperforms tracking-learning-detection (TLD) and face-TLD in terms of recall and precision. The proposed system is also tested on many other types of videos and shows very promising results.","Sat, 19 May 2018 20:00:26 UTC (2,812 KB)"
"670","Reconciled Polynomial Machine: A Unified Representation of Shallow and Deep Learning Models","Jiawei Zhang, Limeng Cui, Fisher B. Gouza","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","In this paper, we aim at introducing a new machine learning model, namely reconciled polynomial machine, which can provide a unified representation of existing shallow and deep machine learning models. Reconciled polynomial machine predicts the output by computing the inner product of the feature kernel function and variable reconciling function. Analysis of several concrete models, including Linear Models, FM, MVM, Perceptron, MLP and Deep Neural Networks, will be provided in this paper, which can all be reduced to the reconciled polynomial machine representations. Detailed analysis of the learning error by these models will also be illustrated in this paper based on their reduced representations from the function approximation perspective.","Sat, 19 May 2018 03:40:52 UTC (339 KB)"
"671","My camera can see through fences: A deep learning approach for image de-fencing","Sankaraganesh Jonna, Krishna Kanth Nakka, Rajiv R. Sahay","Computer Vision and Pattern Recognition (cs.CV)","In recent times, the availability of inexpensive image capturing devices such as smartphones/tablets has led to an exponential increase in the number of images/videos captured. However, sometimes the amateur photographer is hindered by fences in the scene which have to be removed after the image has been captured. Conventional approaches to image de-fencing suffer from inaccurate and non-robust fence detection apart from being limited to processing images of only static occluded scenes. In this paper, we propose a semi-automated de-fencing algorithm using a video of the dynamic scene. We use convolutional neural networks for detecting fence pixels. We provide qualitative as well as quantitative comparison results with existing lattice detection algorithms on the existing PSU NRT data set and a proposed challenging fenced image dataset. The inverse problem of fence removal is solved using split Bregman technique assuming total variation of the de-fenced image as the regularization constraint.","Fri, 18 May 2018 21:02:04 UTC (4,934 KB)"
"672","Dependability in a Multi-tenant Multi-framework Deep Learning as-a-Service Platform","Scott Boag, Parijat Dube, Kaoutar El Maghraoui, Benjamin Herta, Waldemar Hummer, K. R. Jayaram, Rania Khalaf, Vinod Muthusamy, Michael Kalantar, Archit Verma","Distributed, Parallel, and Cluster Computing (cs.DC)","Deep learning (DL), a form of machine learning, is becoming increasingly popular in several application domains. As a result, cloud-based Deep Learning as a Service (DLaaS) platforms have become an essential infrastructure in many organizations. These systems accept, schedule, manage and execute DL training jobs at scale. This paper explores dependability in the context of a DLaaS platform used in IBM. We begin by explaining how DL training workloads are different, and what features ensure dependability in this context. We then describe the architecture, design and implementation of a cloud-based orchestration system for DL training. We show how this system has been architected with dependability in mind while also being horizontally scalable, elastic, flexible and efficient. We also present an initial empirical evaluation of the overheads introduced by our platform, and discuss tradeoffs between efficiency and dependability.","Thu, 17 May 2018 14:32:02 UTC (149 KB)"
"673","Deep-learning Based Modeling of Fault Detachment Stability for Power Grid","Haotian Cui, Xianggen Liu, Yanhao Huang","Machine Learning (cs.LG); Machine Learning (stat.ML)","The project intends to model the stability of power system with a deep learning algorithm to the problem, aiming to delay the removal of the fault. The so-called ""fail-delay cut-off"" refers to the occurrence of N-1 backup protection action on the backbone network of the system, resulting in longer time for the removal of the fault. In practice, through the analysis and calculation of a large number of online data, we have found that the N-1 failure system of the main protection action will not be unstable, which is also a guarantee of the operation mode arrangement. In the case of the N-1 backup protection action, there is an approximately 2.5% probability that the system will be destabilized. Therefore, research is needed to improve the operating arrangement.","Thu, 17 May 2018 08:54:00 UTC (1,115 KB)"
"674","Mad Max: Affine Spline Insights into Deep Learning","Randall Balestriero, Richard Baraniuk","Machine Learning (stat.ML); Machine Learning (cs.LG)","We build a rigorous bridge between deep networks (DNs) and approximation theory via spline functions and operators. Our key result is that a large class of DNs can be written as a composition of max-affine spline operators (MASOs), which provide a powerful portal through which to view and analyze their inner workings. For instance, conditioned on the input signal, the output of a MASO DN can be written as a simple affine transformation of the input. This implies that a DN constructs a set of signal-dependent, class-specific templates against which the signal is compared via a simple inner product; we explore the links to the classical theory of optimal classification via matched filters and the effects of data memorization. Going further, we propose a simple penalty term that can be added to the cost function of any DN learning algorithm to force the templates to be orthogonal with each other; this leads to significantly improved classification performance and reduced overfitting with no change to the DN architecture. The spline partition of the input signal space that is implicitly induced by a MASO directly links DNs to the theory of vector quantization (VQ) and $K$-means clustering, which opens up new geometric avenue to study how DNs organize signals in a hierarchical fashion. To validate the utility of the VQ interpretation, we develop and validate a new distance metric for signals and images that quantifies the difference between their VQ encodings. (This paper is a significantly expanded version of A Spline Theory of Deep Learning from ICML 2018.)","Thu, 17 May 2018 02:04:54 UTC (7,458 KB)[v2] Sat, 14 Jul 2018 09:45:33 UTC (8,114 KB)[v3] Sat, 21 Jul 2018 11:32:05 UTC (8,217 KB)[v4] Wed, 25 Jul 2018 19:34:14 UTC (8,273 KB)[v5] Sun, 11 Nov 2018 23:01:58 UTC (7,030 KB)"
"675","Regularization Learning Networks: Deep Learning for Tabular Datasets","Ira Shavitt, Eran Segal","Machine Learning (stat.ML); Machine Learning (cs.LG)","Despite their impressive performance, Deep Neural Networks (DNNs) typically underperform Gradient Boosting Trees (GBTs) on many tabular-dataset learning tasks. We propose that applying a different regularization coefficient to each weight might boost the performance of DNNs by allowing them to make more use of the more relevant inputs. However, this will lead to an intractable number of hyperparameters. Here, we introduce Regularization Learning Networks (RLNs), which overcome this challenge by introducing an efficient hyperparameter tuning scheme which minimizes a new Counterfactual Loss. Our results show that RLNs significantly improve DNNs on tabular datasets, and achieve comparable results to GBTs, with the best performance achieved with an ensemble that combines GBTs and RLNs. RLNs produce extremely sparse networks, eliminating up to 99.8% of the network edges and 82% of the input features, thus providing more interpretable models and reveal the importance that the network assigns to different inputs. RLNs could efficiently learn a single network in datasets that comprise both tabular and unstructured data, such as in the setting of medical imaging accompanied by electronic health records. An open source implementation of RLN can be found at this https URL.","Wed, 16 May 2018 17:43:20 UTC (3,226 KB)[v2] Sat, 13 Oct 2018 12:26:26 UTC (2,628 KB)[v3] Tue, 23 Oct 2018 19:35:32 UTC (2,628 KB)"
"676","#phramacovigilance - Exploring Deep Learning Techniques for Identifying Mentions of Medication Intake from Twitter","Debanjan Mahata, Jasper Friedrichs, Hitkul, Rajiv Ratn Shah","Computation and Language (cs.CL)","Mining social media messages for health and drug related information has received significant interest in pharmacovigilance research. Social media sites (e.g., Twitter), have been used for monitoring drug abuse, adverse reactions of drug usage and analyzing expression of sentiments related to drugs. Most of these studies are based on aggregated results from a large population rather than specific sets of individuals. In order to conduct studies at an individual level or specific cohorts, identifying posts mentioning intake of medicine by the user is necessary. Towards this objective, we train different deep neural network classification models on a publicly available annotated dataset and study their performances on identifying mentions of personal intake of medicine in tweets. We also design and train a new architecture of a stacked ensemble of shallow convolutional neural network (CNN) ensembles. We use random search for tuning the hyperparameters of the models and share the details of the values taken by the hyperparameters for the best learnt model in different deep neural network architectures. Our system produces state-of-the-art results, with a micro- averaged F-score of 0.693.","Wed, 16 May 2018 15:43:21 UTC (678 KB)"
"677","SHADE: Information-Based Regularization for Deep Learning","Michael Blot, Thomas Robert, Nicolas Thome, Matthieu Cord","Machine Learning (stat.ML); Machine Learning (cs.LG)","Regularization is a big issue for training deep neural networks. In this paper, we propose a new information-theory-based regularization scheme named SHADE for SHAnnon DEcay. The originality of the approach is to define a prior based on conditional entropy, which explicitly decouples the learning of invariant representations in the regularizer and the learning of correlations between inputs and labels in the data fitting term. Our second contribution is to derive a stochastic version of the regularizer compatible with deep learning, resulting in a tractable training scheme. We empirically validate the efficiency of our approach to improve classification performances compared to standard regularization schemes on several standard architectures.","Mon, 14 May 2018 14:21:23 UTC (387 KB)"
"678","The Concept of the Deep Learning-Based System ""Artificial Dispatcher"" to Power System Control and Dispatch","Nikita Tomin, Victor Kurbatsky, Michael Negnevitsky","Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","Year by year control of normal and emergency conditions of up-to-date power systems becomes an increasingly complicated problem. With the increasing complexity the existing control system of power system conditions which includes operative actions of the dispatcher and work of special automatic devices proves to be insufficiently effective more and more frequently, which raises risks of dangerous and emergency conditions in power systems. The paper is aimed at compensating for the shortcomings of man (a cognitive barrier, exposure to stresses and so on) and automatic devices by combining their strong points, i.e. the dispatcher's intelligence and the speed of automatic devices by virtue of development of the intelligent system ""Artificial dispatcher"" on the basis of deep machine learning technology. For realization of the system ""Artificial dispatcher"" in addition to deep learning it is planned to attract the game theory approaches to formalize work of the up-to-date power system as a game problem. The ""gain"" for ""Artificial dispatcher"" will consist in bringing in a power system in the normal steady-state or post-emergency conditions by means of the required control actions.","Mon, 7 May 2018 07:21:42 UTC (981 KB)"
"679","DeepMutation: Mutation Testing of Deep Learning Systems","Lei Ma, Fuyuan Zhang, Jiyuan Sun, Minhui Xue, Bo Li, Felix Juefei-Xu, Chao Xie, Li Li, Yang Liu, Jianjun Zhao, Yadong Wang","Software Engineering (cs.SE)","Deep learning (DL) defines a new data-driven programming paradigm where the internal system logic is largely shaped by the training data. The standard way of evaluating DL models is to examine their performance on a test dataset. The quality of the test dataset is of great importance to gain confidence of the trained models. Using an inadequate test dataset, DL models that have achieved high test accuracy may still lack generality and robustness. In traditional software testing, mutation testing is a well-established technique for quality evaluation of test suites, which analyzes to what extent a test suite detects the injected faults. However, due to the fundamental difference between traditional software and deep learning-based software, traditional mutation testing techniques cannot be directly applied to DL systems. In this paper, we propose a mutation testing framework specialized for DL systems to measure the quality of test data. To do this, by sharing the same spirit of mutation testing in traditional software, we first define a set of source-level mutation operators to inject faults to the source of DL (i.e., training data and training programs). Then we design a set of model-level mutation operators that directly inject faults into DL models without a training process. Eventually, the quality of test data could be evaluated from the analysis on to what extent the injected faults could be detected. The usefulness of the proposed mutation testing techniques is demonstrated on two public datasets, namely MNIST and CIFAR-10, with three DL models.","Mon, 14 May 2018 14:57:44 UTC (434 KB)[v2] Tue, 14 Aug 2018 22:57:44 UTC (541 KB)"
"680","Fast 3D cell tracking with wide-field fluorescence microscopy through deep learning","Kan Liu, Hui Qiao, Jiamin Wu, Haoqian Wang, Lu Fang, Qionghai Dai","Optics (physics.optics)","Tracking cells in 3D at high speed continues to attract extensive attention for many biomedical applications, such as monitoring immune cell migration and observing tumor metastasis in flowing blood vessels. Here, we propose a deep convolutional neural networks (CNNs) based method to retrieve the 3D locations of the fluorophores from a single 2D image captured by a conventional wide-field fluorescence microscope without any hardware modification. The reported method converts the challenging 3D localization from an ill-posed model-based fitting problem, especially with dense samples and low signal-to-noise ratio, to a solvable multi-label classification problem through two cascaded CNNs, where deep learning technique has a great advantage over other algorithms. Compared with traditional kernel-fitting methods, the proposed method achieves more accurate and robust localization of multiple objects across a much larger axial range, which is validated by both simulation and experimental results on 3D distributed fluorescent beads. Moreover, in vivo 3D tracking of multiple blood cells in zebrafish at 100 fps further verifies the feasibility of our framework.","Mon, 14 May 2018 12:27:04 UTC (3,514 KB)[v2] Tue, 15 May 2018 08:28:21 UTC (3,602 KB)"
"681","Multimode Optical Fiber Transmission with a Deep Learning Network","Babak Rahmani, Damien Loterie, Georgia Konstantinou, Demetri Psaltis, Christophe Moser","Optics (physics.optics)","Multimode fibers (MMF) are an example of a highly scattering medium which scramble the coherent light propagating within them and produce seemingly random patterns. Thus, for applications such as imaging and image projection through a MMF, careful measurements of the relationship between inputs and outputs of the fiber are required. We show, as a proof of concept, that a deep learning neural network can learn the input-output relationship in a 0.75 m long MMF. Specifically, we demonstrate that a deep convolutional neural network (CNN) can learn the non-linear relationships between the amplitude of the speckle pattern obtained at the output of the fiber and the phase or amplitude at the input of the fiber. Effectively the network performs a non-linear inversion task. We obtained image fidelity (correlation) of ~98% compared with the image obtained using the measured matrix of the system. We further show that the network can be trained for transfer learning, i.e. it can transmit images through the MMF which belongs to another class which were not used for training/testing.","Mon, 14 May 2018 12:04:30 UTC (814 KB)[v2] Sun, 11 Nov 2018 12:00:51 UTC (817 KB)"
"682","A Deep Learning Approach with an Attention Mechanism for Automatic Sleep Stage Classification","Martin Langkvist, Amy Loutfi","Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC); Machine Learning (stat.ML)","Automatic sleep staging is a challenging problem and state-of-the-art algorithms have not yet reached satisfactory performance to be used instead of manual scoring by a sleep technician. Much research has been done to find good feature representations that extract the useful information to correctly classify each epoch into the correct sleep stage. While many useful features have been discovered, the amount of features have grown to an extent that a feature reduction step is necessary in order to avoid the curse of dimensionality. One reason for the need of such a large feature set is that many features are good for discriminating only one of the sleep stages and are less informative during other stages. This paper explores how a second feature representation over a large set of pre-defined features can be learned using an auto-encoder with a selective attention for the current sleep stage in the training batch. This selective attention allows the model to learn feature representations that focuses on the more relevant inputs without having to perform any dimensionality reduction of the input data. The performance of the proposed algorithm is evaluated on a large data set of polysomnography (PSG) night recordings of patients with sleep-disordered breathing. The performance of the auto-encoder with selective attention is compared with a regular auto-encoder and previous works using a deep belief network (DBN).","Mon, 14 May 2018 07:36:26 UTC (486 KB)"
"683","Deep Learning in Software Engineering","Xiaochen Li, He Jiang, Zhilei Ren, Ge Li, Jingxuan Zhang","Software Engineering (cs.SE)","Recent years, deep learning is increasingly prevalent in the field of Software Engineering (SE). However, many open issues still remain to be investigated. How do researchers integrate deep learning into SE problems? Which SE phases are facilitated by deep learning? Do practitioners benefit from deep learning? The answers help practitioners and researchers develop practical deep learning models for SE tasks. To answer these questions, we conduct a bibliography analysis on 98 research papers in SE that use deep learning techniques. We find that 41 SE tasks in all SE phases have been facilitated by deep learning integrated solutions. In which, 84.7% papers only use standard deep learning models and their variants to solve SE problems. The practicability becomes a concern in utilizing deep learning techniques. How to improve the effectiveness, efficiency, understandability, and testability of deep learning based solutions may attract more SE researchers in the future.","Sun, 13 May 2018 06:01:39 UTC (462 KB)"
"684","Laconic Deep Learning Computing","Sayeh Sharify, Mostafa Mahmoud, Alberto Delmas Lascorz, Milos Nikolic, Andreas Moshovos","Neural and Evolutionary Computing (cs.NE); Hardware Architecture (cs.AR); Machine Learning (cs.LG)","We motivate a method for transparently identifying ineffectual computations in unmodified Deep Learning models and without affecting accuracy. Specifically, we show that if we decompose multiplications down to the bit level the amount of work performed during inference for image classification models can be consistently reduced by two orders of magnitude. In the best case studied of a sparse variant of AlexNet, this approach can ideally reduce computation work by more than 500x. We present Laconic a hardware accelerator that implements this approach to improve execution time, and energy efficiency for inference with Deep Learning Networks. Laconic judiciously gives up some of the work reduction potential to yield a low-cost, simple, and energy efficient design that outperforms other state-of-the-art accelerators. For example, a Laconic configuration that uses a weight memory interface with just 128 wires outperforms a conventional accelerator with a 2K-wire weight memory interface by 2.3x on average while being 2.13x more energy efficient on average. A Laconic configuration that uses a 1K-wire weight memory interface, outperforms the 2K-wire conventional accelerator by 15.4x and is 1.95x more energy efficient. Laconic does not require but rewards advances in model design such as a reduction in precision, the use of alternate numeric representations that reduce the number of bits that are ""1"", or an increase in weight or activation sparsity.","Thu, 10 May 2018 18:14:08 UTC (652 KB)"
"685","Novel Deep Learning Model for Traffic Sign Detection Using Capsule Networks","Amara Dinesh Kumar","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Convolutional neural networks are the most widely used deep learning algorithms for traffic signal classification till date but they fail to capture pose, view, orientation of the images because of the intrinsic inability of max pooling layer.This paper proposes a novel method for Traffic sign detection using deep learning architecture called capsule networks that achieves outstanding performance on the German traffic sign dataset.Capsule network consists of capsules which are a group of neurons representing the instantiating parameters of an object like the pose and orientation by using the dynamic routing and route by agreement algorithms.unlike the previous approaches of manual feature extraction,multiple deep neural networks with many parameters,our method eliminates the manual effort and provides resistance to the spatial variances.CNNs can be fooled easily using various adversary attacks and capsule networks can overcome such attacks from the intruders and can offer more reliability in traffic sign detection for autonomous vehicles.Capsule network have achieved the state-of-the-art accuracy of 97.6% on German Traffic Sign Recognition Benchmark dataset (GTSRB).","Fri, 11 May 2018 14:34:15 UTC (891 KB)"
"686","Adaptive Selection of Deep Learning Models on Embedded Systems","Ben Taylor, Vicent Sanz Marco, Willy Wolff, Yehia Elkhatib, Zheng Wang","Performance (cs.PF); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","The recent ground-breaking advances in deep learning networks ( DNNs ) make them attractive for embedded systems. However, it can take a long time for DNNs to make an inference on resource-limited embedded devices. Offloading the computation into the cloud is often infeasible due to privacy concerns, high latency, or the lack of connectivity. As such, there is a critical need to find a way to effectively execute the DNN models locally on the devices. This paper presents an adaptive scheme to determine which DNN model to use for a given input, by considering the desired accuracy and inference time. Our approach employs machine learning to develop a predictive model to quickly select a pre-trained DNN to use for a given input and the optimization constraint. We achieve this by first training off-line a predictive model, and then use the learnt model to select a DNN model to use for new, unseen inputs. We apply our approach to the image classification task and evaluate it on a Jetson TX2 embedded deep learning platform using the ImageNet ILSVRC 2012 validation dataset. We consider a range of influential DNN models. Experimental results show that our approach achieves a 7.52% improvement in inference accuracy, and a 1.8x reduction in inference time over the most-capable single DNN model.","Fri, 11 May 2018 06:53:59 UTC (2,557 KB)"
"687","Unifying Data, Model and Hybrid Parallelism in Deep Learning via Tensor Tiling","Minjie Wang, Chien-chin Huang, Jinyang Li","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","Deep learning systems have become vital tools across many fields, but the increasing model sizes mean that training must be accelerated to maintain such systems' utility. Current systems like Tensorflow and MXNet focus on one specific parallelization strategy, data parallelism, which requires large training batch sizes in order to scale. We cast the problem of finding the best parallelization strategy as the problem of finding the best tiling to partition tensors with the least overall communication. We propose an algorithm that can find the optimal tiling. Our resulting parallelization solution is a hybrid of data parallelism and model parallelism. We build the SoyBean system that performs automatic parallelization. SoyBean automatically transforms a serial dataflow graph captured by an existing deep learning system frontend into a parallel dataflow graph based on the optimal tiling it has found. Our evaluations show that SoyBean is 1.5x-4x faster than pure data parallelism for AlexNet and VGG. We present this automatic tiling in a new system, SoyBean, that can act as a backend for Tensorflow, MXNet, and others.","Thu, 10 May 2018 20:38:56 UTC (1,353 KB)"
"688","A DAG Model of Synchronous Stochastic Gradient Descent in Distributed Deep Learning","Shaohuai Shi, Qiang Wang, Xiaowen Chu, Bo Li","Distributed, Parallel, and Cluster Computing (cs.DC)","With huge amounts of training data, deep learning has made great breakthroughs in many artificial intelligence (AI) applications. However, such large-scale data sets present computational challenges, requiring training to be distributed on a cluster equipped with accelerators like GPUs. With the fast increase of GPU computing power, the data communications among GPUs have become a potential bottleneck on the overall training performance. In this paper, we first propose a general directed acyclic graph (DAG) model to describe the distributed synchronous stochastic gradient descent (S-SGD) algorithm, which has been widely used in distributed deep learning frameworks. To understand the practical impact of data communications on training performance, we conduct extensive empirical studies on four state-of-the-art distributed deep learning frameworks (i.e., Caffe-MPI, CNTK, MXNet and TensorFlow) over multi-GPU and multi-node environments with different data communication techniques, including PCIe, NVLink, 10GbE, and InfiniBand. Through both analytical and experimental studies, we identify the potential bottlenecks and overheads that could be further optimized. At last, we make the data set of our experimental traces publicly available, which could be used to support simulation-based studies.","Thu, 10 May 2018 04:28:49 UTC (598 KB)[v2] Tue, 25 Sep 2018 07:14:35 UTC (842 KB)[v3] Wed, 31 Oct 2018 17:28:04 UTC (842 KB)"
"689","Deep Learning of Geometric Constellation Shaping including Fiber Nonlinearities","Rasmus T. Jones, Tobias A. Eriksson, Metodi P. Yankov, Darko Zibar","Information Theory (cs.IT); Machine Learning (stat.ML)","A new geometric shaping method is proposed, leveraging unsupervised machine learning to optimize the constellation design. The learned constellation mitigates nonlinear effects with gains up to 0.13 bit/4D when trained with a simplified fiber channel model.","Thu, 10 May 2018 02:08:15 UTC (158 KB)"
"690","k-Space Deep Learning for Accelerated MRI","Yoseob Han, Jong Chul Ye","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","The annihilating filter-based low-rank Hanel matrix approach (ALOHA) is one of the state-of-the-art compressed sensing approaches that directly interpolates the missing k-space data using low-rank Hankel matrix completion. Inspired by the recent mathematical discovery that links deep neural networks to Hankel matrix decomposition using data-driven framelet basis, here we propose a fully data-driven deep learning algorithm for k-space interpolation. Our network can be also easily applied to non-Cartesian k-space trajectories by simply adding an additional re-gridding layer. Extensive numerical experiments show that the proposed deep learning method significantly outperforms the existing image-domain deep learning approaches.","Thu, 10 May 2018 01:43:19 UTC (6,582 KB)"
"691","Pushing the limits of optical information storage using deep learning","Peter R. Wiecha, Aurelie Lecestre, Nicolas Mallet, Guilhem Larrieu","Applied Physics (physics.app-ph); Emerging Technologies (cs.ET); Optics (physics.optics)","Diffraction drastically limits the bit density in optical data storage. To increase the storage density, alternative strategies involving supplementary recording dimensions and robust read-out schemes must be explored. Here, we propose to encode multiple bits of information in the geometry of subwavelength dielectric nanostructures. A crucial problem in high-density information storage concepts is the robustness of the information readout with respect to fabrication errors and experimental noise. Using a machine-learning based approach in which the scattering spectra are analyzed by an artificial neural network, we achieve quasi error free read-out of sequences of up to 9 bit, encoded in top-down fabricated silicon nanostructures. We demonstrate that probing few wavelengths instead of the entire spectrum is sufficient for robust information retrieval and that the readout can be further simplified, exploiting the RGB values from microscopy images. Our work paves the way towards high-density optical information storage using planar silicon nanostructures, compatible with mass-production ready CMOS technology.","Wed, 9 May 2018 12:10:32 UTC (2,335 KB)[v2] Tue, 9 Oct 2018 14:55:44 UTC (6,093 KB)"
"692","DeepWalking: Enabling Smartphone-based Walking Speed Estimation Using Deep Learning","Aawesh Shrestha, Myounggyu Won","Computers and Society (cs.CY)","Walking speed estimation is an essential component of mobile apps in various fields such as fitness, transportation, navigation, and health-care. Most existing solutions are focused on specialized medical applications that utilize body-worn motion sensors. These approaches do not serve effectively the general use case of numerous apps where the user holding a smartphone tries to find his or her walking speed solely based on smartphone sensors. However, existing smartphone-based approaches fail to provide acceptable precision for walking speed estimation. This leads to a question: is it possible to achieve comparable speed estimation accuracy using a smartphone over wearable sensor based obtrusive solutions? We find the answer from advanced neural networks. In this paper, we present DeepWalking, the first deep learning-based walking speed estimation scheme for smartphone. A deep convolutional neural network (DCNN) is applied to automatically identify and extract the most effective features from the accelerometer and gyroscope data of smartphone and to train the network model for accurate speed estimation. Experiments are performed with 10 participants using a treadmill. The average root-mean-squared-error (RMSE) of estimated walking speed is 0.16m/s which is comparable to the results obtained by state-of-the-art approaches based on a number of body-worn sensors (i.e., RMSE of 0.11m/s). The results indicate that a smartphone can be a strong tool for walking speed estimation if the sensor data are effectively calibrated and supported by advanced deep learning techniques.","Wed, 9 May 2018 04:28:37 UTC (581 KB)"
"693","Deep learning from 21-cm images of the Cosmic Dawn","Nicolas Gillet, Andrei Mesinger, Bradley Greig, Adrian Liu, Graziano Ucci","Cosmology and Nongalactic Astrophysics (astro-ph.CO)","The 21-cm power spectrum (PS) has been shown to be a powerful discriminant of reionization and cosmic dawn astrophysical parameters. However, the 21-cm tomographic signal is highly non-Gaussian. Therefore there is additional information which is wasted if only the PS is used for parameter recovery. Here we showcase astrophysical parameter recovery directly from 21-cm images, using deep learning with convolutional neural networks (CNN). Using a database of 2D images taken from 10,000 21-cm lightcones (each generated from different cosmological initial conditions), we show that a CNN is able to recover parameters describing the first galaxies: (i) Tvir , their minimum host halo virial temperatures (or masses) capable of hosting efficient star formation; (ii) ユ , their typical ionizing efficiencies; (iii) LX/SFR , their typical soft-band X-ray luminosity to star formation rate; and (iv) E0 , the minimum X-ray energy capable of escaping the galaxy into the IGM. For most of their allowed ranges, log Tvir and log LX/SFR are recovered with < 1% uncertainty, while ユ and E0 are recovered within 10% uncertainty. Our results are roughly comparable to the accuracy obtained from Monte Carlo Markov Chain sampling of the PS with 21CMMC for the two mock observations analyzed previously, although we caution that we do not yet include noise and foreground contaminants in this proof-of-concept study.","Mon, 7 May 2018 19:02:24 UTC (2,861 KB)"
"694","Holarchic Structures for Decentralized Deep Learning - A Performance Analysis","Evangelos Pournaras, Srivatsan Yadhunathan, Ada Diaconescu","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Structure plays a key role in learning performance. In centralized computational systems, hyperparameter optimization and regularization techniques such as dropout are computational means to enhance learning performance by adjusting the deep hierarchical structure. However, in decentralized deep learning by the Internet of Things, the structure is an actual network of autonomous interconnected devices such as smart phones that interact via complex network protocols. Self-adaptation of the learning structure is a challenge. Uncertainties such as network latency, node and link failures or even bottlenecks by limited processing capacity and energy availability can signif- icantly downgrade learning performance. Network self-organization and self-management is complex, while it requires additional computational and network resources that hinder the feasibility of decentralized deep learning. In contrast, this paper introduces a self-adaptive learning approach based on holarchic learning structures for exploring, mitigating and boosting learning performance in distributed environments with uncertainties. A large-scale performance analysis with 864000 experiments fed with synthetic and real-world data from smart grid and smart city pilot projects confirm the cost-effectiveness of holarchic structures for decentralized deep learning.","Mon, 7 May 2018 18:33:43 UTC (808 KB)[v2] Mon, 17 Sep 2018 21:51:57 UTC (851 KB)"
"695","Examining the Use of Neural Networks for Feature Extraction: A Comparative Analysis using Deep Learning, Support Vector Machines, and K-Nearest Neighbor Classifiers","Stephen Notley, Malik Magdon-Ismail","Machine Learning (cs.LG); Machine Learning (stat.ML)","Neural networks in many varieties are touted as very powerful machine learning tools because of their ability to distill large amounts of information from different forms of data, extracting complex features and enabling powerful classification abilities. In this study, we use neural networks to extract features from both images and numeric data and use these extracted features as inputs for other machine learning models, namely support vector machines (SVMs) and k-nearest neighbor classifiers (KNNs), in order to see if neural-network-extracted features enhance the capabilities of these models. We tested 7 different neural network architectures in this manner, 4 for images and 3 for numeric data, training each for varying lengths of time and then comparing the results of the neural network independently to those of an SVM and KNN on the data, and finally comparing these results to models of SVM and KNN trained using features extracted via the neural network architecture. This process was repeated on 3 different image datasets and 2 different numeric datasets. The results show that, in many cases, the features extracted using the neural network significantly improve the capabilities of SVMs and KNNs compared to running these algorithms on the raw features, and in some cases also surpass the performance of the neural network alone. This in turn suggests that it may be a reasonable practice to use neural networks as a means to extract features for classification by other machine learning models for some datasets.","Sun, 6 May 2018 23:41:18 UTC (99 KB)[v2] Tue, 12 Jun 2018 13:11:14 UTC (73 KB)"
"696","RMDL: Random Multimodel Deep Learning for Classification","Kamran Kowsari, Mojtaba Heidarysafa, Donald E. Brown, Kiana Jafari Meimandi, Laura E. Barnes","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","The continually increasing number of complex datasets each year necessitates ever improving machine learning methods for robust and accurate categorization of these data. This paper introduces Random Multimodel Deep Learning (RMDL): a new ensemble, deep learning approach for classification. Deep learning models have achieved state-of-the-art results across many domains. RMDL solves the problem of finding the best deep learning structure and architecture while simultaneously improving robustness and accuracy through ensembles of deep learning architectures. RDML can accept as input a variety data to include text, video, images, and symbolic. This paper describes RMDL and shows test results for image and text data including MNIST, CIFAR-10, WOS, Reuters, IMDB, and 20newsgroup. These test results show that RDML produces consistently better performance than standard methods over a broad range of data types and classification problems.","Thu, 3 May 2018 19:36:43 UTC (2,743 KB)[v2] Thu, 31 May 2018 16:08:33 UTC (2,953 KB)"
"697","Ultra Low Power Deep-Learning-powered Autonomous Nano Drones","Daniele Palossi, Antonio Loquercio, Francesco Conti, Eric Flamand, Davide Scaramuzza, Luca Benini","Robotics (cs.RO); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Signal Processing (eess.SP)","Flying in dynamic, urban, highly-populated environments represents an open problem in robotics. State-of-the-art (SoA) autonomous Unmanned Aerial Vehicles (UAVs) employ advanced computer vision techniques based on computationally expensive algorithms, such as Simultaneous Localization and Mapping (SLAM) or Convolutional Neural Networks (CNNs) to navigate in such environments. In the Internet-of-Things (IoT) era, nano-size UAVs capable of autonomous navigation would be extremely desirable as self-aware mobile IoT nodes. However, autonomous flight is considered unaffordable in the context of nano-scale UAVs, where the ultra-constrained power envelopes of tiny rotor-crafts limit the on-board computational capabilities to low-power microcontrollers. In this work, we present the first vertically integrated system for fully autonomous deep neural network-based navigation on nano-size UAVs. Our system is based on GAP8, a novel parallel ultra-low-power computing platform, and deployed on a 27 g commercial, open-source CrazyFlie 2.0 nano-quadrotor. We discuss a methodology and software mapping tools that enable the SoA CNN presented in [1] to be fully executed on-board within a strict 12 fps real-time constraint with no compromise in terms of flight results, while all processing is done with only 94 mW on average - 1% of the power envelope of the deployed nano-aircraft.","Fri, 4 May 2018 15:47:33 UTC (3,117 KB)"
"698","Intracranial Error Detection via Deep Learning","Martin Volker, Ji<U+0159>i Hammer, Robin T. Schirrmeister, Joos Behncke, Lukas D.J. Fiederer, Andreas Schulze-Bonhage, Petr Marusi<U+010D>, Wolfram Burgard, Tonio Ball","Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)","Deep learning techniques have revolutionized the field of machine learning and were recently successfully applied to various classification problems in noninvasive electroencephalography (EEG). However, these methods were so far only rarely evaluated for use in intracranial EEG. We employed convolutional neural networks (CNNs) to classify and characterize the error-related brain response as measured in 24 intracranial EEG recordings. Decoding accuracies of CNNs were significantly higher than those of a regularized linear discriminant analysis. Using time-resolved deep decoding, it was possible to classify errors in various regions in the human brain, and further to decode errors over 200 ms before the actual erroneous button press, e.g., in the precentral gyrus. Moreover, deeper networks performed better than shallower networks in distinguishing correct from error trials in all-channel decoding. In single recordings, up to 100 % decoding accuracy was achieved. Visualization of the networks' learned features indicated that multivariate decoding on an ensemble of channels yields related, albeit non-redundant information compared to single-channel decoding. In summary, here we show the usefulness of deep learning for both intracranial error decoding and mapping of the spatio-temporal structure of the human error processing network.","Fri, 4 May 2018 08:53:03 UTC (4,639 KB)[v2] Fri, 22 Jun 2018 13:15:38 UTC (4,639 KB)[v3] Fri, 2 Nov 2018 10:57:22 UTC (4,639 KB)"
"699","Searching for hot subdwarf stars from the LAMOST spectra. III. classifying the hot subdwarf stars from LAMOST DR4 using deep learning method","Yude Bu, Jingjing Zeng, Zhenxin Lei","Instrumentation and Methods for Astrophysics (astro-ph.IM)","Hot subdwarf stars are core He burning stars located at the blue end of the horizontal branch, also known as the extreme horizontal branch. The properties of hot subdwarf stars are important for our understanding of the stellar astrophysics, globular clusters and galaxies. The spectra of hot subdwarf stars can provide us with the detailed information of the stellar atmospheric parameters (such as effective temperature, gravity, and helium abundances), which is important to clarify the astrophysical and statistical properties of hot subdwarf stars. These properties can provide important constraint on the theoretical models of hot subdwarf stars. Searching for hot subdwarf stars from the spectra data obtained by the Large Sky Area Multi-Object Fiber Spectroscopic Telescope (LAMOST) can significantly enlarge the sample size of hot subdwarf stars, and help us better study the nature of hot subdwarf stars. In this paper we study a new method of searching for hot subdwarf stars from LAMOST spectra using convolutional neural networks and support vector machine (CNN+SVM). The experiment on the spectra from LAMOST DR4 shows that CNN+SVM can classify the hot subdwarf stars accurately: the accuracy is 88.98$\%$ and the recall is 94.38 $\%$. Our research provides a new machine learning tool for searching for hot subdwarf stars in large spectroscopic surveys.","Fri, 4 May 2018 05:44:56 UTC (1,214 KB)[v2] Tue, 8 May 2018 02:46:47 UTC (1,218 KB)"
"700","A Deep Learning Model with Hierarchical LSTMs and Supervised Attention for Anti-Phishing","Minh Nguyen, Toan Nguyen, Thien Huu Nguyen","Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)","Anti-phishing aims to detect phishing content/documents in a pool of textual data. This is an important problem in cybersecurity that can help to guard users from fraudulent information. Natural language processing (NLP) offers a natural solution for this problem as it is capable of analyzing the textual content to perform intelligent recognition. In this work, we investigate state-of-the-art techniques for text categorization in NLP to address the problem of anti-phishing for emails (i.e, predicting if an email is phishing or not). These techniques are based on deep learning models that have attracted much attention from the community recently. In particular, we present a framework with hierarchical long short-term memory networks (H-LSTMs) and attention mechanisms to model the emails simultaneously at the word and the sentence level. Our expectation is to produce an effective model for anti-phishing and demonstrate the effectiveness of deep learning for problems in cybersecurity.","Thu, 3 May 2018 21:53:09 UTC (285 KB)"
"701","Binarizer at SemEval-2018 Task 3: Parsing dependency and deep learning for irony detection","Nishant Nikhil, Muktabh Mayank Srivastava","Computation and Language (cs.CL)","In this paper, we describe the system submitted for the SemEval 2018 Task 3 (Irony detection in English tweets) Subtask A by the team Binarizer. Irony detection is a key task for many natural language processing works. Our method treats ironical tweets to consist of smaller parts containing different emotions. We break down tweets into separate phrases using a dependency parser. We then embed those phrases using an LSTM-based neural network model which is pre-trained to predict emoticons for tweets. Finally, we train a fully-connected network to achieve classification.","Thu, 3 May 2018 04:53:06 UTC (681 KB)"
"702","Generalized Seismic Phase Detection with Deep Learning","Zachary E. Ross, Men-Andrin Meier, Egill Hauksson, Thomas H. Heaton","Geophysics (physics.geo-ph)","To optimally monitor earthquake-generating processes, seismologists have sought to lower detection sensitivities ever since instrumental seismic networks were started about a century ago. Recently, it has become possible to search continuous waveform archives for replicas of previously recorded events (template matching), which has led to at least an order of magnitude increase in the number of detected earthquakes and greatly sharpened our view of geological structures. Earthquake catalogs produced in this fashion, however, are heavily biased in that they are completely blind to events for which no templates are available, such as in previously quiet regions or for very large magnitude events. Here we show that with deep learning we can overcome such biases without sacrificing detection sensitivity. We trained a convolutional neural network (ConvNet) on the vast hand-labeled data archives of the Southern California Seismic Network to detect seismic body wave phases. We show that the ConvNet is extremely sensitive and robust in detecting phases, even when masked by high background noise, and when the ConvNet is applied to new data that is not represented in the training set (in particular, very large magnitude events). This generalized phase detection (GPD) framework will significantly improve earthquake monitoring and catalogs, which form the underlying basis for a wide range of basic and applied seismological research.","Thu, 3 May 2018 01:16:28 UTC (5,158 KB)"
"703","Internet of Things Meets Brain-Computer Interface: A Unified Deep Learning Framework for Enabling Human-Thing Cognitive Interactivity","Xiang Zhang, Lina Yao, Shuai Zhang, Salil S. Kanhere, Quan Z. Sheng, Yunhao Liu","Human-Computer Interaction (cs.HC)","A Brain-Computer Interface (BCI) acquires brain signals, analyzes and translates them into commands that are relayed to actuation devices for carrying out desired actions. With the widespread connectivity of everyday devices realized by the advent of the Internet of Things (IoT), BCI can empower individuals to directly control objects such as smart home appliances or assistive robots, directly via their thoughts. However, realization of this vision is faced with a number of challenges, most importantly being the issue of accurately interpreting the intent of the individual from the raw brain signals that are often of low fidelity and subject to noise. Moreover, pre-processing brain signals and the subsequent feature engineering are both time-consuming and highly reliant on human domain expertise. To address the aforementioned issues, in this paper, we propose a unified deep learning based framework that enables effective human-thing cognitive interactivity in order to bridge individuals and IoT objects. We design a reinforcement learning based Selective Attention Mechanism (SAM) to discover the distinctive features from the input brain signals. In addition, we propose a modified Long Short-Term Memory (LSTM) to distinguish the inter-dimensional information forwarded from the SAM. To evaluate the efficiency of the proposed framework, we conduct extensive real-world experiments and demonstrate that our model outperforms a number of competitive state-of-the-art baselines. Two practical real-time human-thing cognitive interaction applications are presented to validate the feasibility of our approach.","Tue, 1 May 2018 05:38:21 UTC (2,997 KB)[v2] Sat, 5 May 2018 10:33:38 UTC (2,997 KB)[v3] Mon, 22 Oct 2018 06:28:26 UTC (2,997 KB)"
"704","Multiparameter optimisation of a magneto-optical trap using deep learning","Aaron D. Tranter, Harry J. Slatyer, Michael R. Hush, Anthony C. Leung, Jesse L. Everett, Karun V. Paul, Pierre Vernaz-Gris, Ping Koy Lam, Ben C. Buchler, Geoff T. Campbell","Quantum Physics (quant-ph); Atomic Physics (physics.atom-ph)","Many important physical processes have dynamics that are too complex to completely model analytically. Optimisation of such processes often relies on intuition, trial-and-error, or the construction of empirical models. Machine learning based on artificial neural networks has emerged as an efficient means to develop empirical models of complex systems. We implement a deep artificial neural network to optimise the magneto-optic cooling and trapping of neutral atomic ensembles. Cold atomic ensembles have become commonplace in laboratories around the world, however, many-body interactions give rise to complex dynamics that preclude precise analytic optimisation of the cooling and trapping process. The solution identified by machine learning is radically different to the smoothly varying adiabatic solutions currently used. Despite this, the solutions vastly outperform best known solutions producing higher optical densities. This may provide a pathway to a new understanding of the dynamics of the cooling and trapping processes in cold atomic ensembles.","Wed, 2 May 2018 07:37:03 UTC (2,290 KB)"
"705","Deep learning approach to Fourier ptychographic microscopy","Thanh Nguyen, Yujia Xue, Yunzhe Li, Lei Tian, George Nehmetallah","Computer Vision and Pattern Recognition (cs.CV); Optics (physics.optics)","Convolutional neural networks (CNNs) have gained tremendous success in solving complex inverse problems. The aim of this work is to develop a novel CNN framework to reconstruct video sequence of dynamic live cells captured using a computational microscopy technique, Fourier ptychographic microscopy (FPM). The unique feature of the FPM is its capability to reconstruct images with both wide field-of-view (FOV) and high resolution, i.e. a large space-bandwidth-product (SBP), by taking a series of low resolution intensity images. For live cell imaging, a single FPM frame contains thousands of cell samples with different morphological features. Our idea is to fully exploit the statistical information provided by this large spatial ensemble so as to make predictions in a sequential measurement, without using any additional temporal dataset. Specifically, we show that it is possible to reconstruct high-SBP dynamic cell videos by a CNN trained only on the first FPM dataset captured at the beginning of a time-series experiment. Our CNN approach reconstructs a 12800X10800 pixels phase image using only ~25 seconds, a 50X speedup compared to the model-based FPM algorithm. In addition, the CNN further reduces the required number of images in each time frame by ~6X. Overall, this significantly improves the imaging throughput by reducing both the acquisition and computational times. The proposed CNN is based on the conditional generative adversarial network (cGAN) framework. Additionally, we also exploit transfer learning so that our pre-trained CNN can be further optimized to image other cell types. Our technique demonstrates a promising deep learning approach to continuously monitor large live-cell populations over an extended time and gather useful spatial and temporal information with sub-cellular resolution.","Fri, 27 Apr 2018 02:53:25 UTC (1,267 KB)[v2] Thu, 26 Jul 2018 20:16:23 UTC (1,610 KB)[v3] Mon, 30 Jul 2018 22:59:06 UTC (1,610 KB)"
"706","Predicting resonant properties of plasmonic structures by deep learning","Iman Sajedian, Jeonghyun Kim, Junsuk Rho","Computer Vision and Pattern Recognition (cs.CV); Optics (physics.optics)","Deep learning can be used to extract meaningful results from images. In this paper, we used convolutional neural networks combined with recurrent neural networks on images of plasmonic structures and extract absorption data form them. To provide the required data for the model we did 100,000 simulations with similar setups and random structures. By designing a deep network we could find a model that could predict the absorption of any structure with similar setup. We used convolutional neural networks to get the spatial information from the images and we used recurrent neural networks to help the model find the relationship between the spatial information obtained from convolutional neural network model. With this design we could reach a very low loss in predicting the absorption compared to the results obtained from numerical simulation in a very short time.","Thu, 19 Apr 2018 09:25:35 UTC (1,125 KB)"
"707","Deep learning improved by biological activation functions","Gardave S Bhumbra","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG); Machine Learning (stat.ML)","`Biologically inspired' activation functions, such as the logistic sigmoid, have been instrumental in the historical advancement of machine learning. However in the field of deep learning, they have been largely displaced by rectified linear units (ReLU) or similar functions, such as its exponential linear unit (ELU) variant, to mitigate the effects of vanishing gradients associated with error back-propagation. The logistic sigmoid however does not represent the true input-output relation in neuronal cells under physiological conditions. Here, bionodal root unit (BRU) activation functions are introduced, exhibiting input-output non-linearities that are substantially more biologically plausible since their functional form is based on known biophysical properties of neuronal cells. In order to evaluate the learning performance of BRU activations, deep networks are constructed with identical architectures except differing in their transfer functions (ReLU, ELU, and BRU). Multilayer perceptrons, stacked auto-encoders, and convolutional networks are used to test supervised and unsupervised learning based on the MNIST and CIFAR-10/100 datasets. Comparisons of learning performance, quantified using loss and error measurements, demonstrate that bionodal networks both train faster than their ReLU and ELU counterparts and result in the best generalised models even in the absence of formal regularisation. These results therefore suggest that revisiting the detailed properties of biological neurones and their circuitry might prove invaluable in the field of deep learning for the future.","Mon, 19 Mar 2018 10:20:28 UTC (521 KB)[v2] Fri, 18 May 2018 08:59:48 UTC (844 KB)"
"708","SHADE: Information Based Regularization for Deep Learning","Michael Blot, Thomas Robert, Nicolas Thome, Matthieu Cord","Machine Learning (stat.ML); Machine Learning (cs.LG)","Regularization is a big issue for training deep neural networks. In this paper, we propose a new information-theory-based regularization scheme named SHADE for SHAnnon DEcay. The originality of the approach is to define a prior based on conditional entropy, which explicitly decouples the learning of invariant representations in the regularizer and the learning of correlations between inputs and labels in the data fitting term. Our second contribution is to derive a stochastic version of the regularizer compatible with deep learning, resulting in a tractable training scheme. We empirically validate the efficiency of our approach to improve classification performances compared to common regularization schemes on several standard architectures.","Sun, 29 Apr 2018 20:32:23 UTC (664 KB)[v2] Mon, 7 May 2018 14:08:23 UTC (667 KB)[v3] Mon, 14 May 2018 14:12:02 UTC (667 KB)[v4] Tue, 22 May 2018 09:14:08 UTC (667 KB)"
"709","Imbalanced Deep Learning by Minority Class Incremental Rectification","Qi Dong, Shaogang Gong, Xiatian Zhu","Computer Vision and Pattern Recognition (cs.CV)","Model learning from class imbalanced training data is a long-standing and significant challenge for machine learning. In particular, existing deep learning methods consider mostly either class balanced data or moderately imbalanced data in model training, and ignore the challenge of learning from significantly imbalanced training data. To address this problem, we formulate a class imbalanced deep learning model based on batch-wise incremental minority (sparsely sampled) class rectification by hard sample mining in majority (frequently sampled) classes during model training. This model is designed to minimise the dominant effect of majority classes by discovering sparsely sampled boundaries of minority classes in an iterative batch-wise learning process. To that end, we introduce a Class Rectification Loss (CRL) function that can be deployed readily in deep network architectures. Extensive experimental evaluations are conducted on three imbalanced person attribute benchmark datasets (CelebA, X-Domain, DeepFashion) and one balanced object category benchmark dataset (CIFAR-100). These experimental results demonstrate the performance advantages and model scalability of the proposed batch-wise incremental minority class rectification model over the existing state-of-the-art models for addressing the problem of imbalanced data learning.","Sat, 28 Apr 2018 22:36:19 UTC (7,339 KB)"
"710","Deep Learning based Inter-Modality Image Registration Supervised by Intra-Modality Similarity","Xiaohuan Cao, Jianhua Yang, Li Wang, Zhong Xue, Qian Wang, Dinggang Shen","Computer Vision and Pattern Recognition (cs.CV)","Non-rigid inter-modality registration can facilitate accurate information fusion from different modalities, but it is challenging due to the very different image appearances across modalities. In this paper, we propose to train a non-rigid inter-modality image registration network, which can directly predict the transformation field from the input multimodal images, such as CT and MR images. In particular, the training of our inter-modality registration network is supervised by intra-modality similarity metric based on the available paired data, which is derived from a pre-aligned CT and MR dataset. Specifically, in the training stage, to register the input CT and MR images, their similarity is evaluated on the warped MR image and the MR image that is paired with the input CT. So that, the intra-modality similarity metric can be directly applied to measure whether the input CT and MR images are well registered. Moreover, we use the idea of dual-modality fashion, in which we measure the similarity on both CT modality and MR modality. In this way, the complementary anatomies in both modalities can be jointly considered to more accurately train the inter-modality registration network. In the testing stage, the trained inter-modality registration network can be directly applied to register the new multimodal images without any paired data. Experimental results have shown that, the proposed method can achieve promising accuracy and efficiency for the challenging non-rigid inter-modality registration task and also outperforms the state-of-the-art approaches.","Sat, 28 Apr 2018 03:53:42 UTC (2,231 KB)"
"711","Mathematical deep learning for pose and binding affinity prediction and ranking in D3R Grand Challenges","Duc Duy Nguyen, Zixuan Cang, Kedi Wu, Menglun Wang, Yin Cao, Guo-Wei Wei","Biomolecules (q-bio.BM)","Advanced mathematics, such as multiscale weighted colored graph and element specific persistent homology, and machine learning including deep neural networks were integrated to construct mathematical deep learning models for pose and binding affinity prediction and ranking in the last two D3R grand challenges in computer-aided drug design and discovery. D3R Grand Challenge 2 (GC2) focused on the pose prediction and binding affinity ranking and free energy prediction for Farnesoid X receptor ligands. Our models obtained the top place in absolute free energy prediction for free energy Set 1 in Stage 2. The latest competition, D3R Grand Challenge 3 (GC3), is considered as the most difficult challenge so far. It has 5 subchallenges involving Cathepsin S and five other kinase targets, namely VEGFR2, JAK2, p38-$メ$, TIE2, and ABL1. There is a total of 26 official competitive tasks for GC3. Our predictions were ranked 1st in 10 out of 26 official competitive tasks.","Fri, 27 Apr 2018 18:54:15 UTC (657 KB)"
"712","Automatic classification of trees using a UAV onboard camera and deep learning","Masanori Onishi, Takeshi Ise","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Automatic classification of trees using remotely sensed data has been a dream of many scientists and land use managers. Recently, Unmanned aerial vehicles (UAV) has been expected to be an easy-to-use, cost-effective tool for remote sensing of forests, and deep learning has attracted attention for its ability concerning machine vision. In this study, using a commercially available UAV and a publicly available package for deep learning, we constructed a machine vision system for the automatic classification of trees. In our method, we segmented a UAV photography image of forest into individual tree crowns and carried out object-based deep learning. As a result, the system was able to classify 7 tree types at 89.0% accuracy. This performance is notable because we only used basic RGB images from a standard UAV. In contrast, most of previous studies used expensive hardware such as multispectral imagers to improve the performance. This result means that our method has the potential to classify individual trees in a cost-effective manner. This can be a usable tool for many forest researchers and managements.","Fri, 27 Apr 2018 08:38:22 UTC (677 KB)"
"713","dhSegment: A generic deep-learning approach for document segmentation","Sofia Ares Oliveira, Benoit Seguin, Frederic Kaplan (Digital Humanities Laboratory, EPFL, Switzerland)","Computer Vision and Pattern Recognition (cs.CV)","In recent years there have been multiple successful attempts tackling document processing problems separately by designing task specific hand-tuned strategies. We argue that the diversity of historical document processing tasks prohibits to solve them one at a time and shows a need for designing generic approaches in order to handle the variability of historical series. In this paper, we address multiple tasks simultaneously such as page extraction, baseline extraction, layout analysis or multiple typologies of illustrations and photograph extraction. We propose an open-source implementation of a CNN-based pixel-wise predictor coupled with task dependent post-processing blocks. We show that a single CNN-architecture can be used across tasks with competitive results. Moreover most of the task-specific post-precessing steps can be decomposed in a small number of simple and standard reusable operations, adding to the flexibility of our approach.","Fri, 27 Apr 2018 07:53:53 UTC (7,002 KB)"
"714","Deep Learning Coordinated Beamforming for Highly-Mobile Millimeter Wave Systems","Ahmed Alkhateeb, Sam Alex, Paul Varkey, Ying Li, Qi Qu, Djordje Tujkovic","Information Theory (cs.IT)","Supporting high mobility in millimeter wave (mmWave) systems enables a wide range of important applications such as vehicular communications and wireless virtual/augmented reality. Realizing this in practice, though, requires overcoming several challenges. First, the use of narrow beams and the sensitivity of mmWave signals to blockage greatly impact the coverage and reliability of highly-mobile links. Second, highly-mobile users in dense mmWave deployments need to frequently hand-off between base stations (BSs), which is associated with critical control and latency overhead. Further, identifying the optimal beamforming vectors in large antenna array mmWave systems requires considerable training overhead, which significantly affects the efficiency of these mobile systems. In this paper, a novel integrated machine learning and coordinated beamforming solution is developed to overcome these challenges and enable highly-mobile mmWave applications. In the proposed solution, a number of distributed yet coordinating BSs simultaneously serve a mobile user. This user ideally needs to transmit only one uplink training pilot sequence that will be jointly received at the coordinating BSs using omni or quasi-omni beam patterns. These received signals draw a defining signature not only for the user location, but also for its interaction with the surrounding environment. The developed solution then leverages a deep learning model that learns how to use these signatures to predict the beamforming vectors at the BSs. This renders a comprehensive solution that supports highly-mobile mmWave applications with reliable coverage, low latency, and negligible training overhead. Simulation results show that the proposed deep-learning coordinated beamforming strategy approaches the achievable rate of the genie-aided solution that knows the optimal beamforming vectors with no training overhead.","Fri, 27 Apr 2018 04:07:49 UTC (950 KB)[v2] Sun, 18 Nov 2018 07:05:17 UTC (1,461 KB)"
"715","CD-CNN: A Partially Supervised Cross-Domain Deep Learning Model for Urban Resident Recognition","Jingyuan Wang, Xu He, Ze Wang, Junjie Wu, Nicholas Jing Yuan, Xing Xie, Zhang Xiong","Computers and Society (cs.CY)","Driven by the wave of urbanization in recent decades, the research topic about migrant behavior analysis draws great attention from both academia and the government. Nevertheless, subject to the cost of data collection and the lack of modeling methods, most of existing studies use only questionnaire surveys with sparse samples and non-individual level statistical data to achieve coarse-grained studies of migrant behaviors. In this paper, a partially supervised cross-domain deep learning model named CD-CNN is proposed for migrant/native recognition using mobile phone signaling data as behavioral features and questionnaire survey data as incomplete labels. Specifically, CD-CNN features in decomposing the mobile data into location domain and communication domain, and adopts a joint learning framework that combines two convolutional neural networks with a feature balancing scheme. Moreover, CD-CNN employs a three-step algorithm for training, in which the co-training step is of great value to partially supervised cross-domain learning. Comparative experiments on the city Wuxi demonstrate the high predictive power of CD-CNN. Two interesting applications further highlight the ability of CD-CNN for in-depth migrant behavioral analysis.","Thu, 26 Apr 2018 06:10:50 UTC (873 KB)[v2] Thu, 11 Oct 2018 17:03:10 UTC (877 KB)"
"716","Prospects for Theranostics in Neurosurgical Imaging: Empowering Confocal Laser Endomicroscopy Diagnostics via Deep Learning","Mohammadhassan Izadyyazdanabadi, Evgenii Belykh, Michael Mooney, Jennifer Eschbacher, Peter Nakaji, Yezhou Yang, Mark C. Preul","Computer Vision and Pattern Recognition (cs.CV)","Confocal laser endomicroscopy (CLE) is an advanced optical fluorescence imaging technology that has the potential to increase intraoperative precision, extend resection, and tailor surgery for malignant invasive brain tumors because of its subcellular dimension resolution. Despite its promising diagnostic potential, interpreting the gray tone fluorescence images can be difficult for untrained users. In this review, we provide a detailed description of bioinformatical analysis methodology of CLE images that begins to assist the neurosurgeon and pathologist to rapidly connect on-the-fly intraoperative imaging, pathology, and surgical observation into a conclusionary system within the concept of theranostics. We present an overview and discuss deep learning models for automatic detection of the diagnostic CLE images and discuss various training regimes and ensemble modeling effect on the power of deep learning predictive models. Two major approaches reviewed in this paper include the models that can automatically classify CLE images into diagnostic/nondiagnostic, glioma/nonglioma, tumor/injury/normal categories and models that can localize histological features on the CLE images using weakly supervised methods. We also briefly review advances in the deep learning approaches used for CLE image analysis in other organs. Significant advances in speed and precision of automated diagnostic frame selection would augment the diagnostic potential of CLE, improve operative workflow and integration into brain tumor surgery. Such technology and bioinformatics analytics lend themselves to improved precision, personalization, and theranostics in brain tumor treatment.","Thu, 26 Apr 2018 03:33:37 UTC (353 KB)[v2] Sat, 18 Aug 2018 06:42:49 UTC (208 KB)"
"717","Off the Beaten Track: Using Deep Learning to Interpolate Between Music Genres","Tijn Borghuis, Alessandro Tibo, Simone Conforti, Luca Canciello, Lorenzo Brusci, Paolo Frasconi","Sound (cs.SD); Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)","We describe a system based on deep learning that generates drum patterns in the electronic dance music domain. Experimental results reveal that generated patterns can be employed to produce musically sound and creative transitions between different genres, and that the process of generation is of interest to practitioners in the field.","Wed, 25 Apr 2018 21:39:39 UTC (895 KB)[v2] Wed, 2 May 2018 16:56:08 UTC (894 KB)"
"718","3D Consistent & Robust Segmentation of Cardiac Images by Deep Learning with Spatial Propagation","Qiao Zheng, Herve Delingette, Nicolas Duchateau, Nicholas Ayache","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","We propose a method based on deep learning to perform cardiac segmentation on short axis MRI image stacks iteratively from the top slice (around the base) to the bottom slice (around the apex). At each iteration, a novel variant of U-net is applied to propagate the segmentation of a slice to the adjacent slice below it. In other words, the prediction of a segmentation of a slice is dependent upon the already existing segmentation of an adjacent slice. 3D-consistency is hence explicitly enforced. The method is trained on a large database of 3078 cases from UK Biobank. It is then tested on 756 different cases from UK Biobank and three other state-of-the-art cohorts (ACDC with 100 cases, Sunnybrook with 30 cases, RVSC with 16 cases). Results comparable or even better than the state-of-the-art in terms of distance measures are achieved. They also emphasize the assets of our method, namely enhanced spatial consistency (currently neither considered nor achieved by the state-of-the-art), and the generalization ability to unseen cases even from other databases.","Wed, 25 Apr 2018 07:39:36 UTC (2,862 KB)"
"719","Deep Learning for Predicting Asset Returns","Guanhao Feng, Jingyu He, Nicholas G. Polson","Machine Learning (stat.ML); Machine Learning (cs.LG); Econometrics (econ.EM)","Deep learning searches for nonlinear factors for predicting asset returns. Predictability is achieved via multiple layers of composite factors as opposed to additive ones. Viewed in this way, asset pricing studies can be revisited using multi-layer deep learners, such as rectified linear units (ReLU) or long-short-term-memory (LSTM) for time-series effects. State-of-the-art algorithms including stochastic gradient descent (SGD), TensorFlow and dropout design provide imple- mentation and efficient factor exploration. To illustrate our methodology, we revisit the equity market risk premium dataset of Welch and Goyal (2008). We find the existence of nonlinear factors which explain predictability of returns, in particular at the extremes of the characteristic space. Finally, we conclude with directions for future research.","Wed, 25 Apr 2018 01:52:34 UTC (3,661 KB)[v2] Thu, 26 Apr 2018 14:50:14 UTC (3,660 KB)"
"720","Recent Progresses in Deep Learning based Acoustic Models (Updated)","Dong Yu, Jinyu Li","Audio and Speech Processing (eess.AS); Computation and Language (cs.CL); Sound (cs.SD)","In this paper, we summarize recent progresses made in deep learning based acoustic models and the motivation and insights behind the surveyed techniques. We first discuss acoustic models that can effectively exploit variable-length contextual information, such as recurrent neural networks (RNNs), convolutional neural networks (CNNs), and their various combination with other models. We then describe acoustic models that are optimized end-to-end with emphasis on feature representations learned jointly with rest of the system, the connectionist temporal classification (CTC) criterion, and the attention-based sequence-to-sequence model. We further illustrate robustness issues in speech recognition systems, and discuss acoustic model adaptation, speech enhancement and separation, and robust training strategies. We also cover modeling techniques that lead to more efficient decoding and discuss possible future directions in acoustic model research.","Wed, 25 Apr 2018 00:24:39 UTC (522 KB)[v2] Fri, 27 Apr 2018 01:13:39 UTC (522 KB)"
"721","A Deep Learning based Approach to Reduced Order Modeling for Turbulent Flow Control using LSTM Neural Networks","Arvind T. Mohan, Datta V. Gaitonde","Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)","Reduced Order Modeling (ROM) for engineering applications has been a major research focus in the past few decades due to the unprecedented physical insight into turbulence offered by high-fidelity CFD. The primary goal of a ROM is to model the key physics/features of a flow-field without computing the full Navier-Stokes (NS) equations. This is accomplished by projecting the high-dimensional dynamics to a low-dimensional subspace, typically utilizing dimensionality reduction techniques like Proper Orthogonal Decomposition (POD), coupled with Galerkin projection. In this work, we demonstrate a deep learning based approach to build a ROM using the POD basis of canonical DNS datasets, for turbulent flow control applications. We find that a type of Recurrent Neural Network, the Long Short Term Memory (LSTM) which has been primarily utilized for problems like speech modeling and language translation, shows attractive potential in modeling temporal dynamics of turbulence. Additionally, we introduce the Hurst Exponent as a tool to study LSTM behavior for non-stationary data, and uncover useful characteristics that may aid ROM development for a variety of applications.","Tue, 24 Apr 2018 21:48:22 UTC (5,992 KB)"
"722","DeepTriangle: A Deep Learning Approach to Loss Reserving","Kevin Kuo","Applications (stat.AP); Machine Learning (cs.LG); Risk Management (q-fin.RM)","We propose a novel approach for loss reserving based on deep neural networks. The approach allows for jointly modeling of paid losses and claims outstanding, and incorporation of heterogenous inputs. We validate the models on loss reserving data across lines of business, and show that they attain or exceed the predictive accuracy of existing stochastic methods. The models require minimal feature engineering and expert input, and can be automated to produce forecasts at a high frequency.","Tue, 24 Apr 2018 20:47:04 UTC (158 KB)[v2] Fri, 18 May 2018 20:35:59 UTC (128 KB)"
"723","Automated Mouse Organ Segmentation: A Deep Learning Based Solution","Naveen Ashish, Mi-Youn Brusniak","Computer Vision and Pattern Recognition (cs.CV)","The analysis of animal cross section images, such as cross sections of laboratory mice, is critical in assessing the effect of experimental drugs such as the biodistribution of candidate compounds in preclinical drug development stage. Tissue distribution of radiolabeled candidate therapeutic compounds can be quantified using techniques like Quantitative Whole-Body Autoradiography (QWBA).QWBA relies, among other aspects, on the accurate segmentation or identification of key organs of interest in the animal cross section image such as the brain, spine, heart, liver and others. We present a deep learning based organ segmentation solution to this problem, using which we can achieve automated organ segmentation with high precision (dice coefficient in the 0.83-0.95 range depending on organ) for the key organs of interest.","Tue, 24 Apr 2018 18:38:01 UTC (818 KB)[v2] Mon, 16 Jul 2018 19:52:50 UTC (872 KB)"
"724","An Information-Theoretic View for Deep Learning","Jingwei Zhang, Tongliang Liu, Dacheng Tao","Machine Learning (stat.ML); Machine Learning (cs.LG)","Deep learning has transformed computer vision, natural language processing, and speech recognition\cite{badrinarayanan2017segnet, dong2016image, ren2017faster, ji20133d}. However, two critical questions remain obscure: (1) why do deep neural networks generalize better than shallow networks; and (2) does it always hold that a deeper network leads to better performance? Specifically, letting $L$ be the number of convolutional and pooling layers in a deep neural network, and $n$ be the size of the training sample, we derive an upper bound on the expected generalization error for this network, i.e., \begin{eqnarray*} \mathbb{E}[R(W)-R_S(W)] \leq \exp{\left(-\frac{L}{2}\log{\frac{1}ョ}\right)}\sqrt{\frac{2ヲ^2}{n}I(S,W) } \end{eqnarray*} where $ヲ>0$ is a constant depending on the loss function, $0<ョ<1$ is a constant depending on the information loss for each convolutional or pooling layer, and $I(S, W)$ is the mutual information between the training sample $S$ and the output hypothesis $W$. This upper bound shows that as the number of convolutional and pooling layers $L$ increases in the network, the expected generalization error will decrease exponentially to zero. Layers with strict information loss, such as the convolutional layers, reduce the generalization error for the whole network; this answers the first question. However, algorithms with zero expected generalization error does not imply a small test error or $\mathbb{E}[R(W)]$. This is because $\mathbb{E}[R_S(W)]$ is large when the information for fitting the data is lost as the number of layers increases. This suggests that the claim `the deeper the better' is conditioned on a small training error or $\mathbb{E}[R_S(W)]$. Finally, we show that deep learning satisfies a weak notion of stability and the sample complexity of deep neural networks will decrease as $L$ increases.","Tue, 24 Apr 2018 14:13:19 UTC (398 KB)[v2] Thu, 3 May 2018 09:27:38 UTC (273 KB)[v3] Fri, 18 May 2018 09:40:26 UTC (275 KB)[v4] Mon, 28 May 2018 12:58:28 UTC (414 KB)[v5] Wed, 30 May 2018 11:57:48 UTC (414 KB)[v6] Thu, 31 May 2018 13:04:59 UTC (414 KB)[v7] Tue, 5 Jun 2018 01:57:20 UTC (415 KB)[v8] Tue, 2 Oct 2018 12:49:32 UTC (838 KB)"
"725","P-wave arrival picking and first-motion polarity determination with deep learning","Zachary E. Ross, Men-Andrin Meier, Egill Hauksson","Geophysics (physics.geo-ph)","Determining earthquake hypocenters and focal mechanisms requires precisely measured P-wave arrival times and first-motion polarities. Automated algorithms for estimating these quantities have been less accurate than estimates by human experts, which is problematic for processing large data volumes. Here, we train convolutional neural networks to measure both quantities, which learn directly from seismograms without the need for feature extraction. The networks are trained on 18.2 million manually picked seismograms for the southern California region. Through cross-validation on 1.2 million independent seismograms, the differences between the automated and manual picks have a standard deviation of 0.023 seconds. The polarities determined by the classifier have a precision of 95% when compared with analyst-determined polarities. We show that the classifier picks more polarities overall than the analysts, without sacrificing quality, resulting in almost double the number of focal mechanisms. The remarkable precision of the trained networks indicates that they can perform as well, or better, than expert seismologists.","Tue, 24 Apr 2018 01:45:03 UTC (1,199 KB)"
"726","Query-Efficient GAN Based Black-Box Attack Against Sequence Based Machine and Deep Learning Classifiers","Ishai Rosenberg, Asaf Shabtai, Yuval Elovici, Lior Rokach","Cryptography and Security (cs.CR); Machine Learning (cs.LG)","In this paper we present an efficient and generic black-box attack demonstrated against API call based machine learning malware classifiers. We generate adversarial examples combining sequences (API call sequences) and other features (e.g., printable strings) that will be misclassified by the classifier without affecting the malware functionality. Opposed to previous studies, our attack minimizes the number of target classifier queries and only requires access to the predicted label of the attacked model (without the confidence level). We evaluate the attack's effectiveness against a variety of classifiers, including recurrent neural network variants, deep neural networks, support vector machines, and gradient-boosted decision trees. We show that the attack requires fewer queries and less knowledge about the attacked model's architecture than other existing black-box attacks, making it practical for attacking cloud based models at a minimal cost. We also implement a software framework that can be used to recraft any malware binary so it will not be detected by classifiers, without access to the malware source code. Finally, we discuss the robustness of this attack to existing defense mechanisms.","Mon, 23 Apr 2018 23:31:09 UTC (213 KB)[v2] Fri, 7 Sep 2018 11:29:11 UTC (146 KB)[v3] Sat, 22 Sep 2018 18:25:48 UTC (88 KB)[v4] Fri, 23 Nov 2018 09:59:04 UTC (206 KB)"
"727","BrainSlug: Transparent Acceleration of Deep Learning Through Depth-First Parallelism","Nicolas Weber, Florian Schmidt, Mathias Niepert, Felipe Huici","Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE); Performance (cs.PF)","Neural network frameworks such as PyTorch and TensorFlow are the workhorses of numerous machine learning applications ranging from object recognition to machine translation. While these frameworks are versatile and straightforward to use, the training of and inference in deep neural networks is resource (energy, compute, and memory) intensive. In contrast to recent works focusing on algorithmic enhancements, we introduce BrainSlug, a framework that transparently accelerates neural network workloads by changing the default layer-by-layer processing to a depth-first approach, reducing the amount of data required by the computations and thus improving the performance of the available hardware caches. BrainSlug achieves performance improvements of up to 41.1% on CPUs and 35.7% on GPUs. These optimizations come at zero cost to the user as they do not require hardware changes and only need tiny adjustments to the software.","Mon, 23 Apr 2018 12:49:04 UTC (473 KB)"
"728","Deep Learning in Spiking Neural Networks","Amirhossein Tavanaei, Masoud Ghodrati, Saeed Reza Kheradpisheh, Timothee Masquelier, Anthony S. Maida","Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI)","In recent years, deep learning has been a revolution in the field of machine learning, for computer vision in particular. In this approach, a deep (multilayer) artificial neural network (ANN) is trained in a supervised manner using backpropagation. Huge amounts of labeled examples are required, but the resulting classification accuracy is truly impressive, sometimes outperforming humans. Neurons in an ANN are characterized by a single, static, continuous-valued activation. Yet biological neurons use discrete spikes to compute and transmit information, and the spike times, in addition to the spike rates, matter. Spiking neural networks (SNNs) are thus more biologically realistic than ANNs, and arguably the only viable option if one wants to understand how the brain computes. SNNs are also more hardware friendly and energy-efficient than ANNs, and are thus appealing for technology, especially for portable devices. However, training deep SNNs remains a challenge. Spiking neurons' transfer function is usually non-differentiable, which prevents using backpropagation. Here we review recent supervised and unsupervised methods to train deep SNNs, and compare them in terms of accuracy, but also computational cost and hardware friendliness. The emerging picture is that SNNs still lag behind ANNs in terms of accuracy, but the gap is decreasing, and can even vanish on some tasks, while the SNNs typically require much fewer operations.","Sun, 22 Apr 2018 18:27:34 UTC (3,996 KB)[v2] Tue, 15 May 2018 02:48:45 UTC (3,998 KB)[v3] Sat, 1 Sep 2018 14:43:38 UTC (4,011 KB)"
"729","A Deep Learning Approach for Forecasting Air Pollution in South Korea Using LSTM","Tien-Cuong Bui, Van-Duc Le, Sang-Kyun Cha","Machine Learning (cs.LG); Computers and Society (cs.CY); Machine Learning (stat.ML)","Tackling air pollution is an imperative problem in South Korea, especially in urban areas, over the last few years. More specially, South Korea has joined the ranks of the world's most polluted countries alongside with other Asian capitals, such as Beijing or Delhi. Much research is being conducted in environmental science to evaluate the dangerous impact of particulate matters on public health. Besides that, deterministic models of air pollutant behavior are also generated; however, this is both complex and often inaccurate. On the contrary, deep recurrent neural network reveals potent potential on forecasting out-comes of time-series data and has become more prevalent. This paper uses Recurrent Neural Network (RNN) with Long Short-Term Memory units as a framework for leveraging knowledge from time-series data of air pollution and meteorological information in Daegu, Seoul, Beijing, and Shenyang. Additionally, we use encoder-decoder model, which is similar to machine comprehension problems, as a crucial part of our prediction machine. Finally, we investigate the prediction accuracy of various configurations. Our experiments prevent the efficiency of integrating multiple layers of RNN on prediction model when forecasting far timesteps ahead. This research is a significant motivation for not only continuing researching on urban air quality but also help the government leverage that insight to enact beneficial policies","Sat, 21 Apr 2018 05:07:47 UTC (1,004 KB)[v2] Tue, 8 May 2018 01:24:44 UTC (579 KB)[v3] Thu, 10 May 2018 13:45:12 UTC (582 KB)"
"730","Super-resolution Ultrasound Localization Microscopy through Deep Learning","Ruud J.G. van Sloun, Oren Solomon, Matthew Bruce, Zin Z. Khaing, Hessel Wijkstra, Yonina C. Eldar, Massimo Mischi","Signal Processing (eess.SP); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)","Ultrasound localization microscopy has enabled super-resolution vascular imaging in laboratory environments through precise localization of individual ultrasound contrast agents across numerous imaging frames. However, analysis of high-density regions with significant overlaps among the agents' point spread responses yields high localization errors, constraining the technique to low-concentration conditions. As such, long acquisition times are required to sufficiently cover the vascular bed. In this work, we present a fast and precise method for obtaining super-resolution vascular images from high-density contrast-enhanced ultrasound imaging data. This method, which we term Deep Ultrasound Localization Microscopy (Deep-ULM), exploits modern deep learning strategies and employs a convolutional neural network to perform localization microscopy in dense scenarios. This end-to-end fully convolutional neural network architecture is trained effectively using on-line synthesized data, enabling robust inference in-vivo under a wide variety of imaging conditions. We show that deep learning attains super-resolution with challenging contrast-agent concentrations (microbubble densities), both in-silico as well as in-vivo, as we go from ultrasound scans of a rodent spinal cord in an experimental setting to standard clinically-acquired recordings in a human prostate. Deep-ULM achieves high quality sub-diffraction recovery, and is suitable for real-time applications, resolving about 135 high-resolution 64x64-patches per second on a standard PC. Exploiting GPU computation, this number increases to 2500 patches per second.","Fri, 20 Apr 2018 15:12:05 UTC (665 KB)"
"731","Detecting Solar-like Oscillations in Red Giants with Deep Learning","Marc Hon, Dennis Stello, Joel C. Zinn","Solar and Stellar Astrophysics (astro-ph.SR); Instrumentation and Methods for Astrophysics (astro-ph.IM)","Time-resolved photometry of tens of thousands of red giant stars from space missions like Kepler and K2 has created the need for automated asteroseismic analysis methods. The first and most fundamental step in such analysis, is to identify which stars show oscillations. It is critical that this step can be performed with no, or little, detection bias, particularly when performing subsequent ensemble analyses that aim to compare properties of observed stellar populations with those from galactic models. Yet, an efficient, automated solution to this initial detection step has still not been found, meaning that expert visual inspection of data from each star is required to obtain the highest level of detections. Hence, to mimic how an expert eye analyses the data, we use supervised deep learning to not only detect oscillations in red giants, but also predict the location of the frequency at maximum power, $ロ_{\mathrm{max}}$, by observing features in 2D images of power spectra. By training on Kepler data, we benchmark our deep learning classifier against K2 data that are given detections by the expert eye, achieving a detection accuracy of 98% on K2 Campaign 6 stars and a detection accuracy of 99% on K2 Campaign 3 stars. We further find that the estimated uncertainty of our deep learning-based $ロ_{\mathrm{max}}$ predictions is about 5%. This is comparable to human-level performance using visual inspection. When examining outliers we find that the deep learning results are more likely to provide robust $ロ_{\mathrm{max}}$ estimates than the classical model-fitting method.","Fri, 20 Apr 2018 08:55:31 UTC (3,151 KB)"
"732","GritNet: Student Performance Prediction with Deep Learning","Byung-Hak Kim, Ethan Vizitei, Varun Ganapathi","Machine Learning (cs.LG); Computers and Society (cs.CY); Machine Learning (stat.ML)","Student performance prediction - where a machine forecasts the future performance of students as they interact with online coursework - is a challenging problem. Reliable early-stage predictions of a student's future performance could be critical to facilitate timely educational interventions during a course. However, very few prior studies have explored this problem from a deep learning perspective. In this paper, we recast the student performance prediction problem as a sequential event prediction problem and propose a new deep learning based algorithm, termed GritNet, which builds upon the bidirectional long short term memory (BLSTM). Our results, from real Udacity students' graduation predictions, show that the GritNet not only consistently outperforms the standard logistic-regression based method, but that improvements are substantially pronounced in the first few weeks when accurate predictions are most challenging.","Thu, 19 Apr 2018 23:35:04 UTC (28 KB)"
"733","Minimizing Area and Energy of Deep Learning Hardware Design Using Collective Low Precision and Structured Compression","Shihui Yin, Gaurav Srivastava, Shreyas K. Venkataramanaiah, Chaitali Chakrabarti, Visar Berisha, Jae-sun Seo","Neural and Evolutionary Computing (cs.NE)","Deep learning algorithms have shown tremendous success in many recognition tasks; however, these algorithms typically include a deep neural network (DNN) structure and a large number of parameters, which makes it challenging to implement them on power/area-constrained embedded platforms. To reduce the network size, several studies investigated compression by introducing element-wise or row-/column-/block-wise sparsity via pruning and regularization. In addition, many recent works have focused on reducing precision of activations and weights with some reducing down to a single bit. However, combining various sparsity structures with binarized or very-low-precision (2-3 bit) neural networks have not been comprehensively explored. In this work, we present design techniques for minimum-area/-energy DNN hardware with minimal degradation in accuracy. During training, both binarization/low-precision and structured sparsity are applied as constraints to find the smallest memory footprint for a given deep learning algorithm. The DNN model for CIFAR-10 dataset with weight memory reduction of 50X exhibits accuracy comparable to that of the floating-point counterpart. Area, performance and energy results of DNN hardware in 40nm CMOS are reported for the MNIST dataset. The optimized DNN that combines 8X structured compression and 3-bit weight precision showed 98.4% accuracy at 20nJ per classification.","Thu, 19 Apr 2018 20:32:04 UTC (1,422 KB)"
"734","Deep Learning Identifies High-z Galaxies in a Central Blue Nugget Phase in a Characteristic Mass Range","M. Huertas-Company, J.R. Primack, A. Dekel, D.C. Koo, S. Lapiner, D. Ceverino, R.C. Simons, G.F. Snyder, M. Bernardi, Z. Chen, H. Dominguez-Sanchez, Z. Chen, C.T. Lee, B. Margalef-Bentabol, D. Tuccillo","Astrophysics of Galaxies (astro-ph.GA)","We use machine learning to identify in color images of high-redshift galaxies an astrophysical phenomenon predicted by cosmological simulations. This phenomenon, called the blue nugget (BN) phase, is the compact star-forming phase in the central regions of many growing galaxies that follows an earlier phase of gas compaction and is followed by a central quenching phase. We train a Convolutional Neural Network (CNN) with mock ""observed"" images of simulated galaxies at three phases of evolution: pre-BN, BN and post-BN, and demonstrate that the CNN successfully retrieves the three phases in other simulated galaxies. We show that BNs are identified by the CNN within a time window of $\sim0.15$ Hubble times. When the trained CNN is applied to observed galaxies from the CANDELS survey at $z=1-3$, it successfully identifies galaxies at the three phases. We find that the observed BNs are preferentially found in galaxies at a characteristic stellar mass range, $10^{9.2-10.3} M_\odot$ at all redshifts. This is consistent with the characteristic galaxy mass for BNs as detected in the simulations, and is meaningful because it is revealed in the observations when the direct information concerning the total galaxy luminosity has been eliminated from the training set. This technique can be applied to the classification of other astrophysical phenomena for improved comparison of theory and observations in the era of large imaging surveys and cosmological simulations.","Thu, 19 Apr 2018 18:00:02 UTC (13,411 KB)"
"735","Semantic Adversarial Deep Learning","Tommaso Dreossi, Somesh Jha, Sanjit A. Seshia","Machine Learning (cs.LG); Machine Learning (stat.ML)","Fueled by massive amounts of data, models produced by machine-learning (ML) algorithms, especially deep neural networks, are being used in diverse domains where trustworthiness is a concern, including automotive systems, finance, health care, natural language processing, and malware detection. Of particular concern is the use of ML algorithms in cyber-physical systems (CPS), such as self-driving cars and aviation, where an adversary can cause serious consequences. However, existing approaches to generating adversarial examples and devising robust ML algorithms mostly ignore the semantics and context of the overall system containing the ML component. For example, in an autonomous vehicle using deep learning for perception, not every adversarial example for the neural network might lead to a harmful consequence. Moreover, one may want to prioritize the search for adversarial examples towards those that significantly modify the desired semantics of the overall system. Along the same lines, existing algorithms for constructing robust ML algorithms ignore the specification of the overall system. In this paper, we argue that the semantics and specification of the overall system has a crucial role to play in this line of research. We present preliminary research results that support this claim.","Thu, 19 Apr 2018 09:15:58 UTC (7,167 KB)[v2] Fri, 18 May 2018 18:14:19 UTC (8,433 KB)"
"736","Forward-Backward Stochastic Neural Networks: Deep Learning of High-dimensional Partial Differential Equations","Maziar Raissi","Machine Learning (stat.ML); Machine Learning (cs.LG); Systems and Control (cs.SY); Analysis of PDEs (math.AP); Optimization and Control (math.OC)","Classical numerical methods for solving partial differential equations suffer from the curse dimensionality mainly due to their reliance on meticulously generated spatio-temporal grids. Inspired by modern deep learning based techniques for solving forward and inverse problems associated with partial differential equations, we circumvent the tyranny of numerical discretization by devising an algorithm that is scalable to high-dimensions. In particular, we approximate the unknown solution by a deep neural network which essentially enables us to benefit from the merits of automatic differentiation. To train the aforementioned neural network we leverage the well-known connection between high-dimensional partial differential equations and forward-backward stochastic differential equations. In fact, independent realizations of a standard Brownian motion will act as training data. We test the effectiveness of our approach for a couple of benchmark problems spanning a number of scientific domains including Black-Scholes-Barenblatt and Hamilton-Jacobi-Bellman equations, both in 100-dimensions.","Thu, 19 Apr 2018 06:30:45 UTC (1,123 KB)"
"737","Infrared and Visible Image Fusion using a Deep Learning Framework","Hui Li, Xiao-Jun Wu, Josef Kittler","Computer Vision and Pattern Recognition (cs.CV)","In recent years, deep learning has become a very active research tool which is used in many image processing fields. In this paper, we propose an effective image fusion method using a deep learning framework to generate a single image which contains all the features from infrared and visible images. First, the source images are decomposed into base parts and detail content. Then the base parts are fused by weighted-averaging. For the detail content, we use a deep learning network to extract multi-layer features. Using these features, we use l_1-norm and weighted-average strategy to generate several candidates of the fused detail content. Once we get these candidates, the max selection strategy is used to get final fused detail content. Finally, the fused image will be reconstructed by combining the fused base part and detail content. The experimental results demonstrate that our proposed method achieves state-of-the-art performance in both objective assessment and visual quality. The Code of our fusion method is available at this https URL","Thu, 19 Apr 2018 04:30:08 UTC (7,633 KB)[v2] Mon, 23 Apr 2018 11:34:40 UTC (7,633 KB)[v3] Sat, 19 May 2018 08:45:41 UTC (4,412 KB)"
"738","DPRed: Making Typical Activation Values Matter In Deep Learning Computing","Alberto Delmas, Sayeh Sharify, Patrick Judd, Kevin Siu, Milos Nikolic, Andreas Moshovos","Neural and Evolutionary Computing (cs.NE)","We show that selecting a fixed precision for all values in Convolutional Neural Networks, even if that precision is different per layer, amounts to worst case design. We show that much lower precisions can be used if we could target the common case instead by tailoring the precision at a much finer granularity than that of a layer. While this observation may not be surprising, to date no design takes advantage of it in practice. We propose Dynamic Prediction Reduction (DPRed), where hardware on-the-fly detects the precision activations need at a much finer granularity than a whole layer. Further we encode activations and weights using the respective per group dynamically and statically detected precisions to reduce off- and on-chip storage and communication. We demonstrate a practical implementation of DPRed with DPRed Stripes (DPRS), a data-parallel hardware accelerator that adjusts precision on-the-fly to accommodate the values of the activations it processes concurrently. DPRS accelerates convolutional layers and executes unmodified convolutional neural networks. Ignoring offchip communication, DPRS is 2.61x faster and 1.84x more energy efficient than a fixed-precision accelerator for a set of convolutional neural networks. We further extend DPRS to exploit activation and weight precisions for fully-connected layers. The enhanced design improves average performance and energy efficiency respectively by 2.59x and 1.19x over the fixed-precision accelerator for a broader set of neural networks. Finally, we consider a lower cost variant that supports only even precision widths which offers better energy efficiency. Taking into account off-chip communication, DPRed compression reduces off-chip traffic to nearly 35% on average compared to no compression making it possible to sustain higher performance for a given off-chip memory interface while also boosting energy efficiency.","Tue, 17 Apr 2018 00:35:04 UTC (980 KB)[v2] Tue, 15 May 2018 22:54:15 UTC (671 KB)"
"739","The Limits and Potentials of Deep Learning for Robotics","Niko Sunderhauf, Oliver Brock, Walter Scheirer, Raia Hadsell, Dieter Fox, Jurgen Leitner, Ben Upcroft, Pieter Abbeel, Wolfram Burgard, Michael Milford, Peter Corke","Robotics (cs.RO)","The application of deep learning in robotics leads to very specific problems and research questions that are typically not addressed by the computer vision and machine learning communities. In this paper we discuss a number of robotics-specific learning, reasoning, and embodiment challenges for deep learning. We explain the need for better evaluation metrics, highlight the importance and unique challenges for deep robotic learning in simulation, and explore the spectrum between purely data-driven and model-driven approaches. We hope this paper provides a motivating overview of important research directions to overcome the current limitations, and help fulfill the promising potentials of deep learning in robotics.","Wed, 18 Apr 2018 05:16:20 UTC (460 KB)"
"740","Analysis of Extremely Obese Individuals Using Deep Learning Stacked Autoencoders and Genome-Wide Genetic Data","Casimiro A. Curbelo Montanez, Paul Fergus, Carl Chalmers, Jade Hind","Genomics (q-bio.GN); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)","The aetiology of polygenic obesity is multifactorial, which indicates that life-style and environmental factors may influence multiples genes to aggravate this disorder. Several low-risk single nucleotide polymorphisms (SNPs) have been associated with BMI. However, identified loci only explain a small proportion of the variation ob-served for this phenotype. The linear nature of genome wide association studies (GWAS) used to identify associations between genetic variants and the phenotype have had limited success in explaining the heritability variation of BMI and shown low predictive capacity in classification studies. GWAS ignores the epistatic interactions that less significant variants have on the phenotypic outcome. In this paper we utilise a novel deep learning-based methodology to reduce the high dimensional space in GWAS and find epistatic interactions between SNPs for classification purposes. SNPs were filtered based on the effects associations have with BMI. Since Bonferroni adjustment for multiple testing is highly conservative, an important proportion of SNPs involved in SNP-SNP interactions are ignored. Therefore, only SNPs with p-values < 1x10-2 were considered for subsequent epistasis analysis using stacked auto encoders (SAE). This allows the nonlinearity present in SNP-SNP interactions to be discovered through progressively smaller hidden layer units and to initialise a multi-layer feedforward artificial neural network (ANN) classifier. The classifier is fine-tuned to classify extremely obese and non-obese individuals. The best results were obtained with 2000 compressed units (SE=0.949153, SP=0.933014, Gini=0.949936, Lo-gloss=0.1956, AUC=0.97497 and MSE=0.054057). Using 50 compressed units it was possible to achieve (SE=0.785311, SP=0.799043, Gini=0.703566, Logloss=0.476864, AUC=0.85178 and MSE=0.156315).","Mon, 16 Apr 2018 15:25:14 UTC (562 KB)[v2] Fri, 24 Aug 2018 10:24:59 UTC (498 KB)"
"741","Data-driven prediction of unsteady flow fields over a circular cylinder using deep learning","Sangseung Lee, Donghyun You","Fluid Dynamics (physics.flu-dyn)","Unsteady flow fields over a circular cylinder are trained and predicted using four different deep learning networks: convolutional neural networks with and without consideration of conservation laws, generative adversarial networks with and without consideration of conservation laws. Flow fields at future occasions are predicted based on information of flow fields at previous occasions. Deep learning networks are trained first using flow fields at Reynolds numbers of 100, 200, 300, and 400, while flow fields at Reynolds numbers of 500 and 3000 are predicted using the trained deep learning networks. Physical loss functions are proposed to explicitly impose information of conservation of mass and momentum to deep learning networks. An adversarial training is applied to extract features of flow dynamics in an unsupervised manner. Effects of the proposed physical loss functions, adversarial training, and network sizes on the prediction accuracy are analyzed. Predicted flow fields using deep learning networks are in favorable agreement with flow fields computed by numerical simulations.","Tue, 17 Apr 2018 07:04:40 UTC (6,120 KB)[v2] Mon, 12 Nov 2018 00:57:30 UTC (5,558 KB)"
"742","Deep Learning on Operational Facility Data Related to Large-Scale Distributed Area Scientific Workflows","Alok Singh, Eric Stephan, Malachi Schram, Ilkay Altintas","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Performance (cs.PF)","Distributed computing platforms provide a robust mechanism to perform large-scale computations by splitting the task and data among multiple locations, possibly located thousands of miles apart geographically. Although such distribution of resources can lead to benefits, it also comes with its associated problems such as rampant duplication of file transfers increasing congestion, long job completion times, unexpected site crashing, suboptimal data transfer rates, unpredictable reliability in a time range, and suboptimal usage of storage elements. In addition, each sub-system becomes a potential failure node that can trigger system wide disruptions. In this vision paper, we outline our approach to leveraging Deep Learning algorithms to discover solutions to unique problems that arise in a system with computational infrastructure that is spread over a wide area. The presented vision, motivated by a real scientific use case from Belle II experiments, is to develop multilayer neural networks to tackle forecasting, anomaly detection and optimization challenges in a complex and distributed data movement environment. Through this vision based on Deep Learning principles, we aim to achieve reduced congestion events, faster file transfer rates, and enhanced site reliability.","Tue, 17 Apr 2018 06:29:56 UTC (448 KB)[v2] Fri, 20 Apr 2018 19:43:16 UTC (596 KB)"
"743","Compressibility and Generalization in Large-Scale Deep Learning","Wenda Zhou, Victor Veitch, Morgane Austern, Ryan P. Adams, Peter Orbanz","Machine Learning (stat.ML); Machine Learning (cs.LG)","Modern neural networks are highly overparameterized, with capacity to substantially overfit to training data. Nevertheless, these networks often generalize well in practice. It has also been observed that trained networks can often be ""compressed"" to much smaller representations. The purpose of this paper is to connect these two empirical observations. Our main technical result is a generalization bound for compressed networks based on the compressed size. Combined with off-the-shelf compression algorithms, the bound leads to state of the art generalization guarantees; in particular, we provide the first non-vacuous generalization guarantees for realistic architectures applied to the ImageNet classification problem. As additional evidence connecting compression and generalization, we show that compressibility of models that tend to overfit is limited: We establish an absolute limit on expected compressibility as a function of expected generalization error, where the expectations are over the random choice of training examples. The bounds are complemented by empirical results that show an increase in overfitting implies an increase in the number of bits required to describe a trained network.","Mon, 16 Apr 2018 18:01:12 UTC (35 KB)[v2] Mon, 21 May 2018 17:27:12 UTC (75 KB)"
"744","BigDL: A Distributed Deep Learning Framework for Big Data","Jason Dai, Yiheng Wang, Xin Qiu, Ding Ding, Yao Zhang, Yanzhang Wang, Xianyan Jia, Cherry Zhang, Yan Wan, Zhichao Li, Jiao Wang, Shengsheng Huang, Zhongyuan Wu, Yang Wang, Yuhao Yang, Bowen She, Dongjie Shi, Qi Lu, Kai Huang, Guoqiong Song","Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","In this paper, we present BigDL, a distributed deep learning framework for Big Data platforms and workflows. It is implemented on top of Apache Spark, and allows users to write their deep learning applications as standard Spark programs (running directly on large-scale big data clusters in a distributed fashion). It provides an expressive, ""data-analytics integrated"" deep learning programming model, so that users can easily build the end-to-end analytics + AI pipelines under a unified programming paradigm; by implementing an AllReduce like operation using existing primitives in Spark (e.g., shuffle, broadcast, and in-memory data persistence), it also provides a highly efficient ""parameter server"" style architecture, so as to achieve highly scalable, data-parallel distributed training. Since its initial open source release, BigDL users have built many analytics and deep learning applications (e.g., object detection, sequence-to-sequence generation, visual similarity, neural recommendations, fraud detection, etc.) on Spark.","Mon, 16 Apr 2018 12:04:03 UTC (1,140 KB)[v2] Mon, 23 Apr 2018 03:21:14 UTC (1,324 KB)[v3] Mon, 25 Jun 2018 02:57:37 UTC (1,318 KB)"
"745","Multi-Modal Emotion recognition on IEMOCAP Dataset using Deep Learning","Samarth Tripathi, Homayoon Beigi","Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)","Emotion recognition has become an important field of research in Human Computer Interactions as we improve upon the techniques for modelling the various aspects of behaviour. With the advancement of technology our understanding of emotions are advancing, there is a growing need for automatic emotion recognition systems. One of the directions the research is heading is the use of Neural Networks which are adept at estimating complex functions that depend on a large number and diverse source of input data. In this paper we attempt to exploit this effectiveness of Neural networks to enable us to perform multimodal Emotion recognition on IEMOCAP dataset using data from Speech, Text, and Motion capture data from face expressions, rotation and hand movements. Prior research has concentrated on Emotion detection from Speech on the IEMOCAP dataset, but our approach is the first that uses the multiple modes of data offered by IEMOCAP for a more robust and accurate emotion detection.","Mon, 16 Apr 2018 16:58:37 UTC (280 KB)[v2] Mon, 12 Nov 2018 08:46:57 UTC (218 KB)"
"746","Deep Learning on Key Performance Indicators for Predictive Maintenance in SAP HANA","Jaekoo Lee, Byunghan Lee, Jongyoon Song, Jaesik Yoon, Yongsik Lee, Donghun Lee, Sungroh Yoon","Machine Learning (cs.LG); Machine Learning (stat.ML)","With a new era of cloud and big data, Database Management Systems (DBMSs) have become more crucial in numerous enterprise business applications in all the industries. Accordingly, the importance of their proactive and preventive maintenance has also increased. However, detecting problems by predefined rules or stochastic modeling has limitations, particularly when analyzing the data on high-dimensional Key Performance Indicators (KPIs) from a DBMS. In recent years, Deep Learning (DL) has opened new opportunities for this complex analysis. In this paper, we present two complementary DL approaches to detect anomalies in SAP HANA. A temporal learning approach is used to detect abnormal patterns based on unlabeled historical data, whereas a spatial learning approach is used to classify known anomalies based on labeled data. We implement a system in SAP HANA integrated with Google TensorFlow. The experimental results with real-world data confirm the effectiveness of the system and models.","Mon, 16 Apr 2018 03:55:42 UTC (2,750 KB)"
"747","Estimating Individualized Optimal Combination Therapies through Outcome Weighted Deep Learning Algorithms","Muxuan Liang, Ye Ting, Haoda Fu","Applications (stat.AP)","With the advancement in drug development, multiple treatments are available for a single disease. Patients can often benefit from taking multiple treatments simultaneously. For example, patients in Clinical Practice Research Datalink (CPRD) with chronic diseases such as type 2 diabetes can receive multiple treatments simultaneously. Therefore, it is important to estimate what combination therapy from which patients can benefit the most. However, to recommend the best treatment combination is not a single-label but a multi-label classification problem. In this paper, we propose a novel outcome weighted deep learning algorithm to estimate individualized optimal combination therapy. The fisher consistency of the proposed loss function under certain conditions is also provided. In addition, we extend our method to a family of loss functions, which allows adaptive changes based on treatment interactions. We demonstrate the performance of our methods through simulations and real data analysis.","Sun, 15 Apr 2018 16:40:03 UTC (254 KB)"
"748","Adversarial Attacks Against Medical Deep Learning Systems","Samuel G. Finlayson, Hyung Won Chung, Isaac S. Kohane, Andrew L. Beam","Cryptography and Security (cs.CR); Computers and Society (cs.CY); Machine Learning (cs.LG); Machine Learning (stat.ML)","The discovery of adversarial examples has raised concerns about the practical deployment of deep learning systems. In this paper, we argue that the field of medicine may be uniquely susceptible to adversarial attacks, both in terms of monetary incentives and technical vulnerability. To this end, we outline the healthcare economy and the incentives it creates for fraud, we extend adversarial attacks to three popular medical imaging tasks, and we provide concrete examples of how and why such attacks could be realistically carried out. For each of our representative medical deep learning classifiers, both white and black box attacks were highly successful. We urge caution in deploying deep learning systems in clinical settings, and encourage the machine learning community to further investigate the domain-specific characteristics of medical learning systems.","Sun, 15 Apr 2018 02:33:08 UTC (3,022 KB)[v2] Mon, 21 May 2018 02:07:47 UTC (6,064 KB)"
"749","A Deep Learning Approach to Fast, Format-Agnostic Detection of Malicious Web Content","Joshua Saxe, Richard Harang, Cody Wild, Hillary Sanders","Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)","Malicious web content is a serious problem on the Internet today. In this paper we propose a deep learning approach to detecting malevolent web pages. While past work on web content detection has relied on syntactic parsing or on emulation of HTML and Javascript to extract features, our approach operates directly on a language-agnostic stream of tokens extracted directly from static HTML files with a simple regular expression. This makes it fast enough to operate in high-frequency data contexts like firewalls and web proxies, and allows it to avoid the attack surface exposure of complex parsing and emulation code. Unlike well-known approaches such as bag-of-words models, which ignore spatial information, our neural network examines content at hierarchical spatial scales, allowing our model to capture locality and yielding superior accuracy compared to bag-of-words baselines. Our proposed architecture achieves a 97.5% detection rate at a 0.1% false positive rate, and classifies small-batched web pages at a rate of over 100 per second on commodity hardware. The speed and accuracy of our approach makes it appropriate for deployment to endpoints, firewalls, and web proxies.","Fri, 13 Apr 2018 16:39:24 UTC (781 KB)"
"750","DeepFM: An End-to-End Wide & Deep Learning Framework for CTR Prediction","Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, Xiuqiang He, Zhenhua Dong","Information Retrieval (cs.IR); Machine Learning (cs.LG); Machine Learning (stat.ML)","Learning sophisticated feature interactions behind user behaviors is critical in maximizing CTR for recommender systems. Despite great progress, existing methods have a strong bias towards low- or high-order interactions, or rely on expertise feature engineering. In this paper, we show that it is possible to derive an end-to-end learning model that emphasizes both low- and high-order feature interactions. The proposed framework, DeepFM, combines the power of factorization machines for recommendation and deep learning for feature learning in a new neural network architecture. Compared to the latest Wide & Deep model from Google, DeepFM has a shared raw feature input to both its ""wide"" and ""deep"" components, with no need of feature engineering besides raw features. DeepFM, as a general learning framework, can incorporate various network architectures in its deep component. In this paper, we study two instances of DeepFM where its ""deep"" component is DNN and PNN respectively, for which we denote as DeepFM-D and DeepFM-P. Comprehensive experiments are conducted to demonstrate the effectiveness of DeepFM-D and DeepFM-P over the existing models for CTR prediction, on both benchmark data and commercial data. We conduct online A/B test in Huawei App Market, which reveals that DeepFM-D leads to more than 10% improvement of click-through rate in the production environment, compared to a well-engineered LR model. We also covered related practice in deploying our framework in Huawei App Market.","Thu, 12 Apr 2018 01:12:13 UTC (6,779 KB)[v2] Wed, 16 May 2018 13:39:20 UTC (6,790 KB)"
"751","Scalable and Interpretable One-class SVMs with Deep Learning and Random Fourier features","Minh-Nghia Nguyen, Ngo Anh Vien","Machine Learning (cs.LG); Machine Learning (stat.ML)","One-class support vector machine (OC-SVM) for a long time has been one of the most effective anomaly detection methods and extensively adopted in both research as well as industrial applications. The biggest issue for OC-SVM is yet the capability to operate with large and high-dimensional datasets due to optimization complexity. Those problems might be mitigated via dimensionality reduction techniques such as manifold learning or autoencoder. However, previous work often treats representation learning and anomaly prediction separately. In this paper, we propose autoencoder based one-class support vector machine (AE-1SVM) that brings OC-SVM, with the aid of random Fourier features to approximate the radial basis kernel, into deep learning context by combining it with a representation learning architecture and jointly exploit stochastic gradient descent to obtain end-to-end training. Interestingly, this also opens up the possible use of gradient-based attribution methods to explain the decision making for anomaly detection, which has ever been challenging as a result of the implicit mappings between the input space and the kernel space. To the best of our knowledge, this is the first work to study the interpretability of deep learning in anomaly detection. We evaluate our method on a wide range of unsupervised anomaly detection tasks in which our end-to-end training architecture achieves a performance significantly better than the previous work using separate training.","Fri, 13 Apr 2018 11:24:33 UTC (222 KB)[v2] Sun, 14 Oct 2018 09:15:10 UTC (222 KB)"
"752","On Deep Learning-based Massive MIMO Indoor User Localization","Maximilian Arnold, Sebastian Dorner, Sebastian Cammerer, Stephan ten Brink","Signal Processing (eess.SP); Information Theory (cs.IT)","We examine the usability of deep neural networks for multiple-input multiple-output (MIMO) user positioning solely based on the orthogonal frequency division multiplex (OFDM) complex channel coefficients. In contrast to other indoor positioning systems (IPSs), the proposed method does not require any additional piloting overhead or any other changes in the communications system itself as it is deployed on top of an existing OFDM MIMO system. Supported by actual measurements, we are mainly interested in the more challenging non-line of sight (NLoS) scenario. However, gradient descent optimization is known to require a large amount of data-points for training, i.e., the required database would be too large when compared to conventional methods. Thus, we propose a twostep training procedure, with training on simulated line of sight (LoS) data in the first step, and finetuning on measured NLoS positions in the second step. This turns out to reduce the required measured training positions and thus, reduces the effort for data acquisition.","Fri, 13 Apr 2018 08:08:31 UTC (806 KB)"
"753","レ-cuDNN: Accelerating Deep Learning Frameworks with Micro-Batching","Yosuke Oyama, Tal Ben-Nun, Torsten Hoefler, Satoshi Matsuoka","Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC); Mathematical Software (cs.MS); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","NVIDIA cuDNN is a low-level library that provides GPU kernels frequently used in deep learning. Specifically, cuDNN implements several equivalent convolution algorithms, whose performance and memory footprint may vary considerably, depending on the layer dimensions. When an algorithm is automatically selected by cuDNN, the decision is performed on a per-layer basis, and thus it often resorts to slower algorithms that fit the workspace size constraints. We present レ-cuDNN, a transparent wrapper library for cuDNN, which divides layers' mini-batch computation into several micro-batches. Based on Dynamic Programming and Integer Linear Programming, レ-cuDNN enables faster algorithms by decreasing the workspace requirements. At the same time, レ-cuDNN keeps the computational semantics unchanged, so that it decouples statistical efficiency from the hardware efficiency safely. We demonstrate the effectiveness of レ-cuDNN over two frameworks, Caffe and TensorFlow, achieving speedups of 1.63x for AlexNet and 1.21x for ResNet-18 on P100-SXM2 GPU. These results indicate that using micro-batches can seamlessly increase the performance of deep learning, while maintaining the same memory footprint.","Fri, 13 Apr 2018 07:20:44 UTC (238 KB)"
"754","Forecasting Future Humphrey Visual Fields Using Deep Learning","Joanne C. Wen, Cecilia S. Lee, Pearse A. Keane, Sa Xiao, Yue Wu, Ariel Rokem, Philip P. Chen, Aaron Y. Lee","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Purpose: To determine if deep learning networks could be trained to forecast a future 24-2 Humphrey Visual Field (HVF). Participants: All patients who obtained a HVF 24-2 at the University of Washington. Methods: All datapoints from consecutive 24-2 HVFs from 1998 to 2018 were extracted from a University of Washington database. Ten-fold cross validation with a held out test set was used to develop the three main phases of model development: model architecture selection, dataset combination selection, and time-interval model training with transfer learning, to train a deep learning artificial neural network capable of generating a point-wise visual field prediction. Results: More than 1.7 million perimetry points were extracted to the hundredth decibel from 32,443 24-2 HVFs. The best performing model with 20 million trainable parameters, CascadeNet-5, was selected. The overall MAE for the test set was 2.47 dB (95% CI: 2.45 dB to 2.48 dB). The 100 fully trained models were able to successfully predict progressive field loss in glaucomatous eyes up to 5.5 years in the future with a correlation of 0.92 between the MD of predicted and actual future HVF (p < 2.2 x 10 -16 ) and an average difference of 0.41 dB. Conclusions: Using unfiltered real-world datasets, deep learning networks show an impressive ability to not only learn spatio-temporal HVF changes but also to generate predictions for future HVFs up to 5.5 years, given only a single HVF.","Mon, 2 Apr 2018 21:05:22 UTC (769 KB)"
"755","Comparision of projection domain, image domain, and comprehensive deep learning for sparse-view X-ray CT image reconstruction","Kaichao Liang, Hongkai Yang, Yuxiang Xing","Medical Physics (physics.med-ph)","X-ray Computed Tomography (CT) imaging has been widely used in clinical diagnosis, non-destructive examination, and public safety inspection. Sparse-view (sparse view) CT has great potential in radiation dose reduction and scan acceleration. However, sparse view CT data is insufficient and traditional reconstruction results in severe streaking artifacts. In this work, based on deep learning, we compared image reconstruction performance for sparse view CT reconstruction with projection domain network, image domain network, and comprehensive network combining projection and image domains. Our study is executed with numerical simulated projection of CT images from real scans. Results demonstrated deep learning networks can effectively reconstruct rich high frequency structural information without streaking artefact commonly seen in sparse view CT. A comprehensive network combining deep learning in both projection domain and image domain can get best results.","Thu, 12 Apr 2018 02:27:40 UTC (4,173 KB)"
"756","End-to-end Deep Learning of Optical Fiber Communications","Boris Karanov, Mathieu Chagnon, Felix Thouin, Tobias A. Eriksson, Henning Bulow, Domanic Lavery, Polina Bayvel, Laurent Schmalen","Information Theory (cs.IT); Machine Learning (stat.ML)","In this paper, we implement an optical fiber communication system as an end-to-end deep neural network, including the complete chain of transmitter, channel model, and receiver. This approach enables the optimization of the transceiver in a single end-to-end process. We illustrate the benefits of this method by applying it to intensity modulation/direct detection (IM/DD) systems and show that we can achieve bit error rates below the 6.7\% hard-decision forward error correction (HD-FEC) threshold. We model all componentry of the transmitter and receiver, as well as the fiber channel, and apply deep learning to find transmitter and receiver configurations minimizing the symbol error rate. We propose and verify in simulations a training method that yields robust and flexible transceivers that allow---without reconfiguration---reliable transmission over a large range of link dispersions. The results from end-to-end deep learning are successfully verified for the first time in an experiment. In particular, we achieve information rates of 42\,Gb/s below the HD-FEC threshold at distances beyond 40\,km. We find that our results outperform conventional IM/DD solutions based on 2 and 4 level pulse amplitude modulation (PAM2/PAM4) with feedforward equalization (FFE) at the receiver. Our study is the first step towards end-to-end deep learning-based optimization of optical fiber communication systems.","Wed, 11 Apr 2018 17:07:43 UTC (377 KB)[v2] Thu, 12 Apr 2018 14:44:02 UTC (377 KB)[v3] Fri, 3 Aug 2018 08:58:17 UTC (827 KB)"
"757","Flexible and Scalable Deep Learning with MMLSpark","Mark Hamilton, Sudarshan Raghunathan, Akshaya Annavajhala, Danil Kirsanov, Eduardo de Leon, Eli Barzilay, Ilya Matiach, Joe Davison, Maureen Busch, Miruna Oprescu, Ratan Sur, Roope Astala, Tong Wen, ChangYoung Park","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","In this work we detail a novel open source library, called MMLSpark, that combines the flexible deep learning library Cognitive Toolkit, with the distributed computing framework Apache Spark. To achieve this, we have contributed Java Language bindings to the Cognitive Toolkit, and added several new components to the Spark ecosystem. In addition, we also integrate the popular image processing library OpenCV with Spark, and present a tool for the automated generation of PySpark wrappers from any SparkML estimator and use this tool to expose all work to the PySpark ecosystem. Finally, we provide a large library of tools for working and developing within the Spark ecosystem. We apply this work to the automated classification of Snow Leopards from camera trap images, and provide an end to end solution for the non-profit conservation organization, the Snow Leopard Trust.","Wed, 11 Apr 2018 14:55:35 UTC (987 KB)"
"758","Deep Learning For Computer Vision Tasks: A review","Rajat Kumar Sinha, Ruchi Pandey, Rohan Pattnaik","Computer Vision and Pattern Recognition (cs.CV)","Deep learning has recently become one of the most popular sub-fields of machine learning owing to its distributed data representation with multiple levels of abstraction. A diverse range of deep learning algorithms are being employed to solve conventional artificial intelligence problems. This paper gives an overview of some of the most widely used deep learning algorithms applied in the field of computer vision. It first inspects the various approaches of deep learning algorithms, followed by a description of their applications in image classification, object identification, image extraction and semantic segmentation in the presence of noise. The paper concludes with the discussion of the future scope and challenges for construction and training of deep neural networks.","Wed, 11 Apr 2018 11:13:35 UTC (453 KB)"
"759","Deep Learning for Digital Text Analytics: Sentiment Analysis","Reshma U, Barathi Ganesh H B, Mandar Kale, Prachi Mankame, Gouri Kulkarni","Computation and Language (cs.CL)","In today's scenario, imagining a world without negativity is something very unrealistic, as bad NEWS spreads more virally than good ones. Though it seems impractical in real life, this could be implemented by building a system using Machine Learning and Natural Language Processing techniques in identifying the news datum with negative shade and filter them by taking only the news with positive shade (good news) to the end user. In this work, around two lakhs datum have been trained and tested using a combination of rule-based and data driven approaches. VADER along with a filtration method has been used as an annotating tool followed by statistical Machine Learning approach that have used Document Term Matrix (representation) and Support Vector Machine (classification). Deep Learning algorithms then came into picture to make this system reliable (Doc2Vec) which finally ended up with Convolutional Neural Network(CNN) that yielded better results than the other experimented modules. It showed up a training accuracy of 96%, while a test accuracy of (internal and external news datum) above 85% was obtained.","Tue, 10 Apr 2018 18:10:33 UTC (37 KB)"
"760","Echo-Liquid State Deep Learning for $360^\circ$ Content Transmission and Caching in Wireless VR Networks with Cellular-Connected UAVs","Mingzhe Chen, Walid Saad, Changchuan Yin","Information Theory (cs.IT)","In this paper, the problem of content caching and transmission is studied for a wireless virtual reality (VR) network in which unmanned aerial vehicles (UAVs) capture videos on live games or sceneries and transmit them to small base stations (SBSs) that service the VR users. However, due to its limited capacity, the wireless network may not be able to meet the delay requirements of such 360 content transmissions. To meet the VR delay requirements, the UAVs can extract specific visible content (e.g., user field of view) from the original 360 data and send this visible content to the users so as to reduce the traffic load over backhaul and radio access links. To further alleviate the UAV-SBS backhaul traffic, the SBSs can also cache the popular contents that users request. This joint content caching and transmission problem is formulated as an optimization problem whose goal is to maximize the users' reliability, defined as the probability that the content transmission delay of each user satisfies the instantaneous VR delay target. To address this problem, a distributed deep learning algorithm that brings together new neural network ideas from liquid state machine (LSM) and echo state networks (ESNs) is proposed. The proposed algorithm enables each SBS to predict the users' reliability so as to find the optimal contents to cache and content transmission format for each UAV. Analytical results are derived to expose the various network factors that impact content caching and content transmission format selection. Simulation results show that the proposed algorithm yields 25.4% gain of reliability compared to Q-learning. The results also show that the proposed algorithm can achieve 14.7% gain of reliability due to the reduction of traffic load over backhaul compared to the proposed algorithm with random caching.","Tue, 10 Apr 2018 00:25:37 UTC (2,607 KB)"
"761","Deep Learning Classification of Polygenic Obesity using Genome Wide Association Study SNPs","Casimiro Adays Curbelo Montanez, Paul Fergus, Almudena Curbelo Montanez, Carl Chalmers","Computers and Society (cs.CY); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG); Genomics (q-bio.GN)","In this paper, association results from genome-wide association studies (GWAS) are combined with a deep learning framework to test the predictive capacity of statistically significant single nucleotide polymorphism (SNPs) associated with obesity phenotype. Our approach demonstrates the potential of deep learning as a powerful framework for GWAS analysis that can capture information about SNPs and the important interactions between them. Basic statistical methods and techniques for the analysis of genetic SNP data from population-based genome-wide studies have been considered. Statistical association testing between individual SNPs and obesity was conducted under an additive model using logistic regression. Four subsets of loci after quality-control (QC) and association analysis were selected: P-values lower than 1x10-5 (5 SNPs), 1x10-4 (32 SNPs), 1x10-3 (248 SNPs) and 1x10-2 (2465 SNPs). A deep learning classifier is initialised using these sets of SNPs and fine-tuned to classify obese and non-obese observations. Using a deep learning classifier model and genetic variants with P-value < 1x10-2 (2465 SNPs) it was possible to obtain results (SE=0.9604, SP=0.9712, Gini=0.9817, LogLoss=0.1150, AUC=0.9908 and MSE=0.0300). As the P-value increased, an evident deterioration in performance was observed. Results demonstrate that single SNP analysis fails to capture the cumulative effect of less significant variants and their overall contribution to the outcome in disease prediction, which is captured using a deep learning framework.","Mon, 9 Apr 2018 19:37:37 UTC (527 KB)[v2] Fri, 24 Aug 2018 10:18:40 UTC (535 KB)"
"762","Markerless tracking of user-defined features with deep learning","Alexander Mathis, Pranav Mamidanna, Taiga Abe, Kevin M. Cury, Venkatesh N. Murthy, Mackenzie W. Mathis, Matthias Bethge","Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)","Quantifying behavior is crucial for many applications in neuroscience. Videography provides easy methods for the observation and recording of animal behavior in diverse settings, yet extracting particular aspects of a behavior for further analysis can be highly time consuming. In motor control studies, humans or other animals are often marked with reflective markers to assist with computer-based tracking, yet markers are intrusive (especially for smaller animals), and the number and location of the markers must be determined a priori. Here, we present a highly efficient method for markerless tracking based on transfer learning with deep neural networks that achieves excellent results with minimal training data. We demonstrate the versatility of this framework by tracking various body parts in a broad collection of experimental settings: mice odor trail-tracking, egg-laying behavior in drosophila, and mouse hand articulation in a skilled forelimb task. For example, during the skilled reaching behavior, individual joints can be automatically tracked (and a confidence score is reported). Remarkably, even when a small number of frames are labeled ($\approx 200$), the algorithm achieves excellent tracking performance on test frames that is comparable to human accuracy.","Mon, 9 Apr 2018 17:10:39 UTC (22,970 KB)"
"763","Deep Learning of the Nonlinear Schrodinger Equation in Fiber-Optic Communications","Christian Hager, Henry D. Pfister","Information Theory (cs.IT); Machine Learning (stat.ML)","An important problem in fiber-optic communications is to invert the nonlinear Schrodinger equation in real time to reverse the deterministic effects of the channel. Interestingly, the popular split-step Fourier method (SSFM) leads to a computation graph that is reminiscent of a deep neural network. This observation allows one to leverage tools from machine learning to reduce complexity. In particular, the main disadvantage of the SSFM is that its complexity using M steps is at least M times larger than a linear equalizer. This is because the linear SSFM operator is a dense matrix. In previous work, truncation methods such as frequency sampling, wavelets, or least-squares have been used to obtain ""cheaper"" operators that can be implemented using filters. However, a large number of filter taps are typically required to limit truncation errors. For example, Ip and Kahn showed that for a 10 Gbaud signal and 2000 km optical link, a truncated SSFM with 25 steps would require 70-tap filters in each step and 100 times more operations than linear equalization. We find that, by jointly optimizing all filters with deep learning, the complexity can be reduced significantly for similar accuracy. Using optimized 5-tap and 3-tap filters in an alternating fashion, one requires only around 2-6 times the complexity of linear equalization, depending on the implementation.","Mon, 9 Apr 2018 02:58:42 UTC (690 KB)"
"764","Visual Analytics for Explainable Deep Learning","Jaegul Choo, Shixia Liu","Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Machine Learning (stat.ML)","Recently, deep learning has been advancing the state of the art in artificial intelligence to a new level, and humans rely on artificial intelligence techniques more than ever. However, even with such unprecedented advancements, the lack of explanation regarding the decisions made by deep learning models and absence of control over their internal processes act as major drawbacks in critical decision-making processes, such as precision medicine and law enforcement. In response, efforts are being made to make deep learning interpretable and controllable by humans. In this paper, we review visual analytics, information visualization, and machine learning perspectives relevant to this aim, and discuss potential challenges and future research directions.","Sat, 7 Apr 2018 07:52:04 UTC (1,523 KB)"
"765","Semantically Enhanced Software Traceability Using Deep Learning Techniques","Jin Guo, Jinghui Cheng, Jane Cleland-Huang","Software Engineering (cs.SE)","In most safety-critical domains the need for traceability is prescribed by certifying bodies. Trace links are generally created among requirements, design, source code, test cases and other artifacts, however, creating such links manually is time consuming and error prone. Automated solutions use information retrieval and machine learning techniques to generate trace links, however, current techniques fail to understand semantics of the software artifacts or to integrate domain knowledge into the tracing process and therefore tend to deliver imprecise and inaccurate results. In this paper, we present a solution that uses deep learning to incorporate requirements artifact semantics and domain knowledge into the tracing solution. We propose a tracing network architecture that utilizes Word Embedding and Recurrent Neural Network (RNN) models to generate trace links. Word embedding learns word vectors that represent knowledge of the domain corpus and RNN uses these word vectors to learn the sentence semantics of requirements artifacts. We trained 360 different configurations of the tracing network using existing trace links in the Positive Train Control domain and identified the Bidirectional Gated Recurrent Unit (BI-GRU) as the best model for the tracing task. BI-GRU significantly out-performed state-of-the-art tracing methods including the Vector Space Model and Latent Semantic Indexing.","Fri, 6 Apr 2018 19:47:25 UTC (3,855 KB)"
"766","Noise-resistant Deep Learning for Object Classification in 3D Point Clouds Using a Point Pair Descriptor","Dmytro Bobkov, Sili Chen, Ruiqing Jian, Muhammad Iqbal, Eckehard Steinbach","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)","Object retrieval and classification in point cloud data is challenged by noise, irregular sampling density and occlusion. To address this issue, we propose a point pair descriptor that is robust to noise and occlusion and achieves high retrieval accuracy. We further show how the proposed descriptor can be used in a 4D convolutional neural network for the task of object classification. We propose a novel 4D convolutional layer that is able to learn class-specific clusters in the descriptor histograms. Finally, we provide experimental validation on 3 benchmark datasets, which confirms the superiority of the proposed approach.","Thu, 5 Apr 2018 23:19:55 UTC (3,208 KB)"
"767","Towards radiologist-level cancer risk assessment in CT lung screening using deep learning","Stojan Trajanovski, Dimitrios Mavroeidis, Christine Leon Swisher, Binyam Gebrekidan Gebre, Bas Veeling, Rafael Wiemker, Tobias Klinder, Amir Tahmasebi, Shawn M. Regis, Christoph Wald, Brady J. McKee, Heber MacMahon, Homer Pien","Computer Vision and Pattern Recognition (cs.CV)","Lung cancer is the leading cause of cancer mortality in the US, responsible for more deaths than breast, prostate, colon and pancreas cancer combined. Recently, it has been demonstrated that screening those at high-risk for lung cancer low-dose computed tomography (CT) of the chest can significantly reduce this death rate. The process of evaluating a chest CT scan involves the identification of nodules that are contained within a scan as well as the evaluation of the likelihood that a nodule is malignant based on its imaging characteristics. This has motivated researchers to develop image analysis research tools, such as nodule detectors and nodule classifiers that can assist radiologists to make accurate assessments of the patient cancer risk. In this work, we propose a two-stage framework that can assess the lung cancer risk associated with a low-dose chest CT scan. At the first stage, our framework employs a nodule detector; while in the second stage, we use both the image area around the nodules and nodule features as inputs to a neural network that estimates the malignancy risk of the whole CT scan. The proposed approach: (a) has better performance than the PanCan Risk Model, a widely accepted method for cancer malignancy assessment, achieving around 7% better Area Under Curve score in two independent datasets we have employed; (b) has comparable performance to radiologists in estimating cancer risk at patient level; (c) employs a novel multi-instance weakly-labeled approach to train the deep learning network that requires confirmed cancer diagnosis only at the patient level (not at the nodule level); and (d) employs a large number of lung CT scans (more than 8000) from heterogeneous data sources (NLST, LHMC, and Kaggle competition data) to validate and compare model performance. AUC scores for our model, evaluated against confirmed cancer diagnosis, range between 82% to 90%.","Thu, 5 Apr 2018 15:12:33 UTC (1,190 KB)"
"768","GoSGD: Distributed Optimization for Deep Learning with Gossip Exchange","Michael Blot, David Picard, Matthieu Cord","Machine Learning (cs.LG); Machine Learning (stat.ML)","We address the issue of speeding up the training of convolutional neural networks by studying a distributed method adapted to stochastic gradient descent. Our parallel optimization setup uses several threads, each applying individual gradient descents on a local variable. We propose a new way of sharing information between different threads based on gossip algorithms that show good consensus convergence properties. Our method called GoSGD has the advantage to be fully asynchronous and decentralized.","Wed, 4 Apr 2018 12:13:41 UTC (4,928 KB)[v2] Mon, 12 Nov 2018 08:49:48 UTC (0 KB)"
"769","Processing of Electronic Health Records using Deep Learning: A review","Venet Osmani, Li Li, Matteo Danieletto, Benjamin Glicksberg, Joel Dudley, Oscar Mayora","Computers and Society (cs.CY)","Availability of large amount of clinical data is opening up new research avenues in a number of fields. An exciting field in this respect is healthcare, where secondary use of healthcare data is beginning to revolutionize healthcare. Except for availability of Big Data, both medical data from healthcare institutions (such as EMR data) and data generated from health and wellbeing devices (such as personal trackers), a significant contribution to this trend is also being made by recent advances on machine learning, specifically deep learning algorithms.","Thu, 5 Apr 2018 10:10:22 UTC (312 KB)"
"770","Review of Deep Learning","Rong Zhang, Weiping Li, Tong Mo","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","In recent years, China, the United States and other countries, Google and other high-tech companies have increased investment in artificial intelligence. Deep learning is one of the current artificial intelligence research's key areas. This paper analyzes and summarizes the latest progress and future research directions of deep learning. Firstly, three basic models of deep learning are outlined, including multilayer perceptrons, convolutional neural networks, and recurrent neural networks. On this basis, we further analyze the emerging new models of convolution neural networks and recurrent neural networks. This paper then summarizes deep learning's applications in many areas of artificial intelligence, including speech processing, computer vision, natural language processing and so on. Finally, this paper discusses the existing problems of deep learning and gives the corresponding possible solutions.","Thu, 5 Apr 2018 02:23:59 UTC (1,136 KB)[v2] Tue, 28 Aug 2018 15:34:03 UTC (1,886 KB)"
"771","Fine-grained Video Attractiveness Prediction Using Multimodal Deep Learning on a Large Real-world Dataset","Xinpeng Chen, Jingyuan Chen, Lin Ma, Jian Yao, Wei Liu, Jiebo Luo, Tong Zhang","Computer Vision and Pattern Recognition (cs.CV)","Nowadays, billions of videos are online ready to be viewed and shared. Among an enormous volume of videos, some popular ones are widely viewed by online users while the majority attract little attention. Furthermore, within each video, different segments may attract significantly different numbers of views. This phenomenon leads to a challenging yet important problem, namely fine-grained video attractiveness prediction. However, one major obstacle for such a challenging problem is that no suitable benchmark dataset currently exists. To this end, we construct the first fine-grained video attractiveness dataset, which is collected from one of the most popular video websites in the world. In total, the constructed FVAD consists of 1,019 drama episodes with 780.6 hours covering different categories and a wide variety of video contents. Apart from the large amount of videos, hundreds of millions of user behaviors during watching videos are also included, such as ""view counts"", ""fast-forward"", ""fast-rewind"", and so on, where ""view counts"" reflects the video attractiveness while other engagements capture the interactions between the viewers and videos. First, we demonstrate that video attractiveness and different engagements present different relationships. Second, FVAD provides us an opportunity to study the fine-grained video attractiveness prediction problem. We design different sequential models to perform video attractiveness prediction by relying solely on video contents. The sequential models exploit the multimodal relationships between visual and audio components of the video contents at different levels. Experimental results demonstrate the effectiveness of our proposed sequential models with different visual and audio representations, the necessity of incorporating the two modalities, and the complementary behaviors of the sequential prediction models at different levels.","Wed, 4 Apr 2018 12:44:43 UTC (3,550 KB)[v2] Sat, 7 Apr 2018 01:45:29 UTC (3,550 KB)"
"772","Event-based Vision meets Deep Learning on Steering Prediction for Self-driving Cars","Ana I. Maqueda, Antonio Loquercio, Guillermo Gallego, Narciso Garcia, Davide Scaramuzza","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)","Event cameras are bio-inspired vision sensors that naturally capture the dynamics of a scene, filtering out redundant information. This paper presents a deep neural network approach that unlocks the potential of event cameras on a challenging motion-estimation task: prediction of a vehicle's steering angle. To make the best out of this sensor-algorithm combination, we adapt state-of-the-art convolutional architectures to the output of event sensors and extensively evaluate the performance of our approach on a publicly available large scale event-camera dataset (~1000 km). We present qualitative and quantitative explanations of why event cameras allow robust steering prediction even in cases where traditional cameras fail, e.g. challenging illumination conditions and fast motion. Finally, we demonstrate the advantages of leveraging transfer learning from traditional to event-based vision, and show that our approach outperforms state-of-the-art algorithms based on standard cameras.","Wed, 4 Apr 2018 09:05:41 UTC (2,975 KB)"
"773","Towards Deep Learning based Hand Keypoints Detection for Rapid Sequential Movements from RGB Images","Srujana Gattupalli, Ashwin Ramesh Babu, James Robert Brady, Fillia Makedon, Vassilis Athitsos","Computer Vision and Pattern Recognition (cs.CV)","Hand keypoints detection and pose estimation has numerous applications in computer vision, but it is still an unsolved problem in many aspects. An application of hand keypoints detection is in performing cognitive assessments of a subject by observing the performance of that subject in physical tasks involving rapid finger motion. As a part of this work, we introduce a novel hand key-points benchmark dataset that consists of hand gestures recorded specifically for cognitive behavior monitoring. We explore the state of the art methods in hand keypoint detection and we provide quantitative evaluations for the performance of these methods on our dataset. In future, these results and our dataset can serve as a useful benchmark for hand keypoint recognition for rapid finger movements.","Tue, 3 Apr 2018 21:28:16 UTC (6,884 KB)"
"774","Reynolds-Averaged Turbulence Modeling Using Type I and Type II Machine Learning Frameworks with Deep Learning","Chih-Wei Chang, Nam T. Dinh","Fluid Dynamics (physics.flu-dyn); Computational Physics (physics.comp-ph)","Deep learning (DL)-based Reynolds stress with its capability to leverage values of large data can be used to close Reynolds-averaged Navier-Stoke (RANS) equations. Type I and Type II machine learning (ML) frameworks are studied to investigate data and flow feature requirements while training DL-based Reynolds stress. The paper presents a method, flow features coverage mapping (FFCM), to quantify the physics coverage of DL-based closures that can be used to examine the sufficiency of training data points as well as input flow features for data-driven turbulence models. Three case studies are formulated to demonstrate the properties of Type I and Type II ML. The first case indicates that errors of RANS equations with DL-based Reynolds stress by Type I ML are accumulated along with the simulation time when training data do not sufficiently cover transient details. The second case uses Type I ML to show that DL can figure out time history of flow transients from data sampled at various times. The case study also shows that the necessary and sufficient flow features of DL-based closures are first-order spatial derivatives of velocity fields. The last case demonstrates the limitation of Type II ML for unsteady flow simulation. Type II ML requires initial conditions to be sufficiently close to reference data. Then reference data can be used to improve RANS simulation.","Tue, 3 Apr 2018 17:04:58 UTC (1,458 KB)[v2] Thu, 12 Apr 2018 01:07:50 UTC (1,436 KB)"
"775","DeepSigns: A Generic Watermarking Framework for IP Protection of Deep Learning Models","Bita Darvish Rouhani, Huili Chen, Farinaz Koushanfar","Cryptography and Security (cs.CR)","Deep Learning (DL) models have caused a paradigm shift in our ability to comprehend raw data in various important fields, ranging from intelligence warfare and healthcare to autonomous transportation and automated manufacturing. A practical concern, in the rush to adopt DL models as a service, is protecting the models against Intellectual Property (IP) infringement. The DL models are commonly built by allocating significant computational resources that process vast amounts of proprietary training data. The resulting models are therefore considered to be the IP of the model builder and need to be protected to preserve the owner's competitive advantage. This paper proposes DeepSigns, a novel end-to-end IP protection framework that enables insertion of coherent digital watermarks in contemporary DL models. DeepSigns, for the first time, introduces a generic watermarking methodology that can be used for protecting DL owner's IP rights in both white-box and black-box settings, where the adversary may or may not have the knowledge of the model internals. The suggested methodology is based on embedding the owner's signature (watermark) in the probability density function (pdf) of the data abstraction obtained in different layers of a DL model. DeepSigns can demonstrably withstand various removal and transformation attacks, including model compression, model fine-tuning, and watermark overwriting. Proof-of-concept evaluations on MNIST, and CIFAR10 datasets, as well as a wide variety of neural network architectures including Wide Residual Networks, Convolution Neural Networks, and Multi-Layer Perceptrons corroborate DeepSigns' effectiveness and applicability.","Mon, 2 Apr 2018 22:23:04 UTC (1,187 KB)[v2] Thu, 31 May 2018 23:57:59 UTC (2,050 KB)"
"776","Land use mapping in the Three Gorges Reservoir Area based on semantic segmentation deep learning method","Xin Zhang, Bingfang Wu, Liang Zhu, Fuyou Tian, Miao Zhang, Yuanzeng","Computer Vision and Pattern Recognition (cs.CV)","The Three Gorges Dam, a massive cross-century project spans the Yangtze River by the town of Sandouping, located in Yichang, Hubei province, China, was built to provide great power, improve the River shipping, control floods in the upper reaches of the Yangtze River, and increase the dry season flow in the middle and lower reaches of the Yangtze River. Benefits are enormous and comprehensive. However, the social and environmental impacts are also immense and far-reaching to its surrounding areas. Mapping land use /land cover changed (LUCC) is critical for tracking the impacts. Remote sensing has been proved to be an effective way to map and monitor land use change in real time and in large areas such as the Three Gorges Reservoir Area(TGRA) by using pixel based or oriented based classifier in different resolution. In this paper, we first test the state of the art semantic segmentation deep learning classifiers for LUCC mapping with 7 categories in the TGRA area with rapideye 5m resolution data. The topographic information was also added for better accuracy in mountain area. By compared with the pixel-based classifier, the semantic segmentation deep learning method has better accuracy and robustness at 5m resolution level.","Sun, 18 Mar 2018 13:30:49 UTC (4,212 KB)"
"777","A Vehicle Detection Approach using Deep Learning Methodologies","Abdullah Asim Yilmaz, Mehmet Serdar Guzel, Iman Askerbeyli, Erkan Bostanci","Computer Vision and Pattern Recognition (cs.CV)","The purpose of this study is to successfully train our vehicle detector using R-CNN, Faster R-CNN deep learning methods on a sample vehicle data sets and to optimize the success rate of the trained detector by providing efficient results for vehicle detection by testing the trained vehicle detector on the test data. The working method consists of six main stages. These are respectively; loading the data set, the design of the convolutional neural network, configuration of training options, training of the Faster R-CNN object detector and evaluation of trained detector. In addition, in the scope of the study, Faster R-CNN, R-CNN deep learning methods were mentioned and experimental analysis comparisons were made with the results obtained from vehicle detection.","Mon, 2 Apr 2018 08:34:38 UTC (468 KB)"
"778","Robust Fruit Counting: Combining Deep Learning, Tracking, and Structure from Motion","Xu Liu, Steven W. Chen, Shreyas Aditya, Nivedha Sivakumar, Sandeep Dcunha, Chao Qu, Camillo J. Taylor, Jnaneshwar Das, Vijay Kumar","Computer Vision and Pattern Recognition (cs.CV)","We present a novel fruit counting pipeline that combines deep segmentation, frame to frame tracking, and 3D localization to accurately count visible fruits across a sequence of images. Our pipeline works on image streams from a monocular camera, both in natural light, as well as with controlled illumination at night. We first train a Fully Convolutional Network (FCN) and segment video frame images into fruit and non-fruit pixels. We then track fruits across frames using the Hungarian Algorithm where the objective cost is determined from a Kalman Filter corrected Kanade-Lucas-Tomasi (KLT) Tracker. In order to correct the estimated count from tracking process, we combine tracking results with a Structure from Motion (SfM) algorithm to calculate relative 3D locations and size estimates to reject outliers and double counted fruit tracks. We evaluate our algorithm by comparing with ground-truth human-annotated visual counts. Our results demonstrate that our pipeline is able to accurately and reliably count fruits across image sequences, and the correction step can significantly improve the counting accuracy and robustness. Although discussed in the context of fruit counting, our work can extend to detection, tracking, and counting of a variety of other stationary features of interest such as leaf-spots, wilt, and blossom.","Sun, 1 Apr 2018 15:44:58 UTC (8,152 KB)[v2] Thu, 2 Aug 2018 04:35:07 UTC (4,783 KB)"
"779","Opening a new window on MR-based Electrical Properties Tomography with deep learning","Stefano Mandija, Ettore F. Meliado, Niek R. F. Huttinga, Peter R. Luijten, Cornelis A. T. van den Berg","Medical Physics (physics.med-ph); Image and Video Processing (eess.IV)","Electrical properties (EPs) of tissues, conductivity and permittivity, are modulated by the ionic and water content, which change in presence of pathologies. Information on tissues EPs can be used e.g. as an endogenous biomarker in oncology. MR-Electrical Properties Tomography (MR-EPT) aims to reconstruct tissue EPs by solving an electromagnetic inverse problem relating MR measurements of the transmit radiofrequency RF field to the EPs. However, MR-EPT reconstructions highly suffer from noise in the RF field maps, which limits the clinical applicability. Instead of employing electromagnetic models posing strict requirements on the measured quantities, we propose a data driven approach where the inverse transformation is learned by means of a neural network. Supervised training of a conditional generative adversarial neural network was performed using simulated realistic RF field maps and realistic human head dielectric models. Deep learning EPT (DL-EPT) reconstructions are presented for in-silica MR data and MR measurements at 3 Tesla on phantoms and human brains. DL-EPT shows high quality EP maps, demonstrating good accuracy and greatly improved precision compared to conventional MR-EPT. Moreover, DL-EPT allows permittivity reconstructions at 3 Tesla, which is not possible with state-of-art MR-EPT techniques. The supervised learning-based approach leverages the strength of tailored electromagnetic simulations, allowing inclusion of a priori information (e.g. coil setup) and circumvention of inaccessible MR electromagnetic quantities. Since DL-EPT is highly noise-robust, the requirements for MRI data acquisitions can be relaxed, allowing faster acquisitions and higher resolutions. We believe that DL-EPT greatly improves the quality and applicability of EPT opening a new window for an endogenous biomarker in MRI diagnostics that reflects differences in ionic tissue content.","Fri, 30 Mar 2018 18:10:20 UTC (2,935 KB)"
"780","SpiderCNN: Deep Learning on Point Sets with Parameterized Convolutional Filters","Yifan Xu, Tianqi Fan, Mingye Xu, Long Zeng, Yu Qiao","Computer Vision and Pattern Recognition (cs.CV)","Deep neural networks have enjoyed remarkable success for various vision tasks, however it remains challenging to apply CNNs to domains lacking a regular underlying structures such as 3D point clouds. Towards this we propose a novel convolutional architecture, termed SpiderCNN, to efficiently extract geometric features from point clouds. SpiderCNN is comprised of units called SpiderConv, which extend convolutional operations from regular grids to irregular point sets that can be embedded in R^n, by parametrizing a family of convolutional filters. We design the filter as a product of a simple step function that captures local geodesic information and a Taylor polynomial that ensures the expressiveness. SpiderCNN inherits the multi-scale hierarchical architecture from classical CNNs, which allows it to extract semantic deep features. Experiments on ModelNet40 demonstrate that SpiderCNN achieves state-of-the-art accuracy 92.4% on standard benchmarks, and shows competitive performance on segmentation task.","Fri, 30 Mar 2018 16:10:21 UTC (4,094 KB)[v2] Mon, 10 Sep 2018 14:16:21 UTC (4,144 KB)[v3] Wed, 12 Sep 2018 15:42:21 UTC (4,144 KB)"
"781","Scalable Deep Learning Logo Detection","Hang Su, Shaogang Gong, Xiatian Zhu","Computer Vision and Pattern Recognition (cs.CV)","Existing logo detection methods usually consider a small number of logo classes and limited images per class with a strong assumption of requiring tedious object bounding box annotations, therefore not scalable to real-world dynamic applications. In this work, we tackle these challenges by exploring the webly data learning principle without the need for exhaustive manual labelling. Specifically, we propose a novel incremental learning approach, called Scalable Logo Self-co-Learning (SL^2), capable of automatically self-discovering informative training images from noisy web data for progressively improving model capability in a cross-model co-learning manner. Moreover, we introduce a very large (2,190,757 images of 194 logo classes) logo dataset ""WebLogo-2M"" by an automatic web data collection and processing method. Extensive comparative evaluations demonstrate the superiority of the proposed SL^2 method over the state-of-the-art strongly and weakly supervised detection models and contemporary webly data learning approaches.","Fri, 30 Mar 2018 11:22:16 UTC (3,160 KB)[v2] Mon, 2 Apr 2018 19:37:23 UTC (3,159 KB)"
"782","Deep learning-based virtual histology staining using auto-fluorescence of label-free tissue","Yair Rivenson, Hongda Wang, Zhensong Wei, Yibo Zhang, Harun Gunaydin, Aydogan Ozcan","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Medical Physics (physics.med-ph)","Histological analysis of tissue samples is one of the most widely used methods for disease diagnosis. After taking a sample from a patient, it goes through a lengthy and laborious preparation, which stains the tissue to visualize different histological features under a microscope. Here, we demonstrate a label-free approach to create a virtually-stained microscopic image using a single wide-field auto-fluorescence image of an unlabeled tissue sample, bypassing the standard histochemical staining process, saving time and cost. This method is based on deep learning, and uses a convolutional neural network trained using a generative adversarial network model to transform an auto-fluorescence image of an unlabeled tissue section into an image that is equivalent to the bright-field image of the stained-version of the same sample. We validated this method by successfully creating virtually-stained microscopic images of human tissue samples, including sections of salivary gland, thyroid, kidney, liver and lung tissue, also covering three different stains. This label-free virtual-staining method eliminates cumbersome and costly histochemical staining procedures, and would significantly simplify tissue preparation in pathology and histology fields.","Fri, 30 Mar 2018 00:23:22 UTC (4,198 KB)"
"783","Security Consideration For Deep Learning-Based Image Forensics","Wei Zhao, Pengpeng Yang, Rongrong Ni, Yao Zhao, Haorui Wu","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM); Machine Learning (stat.ML)","Recently, image forensics community has paied attention to the research on the design of effective algorithms based on deep learning technology and facts proved that combining the domain knowledge of image forensics and deep learning would achieve more robust and better performance than the traditional schemes. Instead of improving it, in this paper, the safety of deep learning based methods in the field of image forensics is taken into account. To the best of our knowledge, this is a first work focusing on this topic. Specifically, we experimentally find that the method using deep learning would fail when adding the slight noise into the images (adversarial images). Furthermore, two kinds of strategys are proposed to enforce security of deep learning-based method. Firstly, an extra penalty term to the loss function is added, which is referred to the 2-norm of the gradient of the loss with respect to the input images, and then an novel training method are adopt to train the model by fusing the normal and adversarial images. Experimental results show that the proposed algorithm can achieve good performance even in the case of adversarial images and provide a safety consideration for deep learning-based image forensics","Thu, 29 Mar 2018 17:06:00 UTC (6,327 KB)[v2] Tue, 3 Apr 2018 09:54:20 UTC (6,407 KB)"
"784","3D Consistent Biventricular Myocardial Segmentation Using Deep Learning for Mesh Generation","Qiao Zheng, Herve Delingette, Nicolas Duchateau, Nicholas Ayache","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","We present a novel automated method to segment the myocardium of both left and right ventricles in MRI volumes. The segmentation is consistent in 3D across the slices such that it can be directly used for mesh generation. Two specific neural networks with multi-scale coarse-to-fine prediction structure are proposed to cope with the small training dataset and trained using an original loss function. The former segments a slice in the middle of the volume. Then the latter iteratively propagates the slice segmentations towards the base and the apex, in a spatially consistent way. We perform 5-fold cross-validation on the 15 cases from STACOM to validate the method. For training, we use real cases and their synthetic variants generated by combining motion simulation and image synthesis. Accurate and consistent testing results are obtained.","Thu, 29 Mar 2018 14:08:12 UTC (1,546 KB)"
"785","Protection against Cloning for Deep Learning","Richard Kenway","Machine Learning (stat.ML); Disordered Systems and Neural Networks (cond-mat.dis-nn); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","The susceptibility of deep learning to adversarial attack can be understood in the framework of the Renormalisation Group (RG) and the vulnerability of a specific network may be diagnosed provided the weights in each layer are known. An adversary with access to the inputs and outputs could train a second network to clone these weights and, having identified a weakness, use them to compute the perturbation of the input data which exploits it. However, the RG framework also provides a means to poison the outputs of the network imperceptibly, without affecting their legitimate use, so as to prevent such cloning of its weights and thereby foil the generation of adversarial data.","Thu, 29 Mar 2018 10:02:09 UTC (6 KB)"
"786","A Survey on Deep Learning Methods for Robot Vision","Javier Ruiz-del-Solar, Patricio Loncomilla, Naiomi Soto","Computer Vision and Pattern Recognition (cs.CV)","Deep learning has allowed a paradigm shift in pattern recognition, from using hand-crafted features together with statistical classifiers to using general-purpose learning procedures for learning data-driven representations, features, and classifiers together. The application of this new paradigm has been particularly successful in computer vision, in which the development of deep learning methods for vision applications has become a hot research topic. Given that deep learning has already attracted the attention of the robot vision community, the main purpose of this survey is to address the use of deep learning in robot vision. To achieve this, a comprehensive overview of deep learning and its usage in computer vision is given, that includes a description of the most frequently used neural models and their main application areas. Then, the standard methodology and tools used for designing deep-learning based vision systems are presented. Afterwards, a review of the principal work using deep learning in robot vision is presented, as well as current and future trends related to the use of deep learning in robotics. This survey is intended to be a guide for the developers of robot vision systems.","Wed, 28 Mar 2018 21:37:14 UTC (807 KB)"
"787","Deep Learning Object Detection Methods for Ecological Camera Trap Data","Stefan Schneider, Graham W. Taylor, Stefan C. Kremer","Computer Vision and Pattern Recognition (cs.CV)","Deep learning methods for computer vision tasks show promise for automating the data analysis of camera trap images. Ecological camera traps are a common approach for monitoring an ecosystem's animal population, as they provide continual insight into an environment without being intrusive. However, the analysis of camera trap images is expensive, labour intensive, and time consuming. Recent advances in the field of deep learning for object detection show promise towards automating the analysis of camera trap images. Here, we demonstrate their capabilities by training and comparing two deep learning object detection classifiers, Faster R-CNN and YOLO v2.0, to identify, quantify, and localize animal species within camera trap images using the Reconyx Camera Trap and the self-labeled Gold Standard Snapshot Serengeti data sets. When trained on large labeled datasets, object recognition methods have shown success. We demonstrate their use, in the context of realistically sized ecological data sets, by testing if object detection methods are applicable for ecological research scenarios when utilizing transfer learning. Faster R-CNN outperformed YOLO v2.0 with average accuracies of 93.0\% and 76.7\% on the two data sets, respectively. Our findings show promising steps towards the automation of the labourious task of labeling camera trap images, which can be used to improve our understanding of the population dynamics of ecosystems across the planet.","Wed, 28 Mar 2018 20:30:39 UTC (8,963 KB)"
"788","Unreasonable Effectivness of Deep Learning","Finn Macleod","Machine Learning (cs.LG); Machine Learning (stat.ML)","We show how well known rules of back propagation arise from a weighted combination of finite automata. By redefining a finite automata as a predictor we combine the set of all $k$-state finite automata using a weighted majority algorithm. This aggregated prediction algorithm can be simplified using symmetry, and we prove the equivalence of an algorithm that does this. We demonstrate that this algorithm is equivalent to a form of a back propagation acting in a completely connected $k$-node neural network. Thus the use of the weighted majority algorithm allows a bound on the general performance of deep learning approaches to prediction via known results from online statistics. The presented framework opens more detailed questions about network topology; it is a bridge to the well studied techniques of semigroup theory and applying these techniques to answer what specific network topologies are capable of predicting. This informs both the design of artificial networks and the exploration of neuroscience models.","Wed, 28 Mar 2018 14:29:30 UTC (79 KB)"
"789","Application of Deep Learning methods to analysis of Imaging Atmospheric Cherenkov Telescopes data","Idan Shilon, Manuel Kraus, Matthias Buchele, Kathrin Egberts, Tobias Fischer, Tim Lukas Holch, Thomas Lohse, Ullrich Schwanke, Constantin Steppa, Stefan Funk","Instrumentation and Methods for Astrophysics (astro-ph.IM)","Ground based gamma-ray observations with Imaging Atmospheric Cherenkov Telescopes (IACTs) play a significant role in the discovery of very high energy (E > 100 GeV) gamma-ray emitters. The analysis of IACT data demands a highly efficient background rejection technique, as well as methods to accurately determine the energy of the recorded gamma-ray and the position of its source in the sky. We present results for background rejection and signal direction reconstruction from first studies of a novel data analysis scheme for IACT measurements. The new analysis is based on a set of Convolutional Neural Networks (CNNs) applied to images from the four H.E.S.S. phase-I telescopes. As the H.E.S.S. cameras pixels are arranged in a hexagonal array, we demonstrate two ways to use such image data to train CNNs: by resampling the images to a square grid and by applying modified convolution kernels that conserve the hexagonal grid properties. The networks were trained on sets of Monte-Carlo simulated events and tested on both simulations and measured data from the H.E.S.S. array. A comparison between the CNN analysis to current state-of-the-art algorithms reveals a clear improvement in background rejection performance. When applied to H.E.S.S. observation data, the CNN direction reconstruction performs at a similar level as traditional methods. These results serve as a proof-of-concept for the application of CNNs to the analysis of events recorded by IACTs.","Wed, 28 Mar 2018 15:55:11 UTC (819 KB)"
"790","What deep learning can tell us about higher cognitive functions like mindreading?","Jaan Aru, Raul Vicente","Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)","Can deep learning (DL) guide our understanding of computations happening in biological brain? We will first briefly consider how DL has contributed to the research on visual object recognition. In the main part we will assess whether DL could also help us to clarify the computations underlying higher cognitive functions such as Theory of Mind. In addition, we will compare the objectives and learning signals of brains and machines, leading us to conclude that simply scaling up the current DL algorithms will not lead to human level mindreading skills. We then provide some insights about how to fairly compare human and DL performance. In the end we find that DL can contribute to our understanding of biological computations by providing an example of an end-to-end algorithm that solves the same problems the biological agents face.","Wed, 28 Mar 2018 08:58:49 UTC (247 KB)"
"791","Disease-Atlas: Navigating Disease Trajectories with Deep Learning","Bryan Lim, Mihaela van der Schaar","Machine Learning (stat.ML); Machine Learning (cs.LG)","Joint models for longitudinal and time-to-event data are commonly used in longitudinal studies to forecast disease trajectories over time. While there are many advantages to joint modeling, the standard forms suffer from limitations that arise from a fixed model specification, and computational difficulties when applied to high-dimensional datasets. In this paper, we propose a deep learning approach to address these limitations, enhancing existing methods with the inherent flexibility and scalability of deep neural networks, while retaining the benefits of joint modeling. Using longitudinal data from a real-world medical dataset, we demonstrate improvements in performance and scalability, as well as robustness in the presence of irregularly sampled data.","Tue, 27 Mar 2018 18:03:02 UTC (343 KB)[v2] Fri, 20 Apr 2018 19:27:13 UTC (380 KB)[v3] Fri, 6 Jul 2018 17:10:33 UTC (333 KB)"
"792","Image-based deep learning for classification of noise transients in gravitational wave detectors","Massimiliano Razzano, Elena Cuoco","General Relativity and Quantum Cosmology (gr-qc); Instrumentation and Methods for Astrophysics (astro-ph.IM); Computer Vision and Pattern Recognition (cs.CV)","The detection of gravitational waves has inaugurated the era of gravitational astronomy and opened new avenues for the multimessenger study of cosmic sources. Thanks to their sensitivity, the Advanced LIGO and Advanced Virgo interferometers will probe a much larger volume of space and expand the capability of discovering new gravitational wave emitters. The characterization of these detectors is a primary task in order to recognize the main sources of noise and optimize the sensitivity of interferometers. Glitches are transient noise events that can impact the data quality of the interferometers and their classification is an important task for detector characterization. Deep learning techniques are a promising tool for the recognition and classification of glitches. We present a classification pipeline that exploits convolutional neural networks to classify glitches starting from their time-frequency evolution represented as images. We evaluated the classification accuracy on simulated glitches, showing that the proposed algorithm can automatically classify glitches on very fast timescales and with high accuracy, thus providing a promising tool for online detector characterization.","Tue, 27 Mar 2018 07:23:13 UTC (975 KB)"
"793","Epileptic Seizure Detection: A Deep Learning Approach","Ramy Hussein, Hamid Palangi, Rabab Ward, Z. Jane Wang","Signal Processing (eess.SP)","Epilepsy is the second most common brain disorder after migraine. Automatic detection of epileptic seizures can considerably improve the patients' quality of life. Current Electroencephalogram (EEG)-based seizure detection systems encounter many challenges in real-life situations. The EEGs are non-stationary signals and seizure patterns vary across patients and recording sessions. Moreover, EEG data are prone to numerous noise types that negatively affect the detection accuracy of epileptic seizures. To address these challenges, we introduce the use of a deep learning-based approach that automatically learns the discriminative EEG features of epileptic seizures. Specifically, to reveal the correlation between successive data samples, the time-series EEG data are first segmented into a sequence of non-overlapping epochs. Second, Long Short-Term Memory (LSTM) network is used to learn the high-level representations of the normal and the seizure EEG patterns. Third, these representations are fed into Softmax function for training and classification. The results on a well-known benchmark clinical dataset demonstrate the superiority of the proposed approach over the existing state-of-the-art methods. Furthermore, our approach is shown to be robust in noisy and real-life conditions. Compared to current methods that are quite sensitive to noise, the proposed method maintains its high detection performance in the presence of common EEG artifacts (muscle activities and eye-blinking) as well as white noise.","Tue, 27 Mar 2018 02:16:53 UTC (659 KB)"
"794","Deep learning as a tool for neural data analysis: speech classification and cross-frequency coupling in human sensorimotor cortex","Jesse A. Livezey, Kristofer E. Bouchard, Edward F. Chang","Neural and Evolutionary Computing (cs.NE); Neurons and Cognition (q-bio.NC)","A fundamental challenge in neuroscience is to understand what structure in the world is represented in spatially distributed patterns of neural activity from multiple single-trial measurements. This is often accomplished by learning a simple, linear transformations between neural features and features of the sensory stimuli or motor task. While successful in some early sensory processing areas, linear mappings are unlikely to be ideal tools for elucidating nonlinear, hierarchical representations of higher-order brain areas during complex tasks, such as the production of speech by humans. Here, we apply deep networks to predict produced speech syllables from cortical surface electric potentials recorded from human sensorimotor cortex. We found that deep networks had higher decoding prediction accuracy compared to baseline models, and also exhibited greater improvements in accuracy with increasing dataset size. We further demonstrate that deep network's confusions revealed hierarchical latent structure in the neural data, which recapitulated the underlying articulatory nature of speech motor control. Finally, we used deep networks to compare task-relevant information in different neural frequency bands, and found that the high-gamma band contains the vast majority of information relevant for the speech prediction task, with little-to-no additional contribution from lower-frequencies. Together, these results demonstrate the utility of deep networks as a data analysis tool for neuroscience.","Mon, 26 Mar 2018 19:26:44 UTC (2,515 KB)"
"795","Transferable Joint Attribute-Identity Deep Learning for Unsupervised Person Re-Identification","Jingya Wang, Xiatian Zhu, Shaogang Gong, Wei Li","Computer Vision and Pattern Recognition (cs.CV)","Most existing person re-identification (re-id) methods require supervised model learning from a separate large set of pairwise labelled training data for every single camera pair. This significantly limits their scalability and usability in real-world large scale deployments with the need for performing re-id across many camera views. To address this scalability problem, we develop a novel deep learning method for transferring the labelled information of an existing dataset to a new unseen (unlabelled) target domain for person re-id without any supervised learning in the target domain. Specifically, we introduce an Transferable Joint Attribute-Identity Deep Learning (TJ-AIDL) for simultaneously learning an attribute-semantic and identitydiscriminative feature representation space transferrable to any new (unseen) target domain for re-id tasks without the need for collecting new labelled training data from the target domain (i.e. unsupervised learning in the target domain). Extensive comparative evaluations validate the superiority of this new TJ-AIDL model for unsupervised person re-id over a wide range of state-of-the-art methods on four challenging benchmarks including VIPeR, PRID, Market-1501, and DukeMTMC-ReID.","Mon, 26 Mar 2018 18:47:55 UTC (1,810 KB)"
"796","Bridging Many-Body Quantum Physics and Deep Learning via Tensor Networks","Yoav Levine, Or Sharir, Nadav Cohen, Amnon Shashua","Quantum Physics (quant-ph); Machine Learning (cs.LG)","The harnessing of modern computational abilities for many-body wave-function representations is naturally placed as a prominent avenue in contemporary condensed matter physics. Specifically, highly expressive computational schemes that are able to efficiently represent the entanglement properties of many-particle systems are of interest. In the seemingly unrelated field of machine learning, deep network architectures have exhibited an unprecedented ability to tractably encompass the dependencies characterizing hard learning tasks such as image classification. However, key questions regarding deep learning architecture design still have no adequate theoretical answers. In this paper, we establish a Tensor Network (TN) based common language between the two disciplines, which allows us to offer bidirectional contributions. By showing that many-body wave-functions are structurally equivalent to mappings of ConvACs and RACs, we construct their TN equivalents, and suggest quantum entanglement measures as natural quantifiers of dependencies in such networks. Accordingly, we propose a novel entanglement based deep learning design scheme. In the other direction, we identify that an inherent re-use of information in state-of-the-art deep learning architectures is a key trait that distinguishes them from standard TNs. Therefore, we employ a TN manifestation of information re-use and construct TNs corresponding to powerful architectures such as deep recurrent and overlapping convolutional networks. This allows us to demonstrate that the entanglement scaling supported by state-of-the-art deep learning architectures matches that of MERA TN in 1D, and that they support volume law entanglement in 2D polynomially more efficiently than RBMs. We thus provide theoretical motivation to shift trending neural-network based wave-function representations closer to state-of-the-art deep learning architectures.","Mon, 26 Mar 2018 18:30:29 UTC (2,930 KB)[v2] Thu, 5 Apr 2018 15:39:15 UTC (2,931 KB)"
"797","Flow From Motion: A Deep Learning Approach","Cem Eteke, Hayati Havlucu, Nisa <U+0130>rem Krbac, Mehmet Cengiz Onba<U+015F>l, Aykut Co<U+015F>kun, Terry Eskenazi, O<U+011F>uzhan Ozcan, Bar<U+015F> Akgun","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (stat.ML)","Wearable devices have the potential to enhance sports performance, yet they are not fulfilling this promise. Our previous studies with 6 professional tennis coaches and 20 players indicate that this could be due the lack of psychological or mental state feedback, which the coaches claim to provide. Towards this end, we propose to detect the flow state, mental state of optimal performance, using wearables data to be later used in training. We performed a study with a professional tennis coach and two players. The coach provided labels about the players' flow state while each player had a wearable device on their racket holding wrist. We trained multiple models using the wearables data and the coach labels. Our deep neural network models achieved around 98% testing accuracy for a variety of conditions. This suggests that the flow state or what coaches recognize as flow, can be detected using wearables data in tennis which is a novel result. The implication for the HCI community is that having access to such information would allow for design of novel hardware and interaction paradigms that would be helpful in professional athlete training.","Mon, 26 Mar 2018 16:12:48 UTC (650 KB)"
"798","Efficient Image Dataset Classification Difficulty Estimation for Predicting Deep-Learning Accuracy","Florian Scheidegger, Roxana Istrate, Giovanni Mariani, Luca Benini, Costas Bekas, Cristiano Malossi","Computer Vision and Pattern Recognition (cs.CV)","In the deep-learning community new algorithms are published at an incredible pace. Therefore, solving an image classification problem for new datasets becomes a challenging task, as it requires to re-evaluate published algorithms and their different configurations in order to find a close to optimal classifier. To facilitate this process, before biasing our decision towards a class of neural networks or running an expensive search over the network space, we propose to estimate the classification difficulty of the dataset. Our method computes a single number that characterizes the dataset difficulty 27x faster than training state-of-the-art networks. The proposed method can be used in combination with network topology and hyper-parameter search optimizers to efficiently drive the search towards promising neural-network configurations.","Mon, 26 Mar 2018 13:46:54 UTC (232 KB)"
"799","A Provably Correct Algorithm for Deep Learning that Actually Works","Eran Malach, Shai Shalev-Shwartz","Machine Learning (cs.LG); Machine Learning (stat.ML)","We describe a layer-by-layer algorithm for training deep convolutional networks, where each step involves gradient updates for a two layer network followed by a simple clustering algorithm. Our algorithm stems from a deep generative model that generates mages level by level, where lower resolution images correspond to latent semantic classes. We analyze the convergence rate of our algorithm assuming that the data is indeed generated according to this model (as well as additional assumptions). While we do not pretend to claim that the assumptions are realistic for natural images, we do believe that they capture some true properties of real data. Furthermore, we show that our algorithm actually works in practice (on the CIFAR dataset), achieving results in the same ballpark as that of vanilla convolutional neural networks that are being trained by stochastic gradient descent. Finally, our proof techniques may be of independent interest.","Mon, 26 Mar 2018 11:48:14 UTC (296 KB)[v2] Sun, 24 Jun 2018 13:55:48 UTC (297 KB)"
"800","Distinguishing Computer-generated Graphics from Natural Images Based on Sensor Pattern Noise and Deep Learning","Ye Yao, Weitong Hu, Wei Zhang, Ting Wu, Yun-Qing Shi","Multimedia (cs.MM)","Computer-generated graphics (CGs) are images generated by computer software. The~rapid development of computer graphics technologies has made it easier to generate photorealistic computer graphics, and these graphics are quite difficult to distinguish from natural images (NIs) with the naked eye. In this paper, we propose a method based on sensor pattern noise (SPN) and deep learning to distinguish CGs from NIs. Before being fed into our convolutional neural network (CNN)-based model, these images---CGs and NIs---are clipped into image patches. Furthermore, three high-pass filters (HPFs) are used to remove low-frequency signals, which represent the image content. These filters are also used to reveal the residual signal as well as SPN introduced by the digital camera device. Different from the traditional methods of distinguishing CGs from NIs, the proposed method utilizes a five-layer CNN to classify the input image patches. Based on the classification results of the image patches, we deploy a majority vote scheme to obtain the classification results for the full-size images. The~experiments have demonstrated that (1) the proposed method with three HPFs can achieve better results than that with only one HPF or no HPF and that (2) the proposed method with three HPFs achieves 100\% accuracy, although the NIs undergo a JPEG compression with a quality factor of 75.","Mon, 26 Mar 2018 03:59:31 UTC (2,266 KB)[v2] Wed, 25 Apr 2018 13:57:42 UTC (2,266 KB)"
"801","A Systematic Comparison of Deep Learning Architectures in an Autonomous Vehicle","Michael Teti, William Edward Hahn, Shawn Martin, Christopher Teti, Elan Barenholtz","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO); Machine Learning (stat.ML)","Self-driving technology is advancing rapidly --- albeit with significant challenges and limitations. This progress is largely due to recent developments in deep learning algorithms. To date, however, there has been no systematic comparison of how different deep learning architectures perform at such tasks, or an attempt to determine a correlation between classification performance and performance in an actual vehicle, a potentially critical factor in developing self-driving systems. Here, we introduce the first controlled comparison of multiple deep-learning architectures in an end-to-end autonomous driving task across multiple testing conditions. We compared performance, under identical driving conditions, across seven architectures including a fully-connected network, a simple 2 layer CNN, AlexNet, VGG-16, Inception-V3, ResNet, and an LSTM by assessing the number of laps each model was able to successfully complete without crashing while traversing an indoor racetrack. We compared performance across models when the conditions exactly matched those in training as well as when the local environment and track were configured differently and objects that were not included in the training dataset were placed on the track in various positions. In addition, we considered performance using several different data types for training and testing including single grayscale and color frames, and multiple grayscale frames stacked together in sequence. With the exception of a fully-connected network, all models performed reasonably well (around or above 80\%) and most very well (~95\%) on at least one input type but with considerable variation across models and inputs. Overall, AlexNet, operating on single color frames as input, achieved the best level of performance (100\% success rate in phase one and 55\% in phase two) while VGG-16 performed well most consistently across image types.","Mon, 26 Mar 2018 01:58:07 UTC (2,648 KB)[v2] Sat, 13 Oct 2018 00:04:29 UTC (5,575 KB)"
"802","Goldbach's Function Approximation Using Deep Learning","Avigail Stekel, Merav Chkroun, Amos Azaria","Machine Learning (cs.LG); Machine Learning (stat.ML)","Goldbach conjecture is one of the most famous open mathematical problems. It states that every even number, bigger than two, can be presented as a sum of 2 prime numbers. % In this work we present a deep learning based model that predicts the number of Goldbach partitions for a given even number. Surprisingly, our model outperforms all state-of-the-art analytically derived estimations for the number of couples, while not requiring prime factorization of the given number. We believe that building a model that can accurately predict the number of couples brings us one step closer to solving one of the world most famous open problems. To the best of our knowledge, this is the first attempt to consider machine learning based data-driven methods to approximate open mathematical problems in the field of number theory, and hope that this work will encourage such attempts.","Sun, 25 Mar 2018 12:09:43 UTC (665 KB)"
"803","Posterior Concentration for Sparse Deep Learning","Nicholas Polson, Veronika Rockova","Machine Learning (stat.ML); Machine Learning (cs.LG)","Spike-and-Slab Deep Learning (SS-DL) is a fully Bayesian alternative to Dropout for improving generalizability of deep ReLU networks. This new type of regularization enables provable recovery of smooth input-output maps with unknown levels of smoothness. Indeed, we show that the posterior distribution concentrates at the near minimax rate for $メ$-Holder smooth maps, performing as well as if we knew the smoothness level $メ$ ahead of time. Our result sheds light on architecture design for deep neural networks, namely the choice of depth, width and sparsity level. These network attributes typically depend on unknown smoothness in order to be optimal. We obviate this constraint with the fully Bayes construction. As an aside, we show that SS-DL does not overfit in the sense that the posterior concentrates on smaller networks with fewer (up to the optimal number of) nodes and links. Our results provide new theoretical justifications for deep ReLU networks from a Bayesian point of view.","Sat, 24 Mar 2018 17:51:15 UTC (22 KB)"
"804","Gradient descent in Gaussian random fields as a toy model for high-dimensional optimisation in deep learning","Mariano Chouza, Stephen Roberts, Stefan Zohren","Machine Learning (stat.ML); Machine Learning (cs.LG)","In this paper we model the loss function of high-dimensional optimization problems by a Gaussian random field, or equivalently a Gaussian process. Our aim is to study gradient descent in such loss functions or energy landscapes and compare it to results obtained from real high-dimensional optimization problems such as encountered in deep learning. In particular, we analyze the distribution of the improved loss function after a step of gradient descent, provide analytic expressions for the moments as well as prove asymptotic normality as the dimension of the parameter space becomes large. Moreover, we compare this with the expectation of the global minimum of the landscape obtained by means of the Euler characteristic of excursion sets. Besides complementing our analytical findings with numerical results from simulated Gaussian random fields, we also compare it to loss functions obtained from optimisation problems on synthetic and real data sets by proposing a ""black box"" random field toy-model for a deep neural network loss function.","Sat, 24 Mar 2018 14:22:36 UTC (1,824 KB)"
"805","Learning to Reweight Examples for Robust Deep Learning","Mengye Ren, Wenyuan Zeng, Bin Yang, Raquel Urtasun","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep neural networks have been shown to be very powerful modeling tools for many supervised learning tasks involving complex input patterns. However, they can also easily overfit to training set biases and label noises. In addition to various regularizers, example reweighting algorithms are popular solutions to these problems, but they require careful tuning of additional hyperparameters, such as example mining schedules and regularization hyperparameters. In contrast to past reweighting methods, which typically consist of functions of the cost value of each example, in this work we propose a novel meta-learning algorithm that learns to assign weights to training examples based on their gradient directions. To determine the example weights, our method performs a meta gradient descent step on the current mini-batch example weights (which are initialized from zero) to minimize the loss on a clean unbiased validation set. Our proposed method can be easily implemented on any type of deep network, does not require any additional hyperparameter tuning, and achieves impressive performance on class imbalance and corrupted label problems where only a small amount of clean validation data is available.","Sat, 24 Mar 2018 03:41:59 UTC (141 KB)[v2] Fri, 8 Jun 2018 15:29:31 UTC (2,579 KB)"
"806","Deep Learning Phase Segregation","Amir Barati Farimani, Joseph Gomes, Rishi Sharma, Franklin L. Lee, Vijay S. Pande","Machine Learning (cs.LG); Computational Physics (physics.comp-ph); Machine Learning (stat.ML)","Phase segregation, the process by which the components of a binary mixture spontaneously separate, is a key process in the evolution and design of many chemical, mechanical, and biological systems. In this work, we present a data-driven approach for the learning, modeling, and prediction of phase segregation. A direct mapping between an initially dispersed, immiscible binary fluid and the equilibrium concentration field is learned by conditional generative convolutional neural networks. Concentration field predictions by the deep learning model conserve phase fraction, correctly predict phase transition, and reproduce area, perimeter, and total free energy distributions up to 98% accuracy.","Fri, 23 Mar 2018 21:59:01 UTC (2,654 KB)"
"807","Effective deep learning training for single-image super-resolution in endomicroscopy exploiting video-registration-based reconstruction","Daniele Ravi, Agnieszka Barbara Szczotka, Dzhoshkun Ismail Shakir, Stephen P Pereira, Tom Vercauteren","Computer Vision and Pattern Recognition (cs.CV)","Purpose: Probe-based Confocal Laser Endomicroscopy (pCLE) is a recent imaging modality that allows performing in vivo optical biopsies. The design of pCLE hardware, and its reliance on an optical fibre bundle, fundamentally limits the image quality with a few tens of thousands fibres, each acting as the equivalent of a single-pixel detector, assembled into a single fibre bundle. Video-registration techniques can be used to estimate high-resolution (HR) images by exploiting the temporal information contained in a sequence of low-resolution (LR) images. However, the alignment of LR frames, required for the fusion, is computationally demanding and prone to artefacts. Methods: In this work, we propose a novel synthetic data generation approach to train exemplar-based Deep Neural Networks (DNNs). HR pCLE images with enhanced quality are recovered by the models trained on pairs of estimated HR images (generated by the video-registration algorithm) and realistic synthetic LR images. Performance of three different state-of-the-art DNNs techniques were analysed on a Smart Atlas database of 8806 images from 238 pCLE video sequences. The results were validated through an extensive Image Quality Assessment (IQA) that takes into account different quality scores, including a Mean Opinion Score (MOS). Results: Results indicate that the proposed solution produces an effective improvement in the quality of the obtained reconstructed image. Conclusion: The proposed training strategy and associated DNNs allows us to perform convincing super-resolution of pCLE images.","Fri, 23 Mar 2018 15:31:40 UTC (1,864 KB)"
"808","Deep learning and its application to medical image segmentation","Holger R. Roth, Chen Shen, Hirohisa Oda, Masahiro Oda, Yuichiro Hayashi, Kazunari Misawa, Kensaku Mori","Computer Vision and Pattern Recognition (cs.CV)","One of the most common tasks in medical imaging is semantic segmentation. Achieving this segmentation automatically has been an active area of research, but the task has been proven very challenging due to the large variation of anatomy across different patients. However, recent advances in deep learning have made it possible to significantly improve the performance of image recognition and semantic segmentation methods in the field of computer vision. Due to the data driven approaches of hierarchical feature learning in deep learning frameworks, these advances can be translated to medical images without much difficulty. Several variations of deep convolutional neural networks have been successfully applied to medical images. Especially fully convolutional architectures have been proven efficient for segmentation of 3D medical images. In this article, we describe how to build a 3D fully convolutional network (FCN) that can process 3D images in order to produce automatic semantic segmentations. The model is trained and evaluated on a clinical computed tomography (CT) dataset and shows state-of-the-art performance in multi-organ segmentation.","Fri, 23 Mar 2018 08:55:10 UTC (7,932 KB)"
"809","Demystifying Deep Learning: A Geometric Approach to Iterative Projections","Ashkan Panahi, Hamid Krim, Liyi Dai","Machine Learning (cs.LG); Machine Learning (stat.ML)","Parametric approaches to Learning, such as deep learning (DL), are highly popular in nonlinear regression, in spite of their extremely difficult training with their increasing complexity (e.g. number of layers in DL). In this paper, we present an alternative semi-parametric framework which foregoes the ordinarily required feedback, by introducing the novel idea of geometric regularization. We show that certain deep learning techniques such as residual network (ResNet) architecture are closely related to our approach. Hence, our technique can be used to analyze these types of deep learning. Moreover, we present preliminary results which confirm that our approach can be easily trained to obtain complex structures.","Thu, 22 Mar 2018 15:49:32 UTC (251 KB)"
"810","Deep Learning using Rectified Linear Units (ReLU)","Abien Fred Agarap","Neural and Evolutionary Computing (cs.NE); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","We introduce the use of rectified linear units (ReLU) as the classification function in a deep neural network (DNN). Conventionally, ReLU is used as an activation function in DNNs, with Softmax function as their classification function. However, there have been several studies on using a classification function other than Softmax, and this study is an addition to those. We accomplish this by taking the activation of the penultimate layer $h_{n - 1}$ in a neural network, then multiply it by weight parameters $ヨ$ to get the raw scores $o_{i}$. Afterwards, we threshold the raw scores $o_{i}$ by $0$, i.e. $f(o) = \max(0, o_{i})$, where $f(o)$ is the ReLU function. We provide class predictions $\hat{y}$ through argmax function, i.e. argmax $f(x)$.","Thu, 22 Mar 2018 14:30:17 UTC (558 KB)"
"811","Extended depth-of-field in holographic image reconstruction using deep learning based auto-focusing and phase-recovery","Yichen Wu, Yair Rivenson, Yibo Zhang, Zhensong Wei, Harun Gunaydin, Xing Lin, Aydogan Ozcan","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Optics (physics.optics)","Holography encodes the three dimensional (3D) information of a sample in the form of an intensity-only recording. However, to decode the original sample image from its hologram(s), auto-focusing and phase-recovery are needed, which are in general cumbersome and time-consuming to digitally perform. Here we demonstrate a convolutional neural network (CNN) based approach that simultaneously performs auto-focusing and phase-recovery to significantly extend the depth-of-field (DOF) in holographic image reconstruction. For this, a CNN is trained by using pairs of randomly de-focused back-propagated holograms and their corresponding in-focus phase-recovered images. After this training phase, the CNN takes a single back-propagated hologram of a 3D sample as input to rapidly achieve phase-recovery and reconstruct an in focus image of the sample over a significantly extended DOF. This deep learning based DOF extension method is non-iterative, and significantly improves the algorithm time-complexity of holographic image reconstruction from O(nm) to O(1), where n refers to the number of individual object points or particles within the sample volume, and m represents the focusing search space within which each object point or particle needs to be individually focused. These results highlight some of the unique opportunities created by data-enabled statistical image reconstruction methods powered by machine learning, and we believe that the presented approach can be broadly applicable to computationally extend the DOF of other imaging modalities.","Wed, 21 Mar 2018 20:59:33 UTC (1,763 KB)"
"812","Information Theoretic Interpretation of Deep learning","Tianchen Zhao","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (stat.ML)","We interpret part of the experimental results of Shwartz-Ziv and Tishby [2017]. Inspired by these results, we established a conjecture of the dynamics of the machinary of deep neural network. This conjecture can be used to explain the counterpart result by Saxe et al. [2018].","Wed, 21 Mar 2018 16:03:29 UTC (1,768 KB)[v2] Thu, 22 Mar 2018 02:36:59 UTC (1,768 KB)"
"813","A Survey of Deep Learning Techniques for Mobile Robot Applications","Jahanzaib Shabbir, Tarique Anwer","Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","Advancements in deep learning over the years have attracted research into how deep artificial neural networks can be used in robotic systems. This research survey will present a summarization of the current research with a specific focus on the gains and obstacles for deep learning to be applied to mobile robotics.","Tue, 20 Mar 2018 19:12:05 UTC (116 KB)"
"814","DeepGauge: Multi-Granularity Testing Criteria for Deep Learning Systems","Lei Ma, Felix Juefei-Xu, Fuyuan Zhang, Jiyuan Sun, Minhui Xue, Bo Li, Chunyang Chen, Ting Su, Li Li, Yang Liu, Jianjun Zhao, Yadong Wang","Software Engineering (cs.SE); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning (DL) defines a new data-driven programming paradigm that constructs the internal system logic of a crafted neuron network through a set of training data. We have seen wide adoption of DL in many safety-critical scenarios. However, a plethora of studies have shown that the state-of-the-art DL systems suffer from various vulnerabilities which can lead to severe consequences when applied to real-world applications. Currently, the testing adequacy of a DL system is usually measured by the accuracy of test data. Considering the limitation of accessible high quality test data, good accuracy performance on test data can hardly provide confidence to the testing adequacy and generality of DL systems. Unlike traditional software systems that have clear and controllable logic and functionality, the lack of interpretability in a DL system makes system analysis and defect detection difficult, which could potentially hinder its real-world deployment. In this paper, we propose DeepGauge, a set of multi-granularity testing criteria for DL systems, which aims at rendering a multi-faceted portrayal of the testbed. The in-depth evaluation of our proposed testing criteria is demonstrated on two well-known datasets, five DL systems, and with four state-of-the-art adversarial attack techniques against DL. The potential usefulness of DeepGauge sheds light on the construction of more generic and robust DL systems.","Tue, 20 Mar 2018 16:52:12 UTC (4,609 KB)[v2] Tue, 15 May 2018 05:02:54 UTC (1,180 KB)[v3] Sat, 28 Jul 2018 07:47:27 UTC (1,342 KB)[v4] Tue, 14 Aug 2018 23:07:39 UTC (1,717 KB)"
"815","Explanation Methods in Deep Learning: Users, Values, Concerns and Challenges","Gabrielle Ras, Marcel van Gerven, Pim Haselager","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","Issues regarding explainable AI involve four components: users, laws & regulations, explanations and algorithms. Together these components provide a context in which explanation methods can be evaluated regarding their adequacy. The goal of this chapter is to bridge the gap between expert users and lay users. Different kinds of users are identified and their concerns revealed, relevant statements from the General Data Protection Regulation are analyzed in the context of Deep Neural Networks (DNNs), a taxonomy for the classification of existing explanation methods is introduced, and finally, the various classes of explanation methods are analyzed to verify if user concerns are justified. Overall, it is clear that (visual) explanations can be given about various aspects of the influence of the input on the output. However, it is noted that explanation methods or interfaces for lay users are missing and we speculate which criteria these methods / interfaces should satisfy. Finally it is noted that two important concerns are difficult to address with explanation methods: the concern about bias in datasets that leads to biased DNNs, as well as the suspicion about unfair outcomes.","Tue, 20 Mar 2018 16:44:47 UTC (287 KB)[v2] Thu, 29 Mar 2018 15:06:04 UTC (289 KB)"
"816","Live Target Detection with Deep Learning Neural Network and Unmanned Aerial Vehicle on Android Mobile Device","Ali Canberk Anar, Erkan Bostanci, Mehmet Serdar Guzel","Computer Vision and Pattern Recognition (cs.CV)","This paper describes the stages faced during the development of an Android program which obtains and decodes live images from DJI Phantom 3 Professional Drone and implements certain features of the TensorFlow Android Camera Demo application. Test runs were made and outputs of the application were noted. A lake was classified as seashore, breakwater and pier with the proximities of 24.44%, 21.16% and 12.96% respectfully. The joystick of the UAV controller and laptop keyboard was classified with the proximities of 19.10% and 13.96% respectfully. The laptop monitor was classified as screen, monitor and television with the proximities of 18.77%, 14.76% and 14.00% respectfully. The computer used during the development of this study was classified as notebook and laptop with the proximities of 20.04% and 11.68% respectfully. A tractor parked at a parking lot was classified with the proximity of 12.88%. A group of cars in the same parking lot were classified as sports car, racer and convertible with the proximities of 31.75%, 18.64% and 13.45% respectfully at an inference time of 851ms.","Mon, 19 Mar 2018 16:15:22 UTC (1,463 KB)[v2] Thu, 22 Mar 2018 17:57:00 UTC (980 KB)"
"817","Universal features of price formation in financial markets: perspectives from Deep Learning","Justin Sirignano, Rama Cont","Statistical Finance (q-fin.ST); Trading and Market Microstructure (q-fin.TR); Machine Learning (stat.ML)","Using a large-scale Deep Learning approach applied to a high-frequency database containing billions of electronic market quotes and transactions for US equities, we uncover nonparametric evidence for the existence of a universal and stationary price formation mechanism relating the dynamics of supply and demand for a stock, as revealed through the order book, to subsequent variations in its market price. We assess the model by testing its out-of-sample predictions for the direction of price moves given the history of price and order flow, across a wide range of stocks and time periods. The universal price formation model is shown to exhibit a remarkably stable out-of-sample prediction accuracy across time, for a wide range of stocks from different sectors. Interestingly, these results also hold for stocks which are not part of the training sample, showing that the relations captured by the model are universal and not asset-specific. The universal model --- trained on data from all stocks --- outperforms, in terms of out-of-sample prediction accuracy, asset-specific linear and nonlinear models trained on time series of any given stock, showing that the universal nature of price formation weighs in favour of pooling together financial data from various stocks, rather than designing asset- or sector-specific models as commonly done. Standard data normalizations based on volatility, price level or average spread, or partitioning the training data into sectors or categories such as large/small tick stocks, do not improve training results. On the other hand, inclusion of price and order flow history over many past observations is shown to improve forecasting performance, showing evidence of path-dependence in price dynamics.","Mon, 19 Mar 2018 13:46:37 UTC (1,098 KB)"
"818","Efficient and accurate inversion of multiple scattering with deep learning","Yu Sun, Zhihao Xia, Ulugbek S. Kamilov","Computer Vision and Pattern Recognition (cs.CV)","Image reconstruction under multiple light scattering is crucial in a number of applications such as diffraction tomography. The reconstruction problem is often formulated as a nonconvex optimization, where a nonlinear measurement model is used to account for multiple scattering and regularization is used to enforce prior constraints on the object. In this paper, we propose a powerful alternative to this optimization-based view of image reconstruction by designing and training a deep convolutional neural network that can invert multiple scattered measurements to produce a high-quality image of the refractive index. Our results on both simulated and experimental datasets show that the proposed approach is substantially faster and achieves higher imaging quality compared to the state-of-the-art methods based on optimization.","Sun, 18 Mar 2018 03:11:48 UTC (1,160 KB)[v2] Thu, 5 Apr 2018 17:02:41 UTC (1,268 KB)"
"819","Constrained Deep Learning using Conditional Gradient and Applications in Computer Vision","Sathya N. Ravi, Tuan Dinh, Vishnu Sai Rao Lokhande, Vikas Singh","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","A number of results have recently demonstrated the benefits of incorporating various constraints when training deep architectures in vision and machine learning. The advantages range from guarantees for statistical generalization to better accuracy to compression. But support for general constraints within widely used libraries remains scarce and their broader deployment within many applications that can benefit from them remains under-explored. Part of the reason is that Stochastic gradient descent (SGD), the workhorse for training deep neural networks, does not natively deal with constraints with global scope very well. In this paper, we revisit a classical first order scheme from numerical optimization, Conditional Gradients (CG), that has, thus far had limited applicability in training deep models. We show via rigorous analysis how various constraints can be naturally handled by modifications of this algorithm. We provide convergence guarantees and show a suite of immediate benefits that are possible -- from training ResNets with fewer layers but better accuracy simply by substituting in our version of CG to faster training of GANs with 50% fewer epochs in image inpainting applications to provably better generalization guarantees using efficiently implementable forms of recently proposed regularizers.","Sat, 17 Mar 2018 03:59:34 UTC (2,864 KB)"
"820","Deep learning for affective computing: text-based emotion recognition in decision support","Bernhard Kratzwald, Suzana Ilic, Mathias Kraus, Stefan Feuerriegel, Helmut Prendinger","Computation and Language (cs.CL)","Emotions widely affect human decision-making. This fact is taken into account by affective computing with the goal of tailoring decision support to the emotional states of individuals. However, the accurate recognition of emotions within narrative documents presents a challenging undertaking due to the complexity and ambiguity of language. Performance improvements can be achieved through deep learning; yet, as demonstrated in this paper, the specific nature of this task requires the customization of recurrent neural networks with regard to bidirectional processing, dropout layers as a means of regularization, and weighted loss functions. In addition, we propose sent2affect, a tailored form of transfer learning for affective computing: here the network is pre-trained for a different task (i.e. sentiment analysis), while the output layer is subsequently tuned to the task of emotion recognition. The resulting performance is evaluated in a holistic setting across 6 benchmark datasets, where we find that both recurrent neural networks and transfer learning consistently outperform traditional machine learning. Altogether, the findings have considerable implications for the use of affective computing.","Fri, 16 Mar 2018 21:05:13 UTC (2,358 KB)[v2] Fri, 23 Mar 2018 15:37:32 UTC (467 KB)[v3] Mon, 26 Mar 2018 15:42:57 UTC (484 KB)[v4] Tue, 10 Apr 2018 09:41:12 UTC (936 KB)[v5] Mon, 20 Aug 2018 17:10:52 UTC (257 KB)[v6] Mon, 10 Sep 2018 09:07:30 UTC (232 KB)"
"821","Vulnerability of Deep Learning","Richard Kenway","Machine Learning (stat.ML); Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","The Renormalisation Group (RG) provides a framework in which it is possible to assess whether a deep-learning network is sensitive to small changes in the input data and hence prone to error, or susceptible to adversarial attack. Distinct classification outputs are associated with different RG fixed points and sensitivity to small changes in the input data is due to the presence of relevant operators at a fixed point. A numerical scheme, based on Monte Carlo RG ideas, is proposed for identifying the existence of relevant operators and the corresponding directions of greatest sensitivity in the input data. Thus, a trained deep-learning network may be tested for its robustness and, if it is vulnerable to attack, dangerous perturbations of the input data identified.","Fri, 16 Mar 2018 08:52:04 UTC (8 KB)"
"822","Deep Learning Reconstruction of Ultra-Short Pulses","Tom Zahavy, Alex Dikopoltsev, Oren Cohen, Shie Mannor, Mordechai Segev","Optics (physics.optics); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","Ultra-short laser pulses with femtosecond to attosecond pulse duration are the shortest systematic events humans can create. Characterization (amplitude and phase) of these pulses is a key ingredient in ultrafast science, e.g., exploring chemical reactions and electronic phase transitions. Here, we propose and demonstrate, numerically and experimentally, the first deep neural network technique to reconstruct ultra-short optical pulses. We anticipate that this approach will extend the range of ultrashort laser pulses that can be characterized, e.g., enabling to diagnose very weak attosecond pulses.","Thu, 15 Mar 2018 22:37:31 UTC (4,792 KB)"
"823","GossipGraD: Scalable Deep Learning using Gossip Communication based Asynchronous Gradient Descent","Jeff Daily, Abhinav Vishnu, Charles Siegel, Thomas Warfel, Vinay Amatya","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","In this paper, we present GossipGraD - a gossip communication protocol based Stochastic Gradient Descent (SGD) algorithm for scaling Deep Learning (DL) algorithms on large-scale systems. The salient features of GossipGraD are: 1) reduction in overall communication complexity from ト(log(p)) for p compute nodes in well-studied SGD to O(1), 2) model diffusion such that compute nodes exchange their updates (gradients) indirectly after every log(p) steps, 3) rotation of communication partners for facilitating direct diffusion of gradients, 4) asynchronous distributed shuffle of samples during the feedforward phase in SGD to prevent over-fitting, 5) asynchronous communication of gradients for further reducing the communication cost of SGD and GossipGraD. We implement GossipGraD for GPU and CPU clusters and use NVIDIA GPUs (Pascal P100) connected with InfiniBand, and Intel Knights Landing (KNL) connected with Aries network. We evaluate GossipGraD using well-studied dataset ImageNet-1K (~250GB), and widely studied neural network topologies such as GoogLeNet and ResNet50 (current winner of ImageNet Large Scale Visualization Research Challenge (ILSVRC)). Our performance evaluation using both KNL and Pascal GPUs indicates that GossipGraD can achieve perfect efficiency for these datasets and their associated neural network topologies. Specifically, for ResNet50, GossipGraD is able to achieve ~100% compute efficiency using 128 NVIDIA Pascal P100 GPUs - while matching the top-1 classification accuracy published in literature.","Thu, 15 Mar 2018 17:32:16 UTC (4,256 KB)"
"824","Development and Validation of Deep Learning Algorithms for Detection of Critical Findings in Head CT Scans","Sasank Chilamkurthy, Rohit Ghosh, Swetha Tanamala, Mustafa Biviji, Norbert G. Campeau, Vasantha Kumar Venugopal, Vidur Mahajan, Pooja Rao, Prashant Warier","Computer Vision and Pattern Recognition (cs.CV)","Importance: Non-contrast head CT scan is the current standard for initial imaging of patients with head trauma or stroke symptoms. Objective: To develop and validate a set of deep learning algorithms for automated detection of following key findings from non-contrast head CT scans: intracranial hemorrhage (ICH) and its types, intraparenchymal (IPH), intraventricular (IVH), subdural (SDH), extradural (EDH) and subarachnoid (SAH) hemorrhages, calvarial fractures, midline shift and mass effect. Design and Settings: We retrospectively collected a dataset containing 313,318 head CT scans along with their clinical reports from various centers. A part of this dataset (Qure25k dataset) was used to validate and the rest to develop algorithms. Additionally, a dataset (CQ500 dataset) was collected from different centers in two batches B1 & B2 to clinically validate the algorithms. Main Outcomes and Measures: Original clinical radiology report and consensus of three independent radiologists were considered as gold standard for Qure25k and CQ500 datasets respectively. Area under receiver operating characteristics curve (AUC) for each finding was primarily used to evaluate the algorithms. Results: Qure25k dataset contained 21,095 scans (mean age 43.31; 42.87% female) while batches B1 and B2 of CQ500 dataset consisted of 214 (mean age 43.40; 43.92% female) and 277 (mean age 51.70; 30.31% female) scans respectively. On Qure25k dataset, the algorithms achieved AUCs of 0.9194, 0.8977, 0.9559, 0.9161, 0.9288 and 0.9044 for detecting ICH, IPH, IVH, SDH, EDH and SAH respectively. AUCs for the same on CQ500 dataset were 0.9419, 0.9544, 0.9310, 0.9521, 0.9731 and 0.9574 respectively. For detecting calvarial fractures, midline shift and mass effect, AUCs on Qure25k dataset were 0.9244, 0.9276 and 0.8583 respectively, while AUCs on CQ500 dataset were 0.9624, 0.9697 and 0.9216 respectively.","Tue, 13 Mar 2018 17:43:30 UTC (1,868 KB)[v2] Thu, 12 Apr 2018 06:32:23 UTC (1,868 KB)"
"825","Accurate Facial Parts Localization and Deep Learning for 3D Facial Expression Recognition","Asim Jan, Huaxiong Ding, Hongying Meng, Liming Chen, Huibin Li","Computer Vision and Pattern Recognition (cs.CV)","Meaningful facial parts can convey key cues for both facial action unit detection and expression prediction. Textured 3D face scan can provide both detailed 3D geometric shape and 2D texture appearance cues of the face which are beneficial for Facial Expression Recognition (FER). However, accurate facial parts extraction as well as their fusion are challenging tasks. In this paper, a novel system for 3D FER is designed based on accurate facial parts extraction and deep feature fusion of facial parts. In particular, each textured 3D face scan is firstly represented as a 2D texture map and a depth map with one-to-one dense correspondence. Then, the facial parts of both texture map and depth map are extracted using a novel 4-stage process consists of facial landmark localization, facial rotation correction, facial resizing, facial parts bounding box extraction and post-processing procedures. Finally, deep fusion Convolutional Neural Networks (CNNs) features of all facial parts are learned from both texture maps and depth maps, respectively and nonlinear SVMs are used for expression prediction. Experiments are conducted on the BU-3DFE database, demonstrating the effectiveness of combing different facial parts, texture and depth cues and reporting the state-of-the-art results in comparison with all existing methods under the same setting.","Sun, 4 Mar 2018 15:04:23 UTC (2,826 KB)"
"826","Computer-aided diagnosis of lung carcinoma using deep learning - a pilot study","Zhang Li, Zheyu Hu, Jiaolong Xu, Tao Tan, Hui Chen, Zhi Duan, Ping Liu, Jun Tang, Guoping Cai, Quchang Ouyang, Yuling Tang, Geert Litjens, Qiang Li","Computer Vision and Pattern Recognition (cs.CV)","Aim: Early detection and correct diagnosis of lung cancer are the most important steps in improving patient outcome. This study aims to assess which deep learning models perform best in lung cancer diagnosis. Methods: Non-small cell lung carcinoma and small cell lung carcinoma biopsy specimens were consecutively obtained and stained. The specimen slides were diagnosed by two experienced pathologists (over 20 years). Several deep learning models were trained to discriminate cancer and non-cancer biopsies. Result: Deep learning models give reasonable AUC from 0.8810 to 0.9119. Conclusion: The deep learning analysis could help to speed up the detection process for the whole-slide image (WSI) and keep the comparable detection rate with human observer.","Wed, 14 Mar 2018 18:46:17 UTC (1,326 KB)"
"827","Deep Learning Analysis of Defect and Phase Evolution During Electron Beam Induced Transformations in WS2","Artem Maksov, Ondrej Dyck, Kai Wang, Kai Xiao, David B. Geohegan, Bobby G. Sumpter, Rama K. Vasudevan, Stephen Jesse, Sergei V. Kalinin, Maxim Ziatdinov","Materials Science (cond-mat.mtrl-sci)","Understanding elementary mechanisms behind solid-state phase transformations and reactions is the key to optimizing desired functional properties of many technologically relevant materials. Recent advances in scanning transmission electron microscopy (STEM) allow the real-time visualization of solid-state transformations in materials, including those induced by an electron beam and temperature, with atomic resolution. However, despite the ever-expanding capabilities for high-resolution data acquisition, the inferred information about kinetics and thermodynamics of the process and single defect dynamics and interactions is minima, due to the inherent limitations of manual ex-situ analysis of the collected volumes of data. To circumvent this problem, we developed a deep learning framework for dynamic STEM imaging that is trained to find the structures (defects) that break a crystal lattice periodicity and apply it for mapping solid state reactions and transformations in layered WS2 doped with Mo. This framework allows extracting thousands of lattice defects from raw STEM data (single images and movies) in a matter of seconds, which are then classified into different categories using unsupervised clustering methods. We further expanded our framework to extract parameters of diffusion for the sulfur vacancies and analyzed transition probabilities associated with switching between different configurations of defect complexes consisting of Mo dopant and sulfur vacancy, providing insight into point defect dynamics and reactions. This approach is universal and its application to beam induced reactions allows mapping chemical transformation pathways in solids at the atomic level.","Wed, 14 Mar 2018 16:16:21 UTC (1,224 KB)[v2] Thu, 15 Mar 2018 05:29:36 UTC (1,224 KB)[v3] Thu, 16 Aug 2018 06:54:26 UTC (1,279 KB)"
"828","Real-time Cardiovascular MR with Spatio-temporal Artifact Suppression using Deep Learning - Proof of Concept in Congenital Heart Disease","Andreas Hauptmann, Simon Arridge, Felix Lucka, Vivek Muthurangu, Jennifer A. Steeden","Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)","PURPOSE: Real-time assessment of ventricular volumes requires high acceleration factors. Residual convolutional neural networks (CNN) have shown potential for removing artifacts caused by data undersampling. In this study we investigated the effect of different radial sampling patterns on the accuracy of a CNN. We also acquired actual real-time undersampled radial data in patients with congenital heart disease (CHD), and compare CNN reconstruction to Compressed Sensing (CS). METHODS: A 3D (2D plus time) CNN architecture was developed, and trained using 2276 gold-standard paired 3D data sets, with 14x radial undersampling. Four sampling schemes were tested, using 169 previously unseen 3D 'synthetic' test data sets. Actual real-time tiny Golden Angle (tGA) radial SSFP data was acquired in 10 new patients (122 3D data sets), and reconstructed using the 3D CNN as well as a CS algorithm; GRASP. RESULTS: Sampling pattern was shown to be important for image quality, and accurate visualisation of cardiac structures. For actual real-time data, overall reconstruction time with CNN (including creation of aliased images) was shown to be more than 5x faster than GRASP. Additionally, CNN image quality and accuracy of biventricular volumes was observed to be superior to GRASP for the same raw data. CONCLUSION: This paper has demonstrated the potential for the use of a 3D CNN for deep de-aliasing of real-time radial data, within the clinical setting. Clinical measures of ventricular volumes using real-time data with CNN reconstruction are not statistically significantly different from the gold-standard, cardiac gated, BH techniques.","Wed, 14 Mar 2018 10:25:35 UTC (2,605 KB)[v2] Wed, 28 Mar 2018 21:27:41 UTC (3,218 KB)[v3] Thu, 14 Jun 2018 13:03:43 UTC (2,429 KB)"
"829","Predicting Human Performance in Vertical Menu Selection Using Deep Learning","Yang Li, Samy Bengio, Gilles Bailly","Human-Computer Interaction (cs.HC)","Predicting human performance in interaction tasks allows designers or developers to understand the expected performance of a target interface without actually testing it with real users. In this work, we present a deep neural net to model and predict human performance in performing a sequence of UI tasks. In particular, we focus on a dominant class of tasks, i.e., target selection from a vertical list or menu. We experimented with our deep neural net using a public dataset collected from a desktop laboratory environment and a dataset collected from hundreds of touchscreen smartphone users via crowdsourcing. Our model significantly outperformed previous methods on these datasets. Importantly, our method, as a deep model, can easily incorporate additional UI attributes such as visual appearance and content semantics without changing model architectures. By understanding about how a deep learning model learns from human behaviors, our approach can be seen as a vehicle to discover new patterns about human behaviors to advance analytical modeling.","Tue, 13 Mar 2018 23:30:35 UTC (617 KB)"
"830","A Survey on Deep Learning Toolkits and Libraries for Intelligent User Interfaces","Jan Zacharias, Michael Barz, Daniel Sonntag","Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)","This paper provides an overview of prominent deep learning toolkits and, in particular, reports on recent publications that contributed open source software for implementing tasks that are common in intelligent user interfaces (IUI). We provide a scientific reference for researchers and software engineers who plan to utilise deep learning techniques within their IUI research and development projects.","Tue, 13 Mar 2018 14:07:40 UTC (217 KB)[v2] Wed, 14 Mar 2018 08:32:02 UTC (218 KB)"
"831","Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning","Nicolas Papernot, Patrick McDaniel","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep neural networks (DNNs) enable innovative applications of machine learning like image recognition, machine translation, or malware detection. However, deep learning is often criticized for its lack of robustness in adversarial settings (e.g., vulnerability to adversarial inputs) and general inability to rationalize its predictions. In this work, we exploit the structure of deep learning to enable new learning-based inference and decision strategies that achieve desirable properties such as robustness and interpretability. We take a first step in this direction and introduce the Deep k-Nearest Neighbors (DkNN). This hybrid classifier combines the k-nearest neighbors algorithm with representations of the data learned by each layer of the DNN: a test input is compared to its neighboring training points according to the distance that separates them in the representations. We show the labels of these neighboring points afford confidence estimates for inputs outside the model's training manifold, including on malicious inputs like adversarial examples--and therein provides protections against inputs that are outside the models understanding. This is because the nearest neighbors can be used to estimate the nonconformity of, i.e., the lack of support for, a prediction in the training data. The neighbors also constitute human-interpretable explanations of predictions. We evaluate the DkNN algorithm on several datasets, and show the confidence estimates accurately identify inputs outside the model, and that the explanations provided by nearest neighbors are intuitive and useful in understanding model failures.","Tue, 13 Mar 2018 13:02:13 UTC (1,886 KB)"
"832","Replication study: Development and validation of deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs","Mike Voets, Kajsa Mllersen, Lars Ailo Bongo","Computer Vision and Pattern Recognition (cs.CV)","Replication studies are essential for validation of new methods, and are crucial to maintain the high standards of scientific publications, and to use the results in practice. We have attempted to replicate the main method in 'Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs' published in JAMA 2016; 316(22). We re-implemented the method since the source code is not available, and we used publicly available data sets. The original study used non-public fundus images from EyePACS and three hospitals in India for training. We used a different EyePACS data set from Kaggle. The original study used the benchmark data set Messidor-2 to evaluate the algorithm's performance. We used the same data set. In the original study, ophthalmologists re-graded all images for diabetic retinopathy, macular edema, and image gradability. There was one diabetic retinopathy grade per image for our data sets, and we assessed image gradability ourselves. Hyper-parameter settings were not described in the original study. But some of these were later published. We were not able to replicate the original study. Our algorithm's area under the receiver operating curve (AUC) of 0.94 on the Kaggle EyePACS test set and 0.80 on Messidor-2 did not come close to the reported AUC of 0.99 in the original study. This may be caused by the use of a single grade per image, different data, or different not described hyper-parameter settings. This study shows the challenges of replicating deep learning, and the need for more replication studies to validate deep learning methods, especially for medical image analysis. Our source code and instructions are available at: this https URL","Mon, 12 Mar 2018 16:04:28 UTC (328 KB)[v2] Mon, 30 Apr 2018 14:51:54 UTC (390 KB)[v3] Thu, 30 Aug 2018 00:28:12 UTC (425 KB)"
"833","Deep Learning in Mobile and Wireless Networking: A Survey","Chaoyun Zhang, Paul Patras, Hamed Haddadi","Networking and Internet Architecture (cs.NI); Machine Learning (cs.LG)","The rapid uptake of mobile devices and the rising popularity of mobile applications and services pose unprecedented demands on mobile and wireless networking infrastructure. Upcoming 5G systems are evolving to support exploding mobile traffic volumes, agile management of network resource to maximize user experience, and extraction of fine-grained real-time analytics. Fulfilling these tasks is challenging, as mobile environments are increasingly complex, heterogeneous, and evolving. One potential solution is to resort to advanced machine learning techniques to help managing the rise in data volumes and algorithm-driven applications. The recent success of deep learning underpins new and powerful tools that tackle problems in this space. In this paper we bridge the gap between deep learning and mobile and wireless networking research, by presenting a comprehensive survey of the crossovers between the two areas. We first briefly introduce essential background and state-of-the-art in deep learning techniques with potential applications to networking. We then discuss several techniques and platforms that facilitate the efficient deployment of deep learning onto mobile systems. Subsequently, we provide an encyclopedic review of mobile and wireless networking research based on deep learning, which we categorize by different domains. Drawing from our experience, we discuss how to tailor deep learning to mobile environments. We complete this survey by pinpointing current challenges and open future directions for research.","Mon, 12 Mar 2018 15:30:04 UTC (3,286 KB)[v2] Mon, 17 Sep 2018 16:08:08 UTC (5,434 KB)"
"834","Adversarial Malware Binaries: Evading Deep Learning for Malware Detection in Executables","Bojan Kolosnjaji, Ambra Demontis, Battista Biggio, Davide Maiorca, Giorgio Giacinto, Claudia Eckert, Fabio Roli","Cryptography and Security (cs.CR)","Machine-learning methods have already been exploited as useful tools for detecting malicious executable files. They leverage data retrieved from malware samples, such as header fields, instruction sequences, or even raw bytes, to learn models that discriminate between benign and malicious software. However, it has also been shown that machine learning and deep neural networks can be fooled by evasion attacks (also referred to as adversarial examples), i.e., small changes to the input data that cause misclassification at test time. In this work, we investigate the vulnerability of malware detection methods that use deep networks to learn from raw bytes. We propose a gradient-based attack that is capable of evading a recently-proposed deep network suited to this purpose by only changing few specific bytes at the end of each malware sample, while preserving its intrusive functionality. Promising results show that our adversarial malware binaries evade the targeted network with high probability, even though less than 1% of their bytes are modified.","Mon, 12 Mar 2018 10:27:17 UTC (292 KB)"
"835","A Deep Learning Based Behavioral Approach to Indoor Autonomous Navigation","Gabriel Sepulveda, Juan Carlos Niebles, Alvaro Soto","Artificial Intelligence (cs.AI); Robotics (cs.RO)","We present a semantically rich graph representation for indoor robotic navigation. Our graph representation encodes: semantic locations such as offices or corridors as nodes, and navigational behaviors such as enter office or cross a corridor as edges. In particular, our navigational behaviors operate directly from visual inputs to produce motor controls and are implemented with deep learning architectures. This enables the robot to avoid explicit computation of its precise location or the geometry of the environment, and enables navigation at a higher level of semantic abstraction. We evaluate the effectiveness of our representation by simulating navigation tasks in a large number of virtual environments. Our results show that using a simple sets of perceptual and navigational behaviors, the proposed approach can successfully guide the way of the robot as it completes navigational missions such as going to a specific office. Furthermore, our implementation shows to be effective to control the selection and switching of behaviors.","Mon, 12 Mar 2018 05:27:07 UTC (2,224 KB)"
"836","A Deep Learning Approach for Pose Estimation from Volumetric OCT Data","Nils Gessert, Matthias Schluter, Alexander Schlaefer","Computer Vision and Pattern Recognition (cs.CV)","Tracking the pose of instruments is a central problem in image-guided surgery. For microscopic scenarios, optical coherence tomography (OCT) is increasingly used as an imaging modality. OCT is suitable for accurate pose estimation due to its micrometer range resolution and volumetric field of view. However, OCT image processing is challenging due to speckle noise and reflection artifacts in addition to the images' 3D nature. We address pose estimation from OCT volume data with a new deep learning-based tracking framework. For this purpose, we design a new 3D convolutional neural network (CNN) architecture to directly predict the 6D pose of a small marker geometry from OCT volumes. We use a hexapod robot to automatically acquire labeled data points which we use to train 3D CNN architectures for multi-output regression. We use this setup to provide an in-depth analysis on deep learning-based pose estimation from volumes. Specifically, we demonstrate that exploiting volume information for pose estimation yields higher accuracy than relying on 2D representations with depth information. Supporting this observation, we provide quantitative and qualitative results that 3D CNNs effectively exploit the depth structure of marker objects. Regarding the deep learning aspect, we present efficient design principles for 3D CNNs, making use of insights from the 2D deep learning community. In particular, we present Inception3D as a new architecture which performs best for our application. We show that our deep learning approach reaches errors at our ground-truth label's resolution. We achieve a mean average error of $\SI{14.89 \pm 9.3}{\micro\metre}$ and $\SI{0.096 \pm 0.072}{\degree}$ for position and orientation learning, respectively.","Sat, 10 Mar 2018 18:48:18 UTC (3,642 KB)"
"837","IcoRating: A Deep-Learning System for Scam ICO Identification","Shuqing Bian, Zhenpeng Deng, Fei Li, Will Monroe, Peng Shi, Zijun Sun, Wei Wu, Sikuang Wang, William Yang Wang, Arianna Yuan, Tianwei Zhang, Jiwei Li","Computation and Language (cs.CL)","Cryptocurrencies (or digital tokens, digital currencies, e.g., BTC, ETH, XRP, NEO) have been rapidly gaining ground in use, value, and understanding among the public, bringing astonishing profits to investors. Unlike other money and banking systems, most digital tokens do not require central authorities. Being decentralized poses significant challenges for credit rating. Most ICOs are currently not subject to government regulations, which makes a reliable credit rating system for ICO projects necessary and urgent. In this paper, we introduce IcoRating, the first learning--based cryptocurrency rating system. We exploit natural-language processing techniques to analyze various aspects of 2,251 digital currencies to date, such as white paper content, founding teams, Github repositories, websites, etc. Supervised learning models are used to correlate the life span and the price change of cryptocurrencies with these features. For the best setting, the proposed system is able to identify scam ICO projects with 0.83 precision. We hope this work will help investors identify scam ICOs and attract more efforts in automatically evaluating and analyzing ICO projects.","Thu, 8 Mar 2018 09:14:37 UTC (725 KB)"
"838","Construction of neural networks for realization of localized deep learning","Charles K. Chui, Shao-Bo Lin, Ding-Xuan Zhou","Machine Learning (cs.LG)","The subject of deep learning has recently attracted users of machine learning from various disciplines, including: medical diagnosis and bioinformatics, financial market analysis and online advertisement, speech and handwriting recognition, computer vision and natural language processing, time series forecasting, and search engines. However, theoretical development of deep learning is still at its infancy. The objective of this paper is to introduce a deep neural network (also called deep-net) approach to localized manifold learning, with each hidden layer endowed with a specific learning task. For the purpose of illustrations, we only focus on deep-nets with three hidden layers, with the first layer for dimensionality reduction, the second layer for bias reduction, and the third layer for variance reduction. A feedback component also designed to eliminate outliers. The main theoretical result in this paper is the order $\mathcal O\left(m^{-2s/(2s+d)}\right)$ of approximation of the regression function with regularity $s$, in terms of the number $m$ of sample points, where the (unknown) manifold dimension $d$ replaces the dimension $D$ of the sampling (Euclidean) space for shallow nets.","Fri, 9 Mar 2018 13:28:01 UTC (20 KB)"
"839","TicTac: Accelerating Distributed Deep Learning with Communication Scheduling","Sayed Hadi Hashemi, Sangeetha Abdu Jyothi, Roy H. Campbell","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Performance (cs.PF)","State-of-the-art deep learning systems rely on iterative distributed training to tackle the increasing complexity of models and input data. The iteration time in these communication-heavy systems depends on the computation time, communication time and the extent of overlap of computation and communication. In this work, we identify a shortcoming in systems with graph representation for computation, such as TensorFlow and PyTorch, that result in high variance in iteration time --- random order of received parameters across workers. We develop a system, TicTac, to improve the iteration time by fixing this issue in distributed deep learning with Parameter Servers while guaranteeing near-optimal overlap of communication and computation. TicTac identifies and enforces an order of network transfers which improves the iteration time using prioritization. Our system is implemented over TensorFlow and requires no changes to the model or developer inputs. TicTac improves the throughput by up to $37.7\%$ in inference and $19.2\%$ in training, while also reducing straggler effect by up to $2.3\times$. Our code is publicly available.","Thu, 8 Mar 2018 20:03:51 UTC (432 KB)[v2] Thu, 4 Oct 2018 00:38:36 UTC (242 KB)"
"840","GONet: A Semi-Supervised Deep Learning Approach For Traversability Estimation","Noriaki Hirose, Amir Sadeghian, Marynel Vazquez, Patrick Goebel, Silvio Savarese","Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","We present semi-supervised deep learning approaches for traversability estimation from fisheye images. Our method, GONet, and the proposed extensions leverage Generative Adversarial Networks (GANs) to effectively predict whether the area seen in the input image(s) is safe for a robot to traverse. These methods are trained with many positive images of traversable places, but just a small set of negative images depicting blocked and unsafe areas. This makes the proposed methods practical. Positive examples can be collected easily by simply operating a robot through traversable spaces, while obtaining negative examples is time consuming, costly, and potentially dangerous. Through extensive experiments and several demonstrations, we show that the proposed traversability estimation approaches are robust and can generalize to unseen scenarios. Further, we demonstrate that our methods are memory efficient and fast, allowing for real-time operation on a mobile robot with single or stereo fisheye cameras. As part of our contributions, we open-source two new datasets for traversability estimation. These datasets are composed of approximately 24h of videos from more than 25 indoor environments. Our methods outperform baseline approaches for traversability estimation on these new datasets.","Thu, 8 Mar 2018 18:52:03 UTC (2,868 KB)"
"841","Deep Learning: A Tool for Computational Nuclear Physics","Gianina Alina Negoita, Glenn R. Luecke, James P. Vary, Pieter Maris, Andrey M. Shirokov, Ik Jae Shin, Youngman Kim, Esmond G. Ng, Chao Yang","Computational Physics (physics.comp-ph); Nuclear Theory (nucl-th)","In recent years, several successful applications of the Artificial Neural Networks (ANNs) have emerged in nuclear physics and high-energy physics, as well as in biology, chemistry, meteorology, and other fields of science. A major goal of nuclear theory is to predict nuclear structure and nuclear reactions from the underlying theory of the strong interactions, Quantum Chromodynamics (QCD). With access to powerful High Performance Computing (HPC) systems, several ab initio approaches, such as the No-Core Shell Model (NCSM), have been developed to calculate the properties of atomic nuclei. However, to accurately solve for the properties of atomic nuclei, one faces immense theoretical and computational challenges. The present study proposes a feed-forward ANN method for predicting the properties of atomic nuclei like ground state energy and ground state point proton root-mean-square (rms) radius based on NCSM results in computationally accessible basis spaces. The designed ANNs are sufficient to produce results for these two very different observables in 6Li from the ab initio NCSM results in small basis spaces that satisfy the theoretical physics condition: independence of basis space parameters in the limit of extremely large matrices. We also provide comparisons of the results from ANNs with established methods of estimating the results in the infinite matrix limit.","Thu, 8 Mar 2018 17:34:19 UTC (584 KB)"
"842","Generating Artificial Data for Private Deep Learning","Aleksei Triastcyn, Boi Faltings","Machine Learning (cs.LG); Cryptography and Security (cs.CR); Machine Learning (stat.ML)","In this paper, we propose generating artificial data that retain statistical properties of real data as the means of providing privacy with respect to the original dataset. We use generative adversarial network to draw privacy-preserving artificial data samples and derive an empirical method to assess the risk of information disclosure in a differential-privacy-like way. Our experiments show that we are able to generate artificial data of high quality and successfully train and validate machine learning models on this data while limiting potential privacy loss.","Thu, 8 Mar 2018 15:22:37 UTC (757 KB)[v2] Thu, 7 Jun 2018 20:27:22 UTC (840 KB)"
"843","Applying Deep Learning to Fast Radio Burst Classification","Liam Connor, Joeri van Leeuwen","Instrumentation and Methods for Astrophysics (astro-ph.IM); High Energy Astrophysical Phenomena (astro-ph.HE)","Upcoming Fast Radio Burst (FRB) surveys will search $\sim$10\,$^3$ beams on sky with very high duty cycle, generating large numbers of single-pulse candidates. The abundance of false positives presents an intractable problem if candidates are to be inspected by eye, making it a good application for artificial intelligence (AI). We apply deep learning to single pulse classification and develop a hierarchical framework for ranking events by their probability of being true astrophysical transients. We construct a tree-like deep neural network (DNN) that takes multiple or individual data products as input (e.g. dynamic spectra and multi-beam detection information) and trains on them simultaneously. We have built training and test sets using false-positive triggers from real telescopes, along with simulated FRBs, and single pulses from pulsars. Training of the DNN was independently done for two radio telescopes: the CHIME Pathfinder, and Apertif on Westerbork. High accuracy and recall can be achieved with a labelled training set of a few thousand events. Even with high triggering rates, classification can be done very quickly on Graphical Processing Units (GPUs). That speed is essential for selective voltage dumps or issuing real-time VOEvents. Next, we investigate whether dedispersion back-ends could be completely replaced by a real-time DNN classifier. It is shown that a single forward propagation through a moderate convolutional network could be faster than brute-force dedispersion; but the low signal-to-noise per pixel makes such a classifier sub-optimal for this problem. Real-time automated classification may prove useful for bright, unexpected signals, both now and in the era of radio astronomy when data volumes and the searchable parameter spaces further outgrow our ability to manually inspect the data, such as for SKA and ngVLA.","Thu, 8 Mar 2018 13:42:15 UTC (3,453 KB)"
"844","A Deep Learning Algorithm for One-step Contour Aware Nuclei Segmentation of Histopathological Images","Yuxin Cui, Guiying Zhang, Zhonghao Liu, Zheng Xiong, Jianjun Hu","Computer Vision and Pattern Recognition (cs.CV)","This paper addresses the task of nuclei segmentation in high-resolution histopathological images. We propose an auto- matic end-to-end deep neural network algorithm for segmenta- tion of individual nuclei. A nucleus-boundary model is introduced to predict nuclei and their boundaries simultaneously using a fully convolutional neural network. Given a color normalized image, the model directly outputs an estimated nuclei map and a boundary map. A simple, fast and parameter-free post-processing procedure is performed on the estimated nuclei map to produce the final segmented nuclei. An overlapped patch extraction and assembling method is also designed for seamless prediction of nuclei in large whole-slide images. We also show the effectiveness of data augmentation methods for nuclei segmentation task. Our experiments showed our method outperforms prior state-of-the- art methods. Moreover, it is efficient that one 1000X1000 image can be segmented in less than 5 seconds. This makes it possible to precisely segment the whole-slide image in acceptable time","Wed, 7 Mar 2018 17:53:20 UTC (8,471 KB)"
"845","Exponential Discriminative Metric Embedding in Deep Learning","Bowen Wu, Zhangling Chen, Jun Wang, Huaming Wu","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","With the remarkable success achieved by the Convolutional Neural Networks (CNNs) in object recognition recently, deep learning is being widely used in the computer vision community. Deep Metric Learning (DML), integrating deep learning with conventional metric learning, has set new records in many fields, especially in classification task. In this paper, we propose a replicable DML method, called Include and Exclude (IE) loss, to force the distance between a sample and its designated class center away from the mean distance of this sample to other class centers with a large margin in the exponential feature projection space. With the supervision of IE loss, we can train CNNs to enhance the intra-class compactness and inter-class separability, leading to great improvements on several public datasets ranging from object recognition to face verification. We conduct a comparative study of our algorithm with several typical DML methods on three kinds of networks with different capacity. Extensive experiments on three object recognition datasets and two face recognition datasets demonstrate that IE loss is always superior to other mainstream DML methods and approach the state-of-the-art results.","Wed, 7 Mar 2018 02:39:34 UTC (662 KB)"
"846","Comparison of Deep Learning Approaches for Multi-Label Chest X-Ray Classification","Ivo M. Baltruschat, Hannes Nickisch, Michael Grass, Tobias Knopp, Axel Saalbach","Computer Vision and Pattern Recognition (cs.CV)","The increased availability of X-ray image archives (e.g. the ChestX-ray14 dataset from the NIH Clinical Center) has triggered a growing interest in deep learning techniques. To provide better insight into the different approaches, and their applications to chest X-ray classification, we investigate a powerful network architecture in detail: the ResNet-50. Building on prior work in this domain, we consider transfer learning with and without fine-tuning as well as the training of a dedicated X-ray network from scratch. To leverage the high spatial resolutions of X-ray data, we also include an extended ResNet-50 architecture, and a network integrating non-image data (patient age, gender and acquisition type) in the classification process. In a systematic evaluation, using 5-fold re-sampling and a multi-label loss function, we evaluate the performance of the different approaches for pathology classification by ROC statistics and analyze differences between the classifiers using rank correlation. We observe a considerable spread in the achieved performance and conclude that the X-ray-specific ResNet-50, integrating non-image data yields the best overall results.","Tue, 6 Mar 2018 18:04:25 UTC (1,822 KB)"
"847","Deep Thermal Imaging: Proximate Material Type Recognition in the Wild through Deep Learning of Spatial Surface Temperature Patterns","Youngjun Cho, Nadia Bianchi-Berthouze, Nicolai Marquardt, Simon J. Julier","Computer Vision and Pattern Recognition (cs.CV); Materials Science (cond-mat.mtrl-sci); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)","We introduce Deep Thermal Imaging, a new approach for close-range automatic recognition of materials to enhance the understanding of people and ubiquitous technologies of their proximal environment. Our approach uses a low-cost mobile thermal camera integrated into a smartphone to capture thermal textures. A deep neural network classifies these textures into material types. This approach works effectively without the need for ambient light sources or direct contact with materials. Furthermore, the use of a deep learning network removes the need to handcraft the set of features for different materials. We evaluated the performance of the system by training it to recognise 32 material types in both indoor and outdoor environments. Our approach produced recognition accuracies above 98% in 14,860 images of 15 indoor materials and above 89% in 26,584 images of 17 outdoor materials. We conclude by discussing its potentials for real-time use in HCI applications and future directions.","Tue, 6 Mar 2018 17:29:08 UTC (1,471 KB)"
"848","Lunar Crater Identification via Deep Learning","Ari Silburt, Mohamad Ali-Dib, Chenchong Zhu, Alan Jackson, Diana Valencia, Yevgeni Kissin, Daniel Tamayo, Kristen Menou","Earth and Planetary Astrophysics (astro-ph.EP)","Crater counting on the Moon and other bodies is crucial to constrain the dynamical history of the Solar System. This has traditionally been done by visual inspection of images, thus limiting the scope, efficiency, and/or accuracy of retrieval. In this paper we demonstrate the viability of using convolutional neural networks (CNNs) to determine the positions and sizes of craters from Lunar digital elevation maps (DEMs). We recover 92% of craters from the human-generated test set and almost double the total number of crater detections. Of these new craters, 15% are smaller in diameter than the minimum crater size in the ground-truth dataset. Our median fractional longitude, latitude and radius errors are 11% or less, representing good agreement with the human-generated datasets. From a manual inspection of 361 new craters we estimate the false positive rate of new craters to be 11%. Moreover, our Moon-trained CNN performs well when tested on DEM images of Mercury, detecting a large fraction of craters in each map. Our results suggest that deep learning will be a useful tool for rapidly and automatically extracting craters on various Solar System bodies. We make our code and data publicly available at this https URL and this https URL .","Tue, 6 Mar 2018 14:13:41 UTC (1,405 KB)[v2] Tue, 17 Jul 2018 15:07:38 UTC (4,917 KB)[v3] Mon, 12 Nov 2018 11:09:40 UTC (4,917 KB)"
"849","A Hybrid Method for Traffic Flow Forecasting Using Multimodal Deep Learning","Shengdong Du, Tianrui Li, Xun Gong, Zeng Yu, Yanyong Huang, Shi-Jinn Horng","Machine Learning (cs.LG); Systems and Control (cs.SY)","Traffic flow forecasting has been regarded as a key problem of intelligent transport systems. In this work, we propose a hybrid multimodal deep learning method for short-term traffic flow forecasting, which can jointly and adaptively learn the spatial-temporal correlation features and long temporal interdependence of multi-modality traffic data by an attention auxiliary multimodal deep learning architecture. According to the highly nonlinear characteristics of multi-modality traffic data, the base module of our method consists of one-dimensional Convolutional Neural Networks (1D CNN) and Gated Recurrent Units (GRU) with the attention mechanism. The former is to capture the local trend features and the latter is to capture the long temporal dependencies. Then, we design a hybrid multimodal deep learning framework (HMDLF) for fusing share representation features of different modality traffic data by multiple CNN-GRU-Attention modules. The experimental results indicate that the proposed multimodal deep learning model is capable of dealing with complex nonlinear urban traffic flow forecasting with satisfying accuracy and effectiveness.","Tue, 6 Mar 2018 10:39:47 UTC (1,262 KB)[v2] Fri, 6 Jul 2018 09:44:49 UTC (1,262 KB)[v3] Mon, 19 Nov 2018 10:42:38 UTC (1,714 KB)"
"850","Online Deep Learning: Growing RBM on the fly","Savitha Ramasamy, Kanagasabai Rajaraman, Pavitra Krishnaswamy, Vijay Chandrasekhar","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG); Machine Learning (stat.ML)","We propose a novel online learning algorithm for Restricted Boltzmann Machines (RBM), namely, the Online Generative Discriminative Restricted Boltzmann Machine (OGD-RBM), that provides the ability to build and adapt the network architecture of RBM according to the statistics of streaming data. The OGD-RBM is trained in two phases: (1) an online generative phase for unsupervised feature representation at the hidden layer and (2) a discriminative phase for classification. The online generative training begins with zero neurons in the hidden layer, adds and updates the neurons to adapt to statistics of streaming data in a single pass unsupervised manner, resulting in a feature representation best suited to the data. The discriminative phase is based on stochastic gradient descent and associates the represented features to the class labels. We demonstrate the OGD-RBM on a set of multi-category and binary classification problems for data sets having varying degrees of class-imbalance. We first apply the OGD-RBM algorithm on the multi-class MNIST dataset to characterize the network evolution. We demonstrate that the online generative phase converges to a stable, concise network architecture, wherein individual neurons are inherently discriminative to the class labels despite unsupervised training. We then benchmark OGD-RBM performance to other machine learning, neural network and ClassRBM techniques for credit scoring applications using 3 public non-stationary two-class credit datasets with varying degrees of class-imbalance. We report that OGD-RBM improves accuracy by 2.5-3% over batch learning techniques while requiring at least 24%-70% fewer neurons and fewer training samples. This online generative training approach can be extended greedily to multiple layers for training Deep Belief Networks in non-stationary data mining applications without the need for a priori fixed architectures.","Tue, 6 Mar 2018 07:24:21 UTC (204 KB)"
"851","M3Fusion: A Deep Learning Architecture for Multi-{Scale/Modal/Temporal} satellite data fusion","P. Benedetti, D. Ienco, R. Gaetano, K. Ose, R. Pensa, S. Dupuy","Computer Vision and Pattern Recognition (cs.CV)","Modern Earth Observation systems provide sensing data at different temporal and spatial resolutions. Among optical sensors, today the Sentinel-2 program supplies high-resolution temporal (every 5 days) and high spatial resolution (10m) images that can be useful to monitor land cover dynamics. On the other hand, Very High Spatial Resolution images (VHSR) are still an essential tool to figure out land cover mapping characterized by fine spatial patterns. Understand how to efficiently leverage these complementary sources of information together to deal with land cover mapping is still challenging. With the aim to tackle land cover mapping through the fusion of multi-temporal High Spatial Resolution and Very High Spatial Resolution satellite images, we propose an End-to-End Deep Learning framework, named M3Fusion, able to leverage simultaneously the temporal knowledge contained in time series data as well as the fine spatial information available in VHSR information. Experiments carried out on the Reunion Island study area asses the quality of our proposal considering both quantitative and qualitative aspects.","Mon, 5 Mar 2018 21:59:42 UTC (8,229 KB)"
"852","Resampling Forgery Detection Using Deep Learning and A-Contrario Analysis","Arjuna Flenner, Lawrence Peterson, Jason Bunk, Tajuddin Manhar Mohammed, Lakshmanan Nataraj, B.S. Manjunath","Computer Vision and Pattern Recognition (cs.CV)","The amount of digital imagery recorded has recently grown exponentially, and with the advancement of software, such as Photoshop or Gimp, it has become easier to manipulate images. However, most images on the internet have not been manipulated and any automated manipulation detection algorithm must carefully control the false alarm rate. In this paper we discuss a method to automatically detect local resampling using deep learning while controlling the false alarm rate using a-contrario analysis. The automated procedure consists of three primary steps. First, resampling features are calculated for image blocks. A deep learning classifier is then used to generate a heatmap that indicates if the image block has been resampled. We expect some of these blocks to be falsely identified as resampled. We use a-contrario hypothesis testing to both identify if the patterns of the manipulated blocks indicate if the image has been tampered with and to localize the manipulation. We demonstrate that this strategy is effective in indicating if an image has been manipulated and localizing the manipulations.","Thu, 1 Mar 2018 21:59:04 UTC (2,242 KB)"
"853","Deep-Learning in Search of Light Charged Higgs","Guleser. K. Demir, Nasuf Sonmez, Hatice Dogan","High Energy Physics - Phenomenology (hep-ph)","In this work, we deep-learn light charged Higgs signal in top quark decays which poses difficulties due to strong W boson contamination. We construct Deep Neural Networks (DNN) with appropriate architecture and determine signal extraction efficiency by considering various features (kinematical and human engineered parameters). Results show that DNN gives better performance than the classical neural networks and has ability to find regions of high efficiency even the input features are not human-engineered. In a sense, human-engineered high-level features are offset by DNNs with different combinations of the low-level kinematical features. Additionally, it is shown that increasing the number of processing units in DNNs does not necessarily cause an increase in efficiency due mainly to increased complexity. Our method and results can set an example of signal extraction from strong backgrounds.","Mon, 5 Mar 2018 08:15:02 UTC (1,113 KB)"
"854","Data Curation with Deep Learning [Vision]: Towards Self Driving Data Curation","Saravanan Thirumuruganathan, Nan Tang, Mourad Ouzzani","Databases (cs.DB)","Past. Data curation - the process of discovering, integrating, and cleaning data - is one of the oldest data management problems. Unfortunately, it is still the most time consuming and least enjoyable work of data scientists. So far, successful data curation stories are mainly ad-hoc solutions that are either domain-specific (for example, ETL rules) or task-specific (for example, entity resolution). Present. The power of current data curation solutions are not keeping up with the ever changing data ecosystem in terms of volume, velocity, variety and veracity, mainly due to the high human cost, instead of machine cost, needed for providing the ad-hoc solutions mentioned above. Meanwhile, deep learning is making strides in achieving remarkable successes in areas such as image recognition, natural language processing, and speech recognition. This is largely due to its ability to understanding features that are neither domain-specific nor task-specific. Future. Data curation solutions need to keep the pace with the fast-changing data ecosystem, where the main hope is to devise domain-agnostic and task-agnostic solutions. To this end, we start a new research project, called AutoDC, to unleash the potential of deep learning towards self-driving data curation. We will discuss how different deep learning concepts can be adapted and extended to solve various data curation problems. We showcase some low-hanging fruits about the early encounters between deep learning and data curation happening in AutoDC. We believe that the directions pointed out by this work will not only drive AutoDC towards democratizing data curation, but also serve as a cornerstone for researchers and practitioners to move to a new realm of data curation solutions.","Sun, 4 Mar 2018 17:08:45 UTC (282 KB)"
"855","Training deep learning based denoisers without ground truth data","Shakarim Soltanayev, Se Young Chun","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Recent deep learning based denoisers often outperform state-of-the-art conventional denoisers such as BM3D. They are typically trained to minimize the mean squared error (MSE) between the output of a deep neural network and the ground truth image. In deep learning based denoisers, it is important to use high quality noiseless ground truth for high performance, but it is often challenging or even infeasible to obtain such a clean image in application areas such as hyperspectral remote sensing and medical imaging. We propose a Stein's Unbiased Risk Estimator (SURE) based method for training deep neural network denoisers only with noisy images. We demonstrated that our SURE based method without ground truth was able to train deep neural network denoisers to yield performance close to deep learning denoisers trained with ground truth and to outperform state-of-the-art BM3D. Further improvements were achieved by including noisy test images for training denoiser networks using our proposed SURE based method.","Sun, 4 Mar 2018 07:55:40 UTC (3,277 KB)[v2] Wed, 23 May 2018 08:23:32 UTC (1,369 KB)"
"856","An Optimal Control Approach to Deep Learning and Applications to Discrete-Weight Neural Networks","Qianxiao Li, Shuji Hao","Machine Learning (cs.LG)","Deep learning is formulated as a discrete-time optimal control problem. This allows one to characterize necessary conditions for optimality and develop training algorithms that do not rely on gradients with respect to the trainable parameters. In particular, we introduce the discrete-time method of successive approximations (MSA), which is based on the Pontryagin's maximum principle, for training neural networks. A rigorous error estimate for the discrete MSA is obtained, which sheds light on its dynamics and the means to stabilize the algorithm. The developed methods are applied to train, in a rather principled way, neural networks with weights that are constrained to take values in a discrete set. We obtain competitive performance and interestingly, very sparse weights in the case of ternary networks, which may be useful in model deployment in low-memory devices.","Sun, 4 Mar 2018 04:37:49 UTC (1,130 KB)[v2] Sat, 2 Jun 2018 08:40:52 UTC (1,174 KB)"
"857","Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction","Huaxiu Yao, Xianfeng Tang, Hua Wei, Guanjie Zheng, Zhenhui Li","Machine Learning (cs.LG)","Traffic prediction has drawn increasing attention in AI research field due to the increasing availability of large-scale traffic data and its importance in the real world. For example, an accurate taxi demand prediction can assist taxi companies in pre-allocating taxis. The key challenge of traffic prediction lies in how to model the complex spatial dependencies and temporal dynamics. Although both factors have been considered in modeling, existing works make strong assumptions about spatial dependence and temporal dynamics, i.e., spatial dependence is stationary in time, and temporal dynamics is strictly periodical. However, in practice, the spatial dependence could be dynamic (i.e., changing from time to time), and the temporal dynamics could have some perturbation from one period to another period. In this paper, we make two important observations: (1) the spatial dependencies between locations are dynamic; and (2) the temporal dependency follows daily and weekly pattern but it is not strictly periodic for its dynamic temporal shifting. To address these two issues, we propose a novel Spatial-Temporal Dynamic Network (STDN), in which a flow gating mechanism is introduced to learn the dynamic similarity between locations, and a periodically shifted attention mechanism is designed to handle long-term periodic temporal shifting. To the best of our knowledge, this is the first work that tackles both issues in a unified framework. Our experimental results on real-world traffic datasets verify the effectiveness of the proposed method.","Sat, 3 Mar 2018 22:38:56 UTC (543 KB)[v2] Sat, 3 Nov 2018 23:45:42 UTC (650 KB)"
"858","A Benchmark for Iris Location and a Deep Learning Detector Evaluation","Evair Severo, Rayson Laroca, Cides S. Bezerra, Luiz A. Zanlorensi, Daniel Weingaertner, Gladston Moreira, David Menotti","Computer Vision and Pattern Recognition (cs.CV)","The iris is considered as the biometric trait with the highest unique probability. The iris location is an important task for biometrics systems, affecting directly the results obtained in specific applications such as iris recognition, spoofing and contact lenses detection, among others. This work defines the iris location problem as the delimitation of the smallest squared window that encompasses the iris region. In order to build a benchmark for iris location we annotate (iris squared bounding boxes) four databases from different biometric applications and make them publicly available to the community. Besides these 4 annotated databases, we include 2 others from the literature. We perform experiments on these six databases, five obtained with near infra-red sensors and one with visible light sensor. We compare the classical and outstanding Daugman iris location approach with two window based detectors: 1) a sliding window detector based on features from Histogram of Oriented Gradients (HOG) and a linear Support Vector Machines (SVM) classifier; 2) a deep learning based detector fine-tuned from YOLO object detector. Experimental results showed that the deep learning based detector outperforms the other ones in terms of accuracy and runtime (GPUs version) and should be chosen whenever possible.","Sat, 3 Mar 2018 22:08:30 UTC (4,493 KB)[v2] Thu, 15 Mar 2018 16:58:26 UTC (4,493 KB)[v3] Fri, 13 Apr 2018 02:57:24 UTC (5,521 KB)[v4] Mon, 16 Apr 2018 05:15:50 UTC (5,510 KB)[v5] Mon, 30 Apr 2018 05:02:39 UTC (3,022 KB)"
"859","Automatic Instrument Segmentation in Robot-Assisted Surgery Using Deep Learning","Alexey Shvets, Alexander Rakhlin, Alexandr A. Kalinin, Vladimir Iglovikov","Computer Vision and Pattern Recognition (cs.CV)","Semantic segmentation of robotic instruments is an important problem for the robot-assisted surgery. One of the main challenges is to correctly detect an instrument's position for the tracking and pose estimation in the vicinity of surgical scenes. Accurate pixel-wise instrument segmentation is needed to address this challenge. In this paper we describe our winning solution for MICCAI 2017 Endoscopic Vision SubChallenge: Robotic Instrument Segmentation. Our approach demonstrates an improvement over the state-of-the-art results using several novel deep neural network architectures. It addressed the binary segmentation problem, where every pixel in an image is labeled as an instrument or background from the surgery video feed. In addition, we solve a multi-class segmentation problem, where we distinguish different instruments or different parts of an instrument from the background. In this setting, our approach outperforms other methods in every task subcategory for automatic instrument segmentation thereby providing state-of-the-art solution for this problem. The source code for our solution is made publicly available at this https URL","Sat, 3 Mar 2018 17:41:55 UTC (2,276 KB)[v2] Tue, 19 Jun 2018 19:50:47 UTC (5,544 KB)"
"860","Chest X-Ray Analysis of Tuberculosis by Deep Learning with Segmentation and Augmentation","Sergii Stirenko, Yuriy Kochura, Oleg Alienin, Oleksandr Rokovyi, Peng Gang, Wei Zeng, Yuri Gordienko","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)","The results of chest X-ray (CXR) analysis of 2D images to get the statistically reliable predictions (availability of tuberculosis) by computer-aided diagnosis (CADx) on the basis of deep learning are presented. They demonstrate the efficiency of lung segmentation, lossless and lossy data augmentation for CADx of tuberculosis by deep convolutional neural network (CNN) applied to the small and not well-balanced dataset even. CNN demonstrates ability to train (despite overfitting) on the pre-processed dataset obtained after lung segmentation in contrast to the original not-segmented dataset. Lossless data augmentation of the segmented dataset leads to the lowest validation loss (without overfitting) and nearly the same accuracy (within the limits of standard deviation) in comparison to the original and other pre-processed datasets after lossy data augmentation. The additional limited lossy data augmentation results in the lower validation loss, but with a decrease of the validation accuracy. In conclusion, besides the more complex deep CNNs and bigger datasets, the better progress of CADx for the small and not well-balanced datasets even could be obtained by better segmentation, data augmentation, dataset stratification, and exclusion of non-evident outliers.","Sat, 3 Mar 2018 16:42:19 UTC (981 KB)"
"861","The History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches","Md Zahangir Alom, Tarek M. Taha, Christopher Yakopcic, Stefan Westberg, Paheding Sidike, Mst Shamima Nasrin, Brian C Van Esesn, Abdul A S. Awwal, Vijayan K. Asari","Computer Vision and Pattern Recognition (cs.CV)","Deep learning has demonstrated tremendous success in variety of application domains in the past few years. This new field of machine learning has been growing rapidly and applied in most of the application domains with some new modalities of applications, which helps to open new opportunity. There are different methods have been proposed on different category of learning approaches, which includes supervised, semi-supervised and un-supervised learning. The experimental results show state-of-the-art performance of deep learning over traditional machine learning approaches in the field of Image Processing, Computer Vision, Speech Recognition, Machine Translation, Art, Medical imaging, Medical information processing, Robotics and control, Bio-informatics, Natural Language Processing (NLP), Cyber security, and many more. This report presents a brief survey on development of DL approaches, including Deep Neural Network (DNN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) including Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). In addition, we have included recent development of proposed advanced variant DL techniques based on the mentioned DL approaches. Furthermore, DL approaches have explored and evaluated in different application domains are also included in this survey. We have also comprised recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys have published on Deep Learning in Neural Networks [1, 38] and a survey on RL [234]. However, those papers have not discussed the individual advanced techniques for training large scale deep learning models and the recently developed method of generative models [1].","Sat, 3 Mar 2018 13:46:40 UTC (2,757 KB)[v2] Wed, 12 Sep 2018 15:57:23 UTC (2,875 KB)"
"862","Real-Time Deep Learning Method for Abandoned Luggage Detection in Video","Sorina Smeureanu, Radu Tudor Ionescu","Computer Vision and Pattern Recognition (cs.CV)","Recent terrorist attacks in major cities around the world have brought many casualties among innocent citizens. One potential threat is represented by abandoned luggage items (that could contain bombs or biological warfare) in public areas. In this paper, we describe an approach for real-time automatic detection of abandoned luggage in video captured by surveillance cameras. The approach is comprised of two stages: (i) static object detection based on background subtraction and motion estimation and (ii) abandoned luggage recognition based on a cascade of convolutional neural networks (CNN). To train our neural networks we provide two types of examples: images collected from the Internet and realistic examples generated by imposing various suitcases and bags over the scene's background. We present empirical results demonstrating that our approach yields better performance than a strong CNN baseline method.","Sat, 3 Mar 2018 13:30:06 UTC (8,063 KB)[v2] Tue, 22 May 2018 16:57:43 UTC (8,063 KB)[v3] Fri, 15 Jun 2018 15:01:43 UTC (8,063 KB)"
"863","Not All Samples Are Created Equal: Deep Learning with Importance Sampling","Angelos Katharopoulos, Francois Fleuret","Machine Learning (cs.LG)","Deep neural network training spends most of the computation on examples that are properly handled, and could be ignored. We propose to mitigate this phenomenon with a principled importance sampling scheme that focuses computation on ""informative"" examples, and reduces the variance of the stochastic gradients during training. Our contribution is twofold: first, we derive a tractable upper bound to the per-sample gradient norm, and second we derive an estimator of the variance reduction achieved with importance sampling, which enables us to switch it on when it will result in an actual speedup. The resulting scheme can be used by changing a few lines of code in a standard SGD procedure, and we demonstrate experimentally, on image classification, CNN fine-tuning, and RNN training, that for a fixed wall-clock time budget, it provides a reduction of the train losses of up to an order of magnitude and a relative improvement of test errors between 5% and 17%.","Fri, 2 Mar 2018 16:40:43 UTC (1,419 KB)[v2] Sat, 9 Jun 2018 20:03:25 UTC (1,831 KB)"
"864","Deep Learning for Signal Authentication and Security in Massive Internet of Things Systems","Aidin Ferdowsi, Walid Saad","Cryptography and Security (cs.CR); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)","Secure signal authentication is arguably one of the most challenging problems in the Internet of Things (IoT) environment, due to the large-scale nature of the system and its susceptibility to man-in-the-middle and eavesdropping attacks. In this paper, a novel deep learning method is proposed for dynamic authentication of IoT signals to detect cyber attacks. The proposed learning framework, based on a long short-term memory (LSTM) structure, enables the IoT devices (IoTDs) to extract a set of stochastic features from their generated signal and dynamically watermark these features into the signal. This method enables the cloud, which collects signals from the IoT devices, to effectively authenticate the reliability of the signals. Moreover, in massive IoT scenarios, since the cloud cannot authenticate all the IoTDs simultaneously due to computational limitations, a game-theoretic framework is proposed to improve the cloud's decision making process by predicting vulnerable IoTDs. The mixed-strategy Nash equilibrium (MSNE) for this game is derived and the uniqueness of the expected utility at the equilibrium is proven. In the massive IoT system, due to a large set of available actions for the cloud, it is shown that analytically deriving the MSNE is challenging and, thus, a learning algorithm proposed that converges to the MSNE. Moreover, in order to cope with the incomplete information case in which the cloud cannot access the state of the unauthenticated IoTDs, a deep reinforcement learning algorithm is proposed to dynamically predict the state of unauthenticated IoTDs and allow the cloud to decide on which IoTDs to authenticate. Simulation results show that, with an attack detection delay of under 1 second the messages can be transmitted from IoT devices with an almost 100% reliability.","Thu, 1 Mar 2018 04:07:13 UTC (3,202 KB)"
"865","Unravelling Robustness of Deep Learning based Face Recognition Against Adversarial Attacks","Gaurav Goswami, Nalini Ratha, Akshay Agarwal, Richa Singh, Mayank Vatsa","Computer Vision and Pattern Recognition (cs.CV)","Deep neural network (DNN) architecture based models have high expressive power and learning capacity. However, they are essentially a black box method since it is not easy to mathematically formulate the functions that are learned within its many layers of representation. Realizing this, many researchers have started to design methods to exploit the drawbacks of deep learning based algorithms questioning their robustness and exposing their singularities. In this paper, we attempt to unravel three aspects related to the robustness of DNNs for face recognition: (i) assessing the impact of deep architectures for face recognition in terms of vulnerabilities to attacks inspired by commonly observed distortions in the real world that are well handled by shallow learning methods along with learning based adversaries; (ii) detecting the singularities by characterizing abnormal filter response behavior in the hidden layers of deep networks; and (iii) making corrections to the processing pipeline to alleviate the problem. Our experimental evaluation using multiple open-source DNN-based face recognition networks, including OpenFace and VGG-Face, and two publicly available databases (MEDS and PaSC) demonstrates that the performance of deep learning based face recognition algorithms can suffer greatly in the presence of such distortions. The proposed method is also compared with existing detection algorithms and the results show that it is able to detect the attacks with very high accuracy by suitably designing a classifier using the response of the hidden layers in the network. Finally, we present several effective countermeasures to mitigate the impact of adversarial attacks and improve the overall robustness of DNN-based face recognition.","Thu, 22 Feb 2018 08:03:26 UTC (9,489 KB)"
"866","Detecting Volcano Deformation in InSAR using Deep learning","N. Anantrasirichai, F. Albino, P. Hill, D. Bull, J. Biggs","Computer Vision and Pattern Recognition (cs.CV)","Globally 800 million people live within 100 km of a volcano and currently 1500 volcanoes are considered active, but half of these have no ground-based monitoring. Alternatively, satellite radar (InSAR) can be employed to observe volcanic ground deformation, which has shown a significant statistical link to eruptions. Modern satellites provide large coverage with high resolution signals, leading to huge amounts of data. The explosion in data has brought major challenges associated with timely dissemination of information and distinguishing volcano deformation patterns from noise, which currently relies on manual inspection. Moreover, volcano observatories still lack expertise to exploit satellite datasets, particularly in developing countries. This paper presents a novel approach to detect volcanic ground deformation automatically from wrapped-phase InSAR images. Convolutional neural networks (CNN) are employed to detect unusual patterns within the radar data.","Sun, 21 Jan 2018 17:28:58 UTC (204 KB)"
"867","A Deep Learning Approach for Multimodal Deception Detection","Gangeshwar Krishnamurthy, Navonil Majumder, Soujanya Poria, Erik Cambria","Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)","Automatic deception detection is an important task that has gained momentum in computational linguistics due to its potential applications. In this paper, we propose a simple yet tough to beat multi-modal neural model for deception detection. By combining features from different modalities such as video, audio, and text along with Micro-Expression features, we show that detecting deception in real life videos can be more accurate. Experimental results on a dataset of real-life deception videos show that our model outperforms existing techniques for deception detection with an accuracy of 96.14% and ROC-AUC of 0.9799.","Thu, 1 Mar 2018 12:38:13 UTC (254 KB)"
"868","DRUNET: A Dilated-Residual U-Net Deep Learning Network to Digitally Stain Optic Nerve Head Tissues in Optical Coherence Tomography Images","Sripad Krishna Devalla, Prajwal K. Renukanand, Bharathwaj K. Sreedhar, Shamira Perera, Jean-Martial Mari, Khai Sing Chin, Tin A. Tun, Nicholas G. Strouthidis, Tin Aung, Alexandre H. Thiery, Michael J. A. Girard","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Given that the neural and connective tissues of the optic nerve head (ONH) exhibit complex morphological changes with the development and progression of glaucoma, their simultaneous isolation from optical coherence tomography (OCT) images may be of great interest for the clinical diagnosis and management of this pathology. A deep learning algorithm was designed and trained to digitally stain (i.e. highlight) 6 ONH tissue layers by capturing both the local (tissue texture) and contextual information (spatial arrangement of tissues). The overall dice coefficient (mean of all tissues) was $0.91 \pm 0.05$ when assessed against manual segmentations performed by an expert observer. We offer here a robust segmentation framework that could be extended for the automated parametric study of the ONH tissues.","Thu, 1 Mar 2018 06:37:30 UTC (4,695 KB)"
"869","Global Convergence in Deep Learning with Variable Splitting via the Kurdyka-┤ojasiewicz Property","Jinshan Zeng, Shikang Ouyang, Tim Tsz-Kit Lau, Shaobo Lin, Yuan Yao","Optimization and Control (math.OC); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning has recently attracted a significant amount of attention due to its great empirical success. However, the effectiveness in training deep neural networks (DNN) remains a mystery in the associated nonconvex optimizations. In this paper, we aim to provide some theoretical understanding on such optimization problems. In particular, the Kurdyka-┤ojasiewicz (KL) property is established for DNN training with variable splitting schemes, which leads to the global convergence of block coordinate descent (BCD) type algorithms to a critical point of objective functions under natural conditions of DNN. Some existing BCD algorithms can be viewed as special cases in this framework. Experiments further show that the proposed algorithms may find network parameters of approximately zero training loss (error) with over-parameterized models.","Thu, 1 Mar 2018 06:11:53 UTC (91 KB)[v2] Mon, 11 Jun 2018 08:46:46 UTC (92 KB)"
"870","Deep Learning for Causal Inference","Vikas Ramachandra","Econometrics (econ.EM); Machine Learning (cs.LG); Machine Learning (stat.ML)","In this paper, we propose deep learning techniques for econometrics, specifically for causal inference and for estimating individual as well as average treatment effects. The contribution of this paper is twofold: 1. For generalized neighbor matching to estimate individual and average treatment effects, we analyze the use of autoencoders for dimensionality reduction while maintaining the local neighborhood structure among the data points in the embedding space. This deep learning based technique is shown to perform better than simple k nearest neighbor matching for estimating treatment effects, especially when the data points have several features/covariates but reside in a low dimensional manifold in high dimensional space. We also observe better performance than manifold learning methods for neighbor matching. 2. Propensity score matching is one specific and popular way to perform matching in order to estimate average and individual treatment effects. We propose the use of deep neural networks (DNNs) for propensity score matching, and present a network called PropensityNet for this. This is a generalization of the logistic regression technique traditionally used to estimate propensity scores and we show empirically that DNNs perform better than logistic regression at propensity score matching. Code for both methods will be made available shortly on Github at: this https URL","Thu, 1 Mar 2018 01:01:16 UTC (686 KB)"
"871","Pulling Out All the Tops with Computer Vision and Deep Learning","Sebastian Macaluso, David Shih","High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Experiment (hep-ex)","We apply computer vision with deep learning -- in the form of a convolutional neural network (CNN) -- to build a highly effective boosted top tagger. Previous work (the ""DeepTop"" tagger of Kasieczka et al) has shown that a CNN-based top tagger can achieve comparable performance to state-of-the-art conventional top taggers based on high-level inputs. Here, we introduce a number of improvements to the DeepTop tagger, including architecture, training, image preprocessing, sample size and color pixels. Our final CNN top tagger outperforms BDTs based on high-level inputs by a factor of $\sim 2$--3 or more in background rejection, over a wide range of tagging efficiencies and fiducial jet selections. As reference points, we achieve a QCD background rejection factor of 500 (60) at 50\% top tagging efficiency for fully-merged (non-merged) top jets with $p_T$ in the 800--900 GeV (350--450 GeV) range. Our CNN can also be straightforwardly extended to the classification of other types of jets, and the lessons learned here may be useful to others designing their own deep NNs for LHC applications.","Wed, 28 Feb 2018 22:02:11 UTC (850 KB)"
"872","Using Deep Learning for Segmentation and Counting within Microscopy Data","Carlos X. Hernandez, Mohammad M. Sultan, Vijay S. Pande","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)","Cell counting is a ubiquitous, yet tedious task that would greatly benefit from automation. From basic biological questions to clinical trials, cell counts provide key quantitative feedback that drive research. Unfortunately, cell counting is most commonly a manual task and can be time-intensive. The task is made even more difficult due to overlapping cells, existence of multiple focal planes, and poor imaging quality, among other factors. Here, we describe a convolutional neural network approach, using a recently described feature pyramid network combined with a VGG-style neural network, for segmenting and subsequent counting of cells in a given microscopy image.","Wed, 28 Feb 2018 17:31:16 UTC (1,027 KB)"
"873","Mapping mesoscopic phase evolution during e-beam induced transformations via deep learning of atomically resolved images","Rama K. Vasudevan, Nouamane Laanait, Erik M. Ferragut, Kai Wang, David B. Geohegan, Kai Xiao, Maxim A. Ziatdinov, Stephen Jesse, Ondrej E. Dyck, Sergei V. Kalinin","Materials Science (cond-mat.mtrl-sci)","Understanding transformations under electron beam irradiation requires mapping the structural phases and their evolution in real time. To date, this has mostly been a manual endeavor comprising of difficult frame-by-frame analysis that is simultaneously tedious and prone to error. Here, we turn towards the use of deep convolutional neural networks (DCNN) to automatically determine the Bravais lattice symmetry present in atomically-resolved images. A DCNN is trained to identify the Bravais lattice class given a 2D fast Fourier transform of the input image. Monte-Carlo dropout is used for determining the prediction probability, and results are shown for both simulated and real atomically-resolved images from scanning tunneling microscopy and scanning transmission electron microscopy. A reduced representation of the final layer output allows to visualize the separation of classes in the DCNN and agrees with physical intuition. We then apply the trained network to electron beam-induced transformations in WS2, which allows tracking and determination of growth rate of voids. These results are novel in two ways: (1) It shows that DCNNs can be trained to recognize diffraction patterns, which is markedly different from the typical ""real image"" cases, and (2) it provides a method with in-built uncertainty quantification, allowing the real-time analysis of phases present in atomically resolved images.","Wed, 28 Feb 2018 16:27:35 UTC (1,141 KB)"
"874","DeepSOFA: A Continuous Acuity Score for Critically Ill Patients using Clinically Interpretable Deep Learning","Benjamin Shickel, Tyler J. Loftus, Lasith Adhikari, Tezcan Ozrazgat-Baslanti, Azra Bihorac, Parisa Rashidi","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Applications (stat.AP); Machine Learning (stat.ML)","Traditional methods for assessing illness severity and predicting in-hospital mortality among critically ill patients require time-consuming, error-prone calculations using static variable thresholds. These methods do not capitalize on the emerging availability of streaming electronic health record data or capture time-sensitive individual physiological patterns, a critical task in the intensive care unit. We propose a novel acuity score framework (DeepSOFA) that leverages temporal measurements and interpretable deep learning models to assess illness severity at any point during an ICU stay. We compare DeepSOFA with SOFA (Sequential Organ Failure Assessment) baseline models using the same model inputs and find that at any point during an ICU admission, DeepSOFA yields significantly more accurate predictions of in-hospital mortality. A DeepSOFA model developed in a public database and validated in a single institutional cohort had a mean AUC for the entire ICU stay of 0.90 (95% CI 0.90-0.91) compared with baseline SOFA models with mean AUC 0.79 (95% CI 0.79-0.80) and 0.85 (95% CI 0.85-0.86). Deep models are well-suited to identify ICU patients in need of life-saving interventions prior to the occurrence of an unexpected adverse event and inform shared decision-making processes among patients, providers, and families regarding goals of care and optimal resource utilization.","Wed, 28 Feb 2018 02:39:02 UTC (1,932 KB)[v2] Thu, 30 Aug 2018 02:04:16 UTC (1,914 KB)"
"875","A Fast Deep Learning Model for Textual Relevance in Biomedical Information Retrieval","Sunil Mohan, Nicolas Fiorini, Sun Kim, Zhiyong Lu","Information Retrieval (cs.IR); Computation and Language (cs.CL)","Publications in the life sciences are characterized by a large technical vocabulary, with many lexical and semantic variations for expressing the same concept. Towards addressing the problem of relevance in biomedical literature search, we introduce a deep learning model for the relevance of a document's text to a keyword style query. Limited by a relatively small amount of training data, the model uses pre-trained word embeddings. With these, the model first computes a variable-length Delta matrix between the query and document, representing a difference between the two texts, which is then passed through a deep convolution stage followed by a deep feed-forward network to compute a relevance score. This results in a fast model suitable for use in an online search engine. The model is robust and outperforms comparable state-of-the-art deep learning approaches.","Mon, 26 Feb 2018 21:43:23 UTC (241 KB)"
"876","A Mathematical Framework for Deep Learning in Elastic Source Imaging","Jaejun Yoo, Abdul Wahab, Jong Chul Ye","Optimization and Control (math.OC); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","An inverse elastic source problem with sparse measurements is of concern. A generic mathematical framework is proposed which incorporates a low- dimensional manifold regularization in the conventional source reconstruction algorithms thereby enhancing their performance with sparse datasets. It is rigorously established that the proposed framework is equivalent to the so-called \emph{deep convolutional framelet expansion} in machine learning literature for inverse problems. Apposite numerical examples are furnished to substantiate the efficacy of the proposed framework.","Tue, 27 Feb 2018 18:14:00 UTC (3,751 KB)[v2] Tue, 6 Mar 2018 15:25:36 UTC (3,814 KB)[v3] Fri, 25 May 2018 23:17:48 UTC (4,592 KB)"
"877","Deep Learning Architectures for Face Recognition in Video Surveillance","Saman Bashbaghi, Eric Granger, Robert Sabourin, Mostafa Parchami","Computer Vision and Pattern Recognition (cs.CV)","Face recognition (FR) systems for video surveillance (VS) applications attempt to accurately detect the presence of target individuals over a distributed network of cameras. In video-based FR systems, facial models of target individuals are designed a priori during enrollment using a limited number of reference still images or video data. These facial models are not typically representative of faces being observed during operations due to large variations in illumination, pose, scale, occlusion, blur, and to camera inter-operability. Specifically, in still-to-video FR application, a single high-quality reference still image captured with still camera under controlled conditions is employed to generate a facial model to be matched later against lower-quality faces captured with video cameras under uncontrolled conditions. Current video-based FR systems can perform well on controlled scenarios, while their performance is not satisfactory in uncontrolled scenarios mainly because of the differences between the source (enrollment) and the target (operational) domains. Most of the efforts in this area have been toward the design of robust video-based FR systems in unconstrained surveillance environments. This chapter presents an overview of recent advances in still-to-video FR scenario through deep convolutional neural networks (CNNs). In particular, deep learning architectures proposed in the literature based on triplet-loss function (e.g., cross-correlation matching CNN, trunk-branch ensemble CNN and HaarNet) and supervised autoencoders (e.g., canonical face representation CNN) are reviewed and compared in terms of accuracy and computational complexity.","Tue, 27 Feb 2018 16:10:15 UTC (1,196 KB)[v2] Wed, 27 Jun 2018 14:00:33 UTC (1,232 KB)"
"878","Mono-Camera 3D Multi-Object Tracking Using Deep Learning Detections and PMBM Filtering","Samuel Scheidegger, Joachim Benjaminsson, Emil Rosenberg, Amrit Krishnan, Karl Granstrom","Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP)","Monocular cameras are one of the most commonly used sensors in the automotive industry for autonomous vehicles. One major drawback using a monocular camera is that it only makes observations in the two dimensional image plane and can not directly measure the distance to objects. In this paper, we aim at filling this gap by developing a multi-object tracking algorithm that takes an image as input and produces trajectories of detected objects in a world coordinate system. We solve this by using a deep neural network trained to detect and estimate the distance to objects from a single input image. The detections from a sequence of images are fed in to a state-of-the art Poisson multi-Bernoulli mixture tracking filter. The combination of the learned detector and the PMBM filter results in an algorithm that achieves 3D tracking using only mono-camera images as input. The performance of the algorithm is evaluated both in 3D world coordinates, and 2D image coordinates, using the publicly available KITTI object tracking dataset. The algorithm shows the ability to accurately track objects, correctly handle data associations, even when there is a big overlap of the objects in the image, and is one of the top performing algorithms on the KITTI object tracking benchmark. Furthermore, the algorithm is efficient, running on average close to 20 frames per second.","Tue, 27 Feb 2018 15:46:15 UTC (964 KB)"
"879","Demystifying Parallel and Distributed Deep Learning: An In-Depth Concurrency Analysis","Tal Ben-Nun, Torsten Hoefler","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC); Neural and Evolutionary Computing (cs.NE)","Deep Neural Networks (DNNs) are becoming an important tool in modern computing applications. Accelerating their training is a major challenge and techniques range from distributed algorithms to low-level circuit design. In this survey, we describe the problem from a theoretical perspective, followed by approaches for its parallelization. We present trends in DNN architectures and the resulting implications on parallelization strategies. We then review and model the different types of concurrency in DNNs: from the single operator, through parallelism in network inference and training, to distributed deep learning. We discuss asynchronous stochastic optimization, distributed system architectures, communication schemes, and neural architecture search. Based on those approaches, we extrapolate potential directions for parallelism in deep learning.","Mon, 26 Feb 2018 08:47:34 UTC (6,466 KB)[v2] Sat, 15 Sep 2018 08:36:28 UTC (3,140 KB)"
"880","Bioinformatics and Medicine in the Era of Deep Learning","Davide Bacciu, Paulo J.G. Lisboa, Jose D. Martin, Ruxandra Stoean, Alfredo Vellido","Machine Learning (cs.LG); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)","Many of the current scientific advances in the life sciences have their origin in the intensive use of data for knowledge discovery. In no area this is so clear as in bioinformatics, led by technological breakthroughs in data acquisition technologies. It has been argued that bioinformatics could quickly become the field of research generating the largest data repositories, beating other data-intensive areas such as high-energy physics or astroinformatics. Over the last decade, deep learning has become a disruptive advance in machine learning, giving new live to the long-standing connectionist paradigm in artificial intelligence. Deep learning methods are ideally suited to large-scale data and, therefore, they should be ideally suited to knowledge discovery in bioinformatics and biomedicine at large. In this brief paper, we review key aspects of the application of deep learning in bioinformatics and medicine, drawing from the themes covered by the contributions to an ESANN 2018 special session devoted to this topic.","Tue, 27 Feb 2018 09:41:44 UTC (72 KB)"
"881","Cognitive Radar Antenna Selection via Deep Learning","Ahmet M. Elbir, Kumar Vijay Mishra, Yonina C. Eldar","Signal Processing (eess.SP); Machine Learning (stat.ML)","Direction of arrival (DoA) estimation of targets improves with the number of elements employed by a phased array radar antenna. Since larger arrays have high associated cost, area and computational load, there is recent interest in thinning the antenna arrays without loss of far-field DoA accuracy. In this context, a cognitive radar may deploy a full array and then select an optimal subarray to transmit and receive the signals in response to changes in the target environment. Prior works have used optimization and greedy search methods to pick the best subarrays cognitively. In this paper, we leverage deep learning to address the antenna selection problem. Specifically, we construct a convolutional neural network (CNN) as a multi-class classification framework where each class designates a different subarray. The proposed network determines a new array every time data is received by the radar, thereby making antenna selection a cognitive operation. Our numerical experiments show that the proposed CNN structure outperforms existing random thinning and other machine learning approaches.","Tue, 27 Feb 2018 06:23:13 UTC (233 KB)"
"882","Segmentation of the prostate and organs at risk in male pelvic CT images using deep learning","Samaneh Kazemifar, Anjali Balagopal, Dan Nguyen, Sarah McGuire, Raquibul Hannan, Steve Jiang, Amir Owrangi","Medical Physics (physics.med-ph)","Inter-and intra-observer variation in delineating regions of interest (ROIs) occurs because of differences in expertise level and preferences of the radiation oncologists. We evaluated the accuracy of a segmentation model using the U-Net structure to delineate the prostate, bladder, and rectum in male pelvic CT images. The dataset used for training and testing the model consisted of raw CT scan images of 85 prostate cancer patients. We designed a 2D U-Net model to directly learn a mapping function that converts a 2D CT grayscale image to its corresponding 2D OAR segmented image. Our network contains blocks of convolution 2D layers with variable kernel sizes, channel number, and activation functions. On the left side of the U-Net model, we used three 3x3 convolutions, each followed by a rectified linear unit (ReLu) (activation function), and one max pooling operation. On the right side of the U-Net model, we used a 2x2 transposed convolution and two 3x3 convolution networks followed by a ReLu activation function. The automatic segmentation using the U-Net generated an average dice similarity coefficient (DC) and standard deviation (SD) of the following: DC +- SD (0.88 +- 0.12), (0.95 +- 0.04), and (0.92 +- 0.06) for the prostate, bladder, and rectum, respectively. Furthermore, the mean of average surface Hausdorff distance (ASHD) and SD were 1.2 +- 0.9 mm, 1.08 +- 0.8 mm, and 0.8 +- 0.6 mm for the prostate, bladder, and rectum, respectively. Our proposed method, which employs the U-Net structure, is highly accurate and reproducible for automated ROI segmentation. This provides a foundation to improve automatic delineation of the boundaries between the target and surrounding normal soft tissues on a standard radiation therapy planning CT scan.","Mon, 26 Feb 2018 20:19:14 UTC (742 KB)"
"883","Forecasting the impact of state pension reforms in post-Brexit England and Wales using microsimulation and deep learning","Agnieszka Werpachowska","Econometrics (econ.EM); General Finance (q-fin.GN)","We employ stochastic dynamic microsimulations to analyse and forecast the pension cost dependency ratio for England and Wales from 1991 to 2061, evaluating the impact of the ongoing state pension reforms and changes in international migration patterns under different Brexit scenarios. To fully account for the recently observed volatility in life expectancies, we propose mortality rate model based on deep learning techniques, which discovers complex patterns in data and extrapolated trends. Our results show that the recent reforms can effectively stave off the ""pension crisis"" and bring back the system on a sounder fiscal footing. At the same time, increasingly more workers can expect to spend greater share of their lifespan in retirement, despite the eligibility age rises. The population ageing due to the observed postponement of death until senectitude often occurs with the compression of morbidity, and thus will not, perforce, intrinsically strain healthcare costs. To a lesser degree, the future pension cost dependency ratio will depend on the post-Brexit relations between the UK and the EU, with ""soft"" alignment on the free movement lowering the relative cost of the pension system compared to the ""hard"" one. In the long term, however, the ratio has a rising tendency.","Tue, 6 Feb 2018 15:30:17 UTC (221 KB)[v2] Sat, 21 Apr 2018 22:22:02 UTC (197 KB)"
"884","A Deep Learning Approach for Privacy Preservation in Assisted Living","Ismini Psychoula, Erinc Merdivan, Deepika Singh, Liming Chen, Feng Chen, Sten Hanke, Johannes Kropf, Andreas Holzinger, Matthieu Geist","Signal Processing (eess.SP); Machine Learning (cs.LG)","In the era of Internet of Things (IoT) technologies the potential for privacy invasion is becoming a major concern especially in regards to healthcare data and Ambient Assisted Living (AAL) environments. Systems that offer AAL technologies make extensive use of personal data in order to provide services that are context-aware and personalized. This makes privacy preservation a very important issue especially since the users are not always aware of the privacy risks they could face. A lot of progress has been made in the deep learning field, however, there has been lack of research on privacy preservation of sensitive personal data with the use of deep learning. In this paper we focus on a Long Short Term Memory (LSTM) Encoder-Decoder, which is a principal component of deep learning, and propose a new encoding technique that allows the creation of different AAL data views, depending on the access level of the end user and the information they require access to. The efficiency and effectiveness of the proposed method are demonstrated with experiments on a simulated AAL dataset. Qualitatively, we show that the proposed model learns privacy operations such as disclosure, deletion and generalization and can perform encoding and decoding of the data with almost perfect recovery.","Thu, 22 Feb 2018 15:19:54 UTC (523 KB)"
"885","2D/3D Pose Estimation and Action Recognition using Multitask Deep Learning","Diogo C. Luvizon, David Picard, Hedi Tabia","Computer Vision and Pattern Recognition (cs.CV)","Action recognition and human pose estimation are closely related but both problems are generally handled as distinct tasks in the literature. In this work, we propose a multitask framework for jointly 2D and 3D pose estimation from still images and human action recognition from video sequences. We show that a single architecture can be used to solve the two problems in an efficient way and still achieves state-of-the-art results. Additionally, we demonstrate that optimization from end-to-end leads to significantly higher accuracy than separated learning. The proposed architecture can be trained with data from different categories simultaneously in a seamlessly way. The reported results on four datasets (MPII, Human3.6M, Penn Action and NTU) demonstrate the effectiveness of our method on the targeted tasks.","Mon, 26 Feb 2018 10:16:48 UTC (1,753 KB)[v2] Wed, 21 Mar 2018 13:39:45 UTC (1,753 KB)"
"886","Deep learning for conifer/deciduous classification of airborne LiDAR 3D point clouds representing individual trees","Hamid Hamraz, Nathan B. Jacobs, Marco A. Contreras, Chase H. Clark","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)","The purpose of this study was to investigate the use of deep learning for coniferous/deciduous classification of individual trees from airborne LiDAR data. To enable efficient processing by a deep convolutional neural network (CNN), we designed two discrete representations using leaf-off and leaf-on LiDAR data: a digital surface model with four channels (DSMx4) and a set of four 2D views (4x2D). A training dataset of labeled tree crowns was generated via segmentation of tree crowns, followed by co-registration with field data. Potential mislabels due to GPS error or tree leaning were corrected using a statistical ensemble filtering procedure. Because the training data was heavily unbalanced (~8% conifers), we trained an ensemble of CNNs on random balanced sub-samples of augmented data (180 rotational variations per instance). The 4x2D representation yielded similar classification accuracies to the DSMx4 representation (~82% coniferous and ~90% deciduous) while converging faster. The data augmentation improved the classification accuracies, but more real training instances (especially coniferous) likely results in much stronger improvements. Leaf-off LiDAR data were the primary source of useful information, which is likely due to the perennial nature of coniferous foliage. LiDAR intensity values also proved to be useful, but normalization yielded no significant improvements. Lastly, the classification accuracies of overstory trees (~90%) were more balanced than those of understory trees (~90% deciduous and ~65% coniferous), which is likely due to the incomplete capture of understory tree crowns via airborne LiDAR. Automatic derivation of optimal features via deep learning provide the opportunity for remarkable improvements in prediction tasks where captured data are not friendly to human visual system - likely yielding sub-optimal human-designed features.","Sat, 24 Feb 2018 16:10:39 UTC (470 KB)"
"887","Euler angles based loss function for camera relocalization with Deep learning","Qiang Fang, Tianjiang Hu","Robotics (cs.RO)","Deep learning has been applied to camera relocalization, in particular, PoseNet and its extended work are the convolutional neural networks which regress the camera pose from a single image. However there are many problems, one of them is expensive parameter selection. In this paper, we directly explore the three Euler angles as the orientation representation in the camera pose regressor. There is no need to select the parameter, which is not tolerant in the previous works. Experimental results on the 7 Scenes datasets and the King's College dataset demonstrate that it has competitive performances.","Sat, 24 Feb 2018 14:26:14 UTC (959 KB)"
"888","Adaptive Deep Learning through Visual Domain Localization","Gabriele Angeletti, Barbara Caputo, Tatiana Tommasi","Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","A commercial robot, trained by its manufacturer to recognize a predefined number and type of objects, might be used in many settings, that will in general differ in their illumination conditions, background, type and degree of clutter, and so on. Recent computer vision works tackle this generalization issue through domain adaptation methods, assuming as source the visual domain where the system is trained and as target the domain of deployment. All approaches assume to have access to images from all classes of the target during training, an unrealistic condition in robotics applications. We address this issue proposing an algorithm that takes into account the specific needs of robot vision. Our intuition is that the nature of the domain shift experienced mostly in robotics is local. We exploit this through the learning of maps that spatially ground the domain and quantify the degree of shift, embedded into an end-to-end deep domain adaptation architecture. By explicitly localizing the roots of the domain shift we significantly reduce the number of parameters of the architecture to tune, we gain the flexibility necessary to deal with subset of categories in the target domain at training time, and we provide a clear feedback on the rationale behind any classification decision, which can be exploited in human-robot interactions. Experiments on two different settings of the iCub World database confirm the suitability of our method for robot vision.","Sat, 24 Feb 2018 10:36:51 UTC (1,883 KB)"
"889","Longitudinal Face Aging in the Wild - Recent Deep Learning Approaches","Chi Nhan Duong, Khoa Luu, Kha Gia Quach, Tien D. Bui","Computer Vision and Pattern Recognition (cs.CV)","Face Aging has raised considerable attentions and interest from the computer vision community in recent years. Numerous approaches ranging from purely image processing techniques to deep learning structures have been proposed in literature. In this paper, we aim to give a review of recent developments of modern deep learning based approaches, i.e. Deep Generative Models, for Face Aging task. Their structures, formulation, learning algorithms as well as synthesized results are also provided with systematic discussions. Moreover, the aging databases used in most methods to learn the aging process are also reviewed.","Fri, 23 Feb 2018 20:29:50 UTC (4,021 KB)"
"890","Deep learning in radiology: an overview of the concepts and a survey of the state of the art","Maciej A. Mazurowski, Mateusz Buda, Ashirbani Saha, Mustafa R. Bashir","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Applications (stat.AP); Machine Learning (stat.ML)","Deep learning is a branch of artificial intelligence where networks of simple interconnected units are used to extract patterns from data in order to solve complex problems. Deep learning algorithms have shown groundbreaking performance in a variety of sophisticated tasks, especially those related to images. They have often matched or exceeded human performance. Since the medical field of radiology mostly relies on extracting useful information from images, it is a very natural application area for deep learning, and research in this area has rapidly grown in recent years. In this article, we review the clinical reality of radiology and discuss the opportunities for application of deep learning algorithms. We also introduce basic concepts of deep learning including convolutional neural networks. Then, we present a survey of the research in deep learning applied to radiology. We organize the studies by the types of specific tasks that they attempt to solve and review the broad range of utilized deep learning algorithms. Finally, we briefly discuss opportunities and challenges for incorporating deep learning in the radiology practice of the future.","Sat, 10 Feb 2018 04:00:55 UTC (2,425 KB)"
"891","Deep learning algorithm for data-driven simulation of noisy dynamical system","Kyongmin Yeo, Igor Melnyk","Computational Physics (physics.comp-ph); Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an); Machine Learning (stat.ML)","We present a deep learning model, DE-LSTM, for the simulation of a stochastic process with an underlying nonlinear dynamics. The deep learning model aims to approximate the probability density function of a stochastic process via numerical discretization and the underlying nonlinear dynamics is modeled by the Long Short-Term Memory (LSTM) network. It is shown that, when the numerical discretization is used, the function estimation problem can be solved by a multi-label classification problem. A penalized maximum log likelihood method is proposed to impose a smoothness condition in the prediction of the probability distribution. We show that the time evolution of the probability distribution can be computed by a high-dimensional integration of the transition probability of the LSTM internal states. A Monte Carlo algorithm to approximate the high-dimensional integration is outlined. The behavior of DE-LSTM is thoroughly investigated by using the Ornstein-Uhlenbeck process and noisy observations of nonlinear dynamical systems; Mackey-Glass time series and forced Van der Pol oscillator. It is shown that DE-LSTM makes a good prediction of the probability distribution without assuming any distributional properties of the stochastic process. For a multiple-step forecast of the Mackey-Glass time series, the prediction uncertainty, denoted by the 95\% confidence interval, first grows, then dynamically adjusts following the evolution of the system, while in the simulation of the forced Van der Pol oscillator, the prediction uncertainty does not grow in time even for a 3,000-step forecast.","Thu, 22 Feb 2018 22:08:14 UTC (4,125 KB)[v2] Wed, 5 Sep 2018 15:09:06 UTC (1,281 KB)"
"892","Deep Learning and AdS/CFT","Koji Hashimoto, Sotaro Sugishita, Akinori Tanaka, Akio Tomiya","High Energy Physics - Theory (hep-th)","We present a deep neural network representation of the AdS/CFT correspondence, and demonstrate the emergence of the bulk metric function via the learning process for given data sets of response in boundary quantum field theories. The emergent radial direction of the bulk is identified with the depth of the layers, and the network itself is interpreted as a bulk geometry. Our network provides a data-driven holographic modeling of strongly coupled systems. With a scalar $ヵ^4$ theory with unknown mass and coupling, in unknown curved spacetime with a black hole horizon, we demonstrate our deep learning (DL) framework can determine them which fit given response data. First, we show that, from boundary data generated by the AdS Schwarzschild spacetime, our network can reproduce the metric. Second, we demonstrate that our network with experimental data as an input can determine the bulk metric, the mass and the quadratic coupling of the holographic model. As an example we use the experimental data of magnetic response of a strongly correlated material Sm$_{0.6}$Sr$_{0.4}$MnO$_3$. This AdS/DL correspondence not only enables gravity modeling of strongly correlated systems, but also sheds light on a hidden mechanism of the emerging space in both AdS and DL.","Thu, 22 Feb 2018 21:59:20 UTC (3,276 KB)"
"893","Multiparametric Deep Learning Tissue Signatures for a Radiological Biomarker of Breast Cancer: Preliminary Results","Vishwa S. Parekh, Katarzyna J. Macura, Susan Harvey, Ihab Kamel, Riham EI-Khouli, David A. Bluemke, Michael A. Jacobs","Medical Physics (physics.med-ph)","A new paradigm is beginning to emerge in Radiology with the advent of increased computational capabilities and algorithms. This has led to the ability of real time learning by computer systems of different lesion types to help the radiologist in defining disease. For example, using a deep learning network, we developed and tested a multiparametric deep learning (MPDL) network for segmentation and classification using multiparametric magnetic resonance imaging (mpMRI) radiological images. The MPDL network was constructed from stacked sparse autoencoders with inputs from mpMRI. Evaluation of MPDL consisted of cross-validation, sensitivity, and specificity. Dice similarity between MPDL and post-DCE lesions were evaluated. We demonstrate high sensitivity and specificity for differentiation of malignant from benign lesions of 90% and 85% respectively with an AUC of 0.93. The Integrated MPDL method accurately segmented and classified different breast tissue from multiparametric breast MRI using deep leaning tissue signatures.","Sat, 10 Feb 2018 02:51:59 UTC (1,335 KB)"
"894","Classification of Breast Cancer Histology using Deep Learning","Aditya Golatkar, Deepak Anand, Amit Sethi","Computer Vision and Pattern Recognition (cs.CV)","Breast Cancer is a major cause of death worldwide among women. Hematoxylin and Eosin (H&E) stained breast tissue samples from biopsies are observed under microscopes for the primary diagnosis of breast cancer. In this paper, we propose a deep learning-based method for classification of H&E stained breast tissue images released for BACH challenge 2018 by fine-tuning Inception-v3 convolutional neural network (CNN) proposed by Szegedy et al. These images are to be classified into four classes namely, i) normal tissue, ii) benign tumor, iii) in-situ carcinoma and iv) invasive carcinoma. Our strategy is to extract patches based on nuclei density instead of random or grid sampling, along with rejection of patches that are not rich in nuclei (non-epithelial) regions for training and testing. Every patch (nuclei-dense region) in an image is classified in one of the four above mentioned categories. The class of the entire image is determined using majority voting over the nuclear classes. We obtained an average four class accuracy of 85% and an average two class (non-cancer vs. carcinoma) accuracy of 93%, which improves upon a previous benchmark by Araujo et al.","Thu, 22 Feb 2018 14:56:38 UTC (1,256 KB)[v2] Wed, 25 Jul 2018 07:58:20 UTC (1,351 KB)"
"895","Super-Resolution 1H Magnetic Resonance Spectroscopic Imaging utilizing Deep Learning","Zohaib Iqbal, Dan Nguyen, Gilbert Hangel, Stanislav Motyka, Wolfgang Bogner, Steve Jiang","Medical Physics (physics.med-ph)","Magnetic resonance spectroscopic imaging (SI) is a unique imaging technique that provides biochemical information from in vivo tissues. The 1H spectra acquired from several spatial regions are quantified to yield metabolite concentrations reflective of tissue metabolism. However, since these metabolites are found in tissues at very low concentrations, SI is often acquired with limited spatial resolution. In this work we test the hypothesis that deep learning is able to upscale low resolution SI, together with the T1-weighted (T1w) image, to reconstruct high resolution SI. We report a novel densely connected Unet (D-Unet) architecture capable of producing super-resolution spectroscopic images. The inputs for the D-UNet are the T1w image and the low resolution SI image while the output is the high resolution SI. The results of the D-UNet are compared both qualitatively and quantitatively to simulated and in vivo high resolution SI. It is found that this deep learning approach can produce high quality spectroscopic images and reconstruct entire 1H spectra from low resolution acquisitions, which can greatly advance the current SI workflow.","Thu, 22 Feb 2018 05:38:44 UTC (6,876 KB)[v2] Mon, 14 May 2018 16:48:41 UTC (5,404 KB)[v3] Mon, 5 Nov 2018 20:06:51 UTC (5,895 KB)"
"896","Deep Learning Classification in Asteroseismology Using an Improved Neural Network: Results on 15000 Kepler Red Giants and Applications to K2 and TESS Data","Marc Hon, Dennis Stello, Jie Yu","Instrumentation and Methods for Astrophysics (astro-ph.IM); Solar and Stellar Astrophysics (astro-ph.SR)","Deep learning in the form of 1D convolutional neural networks have previously been shown to be capable of efficiently classifying the evolutionary state of oscillating red giants into red giant branch stars and helium-core burning stars by recognizing visual features in their asteroseismic frequency spectra. We elaborate further on the deep learning method by developing an improved convolutional neural network classifier. To make our method useful for current and future space missions such as K2, TESS and PLATO, we train classifiers that are able to classify the evolutionary states of lower frequency resolution spectra expected from these missions. Additionally, we provide new classifications for 8633 Kepler red giants, out of which 426 have previously not been classified using asteroseismology. This brings the total to 14983 Kepler red giants classified with our new neural network. We also verify that our classifiers are remarkably robust to suboptimal data, including low signal-to-noise and incorrect training truth labels.","Tue, 20 Feb 2018 13:21:16 UTC (4,584 KB)"
"897","High-Quality Prediction Intervals for Deep Learning: A Distribution-Free, Ensembled Approach","Tim Pearce, Mohamed Zaki, Alexandra Brintrup, Andy Neely","Machine Learning (stat.ML)","This paper considers the generation of prediction intervals (PIs) by neural networks for quantifying uncertainty in regression tasks. It is axiomatic that high-quality PIs should be as narrow as possible, whilst capturing a specified portion of data. We derive a loss function directly from this axiom that requires no distributional assumption. We show how its form derives from a likelihood principle, that it can be used with gradient descent, and that model uncertainty is accounted for in ensembled form. Benchmark experiments show the method outperforms current state-of-the-art uncertainty quantification methods, reducing average PI width by over 10%.","Tue, 20 Feb 2018 16:02:21 UTC (608 KB)[v2] Tue, 12 Jun 2018 15:58:44 UTC (631 KB)[v3] Fri, 15 Jun 2018 17:12:59 UTC (631 KB)"
"898","The Description Length of Deep Learning Models","Leonard Blier, Yann Ollivier","Machine Learning (cs.LG)","Solomonoff's general theory of inference and the Minimum Description Length principle formalize Occam's razor, and hold that a good model of data is a model that is good at losslessly compressing the data, including the cost of describing the model itself. Deep neural networks might seem to go against this principle given the large number of parameters to be encoded. We demonstrate experimentally the ability of deep neural networks to compress the training data even when accounting for parameter encoding. The compression viewpoint originally motivated the use of variational methods in neural networks. Unexpectedly, we found that these variational methods provide surprisingly poor compression bounds, despite being explicitly built to minimize such bounds. This might explain the relatively poor practical performance of variational methods in deep learning. On the other hand, simple incremental encoding methods yield excellent compression values on deep networks, vindicating Solomonoff's approach.","Tue, 20 Feb 2018 10:15:26 UTC (95 KB)[v2] Tue, 22 May 2018 13:41:03 UTC (655 KB)[v3] Wed, 23 May 2018 08:15:32 UTC (310 KB)[v4] Mon, 29 Oct 2018 14:28:50 UTC (75 KB)[v5] Thu, 1 Nov 2018 11:23:09 UTC (75 KB)"
"899","High-Order Graph Convolutional Recurrent Neural Network: A Deep Learning Framework for Network-Scale Traffic Learning and Forecasting","Zhiyong Cui, Kristian Henrickson, Ruimin Ke, Yinhai Wang","Machine Learning (cs.LG); Machine Learning (stat.ML)","Traffic forecasting is a challenging task, due to the complicated spatial dependencies on roadway networks and the time-varying traffic patterns. To address this challenge, we learn the traffic network as a graph and propose a novel deep learning framework, High-Order Graph Convolutional Long Short-Term Memory Neural Network (HGC-LSTM), to learn the interactions between links in the traffic network and forecast the network-wide traffic state. We define the high-order traffic graph convolution based on the physical network topology. The proposed framework employs L1-norms on the graph convolution weights and L2-norms on the graph convolution features to identify the most influential links in the traffic network. We propose a novel Real-Time Branching Learning (RTBL) algorithm for the HGC-LSTM framework to accelerate the training process for spatio-temporal data. Experiments show that our HGC-LSTM network is able to capture the complex spatio-temporal dependencies efficiently present in the traffic network and consistently outperforms state-of-the-art baseline methods on two heterogeneous real-world traffic datasets. The visualization of graph convolution weights shows that the proposed framework can accurately recognize the most influential roadway segments in real-world traffic networks.","Tue, 20 Feb 2018 08:40:21 UTC (1,189 KB)"
"900","Efficient Embedding of MPI Collectives in MXNET DAGs for scaling Deep Learning","Amith R Mamidala","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","Availability of high performance computing infrastructures such as clusters of GPUs and CPUs have fueled the growth of distributed learning systems. Deep Learning frameworks express neural nets as DAGs and execute these DAGs on computation resources such as GPUs. In this paper, we propose efficient designs of embedding MPI collective operations into data parallel DAGs. Incorrect designs can easily lead to deadlocks or program crashes. In particular, we demonstrate three designs: Funneled, Concurrent communication and Dependency chaining of using MPI collectives with DAGs. These designs automatically enable overlap of computation with communication by allowing for concurrent execution with the other tasks. We directly implement these designs into the KVStore API of the MXNET. This allows us to directly leverage the rest of the infrastructure. Using ImageNet and CIFAR data sets, we show the potential of our designs. In particular, our designs scale to 256 GPUs with as low as 50 seconds of epoch times for ImageNet 1K datasets.","Tue, 20 Feb 2018 03:36:20 UTC (1,036 KB)"
"901","Automated soft tissue lesion detection and segmentation in digital mammography using a u-net deep learning network","Timothy de Moor, Alejandro Rodriguez-Ruiz, Albert Gubern Merida, Ritse Mann, Jonas Teuwen","Computer Vision and Pattern Recognition (cs.CV)","Computer-aided detection or decision support systems aim to improve breast cancer screening programs by helping radiologists to evaluate digital mammography (DM) exams. Commonly such methods proceed in two steps: selection of candidate regions for malignancy, and later classification as either malignant or not. In this study, we present a candidate detection method based on deep learning to automatically detect and additionally segment soft tissue lesions in DM. A database of DM exams (mostly bilateral and two views) was collected from our institutional archive. In total, 7196 DM exams (28294 DM images) acquired with systems from three different vendors (General Electric, Siemens, Hologic) were collected, of which 2883 contained malignant lesions verified with histopathology. Data was randomly split on an exam level into training (50\%), validation (10\%) and testing (40\%) of deep neural network with u-net architecture. The u-net classifies the image but also provides lesion segmentation. Free receiver operating characteristic (FROC) analysis was used to evaluate the model, on an image and on an exam level. On an image level, a maximum sensitivity of 0.94 at 7.93 false positives (FP) per image was achieved. Similarly, per exam a maximum sensitivity of 0.98 at 7.81 FP per image was achieved. In conclusion, the method could be used as a candidate selection model with high accuracy and with the additional information of lesion segmentation.","Mon, 19 Feb 2018 21:39:49 UTC (9,201 KB)[v2] Thu, 8 Mar 2018 09:21:11 UTC (9,201 KB)"
"902","Deep Learning for Joint Source-Channel Coding of Text","Nariman Farsad, Milind Rao, Andrea Goldsmith","Information Theory (cs.IT); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","We consider the problem of joint source and channel coding of structured data such as natural language over a noisy channel. The typical approach to this problem in both theory and practice involves performing source coding to first compress the text and then channel coding to add robustness for the transmission across the channel. This approach is optimal in terms of minimizing end-to-end distortion with arbitrarily large block lengths of both the source and channel codes when transmission is over discrete memoryless channels. However, the optimality of this approach is no longer ensured for documents of finite length and limitations on the length of the encoding. We will show in this scenario that we can achieve lower word error rates by developing a deep learning based encoder and decoder. While the approach of separate source and channel coding would minimize bit error rates, our approach preserves semantic information of sentences by first embedding sentences in a semantic space where sentences closer in meaning are located closer together, and then performing joint source and channel coding on these embeddings.","Mon, 19 Feb 2018 20:11:36 UTC (85 KB)"
"903","Shield: Fast, Practical Defense and Vaccination for Deep Learning using JPEG Compression","Nilaksh Das, Madhuri Shanbhogue, Shang-Tse Chen, Fred Hohman, Siwei Li, Li Chen, Michael E. Kounavis, Duen Horng Chau","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)","The rapidly growing body of research in adversarial machine learning has demonstrated that deep neural networks (DNNs) are highly vulnerable to adversarially generated images. This underscores the urgent need for practical defense that can be readily deployed to combat attacks in real-time. Observing that many attack strategies aim to perturb image pixels in ways that are visually imperceptible, we place JPEG compression at the core of our proposed Shield defense framework, utilizing its capability to effectively ""compress away"" such pixel manipulation. To immunize a DNN model from artifacts introduced by compression, Shield ""vaccinates"" a model by re-training it with compressed images, where different compression levels are applied to generate multiple vaccinated models that are ultimately used together in an ensemble defense. On top of that, Shield adds an additional layer of protection by employing randomization at test time that compresses different regions of an image using random compression levels, making it harder for an adversary to estimate the transformation performed. This novel combination of vaccination, ensembling, and randomization makes Shield a fortified multi-pronged protection. We conducted extensive, large-scale experiments using the ImageNet dataset, and show that our approaches eliminate up to 94% of black-box attacks and 98% of gray-box attacks delivered by the recent, strongest attacks, such as Carlini-Wagner's L2 and DeepFool. Our approaches are fast and work without requiring knowledge about the model.","Mon, 19 Feb 2018 19:13:42 UTC (1,822 KB)"
"904","Towards Ultra-High Performance and Energy Efficiency of Deep Learning Systems: An Algorithm-Hardware Co-Optimization Framework","Yanzhi Wang, Caiwen Ding, Zhe Li, Geng Yuan, Siyu Liao, Xiaolong Ma, Bo Yuan, Xuehai Qian, Jian Tang, Qinru Qiu, Xue Lin","Machine Learning (cs.LG); Machine Learning (stat.ML)","Hardware accelerations of deep learning systems have been extensively investigated in industry and academia. The aim of this paper is to achieve ultra-high energy efficiency and performance for hardware implementations of deep neural networks (DNNs). An algorithm-hardware co-optimization framework is developed, which is applicable to different DNN types, sizes, and application scenarios. The algorithm part adopts the general block-circulant matrices to achieve a fine-grained tradeoff between accuracy and compression ratio. It applies to both fully-connected and convolutional layers and contains a mathematically rigorous proof of the effectiveness of the method. The proposed algorithm reduces computational complexity per layer from O($n^2$) to O($n\log n$) and storage complexity from O($n^2$) to O($n$), both for training and inference. The hardware part consists of highly efficient Field Programmable Gate Array (FPGA)-based implementations using effective reconfiguration, batch processing, deep pipelining, resource re-using, and hierarchical control. Experimental results demonstrate that the proposed framework achieves at least 152X speedup and 71X energy efficiency gain compared with IBM TrueNorth processor under the same test accuracy. It achieves at least 31X energy efficiency gain compared with the reference FPGA-based work.","Sun, 18 Feb 2018 16:51:04 UTC (1,154 KB)"
"905","A Collaborative Computer Aided Diagnosis (C-CAD) System with Eye-Tracking, Sparse Attentional Model, and Deep Learning","Naji Khosravan, Haydar Celik, Baris Turkbey, Elizabeth Jones, Bradford Wood, Ulas Bagci","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","There are at least two categories of errors in radiology screening that can lead to suboptimal diagnostic decisions and interventions:(i)human fallibility and (ii)complexity of visual search. Computer aided diagnostic (CAD) tools are developed to help radiologists to compensate for some of these errors. However, despite their significant improvements over conventional screening strategies, most CAD systems do not go beyond their use as second opinion tools due to producing a high number of false positives, which human interpreters need to correct. In parallel with efforts in computerized analysis of radiology scans, several researchers have examined behaviors of radiologists while screening medical images to better understand how and why they miss tumors, how they interact with the information in an image, and how they search for unknown pathology in the images. Eye-tracking tools have been instrumental in exploring answers to these fundamental questions. In this paper, we aim to develop a paradigm shift CAD system, called collaborative CAD (C-CAD), that unifies both of the above mentioned research lines: CAD and eye-tracking. We design an eye-tracking interface providing radiologists with a real radiology reading room experience. Then, we propose a novel algorithm that unifies eye-tracking data and a CAD system. Specifically, we present a new graph based clustering and sparsification algorithm to transform eye-tracking data (gaze) into a signal model to interpret gaze patterns quantitatively and qualitatively. The proposed C-CAD collaborates with radiologists via eye-tracking technology and helps them to improve diagnostic decisions. The C-CAD learns radiologists' search efficiency by processing their gaze patterns. To do this, the C-CAD uses a deep learning algorithm in a newly designed multi-task learning platform to segment and diagnose cancers simultaneously.","Sat, 17 Feb 2018 17:20:50 UTC (5,459 KB)[v2] Sat, 28 Apr 2018 15:06:18 UTC (7,965 KB)"
"906","A deep learning framework for turbulence modeling using data assimilation and feature extraction","Atieh Alizadeh Moghaddam, Amir Sadaghiyani","Fluid Dynamics (physics.flu-dyn); Computational Physics (physics.comp-ph)","Turbulent problems in industrial applications are predominantly solved using Reynolds Averaged Navier Stokes (RANS) turbulence models. The accuracy of the RANS models is limited due to closure assumptions that induce uncertainty into the RANS modeling. We propose the use of deep learning algorithms via convolution neural networks along with data from direct numerical simulations to extract the optimal set of features that explain the evolution of turbulent flow statistics. Statistical tests are used to determine the correlation of these features with the variation in the quantities of interest that are to be predicted. These features are then used to develop improved partial differential equations that can replace classical Reynolds Averaged Navier Stokes models and show improvement in the accuracy of the predictions.","Fri, 16 Feb 2018 20:16:06 UTC (390 KB)"
"907","Variance-based Gradient Compression for Efficient Distributed Deep Learning","Yusuke Tsuzuku, Hiroto Imachi, Takuya Akiba","Machine Learning (cs.LG)","Due to the substantial computational cost, training state-of-the-art deep neural networks for large-scale datasets often requires distributed training using multiple computation workers. However, by nature, workers need to frequently communicate gradients, causing severe bottlenecks, especially on lower bandwidth connections. A few methods have been proposed to compress gradient for efficient communication, but they either suffer a low compression ratio or significantly harm the resulting model accuracy, particularly when applied to convolutional neural networks. To address these issues, we propose a method to reduce the communication overhead of distributed deep learning. Our key observation is that gradient updates can be delayed until an unambiguous (high amplitude, low variance) gradient has been calculated. We also present an efficient algorithm to compute the variance with negligible additional cost. We experimentally show that our method can achieve very high compression ratio while maintaining the result model accuracy. We also analyze the efficiency using computation and communication cost models and provide the evidence that this method enables distributed deep learning for many scenarios with commodity environments.","Fri, 16 Feb 2018 18:15:33 UTC (318 KB)[v2] Tue, 20 Feb 2018 04:13:14 UTC (318 KB)"
"908","Improved GQ-CNN: Deep Learning Model for Planning Robust Grasps","Maciej Ja<U+015B>kowski (1), Jakub <U+015A>wi<U+0105>tkowski (1), Micha Zaj<U+0105>c (1), Maciej Klimek (1), Jarek Potiuk (1), Piotr Rybicki (1), Piotr Polatowski (1), Przemysaw Walczyk (1), Kacper Nowicki (1), Marek Cygan (1 and 2) ((1) NoMagic.AI, (2) Institute of Informatics, University of Warsaw)","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO); Machine Learning (stat.ML)","Recent developments in the field of robot grasping have shown great improvements in the grasp success rates when dealing with unknown objects. In this work we improve on one of the most promising approaches, the Grasp Quality Convolutional Neural Network (GQ-CNN) trained on the DexNet 2.0 dataset. We propose a new architecture for the GQ-CNN and describe practical improvements that increase the model validation accuracy from 92.2% to 95.8% and from 85.9% to 88.0% on respectively image-wise and object-wise training and validation splits.","Fri, 16 Feb 2018 15:54:31 UTC (68 KB)"
"909","Horovod: fast and easy distributed deep learning in TensorFlow","Alexander Sergeev, Mike Del Balso","Machine Learning (cs.LG); Machine Learning (stat.ML)","Training modern deep learning models requires large amounts of computation, often provided by GPUs. Scaling computation from one GPU to many can enable much faster training and research progress but entails two complications. First, the training library must support inter-GPU communication. Depending on the particular methods employed, this communication may entail anywhere from negligible to significant overhead. Second, the user must modify his or her training code to take advantage of inter-GPU communication. Depending on the training library's API, the modification required may be either significant or minimal. Existing methods for enabling multi-GPU training under the TensorFlow library entail non-negligible communication overhead and require users to heavily modify their model-building code, leading many researchers to avoid the whole mess and stick with slower single-GPU training. In this paper we introduce Horovod, an open source library that improves on both obstructions to scaling: it employs efficient inter-GPU communication via ring reduction and requires only a few lines of modification to user code, enabling faster, easier distributed training in TensorFlow. Horovod is available under the Apache 2.0 license at this https URL","Thu, 15 Feb 2018 23:36:51 UTC (521 KB)[v2] Mon, 19 Feb 2018 21:41:57 UTC (521 KB)[v3] Wed, 21 Feb 2018 04:30:30 UTC (521 KB)"
"910","Deep Learning for Lip Reading using Audio-Visual Information for Urdu Language","M Faisal, Sanaullah Manzoor","Computer Vision and Pattern Recognition (cs.CV); Sound (cs.SD); Audio and Speech Processing (eess.AS)","Human lip-reading is a challenging task. It requires not only knowledge of underlying language but also visual clues to predict spoken words. Experts need certain level of experience and understanding of visual expressions learning to decode spoken words. Now-a-days, with the help of deep learning it is possible to translate lip sequences into meaningful words. The speech recognition in the noisy environments can be increased with the visual information [1]. To demonstrate this, in this project, we have tried to train two different deep-learning models for lip-reading: first one for video sequences using spatiotemporal convolution neural network, Bi-gated recurrent neural network and Connectionist Temporal Classification Loss, and second for audio that inputs the MFCC features to a layer of LSTM cells and output the sequence. We have also collected a small audio-visual dataset to train and test our model. Our target is to integrate our both models to improve the speech recognition in the noisy environment","Thu, 15 Feb 2018 13:28:19 UTC (651 KB)"
"911","Deep Learning Based Speech Beamforming","Kaizhi Qian, Yang Zhang, Shiyu Chang, Xuesong Yang, Dinei Florencio, Mark Hasegawa-Johnson","Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)","Multi-channel speech enhancement with ad-hoc sensors has been a challenging task. Speech model guided beamforming algorithms are able to recover natural sounding speech, but the speech models tend to be oversimplified or the inference would otherwise be too complicated. On the other hand, deep learning based enhancement approaches are able to learn complicated speech distributions and perform efficient inference, but they are unable to deal with variable number of input channels. Also, deep learning approaches introduce a lot of errors, particularly in the presence of unseen noise types and settings. We have therefore proposed an enhancement framework called DEEPBEAM, which combines the two complementary classes of algorithms. DEEPBEAM introduces a beamforming filter to produce natural sounding speech, but the filter coefficients are determined with the help of a monaural speech enhancement neural network. Experiments on synthetic and real-world data show that DEEPBEAM is able to produce clean, dry and natural sounding speech, and is robust against unseen noise.","Thu, 15 Feb 2018 02:00:54 UTC (62 KB)"
"912","500+ Times Faster Than Deep Learning (A Case Study Exploring Faster Methods for Text Mining StackOverflow)","Suvodeep Majumder, Nikhila Balaji, Katie Brey, Wei Fu, Tim Menzies","Software Engineering (cs.SE); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning methods are useful for high-dimensional data and are becoming widely used in many areas of software engineering. Deep learners utilizes extensive computational power and can take a long time to train-- making it difficult to widely validate and repeat and improve their results. Further, they are not the best solution in all domains. For example, recent results show that for finding related Stack Overflow posts, a tuned SVM performs similarly to a deep learner, but is significantly faster to train. This paper extends that recent result by clustering the dataset, then tuning very learners within each cluster. This approach is over 500 times faster than deep learning (and over 900 times faster if we use all the cores on a standard laptop computer). Significantly, this faster approach generates classifiers nearly as good (within 2\% F1 Score) as the much slower deep learning method. Hence we recommend this faster methods since it is much easier to reproduce and utilizes far fewer CPU resources. More generally, we recommend that before researchers release research results, that they compare their supposedly sophisticated methods against simpler alternatives (e.g applying simpler learners to build local models).","Wed, 14 Feb 2018 20:57:48 UTC (231 KB)"
"913","Sharkzor: Interactive Deep Learning for Image Triage, Sort and Summary","Meg Pirrung, Nathan Hilliard, Artem Yankov, Nancy O'Brien, Paul Weidert, Courtney D Corley, Nathan O Hodas","Human-Computer Interaction (cs.HC)","Sharkzor is a web application for machine-learning assisted image sort and summary. Deep learning algorithms are leveraged to infer, augment, and automate the user's mental model. Initially, images uploaded by the user are spread out on a canvas. The user then interacts with the images to impute their mental model into the application's algorithmic underpinnings. Methods of interaction within Sharkzor's user interface and user experience support three primary user tasks; triage, organize and automate. The user triages the large pile of overlapping images by moving images of interest into proximity. The user then organizes said images into meaningful groups. After interacting with the images and groups, deep learning helps to automate the user's interactions. The loop of interaction, automation, and response by the user allows the system to quickly make sense of large amounts of data.","Wed, 14 Feb 2018 20:48:28 UTC (1,572 KB)"
"914","Security Analysis and Enhancement of Model Compressed Deep Learning Systems under Adversarial Attacks","Qi Liu, Tao Liu, Zihao Liu, Yanzhi Wang, Yier Jin, Wujie Wen","Machine Learning (cs.LG); Cryptography and Security (cs.CR); Machine Learning (stat.ML)","DNN is presenting human-level performance for many complex intelligent tasks in real-world applications. However, it also introduces ever-increasing security concerns. For example, the emerging adversarial attacks indicate that even very small and often imperceptible adversarial input perturbations can easily mislead the cognitive function of deep learning systems (DLS). Existing DNN adversarial studies are narrowly performed on the ideal software-level DNN models with a focus on single uncertainty factor, i.e. input perturbations, however, the impact of DNN model reshaping on adversarial attacks, which is introduced by various hardware-favorable techniques such as hash-based weight compression during modern DNN hardware implementation, has never been discussed. In this work, we for the first time investigate the multi-factor adversarial attack problem in practical model optimized deep learning systems by jointly considering the DNN model-reshaping (e.g. HashNet based deep compression) and the input perturbations. We first augment adversarial example generating method dedicated to the compressed DNN models by incorporating the software-based approaches and mathematical modeled DNN reshaping. We then conduct a comprehensive robustness and vulnerability analysis of deep compressed DNN models under derived adversarial attacks. A defense technique named ""gradient inhibition"" is further developed to ease the generating of adversarial examples thus to effectively mitigate adversarial attacks towards both software and hardware-oriented DNNs. Simulation results show that ""gradient inhibition"" can decrease the average success rate of adversarial attacks from 87.99% to 4.77% (from 86.74% to 4.64%) on MNIST (CIFAR-10) benchmark with marginal accuracy degradation across various DNNs.","Wed, 14 Feb 2018 16:31:35 UTC (946 KB)[v2] Mon, 19 Mar 2018 18:02:11 UTC (946 KB)"
"915","Cognitive Deficit of Deep Learning in Numerosity","Xiaolin Wu, Xi Zhang, Xiao Shu","Computer Vision and Pattern Recognition (cs.CV)","Subitizing, or the sense of small natural numbers, is an innate cognitive function of humans and primates; it responds to visual stimuli prior to the development of any symbolic skills, language or arithmetic. Given successes of deep learning (DL) in tasks of visual intelligence and given the primitivity of number sense, a tantalizing question is whether DL can comprehend numbers and perform subitizing. But somewhat disappointingly, extensive experiments of the type of cognitive psychology demonstrate that the examples-driven black box DL cannot see through superficial variations in visual representations and distill the abstract notion of natural number, a task that children perform with high accuracy and confidence. The failure is apparently due to the learning method not the CNN computational machinery itself. A recurrent neural network capable of subitizing does exist, which we construct by encoding a mechanism of mathematical morphology into the CNN convolutional kernels. Also, we investigate, using subitizing as a test bed, the ways to aid the black box DL by cognitive priors derived from human insight. Our findings are mixed and interesting, pointing to both cognitive deficit of pure DL, and some measured successes of boosting DL by predetermined cognitive implements. This case study of DL in cognitive computing is meaningful for visual numerosity represents a minimum level of human intelligence.","Fri, 9 Feb 2018 15:01:52 UTC (1,396 KB)[v2] Sun, 15 Apr 2018 12:35:52 UTC (1,552 KB)[v3] Wed, 11 Jul 2018 03:14:50 UTC (513 KB)[v4] Sun, 11 Nov 2018 14:47:31 UTC (910 KB)"
"916","Deep Learning and Data Assimilation for Real-Time Production Prediction in Natural Gas Wells","Kelvin Loh, Pejman Shoeibi Omrani, Ruud van der Linden","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Fluid Dynamics (physics.flu-dyn); Geophysics (physics.geo-ph); Machine Learning (stat.ML)","The prediction of the gas production from mature gas wells, due to their complex end-of-life behavior, is challenging and crucial for operational decision making. In this paper, we apply a modified deep LSTM model for prediction of the gas flow rates in mature gas wells, including the uncertainties in input parameters. Additionally, due to changes in the system in time and in order to increase the accuracy and robustness of the prediction, the Ensemble Kalman Filter (EnKF) is used to update the flow rate predictions based on new observations. The developed approach was tested on the data from two mature gas production wells in which their production is highly dynamic and suffering from salt deposition. The results show that the flow predictions using the EnKF updated model leads to better Jeffreys' J-divergences than the predictions without the EnKF model updating scheme.","Wed, 14 Feb 2018 15:03:09 UTC (1,507 KB)[v2] Thu, 15 Feb 2018 03:16:08 UTC (1,507 KB)"
"917","L4: Practical loss-based stepsize adaptation for deep learning","Michal Rolinek, Georg Martius","Machine Learning (cs.LG); Machine Learning (stat.ML)","We propose a stepsize adaptation scheme for stochastic gradient descent. It operates directly with the loss function and rescales the gradient in order to make fixed predicted progress on the loss. We demonstrate its capabilities by conclusively improving the performance of Adam and Momentum optimizers. The enhanced optimizers with default hyperparameters consistently outperform their constant stepsize counterparts, even the best ones, without a measurable increase in computational cost. The performance is validated on multiple architectures including dense nets, CNNs, ResNets, and the recurrent Differential Neural Computer on classical datasets MNIST, fashion MNIST, CIFAR10 and others.","Wed, 14 Feb 2018 12:47:37 UTC (1,419 KB)[v2] Thu, 15 Feb 2018 19:31:13 UTC (1,419 KB)[v3] Wed, 21 Feb 2018 18:51:03 UTC (1,501 KB)[v4] Tue, 5 Jun 2018 10:09:37 UTC (2,493 KB)"
"918","Molecular Structure Extraction From Documents Using Deep Learning","Joshua Staker, Kyle Marshall, Robert Abel, Carolyn McQuaw","Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)","Chemical structure extraction from documents remains a hard problem due to both false positive identification of structures during segmentation and errors in the predicted structures. Current approaches rely on handcrafted rules and subroutines that perform reasonably well generally, but still routinely encounter situations where recognition rates are not yet satisfactory and systematic improvement is challenging. Complications impacting performance of current approaches include the diversity in visual styles used by various software to render structures, the frequent use of ad hoc annotations, and other challenges related to image quality, including resolution and noise. We here present end-to-end deep learning solutions for both segmenting molecular structures from documents and for predicting chemical structures from these segmented images. This deep learning-based approach does not require any handcrafted features, is learned directly from data, and is robust against variations in image quality and style. Using the deep-learning approach described herein we show that it is possible to perform well on both segmentation and prediction of low resolution images containing moderately sized molecules found in journal articles and patents.","Wed, 14 Feb 2018 00:28:54 UTC (1,526 KB)"
"919","TVM: An Automated End-to-End Optimizing Compiler for Deep Learning","Tianqi Chen, Thierry Moreau, Ziheng Jiang, Lianmin Zheng, Eddie Yan, Meghan Cowan, Haichen Shen, Leyuan Wang, Yuwei Hu, Luis Ceze, Carlos Guestrin, Arvind Krishnamurthy","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Programming Languages (cs.PL)","There is an increasing need to bring machine learning to a wide diversity of hardware devices. Current frameworks rely on vendor-specific operator libraries and optimize for a narrow range of server-class GPUs. Deploying workloads to new platforms -- such as mobile phones, embedded devices, and accelerators (e.g., FPGAs, ASICs) -- requires significant manual effort. We propose TVM, a compiler that exposes graph-level and operator-level optimizations to provide performance portability to deep learning workloads across diverse hardware back-ends. TVM solves optimization challenges specific to deep learning, such as high-level operator fusion, mapping to arbitrary hardware primitives, and memory latency hiding. It also automates optimization of low-level programs to hardware characteristics by employing a novel, learning-based cost modeling method for rapid exploration of code optimizations. Experimental results show that TVM delivers performance across hardware back-ends that are competitive with state-of-the-art, hand-tuned libraries for low-power CPU, mobile GPU, and server-class GPUs. We also demonstrate TVM's ability to target new accelerator back-ends, such as the FPGA-based generic deep learning accelerator. The system is open sourced and in production use inside several major companies.","Mon, 12 Feb 2018 20:49:34 UTC (875 KB)[v2] Sun, 20 May 2018 18:44:40 UTC (956 KB)[v3] Fri, 5 Oct 2018 18:47:38 UTC (1,311 KB)"
"920","Quantifying Uncertainty in Discrete-Continuous and Skewed Data with Bayesian Deep Learning","Thomas Vandal, Evan Kodra, Jennifer Dy, Sangram Ganguly, Ramakrishna Nemani, Auroop R. Ganguly","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Deep Learning (DL) methods have been transforming computer vision with innovative adaptations to other domains including climate change. For DL to pervade Science and Engineering (S&E) applications where risk management is a core component, well-characterized uncertainty estimates must accompany predictions. However, S&E observations and model-simulations often follow heavily skewed distributions and are not well modeled with DL approaches, since they usually optimize a Gaussian, or Euclidean, likelihood loss. Recent developments in Bayesian Deep Learning (BDL), which attempts to capture uncertainties from noisy observations, aleatoric, and from unknown model parameters, epistemic, provide us a foundation. Here we present a discrete-continuous BDL model with Gaussian and lognormal likelihoods for uncertainty quantification (UQ). We demonstrate the approach by developing UQ estimates on `DeepSD', a super-resolution based DL model for Statistical Downscaling (SD) in climate applied to precipitation, which follows an extremely skewed distribution. We find that the discrete-continuous models outperform a basic Gaussian distribution in terms of predictive accuracy and uncertainty calibration. Furthermore, we find that the lognormal distribution, which can handle skewed distributions, produces quality uncertainty estimates at the extremes. Such results may be important across S&E, as well as other domains such as finance and economics, where extremes are often of significant interest. Furthermore, to our knowledge, this is the first UQ model in SD where both aleatoric and epistemic uncertainties are characterized.","Tue, 13 Feb 2018 17:07:13 UTC (2,136 KB)[v2] Thu, 24 May 2018 16:35:23 UTC (2,983 KB)"
"921","Deep Learning for Decoding of Linear Codes - A Syndrome-Based Approach","Amir Bennatan, Yoni Choukroun, Pavel Kisilev","Information Theory (cs.IT); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","We present a novel framework for applying deep neural networks (DNN) to soft decoding of linear codes at arbitrary block lengths. Unlike other approaches, our framework allows unconstrained DNN design, enabling the free application of powerful designs that were developed in other contexts. Our method is robust to overfitting that inhibits many competing methods, which follows from the exponentially large number of codewords required for their training. We achieve this by transforming the channel output before feeding it to the network, extracting only the syndrome of the hard decisions and the channel output reliabilities. We prove analytically that this approach does not involve any intrinsic performance penalty, and guarantees the generalization of performance obtained during training. Our best results are obtained using a recurrent neural network (RNN) architecture combined with simple preprocessing by permutation. We provide simulation results that demonstrate performance that sometimes approaches that of the ordered statistics decoding (OSD) algorithm.","Tue, 13 Feb 2018 17:06:40 UTC (1,452 KB)"
"922","Deep Learning with Apache SystemML","Niketan Pansare, Michael Dusenberry, Nakul Jindal, Matthias Boehm, Berthold Reinwald, Prithviraj Sen","Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC)","Enterprises operate large data lakes using Hadoop and Spark frameworks that (1) run a plethora of tools to automate powerful data preparation/transformation pipelines, (2) run on shared, large clusters to (3) perform many different analytics tasks ranging from model preparation, building, evaluation, and tuning for both machine learning and deep learning. Developing machine/deep learning models on data in such shared environments is challenging. Apache SystemML provides a unified framework for implementing machine learning and deep learning algorithms in a variety of shared deployment scenarios. SystemML's novel compilation approach automatically generates runtime execution plans for machine/deep learning algorithms that are composed of single-node and distributed runtime operations depending on data and cluster characteristics such as data size, data sparsity, cluster size, and memory configurations, while still exploiting the capabilities of the underlying big data frameworks.","Thu, 8 Feb 2018 23:54:37 UTC (9 KB)"
"923","Deceiving End-to-End Deep Learning Malware Detectors using Adversarial Examples","Felix Kreuk, Assi Barak, Shir Aviv-Reuven, Moran Baruch, Benny Pinkas, Joseph Keshet","Machine Learning (cs.LG); Cryptography and Security (cs.CR)","In recent years, deep learning has shown performance breakthroughs in many applications, such as image detection, image segmentation, pose estimation, and speech recognition. However, this comes with a major concern: deep networks have been found to be vulnerable to adversarial examples. Adversarial examples are slightly modified inputs that are intentionally designed to cause a misclassification by the model. In the domains of images and speech, the modifications are so small that they are not seen or heard by humans, but nevertheless greatly affect the classification of the model. Deep learning models have been successfully applied to malware detection. In this domain, generating adversarial examples is not straightforward, as small modifications to the bytes of the file could lead to significant changes in its functionality and validity. We introduce a novel loss function for generating adversarial examples specifically tailored for discrete input sets, such as executable bytes. We modify malicious binaries so that they would be detected as benign, while preserving their original functionality, by injecting a small sequence of bytes (payload) in the binary file. We applied this approach to an end-to-end convolutional deep learning malware detection model and show a high rate of detection evasion. Moreover, we show that our generated payload is robust enough to be transferable within different locations of the same file and across different files, and that its entropy is low and similar to that of benign data sections.","Tue, 13 Feb 2018 09:51:41 UTC (418 KB)[v2] Sun, 13 May 2018 09:12:55 UTC (216 KB)"
"924","Phased Microphone Array for Sound Source Localization with Deep Learning","Wei Ma, Xun Liu","Audio and Speech Processing (eess.AS); Sound (cs.SD)","To phased microphone array for sound source localization, algorithm with both high computational efficiency and high precision is a persistent pursuit. In this paper convolutional neural network (CNN) a kind of deep learning is preliminarily applied as a new algorithm. At high frequency CNN can reconstruct the sound localizations with excellent spatial resolution as good as DAMAS, within a very short time as short as conventional beamforming. This exciting result means that CNN perfectly finds source distribution directly from cross-spectral matrix without given propagation function in advance, and thus CNN deserves to be further explored as a new algorithm.","Tue, 13 Feb 2018 06:53:48 UTC (120 KB)"
"925","Deep Learning Models Delineates Multiple Nuclear Phenotypes in H&E Stained Histology Sections","Mina Khoshdeli, Bahram Parvin","Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)","Nuclear segmentation is an important step for profiling aberrant regions of histology sections. However, segmentation is a complex problem as a result of variations in nuclear geometry (e.g., size, shape), nuclear type (e.g., epithelial, fibroblast), and nuclear phenotypes (e.g., vesicular, aneuploidy). The problem is further complicated as a result of variations in sample preparation. It is shown and validated that fusion of very deep convolutional networks overcomes (i) complexities associated with multiple nuclear phenotypes, and (ii) separation of overlapping nuclei. The fusion relies on integrating of networks that learn region- and boundary-based representations. The system has been validated on a diverse set of nuclear phenotypes that correspond to the breast and brain histology sections.","Tue, 13 Feb 2018 01:50:38 UTC (2,325 KB)[v2] Wed, 14 Feb 2018 19:02:52 UTC (1,728 KB)"
"926","Deep learning based supervised semantic segmentation of Electron Cryo-Subtomograms","Chang Liu, Xiangrui Zeng, Ruogu Lin, Xiaodan Liang, Zachary Freyberg, Eric Xing, Min Xu","Quantitative Methods (q-bio.QM); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Cellular Electron Cryo-Tomography (CECT) is a powerful imaging technique for the 3D visualization of cellular structure and organization at submolecular resolution. It enables analyzing the native structures of macromolecular complexes and their spatial organization inside single cells. However, due to the high degree of structural complexity and practical imaging limitations, systematic macromolecular structural recovery inside CECT images remains challenging. Particularly, the recovery of a macromolecule is likely to be biased by its neighbor structures due to the high molecular crowding. To reduce the bias, here we introduce a novel 3D convolutional neural network inspired by Fully Convolutional Network and Encoder-Decoder Architecture for the supervised segmentation of macromolecules of interest in subtomograms. The tests of our models on realistically simulated CECT data demonstrate that our new approach has significantly improved segmentation performance compared to our baseline approach. Also, we demonstrate that the proposed model has generalization ability to segment new structures that do not exist in training data.","Mon, 12 Feb 2018 14:54:49 UTC (970 KB)"
"927","Supervised classification of Dermatological diseases by Deep learning","Sourav Mishra, Toshihiko Yamasaki, Hideaki Imaizumi","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","This paper introduces a deep-learning based efficient classifier for common dermatological conditions, aimed at people without easy access to skin specialists. We report approximately 80% accuracy, in a situation where primary care doctors have attained 57% success rate, according to recent literature. The rationale of its design is centered on deploying and updating it on handheld devices in near future. Dermatological diseases are common in every population and have a wide spectrum in severity. With a shortage of dermatological expertise being observed in several countries, machine learning solutions can augment medical services and advise regarding existence of common diseases. The paper implements supervised classification of nine distinct conditions which have high occurrence in East Asian countries. Our current attempt establishes that deep learning based techniques are viable avenues for preliminary information to aid patients.","Sun, 11 Feb 2018 15:34:20 UTC (1,113 KB)[v2] Thu, 17 May 2018 16:17:12 UTC (1,272 KB)[v3] Tue, 31 Jul 2018 17:23:02 UTC (1,176 KB)"
"928","Deep learning with t-exponential Bayesian kitchen sinks","Harris Partaourides, Sotirios Chatzis","Machine Learning (cs.LG); Machine Learning (stat.ML)","Bayesian learning has been recently considered as an effective means of accounting for uncertainty in trained deep network parameters. This is of crucial importance when dealing with small or sparse training datasets. On the other hand, shallow models that compute weighted sums of their inputs, after passing them through a bank of arbitrary randomized nonlinearities, have been recently shown to enjoy good test error bounds that depend on the number of nonlinearities. Inspired from these advances, in this paper we examine novel deep network architectures, where each layer comprises a bank of arbitrary nonlinearities, linearly combined using multiple alternative sets of weights. We effect model training by means of approximate inference based on a t-divergence measure; this generalizes the Kullback-Leibler divergence in the context of the t-exponential family of distributions. We adopt the t-exponential family since it can more flexibly accommodate real-world data, that entail outliers and distributions with fat tails, compared to conventional Gaussian model assumptions. We extensively evaluate our approach using several challenging benchmarks, and provide comparative results to related state-of-the-art techniques.","Sat, 10 Feb 2018 21:27:02 UTC (1,337 KB)"
"929","Generative ScatterNet Hybrid Deep Learning (G-SHDL) Network with Structural Priors for Semantic Image Segmentation","Amarjot Singh, Nick Kingsbury","Computer Vision and Pattern Recognition (cs.CV)","This paper proposes a generative ScatterNet hybrid deep learning (G-SHDL) network for semantic image segmentation. The proposed generative architecture is able to train rapidly from relatively small labeled datasets using the introduced structural priors. In addition, the number of filters in each layer of the architecture is optimized resulting in a computationally efficient architecture. The G-SHDL network produces state-of-the-art classification performance against unsupervised and semi-supervised learning on two image datasets. Advantages of the G-SHDL network over supervised methods are demonstrated with experiments performed on training datasets of reduced size.","Fri, 9 Feb 2018 18:19:51 UTC (939 KB)[v2] Tue, 13 Feb 2018 15:56:37 UTC (939 KB)"
"930","Deep Learning for Malicious Flow Detection","Yun-Chun Chen, Yu-Jhe Li, Aragorn Tseng, Tsungnan Lin","Machine Learning (cs.LG); Cryptography and Security (cs.CR); Machine Learning (stat.ML)","Cyber security has grown up to be a hot issue in recent years. How to identify potential malware becomes a challenging task. To tackle this challenge, we adopt deep learning approaches and perform flow detection on real data. However, real data often encounters an issue of imbalanced data distribution which will lead to a gradient dilution issue. When training a neural network, this problem will not only result in a bias toward the majority class but show the inability to learn from the minority classes. In this paper, we propose an end-to-end trainable Tree-Shaped Deep Neural Network (TSDNN) which classifies the data in a layer-wise manner. To better learn from the minority classes, we propose a Quantity Dependent Backpropagation (QDBP) algorithm which incorporates the knowledge of the disparity between classes. We evaluate our method on an imbalanced data set. Experimental result demonstrates that our approach outperforms the state-of-the-art methods and justifies that the proposed method is able to overcome the difficulty of imbalanced learning. We also conduct a partial flow experiment which shows the feasibility of real-time detection and a zero-shot learning experiment which justifies the generalization capability of deep learning in cyber security.","Fri, 9 Feb 2018 17:16:02 UTC (638 KB)"
"931","URLNet: Learning a URL Representation with Deep Learning for Malicious URL Detection","Hung Le, Quang Pham, Doyen Sahoo, Steven C.H. Hoi","Cryptography and Security (cs.CR); Machine Learning (cs.LG)","Malicious URLs host unsolicited content and are used to perpetrate cybercrimes. It is imperative to detect them in a timely manner. Traditionally, this is done through the usage of blacklists, which cannot be exhaustive, and cannot detect newly generated malicious URLs. To address this, recent years have witnessed several efforts to perform Malicious URL Detection using Machine Learning. The most popular and scalable approaches use lexical properties of the URL string by extracting Bag-of-words like features, followed by applying machine learning models such as SVMs. There are also other features designed by experts to improve the prediction performance of the model. These approaches suffer from several limitations: (i) Inability to effectively capture semantic meaning and sequential patterns in URL strings; (ii) Requiring substantial manual feature engineering; and (iii) Inability to handle unseen features and generalize to test data. To address these challenges, we propose URLNet, an end-to-end deep learning framework to learn a nonlinear URL embedding for Malicious URL Detection directly from the URL. Specifically, we apply Convolutional Neural Networks to both characters and words of the URL String to learn the URL embedding in a jointly optimized framework. This approach allows the model to capture several types of semantic information, which was not possible by the existing models. We also propose advanced word-embeddings to solve the problem of too many rare words observed in this task. We conduct extensive experiments on a large-scale dataset and show a significant performance gain over existing methods. We also conduct ablation studies to evaluate the performance of various components of URLNet.","Fri, 9 Feb 2018 08:07:13 UTC (1,682 KB)[v2] Fri, 2 Mar 2018 03:42:49 UTC (975 KB)"
"932","PoTrojan: powerful neural-level trojan designs in deep learning models","Minhui Zou, Yang Shi, Chengliang Wang, Fangyu Li, WenZhan Song, Yu Wang","Cryptography and Security (cs.CR); Machine Learning (cs.LG)","With the popularity of deep learning (DL), artificial intelligence (AI) has been applied in many areas of human life. Neural network or artificial neural network (NN), the main technique behind DL, has been extensively studied to facilitate computer vision and natural language recognition. However, the more we rely on information technology, the more vulnerable we are. That is, malicious NNs could bring huge threat in the so-called coming AI era. In this paper, for the first time in the literature, we propose a novel approach to design and insert powerful neural-level trojans or PoTrojan in pre-trained NN models. Most of the time, PoTrojans remain inactive, not affecting the normal functions of their host NN models. PoTrojans could only be triggered in very rare conditions. Once activated, however, the PoTrojans could cause the host NN models to malfunction, either falsely predicting or classifying, which is a significant threat to human society of the AI era. We would explain the principles of PoTrojans and the easiness of designing and inserting them in pre-trained deep learning models. PoTrojans doesn't modify the existing architecture or parameters of the pre-trained models, without re-training. Hence, the proposed method is very efficient.","Thu, 8 Feb 2018 20:44:41 UTC (3,806 KB)"
"933","A deep learning approach to identify local structures in atomic-resolution transmission electron microscopy images","Jacob Madsen, Pei Liu, Jens Kling, Jakob Birkedal Wagner, Thomas Willum Hansen, Ole Winther, Jakob Schitz","Materials Science (cond-mat.mtrl-sci)","Recording atomic-resolution transmission electron microscopy (TEM) images is becoming increasingly routine. A new bottleneck is then analyzing this information, which often involves time-consuming manual structural identification. We have developed a deep learning-based algorithm for recognition of the local structure in TEM images, which is stable to microscope parameters and noise. The neural network is trained entirely from simulation but is capable of making reliable predictions on experimental images. We apply the method to single sheets of defected graphene, and to metallic nanoparticles on an oxide support.","Thu, 8 Feb 2018 18:57:20 UTC (8,346 KB)[v2] Fri, 9 Feb 2018 10:43:02 UTC (8,346 KB)"
"934","TSViz: Demystification of Deep Learning Models for Time-Series Analysis","Shoaib Ahmed Siddiqui, Dominik Mercier, Mohsin Munir, Andreas Dengel, Sheraz Ahmed","Computer Vision and Pattern Recognition (cs.CV)","This paper presents a novel framework for demystification of convolutional deep learning models for time series analysis. This is a step towards making informed/explainable decisions in the domain of time series, powered by deep learning. There have been numerous efforts to increase the interpretability of image-centric deep neural network models, where the learned features are more intuitive to visualize. Visualization in time-series is much more complicated as there is no direct interpretation of the filters and inputs as compared to image modality. In addition, little or no concentration has been devoted for the development of such tools in the domain of time-series in the past. The visualization engine of the presented framework provides possibilities to explore and analyze a network from different dimensions at four different levels of abstraction. This enables the user to uncover different aspects of the model which includes important filters, filter clusters, and input saliency maps. These representations allow to understand the network features so that the acceptability of deep networks for time-series data can be enhanced. This is extremely important in domains like finance, industry 4.0, self-driving cars, health-care, counter-terrorism etc., where reasons for reaching a particular prediction are equally important as the prediction itself. The framework \footnote{Framework download link: this https URL} can also aid in discovery of the filters which are contributing nothing to the final prediction, hence, can be pruned without any significant loss in performance.","Thu, 8 Feb 2018 16:29:49 UTC (2,281 KB)"
"935","Polisis: Automated Analysis and Presentation of Privacy Policies Using Deep Learning","Hamza Harkous, Kassem Fawaz, Remi Lebret, Florian Schaub, Kang G. Shin, Karl Aberer","Computation and Language (cs.CL); Cryptography and Security (cs.CR); Human-Computer Interaction (cs.HC)","Privacy policies are the primary channel through which companies inform users about their data collection and sharing practices. These policies are often long and difficult to comprehend. Short notices based on information extracted from privacy policies have been shown to be useful but face a significant scalability hurdle, given the number of policies and their evolution over time. Companies, users, researchers, and regulators still lack usable and scalable tools to cope with the breadth and depth of privacy policies. To address these hurdles, we propose an automated framework for privacy policy analysis (Polisis). It enables scalable, dynamic, and multi-dimensional queries on natural language privacy policies. At the core of Polisis is a privacy-centric language model, built with 130K privacy policies, and a novel hierarchy of neural-network classifiers that accounts for both high-level aspects and fine-grained details of privacy practices. We demonstrate Polisis' modularity and utility with two applications supporting structured and free-form querying. The structured querying application is the automated assignment of privacy icons from privacy policies. With Polisis, we can achieve an accuracy of 88.4% on this task. The second application, PriBot, is the first freeform question-answering system for privacy policies. We show that PriBot can produce a correct answer among its top-3 results for 82% of the test questions. Using an MTurk user study with 700 participants, we show that at least one of PriBot's top-3 answers is relevant to users for 89% of the test questions.","Wed, 7 Feb 2018 18:36:38 UTC (2,647 KB)[v2] Fri, 29 Jun 2018 09:27:17 UTC (5,641 KB)"
"936","A Spatial Mapping Algorithm with Applications in Deep Learning-Based Structure Classification","Thomas Corcoran, Rafael Zamora-Resendiz, Xinlian Liu, Silvia Crivelli","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Convolutional Neural Network (CNN)-based machine learning systems have made breakthroughs in feature extraction and image recognition tasks in two dimensions (2D). Although there is significant ongoing work to apply CNN technology to domains involving complex 3D data, the success of such efforts has been constrained, in part, by limitations in data representation techniques. Most current approaches rely upon low-resolution 3D models, strategic limitation of scope in the 3D space, or the application of lossy projection techniques to allow for the use of 2D CNNs. To address this issue, we present a mapping algorithm that converts 3D structures to 2D and 1D data grids by mapping a traversal of a 3D space-filling curve to the traversal of corresponding 2D and 1D curves. We explore the performance of 2D and 1D CNNs trained on data encoded with our method versus comparable volumetric CNNs operating upon raw 3D data from a popular benchmarking dataset. Our experiments demonstrate that both 2D and 1D representations of 3D data generated via our method preserve a significant proportion of the 3D data's features in forms learnable by CNNs. Furthermore, we demonstrate that our method of encoding 3D data into lower-dimensional representations allows for decreased CNN training time cost, increased original 3D model rendering resolutions, and supports increased numbers of data channels when compared to purely volumetric approaches. This demonstration is accomplished in the context of a structural biology classification task wherein we train 3D, 2D, and 1D CNNs on examples of two homologous branches within the Ras protein family. The essential contribution of this paper is the introduction of a dimensionality-reduction method that may ease the application of powerful deep learning tools to domains characterized by complex structural data.","Wed, 7 Feb 2018 17:18:33 UTC (2,811 KB)[v2] Thu, 22 Feb 2018 20:38:14 UTC (2,811 KB)"
"937","A Novel Co-design Peta-scale Heterogeneous Cluster for Deep Learning Training","Xin Chen, Hua Zhou, Yuxiang Gao, Yu Zhu","Computer Vision and Pattern Recognition (cs.CV)","Large scale deep Convolution Neural Networks (CNNs) increasingly demands the computing power. It is key for researchers to own a great powerful computing platform to leverage deep learning (DL) advancing.On the other hand, as the commonly-used accelerator, the commodity GPUs cards of new generations are more and more expensive. Consequently, it is of importance to design an affordable distributed heterogeneous system that provides powerful computational capacity and develop a well-suited software that efficiently utilizes its computational capacity. In this paper, we present our co-design distributed system including a peta-scale GPU cluster, called ""Manoa"". Based on properties and topology of Manoa, we first propose job server framework and implement it, named ""MiMatrix"". The central node of MiMatrix, referred to as the job server, undertakes all of controlling, scheduling and monitoring, and I/O tasks without weight data transfer for AllReduce processing in each iteration. Therefore, MiMatrix intrinsically solves the bandwidth bottleneck of central node in parameter server framework that is widely used in distributed DL tasks. Meanwhile, we also propose a new AllReduce algorithm, GPUDirect RDMA-Aware AllReduce~(GDRAA), in which both computation and handshake message are O(1) and the number of synchronization is two in each iteration that is a theoretical minimum number. Owe to the dedicated co-design distributed system, MiMatrix efficiently makes use of the Manoa's computational capacity and bandwidth. We benchmark Manoa Resnet50 and Resenet101 on Imagenet-1K dataset. Some of results have demonstrated state-of-the-art.","Wed, 7 Feb 2018 07:20:42 UTC (606 KB)[v2] Mon, 16 Apr 2018 05:25:06 UTC (1,289 KB)[v3] Fri, 18 May 2018 23:01:23 UTC (1,320 KB)"
"938","An Empirical Evaluation of Deep Learning for ICD-9 Code Assignment using MIMIC-III Clinical Notes","Jinmiao Huang, Cesar Osorio, Luke Wicent Sy","Computation and Language (cs.CL)","Code assignment is important on many levels in the modern hospital, from ensuring accurate billing process to creating a valid record of patient care history. However, the coding process is tedious, subjective, and requires medical coders with extensive training. The objective of this study is to evaluate the performance of deep learning based systems to automatically map clinical notes to medical codes. We applied the state-of-the-art deep learning methods such as Recurrent Neural Networks and Convolution Neural Networks on MIMIC-III dataset. Experiments show that the deep-learning-based methods outperform other conventional machine learning methods. Our evaluations are focused on end-to-end learning methods without manually defined rules. From our evaluations, the best models are able to predict the top 10 ICD-9 codes with 69.57% F1 and 89.67% accuracy; the top 10 ICD-9 categories with 72.33% F1 and 85.88% accuracy.","Wed, 7 Feb 2018 05:23:21 UTC (1,939 KB)"
"939","Object Detection on Dynamic Occupancy Grid Maps Using Deep Learning and Automatic Label Generation","Stefan Hoermann, Philipp Henzler, Martin Bach, Klaus Dietmayer","Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","We tackle the problem of object detection and pose estimation in a shared space downtown environment. For perception multiple laser scanners with 360‘ coverage were fused in a dynamic occupancy grid map (DOGMa). A single-stage deep convolutional neural network is trained to provide object hypotheses comprising of shape, position, orientation and an existence score from a single input DOGMa. Furthermore, an algorithm for offline object extraction was developed to automatically label several hours of training data. The algorithm is based on a two-pass trajectory extraction, forward and backward in time. Typical for engineered algorithms, the automatic label generation suffers from misdetections, which makes hard negative mining impractical. Therefore, we propose a loss function counteracting the high imbalance between mostly static background and extremely rare dynamic grid cells. Experiments indicate, that the trained network has good generalization capabilities since it detects objects occasionally lost by the label algorithm. Evaluation reaches an average precision (AP) of 75.9%","Tue, 30 Jan 2018 08:18:31 UTC (3,707 KB)"
"940","Compressive Light Field Reconstructions using Deep Learning","Mayank Gupta, Arjun Jauhari, Kuldeep Kulkarni, Suren Jayasuriya, Alyosha Molnar, Pavan Turaga","Computer Vision and Pattern Recognition (cs.CV)","Light field imaging is limited in its computational processing demands of high sampling for both spatial and angular dimensions. Single-shot light field cameras sacrifice spatial resolution to sample angular viewpoints, typically by multiplexing incoming rays onto a 2D sensor array. While this resolution can be recovered using compressive sensing, these iterative solutions are slow in processing a light field. We present a deep learning approach using a new, two branch network architecture, consisting jointly of an autoencoder and a 4D CNN, to recover a high resolution 4D light field from a single coded 2D image. This network decreases reconstruction time significantly while achieving average PSNR values of 26-32 dB on a variety of light fields. In particular, reconstruction time is decreased from 35 minutes to 6.7 minutes as compared to the dictionary method for equivalent visual quality. These reconstructions are performed at small sampling/compression ratios as low as 8%, allowing for cheaper coded light field cameras. We test our network reconstructions on synthetic light fields, simulated coded measurements of real light fields captured from a Lytro Illum camera, and real coded images from a custom CMOS diffractive light field camera. The combination of compressive light field capture with deep learning allows the potential for real-time light field video acquisition systems in the future.","Mon, 5 Feb 2018 23:00:47 UTC (8,117 KB)"
"941","Deep Learning with a Rethinking Structure for Multi-label Classification","Yao-Yuan Yang, Yi-An Lin, Hong-Min Chu, Hsuan-Tien Lin","Machine Learning (cs.LG); Machine Learning (stat.ML)","Multi-label classification (MLC) is an important learning problem that expects the learning algorithm to take the hidden correlation of the labels into account. Extracting the hidden correlation is generally a challenging task. In this work, we propose a novel deep learning framework to better extract the hidden correlation with the help of the memory structure within recurrent neural networks. The memory stores the temporary guesses on the labels and effectively allows the framework to rethink about the goodness and correlation of the guesses before making the final prediction. Furthermore, the rethinking process makes it easy to adapt to different evaluation criterion to match real-world application needs. Experimental results across many real-world data sets justify that the rethinking process indeed improves MLC performance across different evaluation criteria and leads to superior performance over state-of-the-art MLC algorithms.","Mon, 5 Feb 2018 21:27:59 UTC (171 KB)"
"942","The Matrix Calculus You Need For Deep Learning","Terence Parr, Jeremy Howard","Machine Learning (cs.LG); Machine Learning (stat.ML)","This paper is an attempt to explain all the matrix calculus you need in order to understand the training of deep neural networks. We assume no math knowledge beyond what you learned in calculus 1, and provide links to help you refresh the necessary math where needed. Note that you do not need to understand this material before you start learning to train and use deep learning in practice; rather, this material is for those who are already familiar with the basics of neural networks, and wish to deepen their understanding of the underlying math. Don't worry if you get stuck at some point along the way---just go back and reread the previous section, and try writing down and working through some examples. And if you're still stuck, we're happy to answer your questions in the Theory category at forums.fast.ai. Note: There is a reference section at the end of the paper summarizing all the key matrix calculus rules and terminology discussed here. See related articles at this http URL","Mon, 5 Feb 2018 17:37:59 UTC (434 KB)[v2] Tue, 6 Feb 2018 17:35:28 UTC (439 KB)[v3] Mon, 2 Jul 2018 17:36:34 UTC (439 KB)"
"943","To understand deep learning we need to understand kernel learning","Mikhail Belkin, Siyuan Ma, Soumik Mandal","Machine Learning (stat.ML); Machine Learning (cs.LG)","Generalization performance of classifiers in deep learning has recently become a subject of intense study. Deep models, typically over-parametrized, tend to fit the training data exactly. Despite this ""overfitting"", they perform well on test data, a phenomenon not yet fully understood. The first point of our paper is that strong performance of overfitted classifiers is not a unique feature of deep learning. Using six real-world and two synthetic datasets, we establish experimentally that kernel machines trained to have zero classification or near zero regression error perform very well on test data, even when the labels are corrupted with a high level of noise. We proceed to give a lower bound on the norm of zero loss solutions for smooth kernels, showing that they increase nearly exponentially with data size. We point out that this is difficult to reconcile with the existing generalization bounds. Moreover, none of the bounds produce non-trivial results for interpolating solutions. Second, we show experimentally that (non-smooth) Laplacian kernels easily fit random labels, a finding that parallels results for ReLU neural networks. In contrast, fitting noisy data requires many more epochs for smooth Gaussian kernels. Similar performance of overfitted Laplacian and Gaussian classifiers on test, suggests that generalization is tied to the properties of the kernel function rather than the optimization process. Certain key phenomena of deep learning are manifested similarly in kernel methods in the modern ""overfitted"" regime. The combination of the experimental and theoretical results presented in this paper indicates a need for new theoretical ideas for understanding properties of classical kernel methods. We argue that progress on understanding deep learning will be difficult until more tractable ""shallow"" kernel methods are better understood.","Mon, 5 Feb 2018 14:14:28 UTC (1,932 KB)[v2] Tue, 6 Feb 2018 18:19:04 UTC (1,960 KB)[v3] Thu, 14 Jun 2018 21:25:54 UTC (2,478 KB)"
"944","Deep Learning-based Channel Estimation for Beamspace mmWave Massive MIMO Systems","Hengtao He, Chao-Kai Wen, Shi Jin, Geoffrey Ye Li","Information Theory (cs.IT)","Channel estimation is very challenging when the receiver is equipped with a limited number of radio-frequency (RF) chains in beamspace millimeter-wave (mmWave) massive multiple-input and multiple-output systems. To solve this problem, we exploit a learned denoising-based approximate message passing (LDAMP) network. This neural network can learn channel structure and estimate channel from a large number of training data. Furthermore, we provide an analytical framework on the asymptotic performance of the channel estimator. Based on our analysis and simulation results, the LDAMP neural network significantly outperforms state-of-the-art compressed sensingbased algorithms even when the receiver is equipped with a small number of RF chains. Therefore, deep learning is a powerful tool for channel estimation in mmWave communications.","Mon, 5 Feb 2018 07:31:44 UTC (359 KB)"
"945","Non-Gaussian information from weak lensing data via deep learning","Arushi Gupta, Jose Manuel Zorrilla Matilla, Daniel Hsu, Zoltan Haiman","Cosmology and Nongalactic Astrophysics (astro-ph.CO); Machine Learning (cs.LG); Machine Learning (stat.ML)","Weak lensing maps contain information beyond two-point statistics on small scales. Much recent work has tried to extract this information through a range of different observables or via nonlinear transformations of the lensing field. Here we train and apply a 2D convolutional neural network to simulated noiseless lensing maps covering 96 different cosmological models over a range of {$ヘ_m,ヲ_8$}. Using the area of the confidence contour in the {$ヘ_m,ヲ_8$} plane as a figure-of-merit, derived from simulated convergence maps smoothed on a scale of 1.0 arcmin, we show that the neural network yields $\approx 5 \times$ tighter constraints than the power spectrum, and $\approx 4 \times$ tighter than the lensing peaks. Such gains illustrate the extent to which weak lensing data encode cosmological information not accessible to the power spectrum or even other, non-Gaussian statistics such as lensing peaks.","Sun, 4 Feb 2018 22:40:17 UTC (1,578 KB)[v2] Tue, 6 Feb 2018 02:58:07 UTC (1,578 KB)[v3] Tue, 1 May 2018 10:43:32 UTC (1,263 KB)"
"946","Deep Learning Framework for Multi-class Breast Cancer Histology Image Classification","Yeeleng S. Vang, Zhen Chen, Xiaohui Xie","Computer Vision and Pattern Recognition (cs.CV)","In this work, we present a deep learning framework for multi-class breast cancer image classification as our submission to the International Conference on Image Analysis and Recognition (ICIAR) 2018 Grand Challenge on BreAst Cancer Histology images (BACH). As these histology images are too large to fit into GPU memory, we first propose using Inception V3 to perform patch level classification. The patch level predictions are then passed through an ensemble fusion framework involving majority voting, gradient boosting machine (GBM), and logistic regression to obtain the image level prediction. We improve the sensitivity of the Normal and Benign predicted classes by designing a Dual Path Network (DPN) to be used as a feature extractor where these extracted features are further sent to a second layer of ensemble prediction fusion using GBM, logistic regression, and support vector machine (SVM) to refine predictions. Experimental results demonstrate our framework shows a 12.5$\%$ improvement over the state-of-the-art model.","Sat, 3 Feb 2018 07:13:02 UTC (7,301 KB)"
"947","Deep Learning for Genomics: A Concise Overview","Tianwei Yue, Haohan Wang","Genomics (q-bio.GN); Machine Learning (cs.LG)","Advancements in genomic research such as high-throughput sequencing techniques have driven modern genomic studies into ""big data"" disciplines. This data explosion is constantly challenging conventional methods used in genomics. In parallel with the urgent demand for robust algorithms, deep learning has succeeded in a variety of fields such as vision, speech, and text processing. Yet genomics entails unique challenges to deep learning since we are expecting from deep learning a superhuman intelligence that explores beyond our knowledge to interpret the genome. A powerful deep learning model should rely on insightful utilization of task-specific knowledge. In this paper, we briefly discuss the strengths of different deep learning models from a genomic perspective so as to fit each particular task with a proper deep architecture, and remark on practical considerations of developing modern deep learning architectures for genomics. We also provide a concise review of deep learning applications in various aspects of genomic research, as well as pointing out potential opportunities and obstacles for future genomics applications.","Fri, 2 Feb 2018 12:50:25 UTC (57 KB)[v2] Tue, 8 May 2018 15:23:01 UTC (67 KB)"
"948","Handwritten Isolated Bangla Compound Character Recognition: a new benchmark using a novel deep learning approach","Saikat Roy, Nibaran Das, Mahantapas Kundu, Mita Nasipuri","Computer Vision and Pattern Recognition (cs.CV)","In this work, a novel deep learning technique for the recognition of handwritten Bangla isolated compound character is presented and a new benchmark of recognition accuracy on the CMATERdb 3.1.3.3 dataset is reported. Greedy layer wise training of Deep Neural Network has helped to make significant strides in various pattern recognition problems. We employ layerwise training to Deep Convolutional Neural Networks (DCNN) in a supervised fashion and augment the training process with the RMSProp algorithm to achieve faster convergence. We compare results with those obtained from standard shallow learning methods with predefined features, as well as standard DCNNs. Supervised layerwise trained DCNNs are found to outperform standard shallow learning models such as Support Vector Machines as well as regular DCNNs of similar architecture by achieving error rate of 9.67% thereby setting a new benchmark on the CMATERdb 3.1.3.3 with recognition accuracy of 90.33%, representing an improvement of nearly 10%.","Fri, 2 Feb 2018 13:06:43 UTC (557 KB)"
"949","Visual Interpretability for Deep Learning: a Survey","Quanshi Zhang, Song-Chun Zhu","Computer Vision and Pattern Recognition (cs.CV)","This paper reviews recent studies in understanding neural-network representations and learning neural networks with interpretable/disentangled middle-layer representations. Although deep neural networks have exhibited superior performance in various tasks, the interpretability is always the Achilles' heel of deep neural networks. At present, deep neural networks obtain high discrimination power at the cost of low interpretability of their black-box representations. We believe that high model interpretability may help people to break several bottlenecks of deep learning, e.g., learning from very few annotations, learning via human-computer communications at the semantic level, and semantically debugging network representations. We focus on convolutional neural networks (CNNs), and we revisit the visualization of CNN representations, methods of diagnosing representations of pre-trained CNNs, approaches for disentangling pre-trained CNN representations, learning of CNNs with disentangled representations, and middle-to-end learning based on model interpretability. Finally, we discuss prospective trends in explainable artificial intelligence.","Fri, 2 Feb 2018 09:39:40 UTC (7,567 KB)[v2] Wed, 7 Feb 2018 08:02:59 UTC (7,567 KB)"
"950","A Unified Deep Learning Architecture for Abuse Detection","Antigoni-Maria Founta, Despoina Chatzakou, Nicolas Kourtellis, Jeremy Blackburn, Athena Vakali, Ilias Leontiadis","Computation and Language (cs.CL); Social and Information Networks (cs.SI)","Hate speech, offensive language, sexism, racism and other types of abusive behavior have become a common phenomenon in many online social media platforms. In recent years, such diverse abusive behaviors have been manifesting with increased frequency and levels of intensity. This is due to the openness and willingness of popular media platforms, such as Twitter and Facebook, to host content of sensitive or controversial topics. However, these platforms have not adequately addressed the problem of online abusive behavior, and their responsiveness to the effective detection and blocking of such inappropriate behavior remains limited. In the present paper, we study this complex problem by following a more holistic approach, which considers the various aspects of abusive behavior. To make the approach tangible, we focus on Twitter data and analyze user and textual properties from different angles of abusive posting behavior. We propose a deep learning architecture, which utilizes a wide variety of available metadata, and combines it with automatically-extracted hidden patterns within the text of the tweets, to detect multiple abusive behavioral norms which are highly inter-related. We apply this unified architecture in a seamless, transparent fashion to detect different types of abusive behavior (hate speech, sexism vs. racism, bullying, sarcasm, etc.) without the need for any tuning of the model architecture for each task. We test the proposed approach with multiple datasets addressing different and multiple abusive behaviors on Twitter. Our results demonstrate that it largely outperforms the state-of-art methods (between 21 and 45\% improvement in AUC, depending on the dataset).","Thu, 1 Feb 2018 16:48:39 UTC (98 KB)[v2] Wed, 21 Feb 2018 14:19:57 UTC (93 KB)"
"951","Deep Learning of Constrained Autoencoders for Enhanced Understanding of Data","Babajide O. Ayinde, Jacek M. Zurada","Machine Learning (cs.LG)","Unsupervised feature extractors are known to perform an efficient and discriminative representation of data. Insight into the mappings they perform and human ability to understand them, however, remain very limited. This is especially prominent when multilayer deep learning architectures are used. This paper demonstrates how to remove these bottlenecks within the architecture of Nonnegativity Constrained Autoencoder (NCSAE). It is shown that by using both L1 and L2 regularization that induce nonnegativity of weights, most of the weights in the network become constrained to be nonnegative thereby resulting into a more understandable structure with minute deterioration in classification accuracy. Also, this proposed approach extracts features that are more sparse and produces additional output layer sparsification. The method is analyzed for accuracy and feature interpretation on the MNIST data, the NORB normalized uniform object data, and the Reuters text categorization dataset.","Wed, 31 Jan 2018 02:32:40 UTC (3,828 KB)[v2] Sat, 3 Feb 2018 18:25:16 UTC (3,828 KB)"
"952","Deep Learning Works in Practice. But Does it Work in Theory?","Le Nguyen Hoang, Rachid Guerraoui","Artificial Intelligence (cs.AI)","Deep learning relies on a very specific kind of neural networks: those superposing several neural layers. In the last few years, deep learning achieved major breakthroughs in many tasks such as image analysis, speech recognition, natural language processing, and so on. Yet, there is no theoretical explanation of this success. In particular, it is not clear why the deeper the network, the better it actually performs. We argue that the explanation is intimately connected to a key feature of the data collected from our surrounding universe to feed the machine learning algorithms: large non-parallelizable logical depth. Roughly speaking, we conjecture that the shortest computational descriptions of the universe are algorithms with inherently large computation times, even when a large number of computers are available for parallelization. Interestingly, this conjecture, combined with the folklore conjecture in theoretical computer science that $ P \neq NC$, explains the success of deep learning.","Wed, 31 Jan 2018 13:12:30 UTC (528 KB)"
"953","ConvCSNet: A Convolutional Compressive Sensing Framework Based on Deep Learning","Xiaotong Lu, Weisheng Dong, Peiyao Wang, Guangming Shi, Xuemei Xie","Computer Vision and Pattern Recognition (cs.CV)","Compressive sensing (CS), aiming to reconstruct an image/signal from a small set of random measurements has attracted considerable attentions in recent years. Due to the high dimensionality of images, previous CS methods mainly work on image blocks to avoid the huge requirements of memory and computation, i.e., image blocks are measured with Gaussian random matrices, and the whole images are recovered from the reconstructed image blocks. Though efficient, such methods suffer from serious blocking artifacts. In this paper, we propose a convolutional CS framework that senses the whole image using a set of convolutional filters. Instead of reconstructing individual blocks, the whole image is reconstructed from the linear convolutional measurements. Specifically, the convolutional CS is implemented based on a convolutional neural network (CNN), which performs both the convolutional CS and nonlinear reconstruction. Through end-to-end training, the sensing filters and the reconstruction network can be jointly optimized. To facilitate the design of the CS reconstruction network, a novel two-branch CNN inspired from a sparsity-based CS reconstruction model is developed. Experimental results show that the proposed method substantially outperforms previous state-of-the-art CS methods in term of both PSNR and visual quality.","Wed, 31 Jan 2018 08:22:53 UTC (1,673 KB)"
"954","Deep Learning based Retinal OCT Segmentation","Mike Pekala, Neil Joshi, David E. Freund, Neil M. Bressler, Delia Cabrera DeBuc, Philippe M Burlina","Computer Vision and Pattern Recognition (cs.CV)","Our objective is to evaluate the efficacy of methods that use deep learning (DL) for the automatic fine-grained segmentation of optical coherence tomography (OCT) images of the retina. OCT images from 10 patients with mild non-proliferative diabetic retinopathy were used from a public (U. of Miami) dataset. For each patient, five images were available: one image of the fovea center, two images of the perifovea, and two images of the parafovea. For each image, two expert graders each manually annotated five retinal surfaces (i.e. boundaries between pairs of retinal layers). The first grader's annotations were used as ground truth and the second grader's annotations to compute inter-operator agreement. The proposed automated approach segments images using fully convolutional networks (FCNs) together with Gaussian process (GP)-based regression as a post-processing step to improve the quality of the estimates. Using 10-fold cross validation, the performance of the algorithms is determined by computing the per-pixel unsigned error (distance) between the automated estimates and the ground truth annotations generated by the first manual grader. We compare the proposed method against five state of the art automatic segmentation techniques. The results show that the proposed methods compare favorably with state of the art techniques, resulting in the smallest mean unsigned error values and associated standard deviations, and performance is comparable with human annotation of retinal layers from OCT when there is only mild retinopathy. The results suggest that semantic segmentation using FCNs, coupled with regression-based post-processing, can effectively solve the OCT segmentation problem on par with human capabilities with mild retinopathy.","Mon, 29 Jan 2018 20:44:40 UTC (603 KB)"
"955","Denoising Arterial Spin Labeling Cerebral Blood Flow Images Using Deep Learning","Danfeng Xie, Li Bai, Ze Wang","Computer Vision and Pattern Recognition (cs.CV)","Arterial spin labeling perfusion MRI is a noninvasive technique for measuring quantitative cerebral blood flow (CBF), but the measurement is subject to a low signal-to-noise-ratio(SNR). Various post-processing methods have been proposed to denoise ASL MRI but only provide moderate improvement. Deep learning (DL) is an emerging technique that can learn the most representative signal from data without prior modeling which can be highly complex and analytically indescribable. The purpose of this study was to assess whether the record breaking performance of DL can be translated into ASL MRI denoising. We used convolutional neural network (CNN) to build the DL ASL denosing model (DL-ASL) to inherently consider the inter-voxel correlations. To better guide DL-ASL training, we incorporated prior knowledge about ASL MRI: the structural similarity between ASL CBF map and grey matter probability map. A relatively large sample data were used to train the model which was subsequently applied to a new set of data for testing. Experimental results showed that DL-ASL achieved state-of-the-art denoising performance for ASL MRI as compared to current routine methods in terms of higher SNR, keeping CBF quantification quality while shorten the acquisition time by 75%, and automatic partial volume correction.","Mon, 29 Jan 2018 20:54:29 UTC (60 KB)"
"956","Deep-STORM: super-resolution single-molecule microscopy by deep learning","Elias Nehme (1 and 2), Lucien E. Weiss (2), Tomer Michaeli (1), Yoav Shechtman (2) ((1) Department of Electrical Engineering, Technion, Haifa, Israel (2) Department of Biomedical Engineering, Technion, Haifa, Israel)","Optics (physics.optics)","We present an ultra-fast, precise, parameter-free method, which we term Deep-STORM, for obtaining super-resolution images from stochastically-blinking emitters, such as fluorescent molecules used for localization microscopy. Deep-STORM uses a deep convolutional neural network that can be trained on simulated data or experimental measurements, both of which are demonstrated. The method achieves state-of-the-art resolution under challenging signal-to-noise conditions and high emitter densities, and is significantly faster than existing approaches. Additionally, no prior information on the shape of the underlying structure is required, making the method applicable to any blinking data-set. We validate our approach by super-resolution image reconstruction of simulated and experimentally obtained data.","Mon, 29 Jan 2018 17:13:59 UTC (2,519 KB)[v2] Tue, 27 Feb 2018 14:58:50 UTC (6,935 KB)[v3] Wed, 2 May 2018 10:01:46 UTC (7,588 KB)"
"957","Deep Learning Approach for Very Similar Objects Recognition Application on Chihuahua and Muffin Problem","Enkhtogtokh Togootogtokh, Amarzaya Amartuvshin","Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","We address the problem to tackle the very similar objects like Chihuahua or muffin problem to recognize at least in human vision level. Our regular deep structured machine learning still does not solve it. We saw many times for about year in our community the problem. Today we proposed the state-of-the-art solution for it. Our approach is quite tricky to get the very high accuracy. We propose the deep transfer learning method which could be tackled all this type of problems not limited to just Chihuahua or muffin problem. It is the best method to train with small data set not like require huge amount data.","Mon, 29 Jan 2018 15:25:49 UTC (2,111 KB)"
"958","Deep Learning Angiography (DLA): Three-dimensional C-arm Cone Beam CT Angiography Using Deep Learning","Juan C. Montoya, Yinsheng Li, Charles Strother, Guang-Hong Chen","Image and Video Processing (eess.IV); Machine Learning (cs.LG); Medical Physics (physics.med-ph)","Background and Purpose: Our purpose was to develop a deep learning angiography (DLA) method to generate 3D cerebral angiograms from a single contrast-enhanced acquisition. Material and Methods: Under an approved IRB protocol 105 3D-DSA exams were randomly selected from an internal database. All were acquired using a clinical system (Axiom Artis zee, Siemens Healthineers) in conjunction with a standard injection protocol. More than 150 million labeled voxels from 35 subjects were used for training. A deep convolutional neural network was trained to classify each image voxel into three tissue types (vasculature, bone and soft tissue). The trained DLA model was then applied for tissue classification in a validation cohort of 8 subjects and a final testing cohort consisting of the remaining 62 subjects. The final vasculature tissue class was used to generate the 3D-DLA images. To quantify the generalization error of the trained model, accuracy, sensitivity, precision and F1-scores were calculated for vasculature classification in relevant anatomy. The 3D-DLA and clinical 3D-DSA images were subject to a qualitative assessment for the presence of inter-sweep motion artifacts. Results: Vasculature classification accuracy and 95% CI in the testing dataset was 98.7% ([98.3, 99.1] %). No residual signal from osseous structures was observed for all 3D-DLA testing cases except for small regions in the otic capsule and nasal cavity compared to 37% (23/62) of the 3D-DSAs. Conclusion: DLA accurately recreated the vascular anatomy of the 3D-DSA reconstructions without mask. DLA reduced mis-registration artifacts induced by inter-sweep motion. DLA reduces radiation exposure required to obtain clinically useful 3D-DSA","Fri, 26 Jan 2018 15:54:11 UTC (4,361 KB)"
"959","Social Influence (Deep) Learning for Human Behavior Prediction","Luca Luceri, Torsten Braun, Silvia Giordano","Social and Information Networks (cs.SI)","Influence propagation in social networks has recently received large interest. In fact, the understanding of how influence propagates among subjects in a social network opens the way to a growing number of applications. Many efforts have been made to quantitatively measure the influence probability between pairs of subjects. Existing approaches have two main drawbacks: (i) they assume that the influence probabilities are independent of each other, and (ii) they do not consider the actions not performed by the subject (but performed by her/his friends) to learn these probabilities. In this paper, we propose to address these limitations by employing a deep learning approach. We introduce a Deep Neural Network (DNN) framework that has the capability for both modeling social influence and for predicting human behavior. To empirically validate the proposed framework, we conduct experiments on a real-life (offline) dataset of an Event-Based Social Network (EBSN). Results indicate that our approach outperforms existing solutions, by efficiently resolving the limitations previously described.","Mon, 29 Jan 2018 12:27:50 UTC (18 KB)"
"960","Deep LOGISMOS: Deep Learning Graph-based 3D Segmentation of Pancreatic Tumors on CT scans","Zhihui Guo, Ling Zhang, Le Lu, Mohammadhadi Bagheri, Ronald M. Summers, Milan Sonka, Jianhua Yao","Computer Vision and Pattern Recognition (cs.CV)","This paper reports Deep LOGISMOS approach to 3D tumor segmentation by incorporating boundary information derived from deep contextual learning to LOGISMOS - layered optimal graph image segmentation of multiple objects and surfaces. Accurate and reliable tumor segmentation is essential to tumor growth analysis and treatment selection. A fully convolutional network (FCN), UNet, is first trained using three adjacent 2D patches centered at the tumor, providing contextual UNet segmentation and probability map for each 2D patch. The UNet segmentation is then refined by Gaussian Mixture Model (GMM) and morphological operations. The refined UNet segmentation is used to provide the initial shape boundary to build a segmentation graph. The cost for each node of the graph is determined by the UNet probability maps. Finally, a max-flow algorithm is employed to find the globally optimal solution thus obtaining the final segmentation. For evaluation, we applied the method to pancreatic tumor segmentation on a dataset of 51 CT scans, among which 30 scans were used for training and 21 for testing. With Deep LOGISMOS, DICE Similarity Coefficient (DSC) and Relative Volume Difference (RVD) reached 83.2+-7.8% and 18.6+-17.4% respectively, both are significantly improved (p<0.05) compared with contextual UNet and/or LOGISMOS alone.","Thu, 25 Jan 2018 21:34:44 UTC (517 KB)"
"961","Deep Learning in Pharmacogenomics: From Gene Regulation to Patient Stratification","Alexandr A. Kalinin, Gerald A. Higgins, Narathip Reamaroon, S.M. Reza Soroushmehr, Ari Allyn-Feuer, Ivo D. Dinov, Kayvan Najarian, Brian D. Athey","Quantitative Methods (q-bio.QM); Machine Learning (cs.LG); Machine Learning (stat.ML)","This Perspective provides examples of current and future applications of deep learning in pharmacogenomics, including: (1) identification of novel regulatory variants located in noncoding domains and their function as applied to pharmacoepigenomics; (2) patient stratification from medical records; and (3) prediction of drugs, targets, and their interactions. Deep learning encapsulates a family of machine learning algorithms that over the last decade has transformed many important subfields of artificial intelligence (AI) and has demonstrated breakthrough performance improvements on a wide range of tasks in biomedicine. We anticipate that in the future deep learning will be widely used to predict personalized drug response and optimize medication selection and dosing, using knowledge extracted from large and complex molecular, epidemiological, clinical, and demographic datasets.","Thu, 25 Jan 2018 19:21:15 UTC (1,886 KB)[v2] Wed, 7 Mar 2018 00:25:37 UTC (5,151 KB)"
"962","Deep Learning for End-to-End Automatic Target Recognition from Synthetic Aperture Radar Imagery","Hidetoshi Furukawa","Computer Vision and Pattern Recognition (cs.CV)","The standard architecture of synthetic aperture radar (SAR) automatic target recognition (ATR) consists of three stages: detection, discrimination, and classification. In recent years, convolutional neural networks (CNNs) for SAR ATR have been proposed, but most of them classify target classes from a target chip extracted from SAR imagery, as a classification for the third stage of SAR ATR. In this report, we propose a novel CNN for end-to-end ATR from SAR imagery. The CNN named verification support network (VersNet) performs all three stages of SAR ATR end-to-end. VersNet inputs a SAR image of arbitrary sizes with multiple classes and multiple targets, and outputs a SAR ATR image representing the position, class, and pose of each detected target. This report describes the evaluation results of VersNet which trained to output scores of all 12 classes: 10 target classes, a target front class, and a background class, for each pixel using the moving and stationary target acquisition and recognition (MSTAR) public dataset.","Thu, 25 Jan 2018 19:05:38 UTC (878 KB)"
"963","Data-Driven Impulse Response Regularization via Deep Learning","Carl Andersson, Niklas Wahlstrom, Thomas B. Schon","Systems and Control (cs.SY); Machine Learning (cs.LG); Machine Learning (stat.ML)","We consider the problem of impulse response estimation of stable linear single-input single-output systems. It is a well-studied problem where flexible non-parametric models recently offered a leap in performance compared to the classical finite-dimensional model structures. Inspired by this development and the success of deep learning we propose a new flexible data-driven model. Our experiments indicate that the new model is capable of exploiting even more of the hidden patterns that are present in the input-output data as compared to the non-parametric models.","Thu, 25 Jan 2018 12:48:41 UTC (709 KB)[v2] Thu, 11 Oct 2018 08:21:04 UTC (710 KB)"
"964","Phonocardiographic Sensing using Deep Learning for Abnormal Heartbeat Detection","Siddique Latif, Muhammad Usman, Rajib Rana, Junaid Qadir","Computer Vision and Pattern Recognition (cs.CV)","Cardiac auscultation involves expert interpretation of abnormalities in heart sounds using stethoscope. Deep learning based cardiac auscultation is of significant interest to the healthcare community as it can help reducing the burden of manual auscultation with automated detection of abnormal heartbeats. However, the problem of automatic cardiac auscultation is complicated due to the requirement of reliability and high accuracy, and due to the presence of background noise in the heartbeat sound. In this work, we propose a Recurrent Neural Networks (RNNs) based automated cardiac auscultation solution. Our choice of RNNs is motivated by the great success of deep learning in medical applications and by the observation that RNNs represent the deep learning configuration most suitable for dealing with sequential or temporal data even in the presence of noise. We explore the use of various RNN models, and demonstrate that these models deliver the abnormal heartbeat classification score with significant improvement. Our proposed approach using RNNs can be potentially be used for real-time abnormal heartbeat detection in the Internet of Medical Things for remote monitoring applications.","Thu, 25 Jan 2018 09:25:41 UTC (533 KB)[v2] Mon, 28 May 2018 07:38:24 UTC (559 KB)[v3] Tue, 5 Jun 2018 13:02:35 UTC (559 KB)"
"965","Intel nGraph: An Intermediate Representation, Compiler, and Executor for Deep Learning","Scott Cyphers, Arjun K. Bansal, Anahita Bhiwandiwalla, Jayaram Bobba, Matthew Brookhart, Avijit Chakraborty, Will Constable, Christian Convey, Leona Cook, Omar Kanawi, Robert Kimball, Jason Knight, Nikolay Korovaiko, Varun Kumar, Yixing Lao, Christopher R. Lishka, Jaikrishnan Menon, Jennifer Myers, Sandeep Aswath Narayana, Adam Procter, Tristan J. Webb","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","The Deep Learning (DL) community sees many novel topologies published each year. Achieving high performance on each new topology remains challenging, as each requires some level of manual effort. This issue is compounded by the proliferation of frameworks and hardware platforms. The current approach, which we call ""direct optimization"", requires deep changes within each framework to improve the training performance for each hardware backend (CPUs, GPUs, FPGAs, ASICs) and requires $\mathcal{O}(fp)$ effort; where $f$ is the number of frameworks and $p$ is the number of platforms. While optimized kernels for deep-learning primitives are provided via libraries like Intel Math Kernel Library for Deep Neural Networks (MKL-DNN), there are several compiler-inspired ways in which performance can be further optimized. Building on our experience creating neon (a fast deep learning library on GPUs), we developed Intel nGraph, a soon to be open-sourced C++ library to simplify the realization of optimized deep learning performance across frameworks and hardware platforms. Initially-supported frameworks include TensorFlow, MXNet, and Intel neon framework. Initial backends are Intel Architecture CPUs (CPU), the Intel(R) Nervana Neural Network Processor(R) (NNP), and NVIDIA GPUs. Currently supported compiler optimizations include efficient memory management and data layout abstraction. In this paper, we describe our overall architecture and its core components. In the future, we envision extending nGraph API support to a wider range of frameworks, hardware (including FPGAs and ASICs), and compiler optimizations (training versus inference optimizations, multi-node and multi-device scaling via efficient sub-graph partitioning, and HW-specific compounding of operations).","Wed, 24 Jan 2018 16:17:53 UTC (55 KB)[v2] Tue, 30 Jan 2018 00:14:49 UTC (55 KB)"
"966","On Scale-out Deep Learning Training for Cloud and HPC","Srinivas Sridharan, Karthikeyan Vaidyanathan, Dhiraj Kalamkar, Dipankar Das, Mikhail E. Smorkalov, Mikhail Shiryaev, Dheevatsa Mudigere, Naveen Mellempudi, Sasikanth Avancha, Bharat Kaul, Pradeep Dubey","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","The exponential growth in use of large deep neural networks has accelerated the need for training these deep neural networks in hours or even minutes. This can only be achieved through scalable and efficient distributed training, since a single node/card cannot satisfy the compute, memory, and I/O requirements of today's state-of-the-art deep neural networks. However, scaling synchronous Stochastic Gradient Descent (SGD) is still a challenging problem and requires continued research/development. This entails innovations spanning algorithms, frameworks, communication libraries, and system design. In this paper, we describe the philosophy, design, and implementation of Intel Machine Learning Scalability Library (MLSL) and present proof-points demonstrating scaling DL training on 100s to 1000s of nodes across Cloud and HPC systems.","Wed, 24 Jan 2018 15:38:17 UTC (127 KB)"
"967","Deep Learning for Sentiment Analysis : A Survey","Lei Zhang, Shuai Wang, Bing Liu","Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning has emerged as a powerful machine learning technique that learns multiple layers of representations or features of the data and produces state-of-the-art prediction results. Along with the success of deep learning in many other application domains, deep learning is also popularly used in sentiment analysis in recent years. This paper first gives an overview of deep learning and then provides a comprehensive survey of its current applications in sentiment analysis.","Wed, 24 Jan 2018 07:32:29 UTC (5,544 KB)[v2] Tue, 30 Jan 2018 07:20:41 UTC (5,575 KB)"
"968","Scalable and accurate deep learning for electronic health records","Alvin Rajkomar, Eyal Oren, Kai Chen, Andrew M. Dai, Nissan Hajaj, Peter J. Liu, Xiaobing Liu, Mimi Sun, Patrik Sundberg, Hector Yee, Kun Zhang, Gavin E. Duggan, Gerardo Flores, Michaela Hardt, Jamie Irvine, Quoc Le, Kurt Litsch, Jake Marcus, Alexander Mossin, Justin Tansuwan, De Wang, James Wexler, Jimbo Wilson, Dana Ludwig, Samuel L. Volchenboum, Katherine Chou, Michael Pearson, Srinivasan Madabushi, Nigam H. Shah, Atul J. Butte, Michael Howell, Claire Cui, Greg Corrado, Jeff Dean","Computers and Society (cs.CY); Machine Learning (cs.LG)","Predictive modeling with electronic health record (EHR) data is anticipated to drive personalized medicine and improve healthcare quality. Constructing predictive statistical models typically requires extraction of curated predictor variables from normalized EHR data, a labor-intensive process that discards the vast majority of information in each patient's record. We propose a representation of patients' entire, raw EHR records based on the Fast Healthcare Interoperability Resources (FHIR) format. We demonstrate that deep learning methods using this representation are capable of accurately predicting multiple medical events from multiple centers without site-specific data harmonization. We validated our approach using de-identified EHR data from two U.S. academic medical centers with 216,221 adult patients hospitalized for at least 24 hours. In the sequential format we propose, this volume of EHR data unrolled into a total of 46,864,534,945 data points, including clinical notes. Deep learning models achieved high accuracy for tasks such as predicting in-hospital mortality (AUROC across sites 0.93-0.94), 30-day unplanned readmission (AUROC 0.75-0.76), prolonged length of stay (AUROC 0.85-0.86), and all of a patient's final discharge diagnoses (frequency-weighted AUROC 0.90). These models outperformed state-of-the-art traditional predictive models in all cases. We also present a case-study of a neural-network attribution system, which illustrates how clinicians can gain some transparency into the predictions. We believe that this approach can be used to create accurate and scalable predictions for a variety of clinical scenarios, complete with explanations that directly highlight evidence in the patient's chart.","Wed, 24 Jan 2018 05:06:43 UTC (693 KB)[v2] Fri, 26 Jan 2018 18:57:00 UTC (732 KB)[v3] Fri, 11 May 2018 12:16:50 UTC (1,431 KB)"
"969","Deep Learning for Electromyographic Hand Gesture Signal Classification Using Transfer Learning","Ulysse Cote-Allard, Cheikh Latyr Fall, Alexandre Drouin, Alexandre Campeau-Lecours, Clement Gosselin, Kyrre Glette, Francois Laviolette, Benoit Gosselin","Machine Learning (cs.LG); Machine Learning (stat.ML)","In recent years, deep learning algorithms have become increasingly more prominent for their unparalleled ability to automatically learn discriminant features from large amounts of data. However, within the field of electromyography-based gesture recognition, deep learning algorithms are seldom employed as they require an unreasonable amount of effort from a single person, to generate tens of thousands of examples. This work's hypothesis is that general, informative features can be learned from the large amounts of data generated by aggregating the signals of multiple users, thus reducing the recording burden while enhancing gesture recognition. Consequently, this paper proposes applying transfer learning on aggregated data from multiple users, while leveraging the capacity of deep learning algorithms to learn discriminant features from large datasets. Two datasets comprised of 19 and 17 able-bodied participants respectively (the first one is employed for pre-training) were recorded for this work, using the Myo Armband. A third Myo Armband dataset was taken from the NinaPro database and is comprised of 10 able-bodied participants. Three different deep learning networks employing three different modalities as input (raw EMG, Spectrograms and Continuous Wavelet Transform (CWT)) are tested on the second and third dataset. The proposed transfer learning scheme is shown to systematically and significantly enhance the performance for all three networks on the two datasets, achieving an offline accuracy of 98.31% for 7 gestures over 17 participants for the CWT-based ConvNet and 68.98% for 18 gestures over 10 participants for the raw EMG-based ConvNet. Finally, a use-case study employing eight able-bodied participants suggests that real-time feedback allows users to adapt their muscle activation strategy which reduces the degradation in accuracy normally experienced over time.","Wed, 10 Jan 2018 11:42:30 UTC (2,106 KB)[v2] Tue, 13 Feb 2018 14:29:42 UTC (2,110 KB)[v3] Tue, 12 Jun 2018 09:25:44 UTC (2,253 KB)[v4] Mon, 19 Nov 2018 16:48:25 UTC (2,690 KB)"
"970","Clustering with Deep Learning: Taxonomy and New Methods","Elie Aljalbout, Vladimir Golkov, Yawar Siddiqui, Maximilian Strobel, Daniel Cremers","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","Clustering methods based on deep neural networks have proven promising for clustering real-world data because of their high representational power. In this paper, we propose a systematic taxonomy of clustering methods that utilize deep neural networks. We base our taxonomy on a comprehensive review of recent work and validate the taxonomy in a case study. In this case study, we show that the taxonomy enables researchers and practitioners to systematically create new clustering methods by selectively recombining and replacing distinct aspects of previous methods with the goal of overcoming their individual limitations. The experimental evaluation confirms this and shows that the method created for the case study achieves state-of-the-art clustering quality and surpasses it in some cases.","Tue, 23 Jan 2018 16:41:03 UTC (530 KB)[v2] Thu, 13 Sep 2018 19:41:22 UTC (665 KB)"
"971","DeepGestalt - Identifying Rare Genetic Syndromes Using Deep Learning","Yaron Gurovich, Yair Hanani, Omri Bar, Nicole Fleischer, Dekel Gelbman, Lina Basel-Salmon, Peter Krawitz, Susanne B Kamphausen, Martin Zenker, Lynne M. Bird, Karen W. Gripp","Computer Vision and Pattern Recognition (cs.CV)","Facial analysis technologies have recently measured up to the capabilities of expert clinicians in syndrome identification. To date, these technologies could only identify phenotypes of a few diseases, limiting their role in clinical settings where hundreds of diagnoses must be considered. We developed a facial analysis framework, DeepGestalt, using computer vision and deep learning algorithms, that quantifies similarities to hundreds of genetic syndromes based on unconstrained 2D images. DeepGestalt is currently trained with over 26,000 patient cases from a rapidly growing phenotype-genotype database, consisting of tens of thousands of validated clinical cases, curated through a community-driven platform. DeepGestalt currently achieves 91% top-10-accuracy in identifying over 215 different genetic syndromes and has outperformed clinical experts in three separate experiments. We suggest that this form of artificial intelligence is ready to support medical genetics in clinical and laboratory practices and will play a key role in the future of precision medicine.","Tue, 23 Jan 2018 16:18:24 UTC (1,104 KB)"
"972","Fast Point Spread Function Modeling with Deep Learning","Jorg Herbel, Tomasz Kacprzak, Adam Amara, Alexandre Refregier, Aurelien Lucchi (ETH Zurich)","Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (stat.ML)","Modeling the Point Spread Function (PSF) of wide-field surveys is vital for many astrophysical applications and cosmological probes including weak gravitational lensing. The PSF smears the image of any recorded object and therefore needs to be taken into account when inferring properties of galaxies from astronomical images. In the case of cosmic shear, the PSF is one of the dominant sources of systematic errors and must be treated carefully to avoid biases in cosmological parameters. Recently, forward modeling approaches to calibrate shear measurements within the Monte-Carlo Control Loops ($MCCL$) framework have been developed. These methods typically require simulating a large amount of wide-field images, thus, the simulations need to be very fast yet have realistic properties in key features such as the PSF pattern. Hence, such forward modeling approaches require a very flexible PSF model, which is quick to evaluate and whose parameters can be estimated reliably from survey data. We present a PSF model that meets these requirements based on a fast deep-learning method to estimate its free parameters. We demonstrate our approach on publicly available SDSS data. We extract the most important features of the SDSS sample via principal component analysis. Next, we construct our model based on perturbations of a fixed base profile, ensuring that it captures these features. We then train a Convolutional Neural Network to estimate the free parameters of the model from noisy images of the PSF. This allows us to render a model image of each star, which we compare to the SDSS stars to evaluate the performance of our method. We find that our approach is able to accurately reproduce the SDSS PSF at the pixel level, which, due to the speed of both the model evaluation and the parameter estimation, offers good prospects for incorporating our method into the $MCCL$ framework.","Tue, 23 Jan 2018 15:31:33 UTC (896 KB)[v2] Wed, 25 Jul 2018 07:20:54 UTC (1,171 KB)"
"973","Secure Mobile Crowdsensing with Deep Learning","Liang Xiao, Donghua Jiang, Dongjin Xu, Ning An","Cryptography and Security (cs.CR); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)","In order to stimulate secure sensing for Internet of Things (IoT) applications such as healthcare and traffic monitoring, mobile crowdsensing (MCS) systems have to address security threats, such as jamming, spoofing and faked sensing attacks, during both the sensing and the information exchange processes in large-scale dynamic and heterogenous networks. In this article, we investigate secure mobile crowdsensing and present how to use deep learning (DL) methods such as stacked autoencoder (SAE), deep neural network (DNN), and convolutional neural network (CNN) to improve the MCS security approaches including authentication, privacy protection, faked sensing countermeasures, intrusion detection and anti-jamming transmissions in MCS. We discuss the performance gain of these DL-based approaches compared with traditional security schemes and identify the challenges that need to be addressed to implement them in practical MCS systems.","Tue, 23 Jan 2018 02:57:12 UTC (1,830 KB)"
"974","Seismic Full-Waveform Inversion Using Deep Learning Tools and Techniques","Alan Richardson","Geophysics (physics.geo-ph); Computational Physics (physics.comp-ph)","I demonstrate that the conventional seismic full-waveform inversion algorithm can be constructed as a recurrent neural network and so implemented using deep learning software such as TensorFlow. Applying another deep learning concept, the Adam optimizer with minibatches of data, produces quicker convergence toward the true wave speed model on a 2D dataset than Stochastic Gradient Descent and than the L-BFGS-B optimizer with the cost function and gradient computed using the entire training dataset. I also show that the cost function gradient calculation using reverse-mode automatic differentiation is the same as that used in the adjoint state method.","Mon, 22 Jan 2018 18:27:19 UTC (147 KB)[v2] Wed, 31 Jan 2018 17:24:56 UTC (153 KB)"
"975","Computational Protein Design with Deep Learning Neural Networks","Jingxue Wang, Huali Cao, John Z.H. Zhang, Yifei Qi","Quantitative Methods (q-bio.QM); Biomolecules (q-bio.BM)","Computational protein design has a wide variety of applications. Despite its remarkable success, designing a protein for a given structure and function is still a challenging task. On the other hand, the number of solved protein structures is rapidly increasing while the number of unique protein folds has reached a steady number, suggesting more structural information is being accumulated on each fold. Deep learning neural network is a powerful method to learn such big data set and has shown superior performance in many machine learning fields. In this study, we applied the deep learning neural network approach to computational protein design for predicting the probability of 20 natural amino acids on each residue in a protein. A large set of protein structures was collected and a multi-layer neural network was constructed. A number of structural properties were extracted as input features and the best network achieved an accuracy of 38.3%. Using the network output as residue type restraints was able to improve the average sequence identity in designing three natural proteins using Rosetta. Moreover, the predictions from our network show ~3% higher sequence identity than a previous method. Results from this study may benefit further development of computational protein design methods.","Mon, 22 Jan 2018 14:59:18 UTC (2,259 KB)[v2] Sat, 24 Feb 2018 03:15:40 UTC (2,598 KB)"
"976","Towards Automated Tuberculosis detection using Deep Learning","Sonaal Kant, Muktabh Mayank Srivastava","Computer Vision and Pattern Recognition (cs.CV)","Tuberculosis(TB) in India is the world's largest TB epidemic. TB leads to 480,000 deaths every year. Between the years 2006 and 2014, Indian economy lost US$340 Billion due to TB. This combined with the emergence of drug resistant bacteria in India makes the problem worse. The government of India has hence come up with a new strategy which requires a high-sensitivity microscopy based TB diagnosis mechanism. We propose a new Deep Neural Network based drug sensitive TB detection methodology with recall and precision of 83.78% and 67.55% respectively for bacillus detection. This method takes a microscopy image with proper zoom level as input and returns location of suspected TB germs as output. The high accuracy of our method gives it the potential to evolve into a high sensitivity system to diagnose TB when trained at scale.","Mon, 22 Jan 2018 13:21:06 UTC (1,170 KB)"
"977","Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers","Fred Hohman, Minsuk Kahng, Robert Pienta, Duen Horng Chau","Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning has recently seen rapid development and received significant attention due to its state-of-the-art performance on previously-thought hard problems. However, because of the internal complexity and nonlinear structure of deep neural networks, the underlying decision making processes for why these models are achieving such performance are challenging and sometimes mystifying to interpret. As deep learning spreads across domains, it is of paramount importance that we equip users of deep learning with tools for understanding when a model works correctly, when it fails, and ultimately how to improve its performance. Standardized toolkits for building neural networks have helped democratize deep learning; visual analytics systems have now been developed to support model explanation, interpretation, debugging, and improvement. We present a survey of the role of visual analytics in deep learning research, which highlights its short yet impactful history and thoroughly summarizes the state-of-the-art using a human-centered interrogative framework, focusing on the Five W's and How (Why, Who, What, How, When, and Where). We conclude by highlighting research directions and open research problems. This survey helps researchers and practitioners in both visual analytics and deep learning to quickly learn key aspects of this young and rapidly growing body of research, whose impact spans a diverse range of domains.","Sun, 21 Jan 2018 20:13:07 UTC (900 KB)[v2] Fri, 4 May 2018 01:09:33 UTC (3,592 KB)[v3] Mon, 14 May 2018 04:59:24 UTC (7,586 KB)"
"978","Using Deep Learning for Title-Based Semantic Subject Indexing to Reach Competitive Performance to Full-Text","Florian Mai, Lukas Galke, Ansgar Scherp","Digital Libraries (cs.DL)","For (semi-)automated subject indexing systems in digital libraries, it is often more practical to use metadata such as the title of a publication instead of the full-text or the abstract. Therefore, it is desirable to have good text mining and text classification algorithms that operate well already on the title of a publication. So far, the classification performance on titles is not competitive with the performance on the full-texts if the same number of training samples is used for training. However, it is much easier to obtain title data in large quantities and to use it for training than full-text data. In this paper, we investigate the question how models obtained from training on increasing amounts of title training data compare to models from training on a constant number of full-texts. We evaluate this question on a large-scale dataset from the medical domain (PubMed) and from economics (EconBiz). In these datasets, the titles and annotations of millions of publications are available, and they outnumber the available full-texts by a factor of 20 and 15, respectively. To exploit these large amounts of data to their full potential, we develop three strong deep learning classifiers and evaluate their performance on the two datasets. The results are promising. On the EconBiz dataset, all three classifiers outperform their full-text counterparts by a large margin. The best title-based classifier outperforms the best full-text method by 9.4%. On the PubMed dataset, the best title-based method almost reaches the performance of the best full-text classifier, with a difference of only 2.9%.","Sat, 20 Jan 2018 19:26:20 UTC (854 KB)[v2] Tue, 29 May 2018 10:20:34 UTC (152 KB)"
"979","Real-time photoacoustic projection imaging using deep learning","Johannes Schwab, Stephan Antholzer, Robert Nuster, Markus Haltmeier","Numerical Analysis (math.NA); Medical Physics (physics.med-ph); Optics (physics.optics)","Photoacoustic tomography (PAT) is an emerging and non-invasive hybrid imaging modality for visualizing light absorbing structures in biological tissue. The recently invented PAT systems using arrays of 64 parallel integrating line detectors allow capturing photoacoustic projection images in fractions of a second. Standard image formation algorithms for this type of setup suffer from under-sampling due to the sparse detector array, blurring due to the finite impulse response of the detection system, and artifacts due to the limited detection view. To address these issues, in this paper we develop a new direct and non-iterative image reconstruction framework using deep learning. The proposed DALnet combines the universal backprojection (UBP) using dynamic aperture length (DAL) correction with a deep convolutional neural network (CNN). Both subnetworks contain free parameters that are adjusted in the training phase. As demonstrated by simulation and experiment, the DALnet is capable of producing high-resolution projection images of 3D structures at a frame rate of over 50 images per second on a standard PC with NVIDIA TITAN Xp GPU. The proposed network is shown to outperform state-of-the-art iterative total variation reconstruction algorithms in terms of reconstruction speed as well as in terms of various evaluation metrics.","Sat, 20 Jan 2018 16:02:29 UTC (3,228 KB)[v2] Wed, 24 Jan 2018 08:29:50 UTC (3,228 KB)[v3] Fri, 17 Aug 2018 17:53:35 UTC (1,331 KB)[v4] Thu, 30 Aug 2018 13:19:14 UTC (1,332 KB)"
"980","Deep Hidden Physics Models: Deep Learning of Nonlinear Partial Differential Equations","Maziar Raissi","Machine Learning (stat.ML); Machine Learning (cs.LG); Numerical Analysis (cs.NA); Analysis of PDEs (math.AP)","A long-standing problem at the interface of artificial intelligence and applied mathematics is to devise an algorithm capable of achieving human level or even superhuman proficiency in transforming observed data into predictive mathematical models of the physical world. In the current era of abundance of data and advanced machine learning capabilities, the natural question arises: How can we automatically uncover the underlying laws of physics from high-dimensional data generated from experiments? In this work, we put forth a deep learning approach for discovering nonlinear partial differential equations from scattered and potentially noisy observations in space and time. Specifically, we approximate the unknown solution as well as the nonlinear dynamics by two deep neural networks. The first network acts as a prior on the unknown solution and essentially enables us to avoid numerical differentiations which are inherently ill-conditioned and unstable. The second network represents the nonlinear dynamics and helps us distill the mechanisms that govern the evolution of a given spatiotemporal data-set. We test the effectiveness of our approach for several benchmark problems spanning a number of scientific domains and demonstrate how the proposed framework can help us accurately learn the underlying dynamics and forecast future states of the system. In particular, we study the Burgers', Korteweg-de Vries (KdV), Kuramoto-Sivashinsky, nonlinear Schrodinger, and Navier-Stokes equations.","Sat, 20 Jan 2018 08:02:09 UTC (2,814 KB)"
"981","Dimensionality Reduction in Deep Learning for Chest X-Ray Analysis of Lung Cancer","Yu.Gordienko, Yu.Kochura, O.Alienin, O. Rokovyi, S. Stirenko, Peng Gang, Jiang Hui, Wei Zeng","Machine Learning (cs.LG); Computers and Society (cs.CY)","Efficiency of some dimensionality reduction techniques, like lung segmentation, bone shadow exclusion, and t-distributed stochastic neighbor embedding (t-SNE) for exclusion of outliers, is estimated for analysis of chest X-ray (CXR) 2D images by deep learning approach to help radiologists identify marks of lung cancer in CXR. Training and validation of the simple convolutional neural network (CNN) was performed on the open JSRT dataset (dataset #01), the JSRT after bone shadow exclusion - BSE-JSRT (dataset #02), JSRT after lung segmentation (dataset #03), BSE-JSRT after lung segmentation (dataset #04), and segmented BSE-JSRT after exclusion of outliers by t-SNE method (dataset #05). The results demonstrate that the pre-processed dataset obtained after lung segmentation, bone shadow exclusion, and filtering out the outliers by t-SNE (dataset #05) demonstrates the highest training rate and best accuracy in comparison to the other pre-processed datasets.","Fri, 19 Jan 2018 17:15:25 UTC (649 KB)"
"982","Deep Learning for Detecting Cyberbullying Across Multiple Social Media Platforms","Sweta Agrawal, Amit Awekar","Information Retrieval (cs.IR); Computation and Language (cs.CL); Social and Information Networks (cs.SI)","Harassment by cyberbullies is a significant phenomenon on the social media. Existing works for cyberbullying detection have at least one of the following three bottlenecks. First, they target only one particular social media platform (SMP). Second, they address just one topic of cyberbullying. Third, they rely on carefully handcrafted features of the data. We show that deep learning based models can overcome all three bottlenecks. Knowledge learned by these models on one dataset can be transferred to other datasets. We performed extensive experiments using three real-world datasets: Formspring (12k posts), Twitter (16k posts), and Wikipedia(100k posts). Our experiments provide several useful insights about cyberbullying detection. To the best of our knowledge, this is the first work that systematically analyzes cyberbullying detection on various topics across multiple SMPs using deep learning based models and transfer learning.","Fri, 19 Jan 2018 16:27:36 UTC (71 KB)"
"983","Reionization Models Classifier using 21cm Map Deep Learning","Sultan Hassan, Adrian Liu, Saul Kohn, James E. Aguirre, Paul La Plante, Adam Lidz","Cosmology and Nongalactic Astrophysics (astro-ph.CO); Astrophysics of Galaxies (astro-ph.GA)","Next-generation 21cm observations will enable imaging of reionization on very large scales. These images will contain more astrophysical and cosmological information than the power spectrum, and hence providing an alternative way to constrain the contribution of different reionizing sources populations to cosmic reionization. Using Convolutional Neural Networks, we present a simple network architecture that is sufficient to discriminate between Galaxy-dominated versus AGN-dominated models, even in the presence of simulated noise from different experiments such as the HERA and SKA.","Fri, 19 Jan 2018 12:34:26 UTC (1,044 KB)[v2] Wed, 25 Jul 2018 18:17:02 UTC (1,044 KB)"
"984","An End-to-End Deep Learning Histochemical Scoring System for Breast Cancer Tissue Microarray","Jingxin Liu, Bolei Xu, Chi Zheng, Yuanhao Gong, Jon Garibaldi, Daniele Soria, Andew Green, Ian O. Ellis, Wenbin Zou, Guoping Qiu","Computer Vision and Pattern Recognition (cs.CV)","One of the methods for stratifying different molecular classes of breast cancer is the Nottingham Prognostic Index Plus (NPI+) which uses breast cancer relevant biomarkers to stain tumour tissues prepared on tissue microarray (TMA). To determine the molecular class of the tumour, pathologists will have to manually mark the nuclei activity biomarkers through a microscope and use a semi-quantitative assessment method to assign a histochemical score (H-Score) to each TMA core. Manually marking positively stained nuclei is a time consuming, imprecise and subjective process which will lead to inter-observer and intra-observer discrepancies. In this paper, we present an end-to-end deep learning system which directly predicts the H-Score automatically. Our system imitates the pathologists' decision process and uses one fully convolutional network (FCN) to extract all nuclei region (tumour and non-tumour), a second FCN to extract tumour nuclei region, and a multi-column convolutional neural network which takes the outputs of the first two FCNs and the stain intensity description image as input and acts as the high-level decision making mechanism to directly output the H-Score of the input TMA image. To the best of our knowledge, this is the first end-to-end system that takes a TMA image as input and directly outputs a clinical score. We will present experimental results which demonstrate that the H-Scores predicted by our model have very high and statistically significant correlation with experienced pathologists' scores and that the H-Score discrepancy between our algorithm and the pathologists is on par with the inter-subject discrepancy between the pathologists.","Fri, 19 Jan 2018 04:04:50 UTC (8,532 KB)"
"985","Deep Learning for Fatigue Estimation on the Basis of Multimodal Human-Machine Interactions","Yuri Gordienko, Sergii Stirenko, Yuriy Kochura, Oleg Alienin, Michail Novotarskiy, Nikita Gordienko","Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)","The new method is proposed to monitor the level of current physical load and accumulated fatigue by several objective and subjective characteristics. It was applied to the dataset targeted to estimate the physical load and fatigue by several statistical and machine learning methods. The data from peripheral sensors (accelerometer, GPS, gyroscope, magnetometer) and brain-computing interface (electroencephalography) were collected, integrated, and analyzed by several statistical and machine learning methods (moment analysis, cluster analysis, principal component analysis, etc.). The hypothesis 1 was presented and proved that physical activity can be classified not only by objective parameters, but by subjective parameters also. The hypothesis 2 (experienced physical load and subsequent restoration as fatigue level can be estimated quantitatively and distinctive patterns can be recognized) was presented and some ways to prove it were demonstrated. Several ""physical load"" and ""fatigue"" metrics were proposed. The results presented allow to extend application of the machine learning methods for characterization of complex human activity patterns (for example, to estimate their actual physical load and fatigue, and give cautions and advice).","Sat, 30 Dec 2017 17:49:03 UTC (2,485 KB)"
"986","Deep Learning: An Introduction for Applied Mathematicians","Catherine F. Higham, Desmond J. Higham","History and Overview (math.HO); Machine Learning (cs.LG); Numerical Analysis (math.NA); Machine Learning (stat.ML)","Multilayered artificial neural networks are becoming a pervasive tool in a host of application fields. At the heart of this deep learning revolution are familiar concepts from applied and computational mathematics; notably, in calculus, approximation theory, optimization and linear algebra. This article provides a very brief introduction to the basic ideas that underlie deep learning from an applied mathematics perspective. Our target audience includes postgraduate and final year undergraduate students in mathematics who are keen to learn about the area. The article may also be useful for instructors in mathematics who wish to enliven their classes with references to the application of deep learning techniques. We focus on three fundamental questions: what is a deep neural network? how is a network trained? what is the stochastic gradient method? We illustrate the ideas with a short MATLAB code that sets up and trains a network. We also show the use of state-of-the art software on a large scale image classification problem. We finish with references to the current literature.","Wed, 17 Jan 2018 16:05:25 UTC (331 KB)"
"987","Deep Learning of Atomically Resolved Scanning Transmission Electron Microscopy Images: Chemical Identification and Tracking Local Transformations","Maxim Ziatdinov, Ondrej Dyck, Artem Maksov, Xufan Li, Xiahan Sang, Kai Xiao, Raymond R. Unocic, Rama Vasudevan, Stephen Jesse, Sergei V. Kalinin","Materials Science (cond-mat.mtrl-sci)","Recent advances in scanning transmission electron and scanning probe microscopies have opened exciting opportunities in probing the materials structural parameters and various functional properties in real space with angstrom-level precision. This progress has been accompanied by an exponential increase in the size and quality of datasets produced by microscopic and spectroscopic experimental techniques. These developments necessitate adequate methods for extracting relevant physical and chemical information from the large datasets, for which a priori information on the structures of various atomic configurations and lattice defects is limited or absent. Here we demonstrate an application of deep neural networks to extract information from atomically resolved images including location of the atomic species and type of defects. We develop a 'weakly-supervised' approach that uses information on the coordinates of all atomic species in the image, extracted via a deep neural network, to identify a rich variety of defects that are not part of an initial training set. We further apply our approach to interpret complex atomic and defect transformation, including switching between different coordination of silicon dopants in graphene as a function of time, formation of peculiar silicon dimer with mixed 3-fold and 4-fold coordination, and the motion of molecular 'rotor'. This deep learning based approach resembles logic of a human operator, but can be scaled leading to significant shift in the way of extracting and analyzing information from raw experimental data.","Wed, 17 Jan 2018 20:45:52 UTC (1,997 KB)"
"988","Deep learning for determining a near-optimal topological design without any iteration","Yonggyun Yu, Taeil Hur, Jaeho Jung, In Gwun Jang","Machine Learning (cs.LG); Computational Physics (physics.comp-ph)","In this study, we propose a novel deep learning-based method to predict an optimized structure for a given boundary condition and optimization setting without using any iterative scheme. For this purpose, first, using open-source topology optimization code, datasets of the optimized structures paired with the corresponding information on boundary conditions and optimization settings are generated at low (32 x 32) and high (128 x 128) resolutions. To construct the artificial neural network for the proposed method, a convolutional neural network (CNN)-based encoder and decoder network is trained using the training dataset generated at low resolution. Then, as a two-stage refinement, the conditional generative adversarial network (cGAN) is trained with the optimized structures paired at both low and high resolutions, and is connected to the trained CNN-based encoder and decoder network. The performance evaluation results of the integrated network demonstrate that the proposed method can determine a near-optimal structure in terms of pixel values and compliance with negligible computational time.","Sat, 13 Jan 2018 17:10:35 UTC (2,339 KB)[v2] Tue, 22 May 2018 08:53:55 UTC (1,898 KB)[v3] Sat, 22 Sep 2018 07:50:36 UTC (1,898 KB)"
"989","Solutions to problems with deep learning","J Gerard Wolff","Machine Learning (cs.LG); Artificial Intelligence (cs.AI)","Despite the several successes of deep learning systems, there are concerns about their limitations, discussed most recently by Gary Marcus. This paper discusses Marcus's concerns and some others, together with solutions to several of these problems provided by the ""P theory of intelligence"" and its realisation in the ""SP computer model"". The main advantages of the SP system are: relatively small requirements for data and the ability to learn from a single experience; the ability to model both hierarchical and non-hierarchical structures; strengths in several kinds of reasoning, including `commonsense' reasoning; transparency in the representation of knowledge, and the provision of an audit trail for all processing; the likelihood that the SP system could not be fooled into bizarre or eccentric recognition of stimuli, as deep learning systems can be; the SP system provides a robust solution to the problem of `catastrophic forgetting' in deep learning systems; the SP system provides a theoretically-coherent solution to the problems of correcting over- and under-generalisations in learning, and learning correct structures despite errors in data; unlike most research on deep learning, the SP programme of research draws extensively on research on human learning, perception, and cognition; and the SP programme of research has an overarching theory, supported by evidence, something that is largely missing from research on deep learning. In general, the SP system provides a much firmer foundation than deep learning for the development of artificial general intelligence.","Mon, 8 Jan 2018 20:37:07 UTC (14 KB)"
"990","An Automated System for Epilepsy Detection using EEG Brain Signals based on Deep Learning Approach","Ihsan Ullah, Muhammad Hussain, Emad-ul-Haq Qazi, Hatim Aboalsamh","Computer Vision and Pattern Recognition (cs.CV)","Epilepsy is a neurological disorder and for its detection, encephalography (EEG) is a commonly used clinical approach. Manual inspection of EEG brain signals is a time-consuming and laborious process, which puts heavy burden on neurologists and affects their performance. Several automatic techniques have been proposed using traditional approaches to assist neurologists in detecting binary epilepsy scenarios e.g. seizure vs. non-seizure or normal vs. ictal. These methods do not perform well when classifying ternary case e.g. ictal vs. normal vs. inter-ictal; the maximum accuracy for this case by the state-of-the-art-methods is 97+-1%. To overcome this problem, we propose a system based on deep learning, which is an ensemble of pyramidal one-dimensional convolutional neural network (P-1D-CNN) models. In a CNN model, the bottleneck is the large number of learnable parameters. P-1D-CNN works on the concept of refinement approach and it results in 60% fewer parameters compared to traditional CNN models. Further to overcome the limitations of small amount of data, we proposed augmentation schemes for learning P-1D-CNN model. In almost all the cases concerning epilepsy detection, the proposed system gives an accuracy of 99.1+-0.9% on the University of Bonn dataset.","Tue, 16 Jan 2018 18:49:52 UTC (976 KB)"
"991","Evidential Occupancy Grid Map Augmentation using Deep Learning","Sascha Wirges, Felix Hartenbach, Christoph Stiller","Robotics (cs.RO)","A detailed environment representation is a crucial component of automated vehicles. Using single range sensor scans, data is often too sparse and subject to occlusions. Therefore, we present a method to augment occupancy grid maps from single views to be similar to evidential occupancy maps acquired from different views using Deep Learning. To accomplish this, we estimate motion between subsequent range sensor measurements and create an evidential 3D voxel map in an extensive post-processing step. Within this voxel map, we explicitly model uncertainty using evidence theory and create a 2D projection using combination rules. As input for our neural networks, we use a multi-layer grid map consisting of the three features detections, transmissions and intensity, each for ground and non-ground measurements. Finally, we perform a quantitative and qualitative evaluation which shows that different network architectures accurately infer evidential measures in real-time.","Tue, 16 Jan 2018 15:28:28 UTC (7,273 KB)[v2] Wed, 18 Apr 2018 22:36:38 UTC (5,090 KB)"
"992","Radio Galaxy Zoo: Compact and extended radio source classification with deep learning","V. Lukic, M. Bruggen, J.K. Banfield, O.I. Wong, L. Rudnick, R.P. Norris, B. Simmons","Instrumentation and Methods for Astrophysics (astro-ph.IM)","Machine learning techniques have been increasingly useful in astronomical applications over the last few years, for example in the morphological classification of galaxies. Convolutional neural networks have proven to be highly effective in classifying objects in image data. The current work aims to establish when multiple components are present, in the astronomical context of synthesis imaging observations of radio sources. To this effect, we design a convolutional neural network to differentiate between different morphology classes using sources from the Radio Galaxy Zoo (RGZ) citizen science project. In this first step, we focus on exploring the factors that affect the performance of such neural networks, such as the amount of training data, number and nature of layers and the hyperparameters. We begin with a simple experiment in which we only differentiate between two extreme morphologies, using compact and multiple component extended sources. We found that a three convolutional layer architecture yielded very good results, achieving a classification accuracy of 97.4% on a test data set. The same architecture was then tested on a four-class problem where we let the network classify sources into compact and three classes of extended sources, achieving a test achieving a test accuracy of 93.5%. The best-performing convolutional neural network setup has been verified against RGZ Data Release 1 where a final test accuracy of 94.8% was obtained, using both original and augmented images. The use of sigma clipping does not offer a significant benefit overall, except in cases with a small number of training images.","Mon, 15 Jan 2018 16:23:03 UTC (1,360 KB)"
"993","Detecting Offensive Language in Tweets Using Deep Learning","Georgios K. Pitsilis, Heri Ramampiaro, Helge Langseth","Computation and Language (cs.CL); Computers and Society (cs.CY); Social and Information Networks (cs.SI)","This paper addresses the important problem of discerning hateful content in social media. We propose a detection scheme that is an ensemble of Recurrent Neural Network (RNN) classifiers, and it incorporates various features associated with user-related information, such as the users' tendency towards racism or sexism. These data are fed as input to the above classifiers along with the word frequency vectors derived from the textual content. Our approach has been evaluated on a publicly available corpus of 16k tweets, and the results demonstrate its effectiveness in comparison to existing state of the art solutions. More specifically, our scheme can successfully distinguish racism and sexism messages from normal text, and achieve higher classification quality than current state-of-the-art algorithms.","Sat, 13 Jan 2018 12:58:43 UTC (69 KB)"
"994","Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers","Ji Gao, Jack Lanchantin, Mary Lou Soffa, Yanjun Qi","Computation and Language (cs.CL); Cryptography and Security (cs.CR); Information Retrieval (cs.IR); Machine Learning (cs.LG)","Although various techniques have been proposed to generate adversarial samples for white-box attacks on text, little attention has been paid to black-box attacks, which are more realistic scenarios. In this paper, we present a novel algorithm, DeepWordBug, to effectively generate small text perturbations in a black-box setting that forces a deep-learning classifier to misclassify a text input. We employ novel scoring strategies to identify the critical tokens that, if modified, cause the classifier to make an incorrect prediction. Simple character-level transformations are applied to the highest-ranked tokens in order to minimize the edit distance of the perturbation, yet change the original classification. We evaluated DeepWordBug on eight real-world text datasets, including text classification, sentiment analysis, and spam detection. We compare the result of DeepWordBug with two baselines: Random (Black-box) and Gradient (White-box). Our experimental results indicate that DeepWordBug reduces the prediction accuracy of current state-of-the-art deep-learning models, including a decrease of 68\% on average for a Word-LSTM model and 48\% on average for a Char-CNN model.","Sat, 13 Jan 2018 00:42:30 UTC (545 KB)[v2] Tue, 3 Apr 2018 02:59:45 UTC (3,055 KB)[v3] Sat, 7 Apr 2018 03:32:12 UTC (3,066 KB)[v4] Mon, 16 Apr 2018 12:59:01 UTC (3,132 KB)[v5] Wed, 23 May 2018 15:55:55 UTC (3,610 KB)"
"995","Towards Arbitrary Noise Augmentation - Deep Learning for Sampling from Arbitrary Probability Distributions","Felix Horger, Tobias Wurfl, Vincent Christlein, Andreas Maier","Machine Learning (cs.LG); Machine Learning (stat.ML)","Accurate noise modelling is important for training of deep learning reconstruction algorithms. While noise models are well known for traditional imaging techniques, the noise distribution of a novel sensor may be difficult to determine a priori. Therefore, we propose learning arbitrary noise distributions. To do so, this paper proposes a fully connected neural network model to map samples from a uniform distribution to samples of any explicitly known probability density function. During the training, the Jensen-Shannon divergence between the distribution of the model's output and the target distribution is minimized. We experimentally demonstrate that our model converges towards the desired state. It provides an alternative to existing sampling methods such as inversion sampling, rejection sampling, Gaussian mixture models and Markov-Chain-Monte-Carlo. Our model has high sampling efficiency and is easily applied to any probability distribution, without the need of further analytical or numerical calculations.","Fri, 12 Jan 2018 16:03:21 UTC (1,187 KB)[v2] Tue, 10 Jul 2018 08:55:22 UTC (1,447 KB)"
"996","Arhuaco: Deep Learning and Isolation Based Security for Distributed High-Throughput Computing","A. Gomez Ramirez, C. Lara, L. Betev, D. Bilanovic, U. Kebschull (and for the ALICE Collaboration)","Distributed, Parallel, and Cluster Computing (cs.DC); Cryptography and Security (cs.CR); Machine Learning (cs.LG)","Grid computing systems require innovative methods and tools to identify cybersecurity incidents and perform autonomous actions i.e. without administrator intervention. They also require methods to isolate and trace job payload activity in order to protect users and find evidence of malicious behavior. We introduce an integrated approach of security monitoring via Security by Isolation with Linux Containers and Deep Learning methods for the analysis of real time data in Grid jobs running inside virtualized High-Throughput Computing infrastructure in order to detect and prevent intrusions. A dataset for malware detection in Grid computing is described. We show in addition the utilization of generative methods with Recurrent Neural Networks to improve the collected dataset. We present Arhuaco, a prototype implementation of the proposed methods. We empirically study the performance of our technique. The results show that Arhuaco outperforms other methods used in Intrusion Detection Systems for Grid Computing. The study is carried out in the ALICE Collaboration Grid, part of the Worldwide LHC Computing Grid.","Fri, 12 Jan 2018 14:35:19 UTC (2,550 KB)"
"997","MXNET-MPI: Embedding MPI parallelism in Parameter Server Task Model for scaling Deep Learning","Amith R Mamidala, Georgios Kollias, Chris Ward, Fausto Artico","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","Existing Deep Learning frameworks exclusively use either Parameter Server(PS) approach or MPI parallelism. In this paper, we discuss the drawbacks of such approaches and propose a generic framework supporting both PS and MPI programming paradigms, co-existing at the same time. The key advantage of the new model is to embed the scaling benefits of MPI parallelism into the loosely coupled PS task model. Apart from providing a practical usage model of MPI in cloud, such framework allows for novel communication avoiding algorithms that do parameter averaging in Stochastic Gradient Descent(SGD) approaches. We show how MPI and PS models can synergestically apply algorithms such as Elastic SGD to improve the rate of convergence against existing approaches. These new algorithms directly help scaling SGD clusterwide. Further, we also optimize the critical component of the framework, namely global aggregation or allreduce using a novel concept of tensor collectives. These treat a group of vectors on a node as a single object allowing for the existing single vector algorithms to be directly applicable. We back our claims with sufficient emperical evidence using large scale ImageNet 1K data. Our framework is built upon MXNET but the design is generic and can be adapted to other popular DL infrastructures.","Thu, 11 Jan 2018 16:32:10 UTC (427 KB)"
"998","Applications of deep learning to relativistic hydrodynamics","Hengfeng Huang, Bowen Xiao, Huixin Xiong, Zeming Wu, Yadong Mu, Huichao Song","Nuclear Theory (nucl-th); High Energy Astrophysical Phenomena (astro-ph.HE); Disordered Systems and Neural Networks (cond-mat.dis-nn); High Energy Physics - Phenomenology (hep-ph)","Relativistic hydrodynamics is a powerful tool to simulate the evolution of the quark gluon plasma (QGP) in relativistic heavy ion collisions. Using 10000 initial and final profiles generated from 2+1-d relativistic hydrodynamics VISH2+1 with MC-Glauber initial conditions, we train a deep neural network based on stacked U-net, and use it to predict the final profiles associated with various initial conditions, including MC-Glauber, MC-KLN and AMPT and TRENTo. A comparison with the VISH2+1 results shows that the network predictions can nicely capture the magnitude and inhomogeneous structures of the final profiles, and nicely describe the related eccentricity distributions $P(\varepsilon_n)$ (n=2, 3, 4). These results indicate that deep learning technique can capture the main features of the non-linear evolution of hydrodynamics, showing its potential to largely accelerate the event-by-event simulations of relativistic hydrodynamics.","Wed, 10 Jan 2018 12:17:57 UTC (958 KB)[v2] Sat, 21 Apr 2018 09:15:23 UTC (1,375 KB)"
"999","Supervised and Unsupervised Tumor Characterization in the Deep Learning Era","Sarfaraz Hussein, Maria M. Chuquicusma, Pujan Kandel, Candice W. Bolan, Michael B. Wallace, Ulas Bagci","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM); Tissues and Organs (q-bio.TO)","Cancer is among the leading causes of death worldwide. Risk stratification of cancer tumors in radiology images can be improved with computer-aided diagnosis (CAD) tools which can be made faster and more accurate. Tumor characterization through CADs can enable non-invasive cancer staging and prognosis, and foster personalized treatment planning as a part of precision medicine. In this study, we propose both supervised and unsupervised machine learning strategies to improve tumor characterization. Our first approach is based on supervised learning for which we demonstrate significant gains in deep learning algorithms, particularly by utilizing a 3D Convolutional Neural Network along with transfer learning. Motivated by the radiologists' interpretations of the scans, we then show how to incorporate task dependent feature representations into a CAD system via a ""graph-regularized sparse Multi-Task Learning (MTL)"" framework. In the second approach, we explore an unsupervised scheme to address the limited availability of labeled training data, a common problem in medical imaging applications. Inspired by learning from label proportion (LLP) approaches, we propose a new algorithm, proportion-SVM, to characterize tumor types. We also seek the answer to the fundamental question about the goodness of ""deep features"" for unsupervised tumor classification. We evaluate our proposed approaches (both supervised and unsupervised) on two different tumor diagnosis challenges: lung and pancreas with 1018 CT and 171 MRI scans respectively.","Wed, 10 Jan 2018 03:47:07 UTC (2,724 KB)[v2] Sun, 29 Jul 2018 05:30:33 UTC (2,564 KB)"
"1000","An overview of deep learning based methods for unsupervised and semi-supervised anomaly detection in videos","B Ravi Kiran, Dilip Mathew Thomas, Ranjith Parakkal","Computer Vision and Pattern Recognition (cs.CV)","Videos represent the primary source of information for surveillance applications and are available in large amounts but in most cases contain little or no annotation for supervised learning. This article reviews the state-of-the-art deep learning based methods for video anomaly detection and categorizes them based on the type of model and criteria of detection. We also perform simple studies to understand the different approaches and provide the criteria of evaluation for spatio-temporal anomaly detection.","Tue, 9 Jan 2018 21:44:26 UTC (1,700 KB)[v2] Tue, 30 Jan 2018 10:50:11 UTC (1,422 KB)"
"1001","Utilising Deep Learning and Genome Wide Association Studies for Epistatic-Driven Preterm Birth Classification in African-American Women","Paul Fergus, Casimiro Curbelo Montanez, Basma Abdulaimma, Paulo Lisboa, Carl Chalmers","Computational Engineering, Finance, and Science (cs.CE)","Genome Wide Association Studies (GWAS) are used to identify statistically significant genetic variants in case-control studies. GWAS typically use a p-value threshold of 5 x 10-8 to identify highly ranked single nucleotide polymorphisms (SNPs). However, evidence has shown that many of these are, in fact, false positives. Using lower p-values it is possible to to investigate the joint epistatic interactions between SNPs and provide better insights into phenotype expression. However, computational complexity is increased exponentially as a function of higher-order combinations. In this paper, we propose a novel framework, based on nonlinear transformations of combinatorically large SNP data, using stacked autoencoders, to identify higher-order SNP interactions. We focus on the challenging problem of classifying preterm births. Evidence suggests that this complex condition has a strong genetic component with unexplained heritability reportedly between 20%-40%. This claim is substantiated using a GWAS data set, obtained from dbGap, which contains predominantly urban low-income African-American women who had normal deliveries (between 37 and 42 weeks of gestation) and preterm deliveries (less than 37 weeks of gestation). Latent representations from original SNP sequences are used to initialize a deep learning classifier before it is fine-tuned for classification tasks (term and preterm births). The complete network models the epistatic effects of major and minor SNP perturbations. All models are evaluated using standard binary classifier performance metrics. The findings show that important information pertaining to SNPs and epistasis can be extracted from 4666 raw SNPs generated using logistic regression (p-value=5 x 10-3) and used to fit a deep learning model and obtain results (Sen=0.9289, Spec=0.9591, Gini=0.9651, Logloss=0.3080, AUC=0.9825, MSE=0.0942) using 500 hidden nodes.","Sat, 6 Jan 2018 17:10:19 UTC (1,887 KB)"
"1002","Adversarial Deep Learning for Robust Detection of Binary Encoded Malware","Abdullah Al-Dujaili, Alex Huang, Erik Hemberg, Una-May O'Reilly","Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)","Malware is constantly adapting in order to avoid detection. Model based malware detectors, such as SVM and neural networks, are vulnerable to so-called adversarial examples which are modest changes to detectable malware that allows the resulting malware to evade detection. Continuous-valued methods that are robust to adversarial examples of images have been developed using saddle-point optimization formulations. We are inspired by them to develop similar methods for the discrete, e.g. binary, domain which characterizes the features of malware. A specific extra challenge of malware is that the adversarial examples must be generated in a way that preserves their malicious functionality. We introduce methods capable of generating functionally preserved adversarial malware examples in the binary domain. Using the saddle-point formulation, we incorporate the adversarial examples into the training of models that are robust to them. We evaluate the effectiveness of the methods and others in the literature on a set of Portable Execution~(PE) files. Comparison prompts our introduction of an online measure computed during training to assess general expectation of robustness.","Tue, 9 Jan 2018 14:32:30 UTC (658 KB)[v2] Sat, 17 Mar 2018 20:29:25 UTC (658 KB)[v3] Sun, 25 Mar 2018 14:17:03 UTC (659 KB)"
"1003","Near Maximum Likelihood Decoding with Deep Learning","Eliya Nachmani, Yaron Bachar, Elad Marciano, David Burshtein, Yair Be'ery","Information Theory (cs.IT); Neural and Evolutionary Computing (cs.NE)","A novel and efficient neural decoder algorithm is proposed. The proposed decoder is based on the neural Belief Propagation algorithm and the Automorphism Group. By combining neural belief propagation with permutations from the Automorphism Group we achieve near maximum likelihood performance for High Density Parity Check codes. Moreover, the proposed decoder significantly improves the decoding complexity, compared to our earlier work on the topic. We also investigate the training process and show how it can be accelerated. Simulations of the hessian and the condition number show why the learning process is accelerated. We demonstrate the decoding algorithm for various linear block codes of length up to 63 bits.","Mon, 8 Jan 2018 23:49:42 UTC (5,396 KB)"
"1004","Personalizing deep learning models for automatic sleep staging","Kaare Mikkelsen, Maarten de Vos","Neurons and Cognition (q-bio.NC)","Despite continued advancement in machine learning algorithms and increasing availability of large data sets, there is still no universally acceptable solution for automatic sleep staging of human sleep recordings. One reason is that a skilled neurophysiologist scoring brain recordings of a sleeping person implicitly adapts his/her staging to the individual characteristics present in the brain recordings. Trying to incorporate this adaptation step in an automatic scoring algorithm, we introduce in this paper a method for personalizing a general sleep scoring model. Starting from a general convolutional neural network architecture, we allow the model to learn individual characteristics of the first night of sleep in order to quantify sleep stages of the second night. While the original neural network allows to sleep stage on a public database with a state of the art accuracy, personalizing the model further increases performance (on the order of two percentage points on average, but more for difficult subjects). This improvement is particularly present in subjects where the original algorithm did not perform well (typically subjects with accuracy less than $80\%$). Looking deeper, we find that optimal classification can be achieved when broad knowledge of sleep staging in general (at least 20 separate nights) is combined with subject-specific knowledge. We hypothesize that this method will be very valuable for improving scoring of lower quality sleep recordings, such as those from wearable devices.","Mon, 8 Jan 2018 19:08:17 UTC (539 KB)"
"1005","HeNet: A Deep Learning Approach on Intel$^\circledR$ Processor Trace for Effective Exploit Detection","Li Chen, Salmin Sultana, Ravi Sahita","Cryptography and Security (cs.CR); Machine Learning (cs.LG)","This paper presents HeNet, a hierarchical ensemble neural network, applied to classify hardware-generated control flow traces for malware detection. Deep learning-based malware detection has so far focused on analyzing executable files and runtime API calls. Static code analysis approaches face challenges due to obfuscated code and adversarial perturbations. Behavioral data collected during execution is more difficult to obfuscate but recent research has shown successful attacks against API call based malware classifiers. We investigate control flow based characterization of a program execution to build robust deep learning malware classifiers. HeNet consists of a low-level behavior model and a top-level ensemble model. The low-level model is a per-application behavior model, trained via transfer learning on a time-series of images generated from control flow trace of an execution. We use Intel$^\circledR$ Processor Trace enabled processor for low overhead execution tracing and design a lightweight image conversion and segmentation of the control flow trace. The top-level ensemble model aggregates the behavior classification of all the trace segments and detects an attack. The use of hardware trace adds portability to our system and the use of deep learning eliminates the manual effort of feature engineering. We evaluate HeNet against real-world exploitations of PDF readers. HeNet achieves 100\% accuracy and 0\% false positive on test set, and higher classification accuracy compared to classical machine learning algorithms.","Mon, 8 Jan 2018 06:34:40 UTC (600 KB)"
"1006","Deep Fingerprinting: Undermining Website Fingerprinting Defenses with Deep Learning","Payap Sirinam, Mohsen Imani, Marc Juarez, Matthew Wright","Cryptography and Security (cs.CR)","Website fingerprinting enables a local eavesdropper to determine which websites a user is visiting over an encrypted connection. State-of-the-art website fingerprinting attacks have been shown to be effective even against Tor. Recently, lightweight website fingerprinting defenses for Tor have been proposed that substantially degrade existing attacks: WTF-PAD and Walkie-Talkie. In this work, we present Deep Fingerprinting (DF), a new website fingerprinting attack against Tor that leverages a type of deep learning called Convolutional Neural Networks (CNN) with a sophisticated architecture design, and we evaluate this attack against WTF-PAD and Walkie-Talkie. The DF attack attains over 98% accuracy on Tor traffic without defenses, better than all prior attacks, and it is also the only attack that is effective against WTF-PAD with over 90% accuracy. Walkie-Talkie remains effective, holding the attack to just 49.7% accuracy. In the more realistic open-world setting, our attack remains effective, with 0.99 precision and 0.94 recall on undefended traffic. Against traffic defended with WTF-PAD in this setting, the attack still can get 0.96 precision and 0.68 recall. These findings highlight the need for effective defenses that protect against this new attack and that could be deployed in Tor.","Sun, 7 Jan 2018 23:07:18 UTC (1,498 KB)[v2] Tue, 13 Feb 2018 20:19:11 UTC (2,313 KB)[v3] Sat, 12 May 2018 18:32:47 UTC (2,475 KB)[v4] Tue, 10 Jul 2018 15:39:52 UTC (2,475 KB)[v5] Mon, 20 Aug 2018 01:28:48 UTC (2,475 KB)"
"1007","Theory of Deep Learning IIb: Optimization Properties of SGD","Chiyuan Zhang, Qianli Liao, Alexander Rakhlin, Brando Miranda, Noah Golowich, Tomaso Poggio","Machine Learning (cs.LG)","In Theory IIb we characterize with a mix of theory and experiments the optimization of deep convolutional networks by Stochastic Gradient Descent. The main new result in this paper is theoretical and experimental evidence for the following conjecture about SGD: SGD concentrates in probability -- like the classical Langevin equation -- on large volume, ""flat"" minima, selecting flat minimizers which are with very high probability also global minimizers","Sun, 7 Jan 2018 21:43:28 UTC (3,588 KB)"
"1008","Detection and segmentation of the Left Ventricle in Cardiac MRI using Deep Learning","Alexandre Attia, Sharone Dayan","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Manual segmentation of the Left Ventricle (LV) is a tedious and meticulous task that can vary depending on the patient, the Magnetic Resonance Images (MRI) cuts and the experts. Still today, we consider manual delineation done by experts as being the ground truth for cardiac diagnosticians. Thus, we are reviewing the paper - written by Avendi and al. - who presents a combined approach with Convolutional Neural Networks, Stacked Auto-Encoders and Deformable Models, to try and automate the segmentation while performing more accurately. Furthermore, we have implemented parts of the paper (around three quarts) and experimented both the original method and slightly modified versions when changing the architecture and the parameters.","Sun, 7 Jan 2018 11:22:12 UTC (750 KB)"
"1009","Learning Implicit Brain MRI Manifolds with Deep Learning","Camilo Bermudez, Andrew J. Plassard, Larry T. Davis, Allen T. Newton, Susan M Resnick, Bennett A. Landman","Computer Vision and Pattern Recognition (cs.CV)","An important task in image processing and neuroimaging is to extract quantitative information from the acquired images in order to make observations about the presence of disease or markers of development in populations. Having a lowdimensional manifold of an image allows for easier statistical comparisons between groups and the synthesis of group representatives. Previous studies have sought to identify the best mapping of brain MRI to a low-dimensional manifold, but have been limited by assumptions of explicit similarity measures. In this work, we use deep learning techniques to investigate implicit manifolds of normal brains and generate new, high-quality images. We explore implicit manifolds by addressing the problems of image synthesis and image denoising as important tools in manifold learning. First, we propose the unsupervised synthesis of T1-weighted brain MRI using a Generative Adversarial Network (GAN) by learning from 528 examples of 2D axial slices of brain MRI. Synthesized images were first shown to be unique by performing a crosscorrelation with the training set. Real and synthesized images were then assessed in a blinded manner by two imaging experts providing an image quality score of 1-5. The quality score of the synthetic image showed substantial overlap with that of the real images. Moreover, we use an autoencoder with skip connections for image denoising, showing that the proposed method results in higher PSNR than FSL SUSAN after denoising. This work shows the power of artificial networks to synthesize realistic imaging data, which can be used to improve image processing techniques and provide a quantitative framework to structural changes in the brain.","Fri, 5 Jan 2018 17:24:37 UTC (4,225 KB)"
"1010","Deep Learning for Forecasting Stock Returns in the Cross-Section","Masaya Abe, Hideki Nakayama","Statistical Finance (q-fin.ST); Machine Learning (cs.LG)","Many studies have been undertaken by using machine learning techniques, including neural networks, to predict stock returns. Recently, a method known as deep learning, which achieves high performance mainly in image recognition and speech recognition, has attracted attention in the machine learning field. This paper implements deep learning to predict one-month-ahead stock returns in the cross-section in the Japanese stock market and investigates the performance of the method. Our results show that deep neural networks generally outperform shallow neural networks, and the best networks also outperform representative machine learning models. These results indicate that deep learning shows promise as a skillful machine learning method to predict stock returns in the cross-section.","Wed, 3 Jan 2018 23:47:52 UTC (414 KB)[v2] Tue, 20 Feb 2018 00:17:25 UTC (562 KB)[v3] Wed, 16 May 2018 00:28:55 UTC (562 KB)[v4] Wed, 13 Jun 2018 00:56:57 UTC (562 KB)"
"1011","VulDeePecker: A Deep Learning-Based System for Vulnerability Detection","Zhen Li, Deqing Zou, Shouhuai Xu, Xinyu Ou, Hai Jin, Sujuan Wang, Zhijun Deng, Yuyi Zhong","Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","The automatic detection of software vulnerabilities is an important research problem. However, existing solutions to this problem rely on human experts to define features and often miss many vulnerabilities (i.e., incurring high false negative rate). In this paper, we initiate the study of using deep learning-based vulnerability detection to relieve human experts from the tedious and subjective task of manually defining features. Since deep learning is motivated to deal with problems that are very different from the problem of vulnerability detection, we need some guiding principles for applying deep learning to vulnerability detection. In particular, we need to find representations of software programs that are suitable for deep learning. For this purpose, we propose using code gadgets to represent programs and then transform them into vectors, where a code gadget is a number of (not necessarily consecutive) lines of code that are semantically related to each other. This leads to the design and implementation of a deep learning-based vulnerability detection system, called Vulnerability Deep Pecker (VulDeePecker). In order to evaluate VulDeePecker, we present the first vulnerability dataset for deep learning approaches. Experimental results show that VulDeePecker can achieve much fewer false negatives (with reasonable false positives) than other approaches. We further apply VulDeePecker to 3 software products (namely Xen, Seamonkey, and Libav) and detect 4 vulnerabilities, which are not reported in the National Vulnerability Database but were ""silently"" patched by the vendors when releasing later versions of these products; in contrast, these vulnerabilities are almost entirely missed by the other vulnerability detection systems we experimented with.","Fri, 5 Jan 2018 09:37:18 UTC (1,913 KB)"
"1012","Deep learning for word-level handwritten Indic script identification","Soumya Ukil, Swarnendu Ghosh, Sk Md Obaidullah, K. C. Santosh, Kaushik Roy, Nibaran Das","Computer Vision and Pattern Recognition (cs.CV)","We propose a novel method that uses convolutional neural networks (CNNs) for feature extraction. Not just limited to conventional spatial domain representation, we use multilevel 2D discrete Haar wavelet transform, where image representations are scaled to a variety of different sizes. These are then used to train different CNNs to select features. To be precise, we use 10 different CNNs that select a set of 10240 features, i.e. 1024/CNN. With this, 11 different handwritten scripts are identified, where 1K words per script are used. In our test, we have achieved the maximum script identification rate of 94.73% using multi-layer perceptron (MLP). Our results outperform the state-of-the-art techniques.","Fri, 5 Jan 2018 04:52:55 UTC (2,782 KB)"
"1013","Combination of Hyperband and Bayesian Optimization for Hyperparameter Optimization in Deep Learning","Jiazhuo Wang, Jason Xu, Xuejun Wang","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","Deep learning has achieved impressive results on many problems. However, it requires high degree of expertise or a lot of experience to tune well the hyperparameters, and such manual tuning process is likely to be biased. Moreover, it is not practical to try out as many different hyperparameter configurations in deep learning as in other machine learning scenarios, because evaluating each single hyperparameter configuration in deep learning would mean training a deep neural network, which usually takes quite long time. Hyperband algorithm achieves state-of-the-art performance on various hyperparameter optimization problems in the field of deep learning. However, Hyperband algorithm does not utilize history information of previous explored hyperparameter configurations, thus the solution found is suboptimal. We propose to combine Hyperband algorithm with Bayesian optimization (which does not ignore history when sampling next trial configuration). Experimental results show that our combination approach is superior to other hyperparameter optimization approaches including Hyperband algorithm.","Fri, 5 Jan 2018 01:00:03 UTC (207 KB)"
"1014","DeepIso: A Deep Learning Model for Peptide Feature Detection","Fatema Tuz Zohora, Ngoc Hieu Tran, Xianglilan Zhang, Lei Xin, Baozhen Shan, Ming Li","Quantitative Methods (q-bio.QM); Neural and Evolutionary Computing (cs.NE); Medical Physics (physics.med-ph)","Liquid chromatography with tandem mass spectrometry (LC-MS/MS) based proteomics is a well-established research field with major applications such as identification of disease biomarkers, drug discovery, drug design and development. In proteomics, protein identification and quantification is a fundamental task, which is done by first enzymatically digesting it into peptides, and then analyzing peptides by LC-MS/MS instruments. The peptide feature detection and quantification from an LC-MS map is the first step in typical analysis workflows. In this paper we propose a novel deep learning based model, DeepIso, that uses Convolutional Neural Networks (CNNs) to scan an LC-MS map to detect peptide features and estimate their abundance. Existing tools are often designed with limited engineered features based on domain knowledge, and depend on pretrained parameters which are hardly updated despite huge amount of new coming proteomic data. Our proposed model, on the other hand, is capable of learning multiple levels of representation of high dimensional data through its many layers of neurons and continuously evolving with newly acquired data. To evaluate our proposed model, we use an antibody dataset including a heavy and a light chain, each digested by Asp-N, Chymotrypsin, Trypsin, thus giving six LC-MS maps for the experiment. Our model achieves 93.21% sensitivity with specificity of 99.44% on this dataset. Our results demonstrate that novel deep learning tools are desirable to advance the state-of-the-art in protein identification and quantification.","Sat, 9 Dec 2017 04:55:39 UTC (1,273 KB)"
"1015","A deep learning approach for detecting traffic accidents from social media data","Zhenhua Zhang, Qing Heb, Jing Gao, Ming Ni","Social and Information Networks (cs.SI); Other Statistics (stat.OT)","This paper employs deep learning in detecting the traffic accident from social media data. First, we thoroughly investigate the 1-year over 3 million tweet contents in two metropolitan areas: Northern Virginia and New York City. Our results show that paired tokens can capture the association rules inherent in the accident-related tweets and further increase the accuracy of the traffic accident detection. Second, two deep learning methods: Deep Belief Network (DBN) and Long Short-Term Memory (LSTM) are investigated and implemented on the extracted token. Results show that DBN can obtain an overall accuracy of 85% with about 44 individual token features and 17 paired token features. The classification results from DBN outperform those of Support Vector Machines (SVMs) and supervised Latent Dirichlet allocation (sLDA). Finally, to validate this study, we compare the accident-related tweets with both the traffic accident log on freeways and traffic data on local roads from 15,000 loop detectors. It is found that nearly 66% of the accident-related tweets can be located by the accident log and more than 80% of them can be tied to nearby abnormal traffic data. Several important issues of using Twitter to detect traffic accidents have been brought up by the comparison including the location and time bias, as well as the characteristics of influential users and hashtags.","Thu, 4 Jan 2018 19:54:35 UTC (809 KB)"
"1016","DeepTriage: Exploring the Effectiveness of Deep Learning for Bug Triaging","Senthil Mani, Anush Sankaran, Rahul Aralikatte","Software Engineering (cs.SE); Machine Learning (cs.LG)","For a given software bug report, identifying an appropriate developer who could potentially fix the bug is the primary task of a bug triaging process. A bug title (summary) and a detailed description is present in most of the bug tracking systems. Automatic bug triaging algorithm can be formulated as a classification problem, with the bug title and description as the input, mapping it to one of the available developers (classes). The major challenge is that the bug description usually contains a combination of free unstructured text, code snippets, and stack trace making the input data noisy. The existing bag-of-words (BOW) feature models do not consider the syntactical and sequential word information available in the unstructured text. We propose a novel bug report representation algorithm using an attention based deep bidirectional recurrent neural network (DBRNN-A) model that learns a syntactic and semantic feature from long word sequences in an unsupervised manner. Instead of BOW features, the DBRNN-A based bug representation is then used for training the classifier. Using an attention mechanism enables the model to learn the context representation over a long word sequence, as in a bug report. To provide a large amount of data to learn the feature learning model, the unfixed bug reports (~70% bugs in an open source bug tracking system) are leveraged, which were completely ignored in the previous studies. Another contribution is to make this research reproducible by making the source code available and creating a public benchmark dataset of bug reports from three open source bug tracking system: Google Chromium (383,104 bug reports), Mozilla Core (314,388 bug reports), and Mozilla Firefox (162,307 bug reports). Experimentally we compare our approach with BOW model and machine learning approaches and observe that DBRNN-A provides a higher rank-10 average accuracy.","Thu, 4 Jan 2018 08:32:05 UTC (1,014 KB)"
"1017","Deep Learning Reconstruction for 9-View Dual Energy CT Baggage Scanner","Yoseob Han, Jingu Kang, Jong Chul Ye","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","For homeland and transportation security applications, 2D X-ray explosive detection system (EDS) have been widely used, but they have limitations in recognizing 3D shape of the hidden objects. Among various types of 3D computed tomography (CT) systems to address this issue, this paper is interested in a stationary CT using fixed X-ray sources and detectors. However, due to the limited number of projection views, analytic reconstruction algorithms produce severe streaking artifacts. Inspired by recent success of deep learning approach for sparse view CT reconstruction, here we propose a novel image and sinogram domain deep learning architecture for 3D reconstruction from very sparse view measurement. The algorithm has been tested with the real data from a prototype 9-view dual energy stationary CT EDS carry-on baggage scanner developed by GEMSS Medical Systems, Korea, which confirms the superior reconstruction performance over the existing approaches.","Thu, 4 Jan 2018 06:35:53 UTC (2,631 KB)"
"1018","Proteomics Analysis of FLT3-ITD Mutation in Acute Myeloid Leukemia Using Deep Learning Neural Network","Christine A. Liang, Lei Chen, Amer Wahed, Andy N.D. Nguyen","Quantitative Methods (q-bio.QM); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep Learning can significantly benefit cancer proteomics and genomics. In this study, we attempt to determine a set of critical proteins that are associated with the FLT3-ITD mutation in newly-diagnosed acute myeloid leukemia patients. A Deep Learning network consisting of autoencoders forming a hierarchical model from which high-level features are extracted without labeled training data. Dimensional reduction reduced the number of critical proteins from 231 to 20. Deep Learning found an excellent correlation between FLT3-ITD mutation with the levels of these 20 critical proteins (accuracy 97%, sensitivity 90%, specificity 100%). Our Deep Learning network could hone in on 20 proteins with the strongest association with FLT3-ITD. The results of this study allow a novel approach to determine critical protein pathways in the FLT3-ITD mutation, and provide proof-of-concept for an accurate approach to model big data in cancer proteomics and genomics.","Fri, 29 Dec 2017 13:05:30 UTC (547 KB)"
"1019","Deep Learning for Identifying Potential Conceptual Shifts for Co-creative Drawing","Pegah Karimi, Nicholas Davis, Kazjon Grace, Mary Lou Maher","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","We present a system for identifying conceptual shifts between visual categories, which will form the basis for a co-creative drawing system to help users draw more creative sketches. The system recognizes human sketches and matches them to structurally similar sketches from categories to which they do not belong. This would allow a co-creative drawing system to produce an ambiguous sketch that blends features from both categories.","Tue, 2 Jan 2018 16:51:22 UTC (4,649 KB)"
"1020","High Dimensional Spaces, Deep Learning and Adversarial Examples","Simant Dube","Computer Vision and Pattern Recognition (cs.CV); Cryptography and Security (cs.CR); Machine Learning (cs.LG)","In this paper, we analyze deep learning from a mathematical point of view and derive several novel results. The results are based on intriguing mathematical properties of high dimensional spaces. We first look at perturbation based adversarial examples and show how they can be understood using topological and geometrical arguments in high dimensions. We point out mistake in an argument presented in prior published literature, and we present a more rigorous, general and correct mathematical result to explain adversarial examples in terms of topology of image manifolds. Second, we look at optimization landscapes of deep neural networks and examine the number of saddle points relative to that of local minima. Third, we show how multiresolution nature of images explains perturbation based adversarial examples in form of a stronger result. Our results state that expectation of $L_2$-norm of adversarial perturbations is $O\left(\frac{1}{\sqrt{n}}\right)$ and therefore shrinks to 0 as image resolution $n$ becomes arbitrarily large. Finally, by incorporating the parts-whole manifold learning hypothesis for natural images, we investigate the working of deep neural networks and root causes of adversarial examples and discuss how future improvements can be made and how adversarial examples can be eliminated.","Tue, 2 Jan 2018 12:54:22 UTC (3,854 KB)[v2] Wed, 3 Jan 2018 05:30:30 UTC (3,854 KB)[v3] Mon, 8 Jan 2018 13:53:22 UTC (3,896 KB)[v4] Sun, 14 Jan 2018 01:57:47 UTC (5,771 KB)[v5] Sun, 15 Apr 2018 19:39:11 UTC (5,871 KB)"
"1021","Deep Learning: A Critical Appraisal","Gary Marcus","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","Although deep learning has historical roots going back decades, neither the term ""deep learning"" nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic (2012) deep network model of Imagenet. What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.","Tue, 2 Jan 2018 12:49:35 UTC (258 KB)"
"1022","Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey","Naveed Akhtar, Ajmal Mian","Computer Vision and Pattern Recognition (cs.CV)","Deep learning is at the heart of the current rise of machine learning and artificial intelligence. In the field of Computer Vision, it has become the workhorse for applications ranging from self-driving cars to surveillance and security. Whereas deep neural networks have demonstrated phenomenal success (often beyond human capabilities) in solving complex problems, recent studies show that they are vulnerable to adversarial attacks in the form of subtle perturbations to inputs that lead a model to predict incorrect outputs. For images, such perturbations are often too small to be perceptible, yet they completely fool the deep learning models. Adversarial attacks pose a serious threat to the success of deep learning in practice. This fact has lead to a large influx of contributions in this direction. This article presents the first comprehensive survey on adversarial attacks on deep learning in Computer Vision. We review the works that design adversarial attacks, analyze the existence of such attacks and propose defenses against them. To emphasize that adversarial attacks are possible in practical conditions, we separately review the contributions that evaluate adversarial attacks in the real-world scenarios. Finally, we draw on the literature to provide a broader outlook of the research direction.","Tue, 2 Jan 2018 05:22:06 UTC (7,167 KB)[v2] Thu, 4 Jan 2018 08:50:39 UTC (7,168 KB)[v3] Mon, 26 Feb 2018 06:18:58 UTC (7,170 KB)"
"1023","Accelerating Deep Learning with Memcomputing","Haik Manukian, Fabio L. Traversa, Massimiliano Di Ventra","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Neural and Evolutionary Computing (cs.NE)","Restricted Boltzmann machines (RBMs) and their extensions, called 'deep-belief networks', are powerful neural networks that have found applications in the fields of machine learning and artificial intelligence. The standard way to training these models resorts to an iterative unsupervised procedure based on Gibbs sampling, called 'contrastive divergence' (CD), and additional supervised tuning via back-propagation. However, this procedure has been shown not to follow any gradient and can lead to suboptimal solutions. In this paper, we show an efficient alternative to CD by means of simulations of digital memcomputing machines (DMMs). We test our approach on pattern recognition using a modified version of the MNIST data set. DMMs sample effectively the vast phase space given by the model distribution of the RBM, and provide a very good approximation close to the optimum. This efficient search significantly reduces the number of pretraining iterations necessary to achieve a given level of accuracy, as well as a total performance gain over CD. In fact, the acceleration of pretraining achieved by simulating DMMs is comparable to, in number of iterations, the recently reported hardware application of the quantum annealing method on the same network and data set. Notably, however, DMMs perform far better than the reported quantum annealing results in terms of quality of the training. We also compare our method to advances in supervised training, like batch-normalization and rectifiers, that work to reduce the advantage of pretraining. We find that the memcomputing method still maintains a quality advantage ($>1\%$ in accuracy, and a $20\%$ reduction in error rate) over these approaches. Furthermore, our method is agnostic about the connectivity of the network. Therefore, it can be extended to train full Boltzmann machines, and even deep networks at once.","Mon, 1 Jan 2018 21:27:11 UTC (264 KB)[v2] Wed, 24 Jan 2018 01:33:19 UTC (288 KB)[v3] Tue, 23 Oct 2018 19:23:11 UTC (310 KB)"
"1024","Towards Building an Intelligent Anti-Malware System: A Deep Learning Approach using Support Vector Machine (SVM) for Malware Classification","Abien Fred Agarap, Francis John Hill Pepito","Neural and Evolutionary Computing (cs.NE); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Effective and efficient mitigation of malware is a long-time endeavor in the information security community. The development of an anti-malware system that can counteract an unknown malware is a prolific activity that may benefit several sectors. We envision an intelligent anti-malware system that utilizes the power of deep learning (DL) models. Using such models would enable the detection of newly-released malware through mathematical generalization. That is, finding the relationship between a given malware $x$ and its corresponding malware family $y$, $f: x \mapsto y$. To accomplish this feat, we used the Malimg dataset (Nataraj et al., 2011) which consists of malware images that were processed from malware binaries, and then we trained the following DL models 1 to classify each malware family: CNN-SVM (Tang, 2013), GRU-SVM (Agarap, 2017), and MLP-SVM. Empirical evidence has shown that the GRU-SVM stands out among the DL models with a predictive accuracy of ~84.92%. This stands to reason for the mentioned model had the relatively most sophisticated architecture design among the presented models. The exploration of an even more optimal DL-SVM model is the next stage towards the engineering of an intelligent anti-malware system.","Sun, 31 Dec 2017 17:13:55 UTC (736 KB)"
"1025","Early detection of Crossfire attacks using deep learning","Saurabh Misra, Mengxuan Tan, Mostafa Rezazad, Matthias R. Brust, Ngai-Man Cheung","Cryptography and Security (cs.CR)","Crossfire attack is a recently proposed threat designed to disconnect whole geographical areas, such as cities or states, from the Internet. Orchestrated in multiple phases, the attack uses a massively distributed botnet to generate low-rate benign traffic aiming to congest selected network links, so-called target links. The adoption of benign traffic, while simultaneously targeting multiple network links, makes the detection of the Crossfire attack a serious challenge. In this paper, we propose a framework for early detection of Crossfire attack, i.e., detection in the warm-up period of the attack. We propose to monitor traffic at the potential decoy servers and discuss the advantages comparing with other monitoring approaches. Since the low-rate attack traffic is very difficult to distinguish from the background traffic, we investigate several deep learning methods to mine the spatiotemporal features for attack detection. We investigate Autoencoder, Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) Network to detect the Crossfire attack during its warm-up period. We report encouraging experiment results.","Sun, 31 Dec 2017 04:29:21 UTC (589 KB)[v2] Thu, 4 Jan 2018 08:51:19 UTC (590 KB)[v3] Fri, 20 Apr 2018 03:30:25 UTC (590 KB)"
"1026","Theory of Deep Learning III: explaining the non-overfitting puzzle","Tomaso Poggio, Kenji Kawaguchi, Qianli Liao, Brando Miranda, Lorenzo Rosasco, Xavier Boix, Jack Hidary, Hrushikesh Mhaskar","Machine Learning (cs.LG)","A main puzzle of deep networks revolves around the absence of overfitting despite large overparametrization and despite the large capacity demonstrated by zero training error on randomly labeled data. In this note, we show that the dynamics associated to gradient descent minimization of nonlinear networks is topologically equivalent, near the asymptotically stable minima of the empirical error, to linear gradient system in a quadratic potential with a degenerate (for square loss) or almost degenerate (for logistic or crossentropy loss) Hessian. The proposition depends on the qualitative theory of dynamical systems and is supported by numerical results. Our main propositions extend to deep nonlinear networks two properties of gradient descent for linear networks, that have been recently established (1) to be key to their generalization properties: 1. Gradient descent enforces a form of implicit regularization controlled by the number of iterations, and asymptotically converges to the minimum norm solution for appropriate initial conditions of gradient descent. This implies that there is usually an optimum early stopping that avoids overfitting of the loss. This property, valid for the square loss and many other loss functions, is relevant especially for regression. 2. For classification, the asymptotic convergence to the minimum norm solution implies convergence to the maximum margin solution which guarantees good classification error for ""low noise"" datasets. This property holds for loss functions such as the logistic and cross-entropy loss independently of the initial conditions. The robustness to overparametrization has suggestive implications for the robustness of the architecture of deep convolutional networks with respect to the curse of dimensionality.","Sat, 30 Dec 2017 18:27:35 UTC (2,188 KB)[v2] Tue, 16 Jan 2018 08:54:12 UTC (2,425 KB)"
"1027","Towards automated patient data cleaning using deep learning: A feasibility study on the standardization of organ labeling","Timothy Rozario, Troy Long, Mingli Chen, Weiguo Lu, Steve Jiang","Medical Physics (physics.med-ph); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Data cleaning consumes about 80% of the time spent on data analysis for clinical research projects. This is a much bigger problem in the era of big data and machine learning in the field of medicine where large volumes of data are being generated. We report an initial effort towards automated patient data cleaning using deep learning: the standardization of organ labeling in radiation therapy. Organs are often labeled inconsistently at different institutions (sometimes even within the same institution) and at different time periods, which poses a problem for clinical research, especially for multi-institutional collaborative clinical research where the acquired patient data is not being used effectively. We developed a convolutional neural network (CNN) to automatically identify each organ in the CT image and then label it with the standardized nomenclature presented at AAPM Task Group 263. We tested this model on the CT images of 54 patients with prostate and 100 patients with head and neck cancer who previously received radiation therapy. The model achieved 100% accuracy in detecting organs and assigning standardized labels for the patients tested. This work shows the feasibility of using deep learning in patient data cleaning that enables standardized datasets to be generated for effective intra- and interinstitutional collaborative clinical research.","Sat, 30 Dec 2017 07:56:46 UTC (1,034 KB)"
"1028","Deep Learning Interior Tomography for Region-of-Interest Reconstruction","Yoseob Han, Jawook Gu, Jong Chul Ye","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","Interior tomography for the region-of-interest (ROI) imaging has advantages of using a small detector and reducing X-ray radiation dose. However, standard analytic reconstruction suffers from severe cupping artifacts due to existence of null space in the truncated Radon transform. Existing penalized reconstruction methods may address this problem but they require extensive computations due to the iterative reconstruction. Inspired by the recent deep learning approaches to low-dose and sparse view CT, here we propose a deep learning architecture that removes null space signals from the FBP reconstruction. Experimental results have shown that the proposed method provides near-perfect reconstruction with about 7-10 dB improvement in PSNR over existing methods in spite of significantly reduced run-time complexity.","Fri, 29 Dec 2017 14:59:41 UTC (6,436 KB)[v2] Wed, 3 Jan 2018 15:54:24 UTC (6,499 KB)"
"1029","Automatic Analysis of EEGs Using Big Data and Hybrid Deep Learning Architectures","Meysam Golmohammadi, Amir Hossein Harati Nejad Torbati, Silvia Lopez de Diego, Iyad Obeid, Joseph Picone","Machine Learning (cs.LG); Signal Processing (eess.SP); Neurons and Cognition (q-bio.NC); Machine Learning (stat.ML)","Objective: A clinical decision support tool that automatically interprets EEGs can reduce time to diagnosis and enhance real-time applications such as ICU monitoring. Clinicians have indicated that a sensitivity of 95% with a specificity below 5% was the minimum requirement for clinical acceptance. We propose a highperformance classification system based on principles of big data and machine learning. Methods: A hybrid machine learning system that uses hidden Markov models (HMM) for sequential decoding and deep learning networks for postprocessing is proposed. These algorithms were trained and evaluated using the TUH EEG Corpus, which is the world's largest publicly available database of clinical EEG data. Results: Our approach delivers a sensitivity above 90% while maintaining a specificity below 5%. This system detects three events of clinical interest: (1) spike and/or sharp waves, (2) periodic lateralized epileptiform discharges, (3) generalized periodic epileptiform discharges. It also detects three events used to model background noise: (1) artifacts, (2) eye movement (3) background. Conclusions: A hybrid HMM/deep learning system can deliver a low false alarm rate on EEG event detection, making automated analysis a viable option for clinicians. Significance: The TUH EEG Corpus enables application of highly data consumptive machine learning algorithms to EEG analysis. Performance is approaching clinical acceptance for real-time applications.","Thu, 28 Dec 2017 06:22:28 UTC (1,392 KB)"
"1030","Deep learning for universal linear embeddings of nonlinear dynamics","Bethany Lusch, J. Nathan Kutz, Steven L. Brunton","Dynamical Systems (math.DS); Machine Learning (cs.LG); Machine Learning (stat.ML)","Identifying coordinate transformations that make strongly nonlinear dynamics approximately linear is a central challenge in modern dynamical systems. These transformations have the potential to enable prediction, estimation, and control of nonlinear systems using standard linear theory. The Koopman operator has emerged as a leading data-driven embedding, as eigenfunctions of this operator provide intrinsic coordinates that globally linearize the dynamics. However, identifying and representing these eigenfunctions has proven to be mathematically and computationally challenging. This work leverages the power of deep learning to discover representations of Koopman eigenfunctions from trajectory data of dynamical systems. Our network is parsimonious and interpretable by construction, embedding the dynamics on a low-dimensional manifold that is of the intrinsic rank of the dynamics and parameterized by the Koopman eigenfunctions. In particular, we identify nonlinear coordinates on which the dynamics are globally linear using a modified auto-encoder. We also generalize Koopman representations to include a ubiquitous class of systems that exhibit continuous spectra, ranging from the simple pendulum to nonlinear optics and broadband turbulence. Our framework parametrizes the continuous frequency using an auxiliary network, enabling a compact and efficient embedding at the intrinsic rank, while connecting our models to half a century of asymptotics. In this way, we benefit from the power and generality of deep learning, while retaining the physical interpretability of Koopman embeddings.","Wed, 27 Dec 2017 23:10:35 UTC (1,941 KB)[v2] Fri, 13 Apr 2018 06:17:30 UTC (6,368 KB)"
"1031","Multiple Instance Deep Learning for Weakly Supervised Small-Footprint Audio Event Detection","Shao-Yen Tseng, Juncheng Li, Yun Wang, Joseph Szurley, Florian Metze, Samarjit Das","Sound (cs.SD); Audio and Speech Processing (eess.AS)","State-of-the-art audio event detection (AED) systems rely on supervised learning using strongly labeled data. However, this dependence severely limits scalability to large-scale datasets where fine resolution annotations are too expensive to obtain. In this paper, we propose a small-footprint multiple instance learning (MIL) framework for multi-class AED using weakly annotated labels. The proposed MIL framework uses audio embeddings extracted from a pre-trained convolutional neural network as input features. We show that by using audio embeddings the MIL framework can be implemented using a simple DNN with performance comparable to recurrent neural networks. We evaluate our approach by training an audio tagging system using a subset of AudioSet, which is a large collection of weakly labeled YouTube video excerpts. Combined with a late-fusion approach, we improve the F1 score of a baseline audio tagging system by 17%. We show that audio embeddings extracted by the convolutional neural networks significantly boost the performance of all MIL models. This framework reduces the model complexity of the AED system and is suitable for applications where computational resources are limited.","Wed, 27 Dec 2017 20:30:45 UTC (417 KB)[v2] Mon, 26 Mar 2018 12:56:57 UTC (430 KB)"
"1032","Android Malware Detection using Deep Learning on API Method Sequences","ElMouatez Billah Karbab, Mourad Debbabi, Abdelouahid Derhab, Djedjiga Mouheb","Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)","Android OS experiences a blazing popularity since the last few years. This predominant platform has established itself not only in the mobile world but also in the Internet of Things (IoT) devices. This popularity, however, comes at the expense of security, as it has become a tempting target of malicious apps. Hence, there is an increasing need for sophisticated, automatic, and portable malware detection solutions. In this paper, we propose MalDozer, an automatic Android malware detection and family attribution framework that relies on sequences classification using deep learning techniques. Starting from the raw sequence of the app's API method calls, MalDozer automatically extracts and learns the malicious and the benign patterns from the actual samples to detect Android malware. MalDozer can serve as a ubiquitous malware detection system that is not only deployed on servers, but also on mobile and even IoT devices. We evaluate MalDozer on multiple Android malware datasets ranging from 1K to 33K malware apps, and 38K benign apps. The results show that MalDozer can correctly detect malware and attribute them to their actual families with an F1-Score of 96%-99% and a false positive rate of 0.06%-2%, under all tested datasets and settings.","Mon, 25 Dec 2017 03:26:21 UTC (2,177 KB)"
"1033","Deep Learning for Massive MIMO CSI Feedback","Chao-Kai Wen, Wan-Ting Shih, Shi Jin","Information Theory (cs.IT)","In frequency division duplex mode, the downlink channel state information (CSI) should be sent to the base station through feedback links so that the potential gains of a massive multiple-input multiple-output can be exhibited. However, such a transmission is hindered by excessive feedback overhead. In this letter, we use deep learning technology to develop CsiNet, a novel CSI sensing and recovery {mechanism} that learns to effectively use channel structure from training samples. CsiNet learns a transformation from CSI to a near-optimal number of representations (or codewords) and an inverse transformation from codewords to CSI. We perform experiments to demonstrate that CsiNet can recover CSI with significantly improved reconstruction quality compared with existing compressive sensing (CS)-based methods. Even at excessively low compression regions where CS-based methods cannot work, CsiNet retains effective beamforming gain.","Sun, 24 Dec 2017 13:34:27 UTC (443 KB)[v2] Sun, 4 Mar 2018 04:45:41 UTC (233 KB)[v3] Thu, 12 Apr 2018 05:51:20 UTC (233 KB)[v4] Mon, 23 Apr 2018 13:29:55 UTC (232 KB)"
"1034","Dropout Feature Ranking for Deep Learning Models","Chun-Hao Chang, Ladislav Rampasek, Anna Goldenberg","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep neural networks (DNNs) achieve state-of-the-art results in a variety of domains. Unfortunately, DNNs are notorious for their non-interpretability, and thus limit their applicability in hypothesis-driven domains such as biology and healthcare. Moreover, in the resource-constraint setting, it is critical to design tests relying on fewer more informative features leading to high accuracy performance within reasonable budget. We aim to close this gap by proposing a new general feature ranking method for deep learning. We show that our simple yet effective method performs on par or compares favorably to eight strawman, classical and deep-learning feature ranking methods in two simulations and five very different datasets on tasks ranging from classification to regression, in both static and time series scenarios. We also illustrate the use of our method on a drug response dataset and show that it identifies genes relevant to the drug-response.","Fri, 22 Dec 2017 20:25:31 UTC (199 KB)[v2] Fri, 9 Mar 2018 16:36:04 UTC (831 KB)"
"1035","Learning in the Machine: the Symmetries of the Deep Learning Channel","Pierre Baldi, Peter Sadowski, Zhiqin Lu","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG)","In a physical neural system, learning rules must be local both in space and time. In order for learning to occur, non-local information must be communicated to the deep synapses through a communication channel, the deep learning channel. We identify several possible architectures for this learning channel (Bidirectional, Conjoined, Twin, Distinct) and six symmetry challenges: 1) symmetry of architectures; 2) symmetry of weights; 3) symmetry of neurons; 4) symmetry of derivatives; 5) symmetry of processing; and 6) symmetry of learning rules. Random backpropagation (RBP) addresses the second and third symmetry, and some of its variations, such as skipped RBP (SRBP) address the first and the fourth symmetry. Here we address the last two desirable symmetries showing through simulations that they can be achieved and that the learning channel is particularly robust to symmetry variations. Specifically, random backpropagation and its variations can be performed with the same non-linear neurons used in the main input-output forward channel, and the connections in the learning channel can be adapted using the same algorithm used in the forward channel, removing the need for any specialized hardware in the learning channel. Finally, we provide mathematical results in simple cases showing that the learning equations in the forward and backward channels converge to fixed points, for almost any initial conditions. In symmetric architectures, if the weights in both channels are small at initialization, adaptation in both channels leads to weights that are essentially symmetric during and after learning. Biological connections are discussed.","Fri, 22 Dec 2017 18:43:58 UTC (3,009 KB)"
"1036","Differential geometry and stochastic dynamics with deep learning numerics","Line Kuhnel, Alexis Arnaudon, Stefan Sommer","Computational Geometry (cs.CG); Computation (stat.CO)","In this paper, we demonstrate how deterministic and stochastic dynamics on manifolds, as well as differential geometric constructions can be implemented concisely and efficiently using modern computational frameworks that mix symbolic expressions with efficient numerical computations. In particular, we use the symbolic expression and automatic differentiation features of the python library Theano, originally developed for high-performance computations in deep learning. We show how various aspects of differential geometry and Lie group theory, connections, metrics, curvature, left/right invariance, geodesics and parallel transport can be formulated with Theano using the automatic computation of derivatives of any order. We will also show how symbolic stochastic integrators and concepts from non-linear statistics can be formulated and optimized with only a few lines of code. We will then give explicit examples on low-dimensional classical manifolds for visualization and demonstrate how this approach allows both a concise implementation and efficient scaling to high dimensional problems.","Fri, 22 Dec 2017 09:23:06 UTC (2,947 KB)"
"1037","A Deep Learning Interpretable Classifier for Diabetic Retinopathy Disease Grading","Jordi de la Torre, Aida Valls, Domenec Puig","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Deep neural network models have been proven to be very successful in image classification tasks, also for medical diagnosis, but their main concern is its lack of interpretability. They use to work as intuition machines with high statistical confidence but unable to give interpretable explanations about the reported results. The vast amount of parameters of these models make difficult to infer a rationale interpretation from them. In this paper we present a diabetic retinopathy interpretable classifier able to classify retine images into the different levels of disease severity and of explaining its results by assigning a score for every point in the hidden and input space, evaluating its contribution to the final classification in a linear way. The generated visual maps can be interpreted by an expert in order to compare its own knowledge with the interpretation given by the model.","Thu, 21 Dec 2017 17:40:32 UTC (7,410 KB)"
"1038","Multiview Deep Learning for Predicting Twitter Users' Location","Tien Huu Do, Duc Minh Nguyen, Evaggelia Tsiligianni, Bruno Cornelis, Nikos Deligiannis","Machine Learning (cs.LG); Information Retrieval (cs.IR); Social and Information Networks (cs.SI); Machine Learning (stat.ML)","The problem of predicting the location of users on large social networks like Twitter has emerged from real-life applications such as social unrest detection and online marketing. Twitter user geolocation is a difficult and active research topic with a vast literature. Most of the proposed methods follow either a content-based or a network-based approach. The former exploits user-generated content while the latter utilizes the connection or interaction between Twitter users. In this paper, we introduce a novel method combining the strength of both approaches. Concretely, we propose a multi-entry neural network architecture named MENET leveraging the advances in deep learning and multiview learning. The generalizability of MENET enables the integration of multiple data representations. In the context of Twitter user geolocation, we realize MENET with textual, network, and metadata features. Considering the natural distribution of Twitter users across the concerned geographical area, we subdivide the surface of the earth into multi-scale cells and train MENET with the labels of the cells. We show that our method outperforms the state of the art by a large margin on three benchmark datasets.","Thu, 21 Dec 2017 17:15:41 UTC (8,672 KB)"
"1039","Prediction of laminar vortex shedding over a cylinder using deep learning","Sangseung Lee, Donghyun You","Fluid Dynamics (physics.flu-dyn)","Unsteady laminar vortex shedding over a circular cylinder is predicted using a deep learning technique, a generative adversarial network (GAN), with a particular emphasis on elucidating the potential of learning the solution of the Navier-Stokes equations. Numerical simulations at two different Reynolds numbers with different time-step sizes are conducted to produce training datasets of flow field variables. Unsteady flow fields in the future at a Reynolds number which is not in the training datasets are predicted using a GAN. Predicted flow fields are found to qualitatively and quantitatively agree well with flow fields calculated by numerical simulations. The present study suggests that a deep learning technique can be utilized for prediction of laminar wake flow in lieu of solving the Navier-Stokes equations.","Thu, 21 Dec 2017 10:06:28 UTC (3,395 KB)"
"1040","Wolf in Sheep's Clothing - The Downscaling Attack Against Deep Learning Applications","Qixue Xiao, Kang Li, Deyue Zhang, Yier Jin","Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","This paper considers security risks buried in the data processing pipeline in common deep learning applications. Deep learning models usually assume a fixed scale for their training and input data. To allow deep learning applications to handle a wide range of input data, popular frameworks, such as Caffe, TensorFlow, and Torch, all provide data scaling functions to resize input to the dimensions used by deep learning models. Image scaling algorithms are intended to preserve the visual features of an image after scaling. However, common image scaling algorithms are not designed to handle human crafted images. Attackers can make the scaling outputs look dramatically different from the corresponding input images. This paper presents a downscaling attack that targets the data scaling process in deep learning applications. By carefully crafting input data that mismatches with the dimension used by deep learning models, attackers can create deceiving effects. A deep learning application effectively consumes data that are not the same as those presented to users. The visual inconsistency enables practical evasion and data poisoning attacks to deep learning applications. This paper presents proof-of-concept attack samples to popular deep-learning-based image classification applications. To address the downscaling attacks, the paper also suggests multiple potential mitigation strategies.","Thu, 21 Dec 2017 06:17:43 UTC (1,008 KB)"
"1041","Towards a Deep Improviser: a prototype deep learning post-tonal free music generator","Roger T. Dean, Jamie Forth","Sound (cs.SD); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)","Two modest-sized symbolic corpora of post-tonal and post-metric keyboard music have been constructed, one algorithmic, the other improvised. Deep learning models of each have been trained and largely optimised. Our purpose is to obtain a model with sufficient generalisation capacity that in response to a small quantity of separate fresh input seed material, it can generate outputs that are distinctive, rather than recreative of the learned corpora or the seed material. This objective has been first assessed statistically, and as judged by k-sample Anderson-Darling and Cramer tests, has been achieved. Music has been generated using the approach, and informal judgements place it roughly on a par with algorithmic and composed music in related forms. Future work will aim to enhance the model such that it can be evaluated in relation to expression, meaning and utility in real-time performance.","Thu, 21 Dec 2017 05:28:15 UTC (193 KB)"
"1042","Deep learning for predicting refractive error from retinal fundus images","Avinash V. Varadarajan, Ryan Poplin, Katy Blumer, Christof Angermueller, Joe Ledsam, Reena Chopra, Pearse A. Keane, Greg S. Corrado, Lily Peng, Dale R. Webster","Computer Vision and Pattern Recognition (cs.CV)","Refractive error, one of the leading cause of visual impairment, can be corrected by simple interventions like prescribing eyeglasses. We trained a deep learning algorithm to predict refractive error from the fundus photographs from participants in the UK Biobank cohort, which were 45 degree field of view images and the AREDS clinical trial, which contained 30 degree field of view images. Our model use the ""attention"" method to identify features that are correlated with refractive error. Mean absolute error (MAE) of the algorithm's prediction compared to the refractive error obtained in the AREDS and UK Biobank. The resulting algorithm had a MAE of 0.56 diopters (95% CI: 0.55-0.56) for estimating spherical equivalent on the UK Biobank dataset and 0.91 diopters (95% CI: 0.89-0.92) for the AREDS dataset. The baseline expected MAE (obtained by simply predicting the mean of this population) was 1.81 diopters (95% CI: 1.79-1.84) for UK Biobank and 1.63 (95% CI: 1.60-1.67) for AREDS. Attention maps suggested that the foveal region was one of the most important areas used by the algorithm to make this prediction, though other regions also contribute to the prediction. The ability to estimate refractive error with high accuracy from retinal fundus photos has not been previously known and demonstrates that deep learning can be applied to make novel predictions from medical images. Given that several groups have recently shown that it is feasible to obtain retinal fundus photos using mobile phones and inexpensive attachments, this work may be particularly relevant in regions of the world where autorefractors may not be readily available.","Thu, 21 Dec 2017 05:27:56 UTC (871 KB)"
"1043","The Character Thinks Ahead: creative writing with deep learning nets and its stylistic assessment","Roger T. Dean, Hazel Smith","Computation and Language (cs.CL)","We discuss how to control outputs from deep learning models of text corpora so as to create contemporary poetic works. We assess whether these controls are successful in the immediate sense of creating stylo- metric distinctiveness. The specific context is our piece The Character Thinks Ahead (2016/17); the potential applications are broad.","Thu, 21 Dec 2017 05:16:51 UTC (700 KB)"
"1044","Deep Learning with Lung Segmentation and Bone Shadow Exclusion Techniques for Chest X-Ray Analysis of Lung Cancer","Yu.Gordienko, Peng Gang, Jiang Hui, Wei Zeng, Yu.Kochura, O.Alienin, O. Rokovyi, S. Stirenko","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)","The recent progress of computing, machine learning, and especially deep learning, for image recognition brings a meaningful effect for automatic detection of various diseases from chest X-ray images (CXRs). Here efficiency of lung segmentation and bone shadow exclusion techniques is demonstrated for analysis of 2D CXRs by deep learning approach to help radiologists identify suspicious lesions and nodules in lung cancer patients. Training and validation was performed on the original JSRT dataset (dataset #01), BSE-JSRT dataset, i.e. the same JSRT dataset, but without clavicle and rib shadows (dataset #02), original JSRT dataset after segmentation (dataset #03), and BSE-JSRT dataset after segmentation (dataset #04). The results demonstrate the high efficiency and usefulness of the considered pre-processing techniques in the simplified configuration even. The pre-processed dataset without bones (dataset #02) demonstrates the much better accuracy and loss results in comparison to the other pre-processed datasets after lung segmentation (datasets #02 and #03).","Wed, 20 Dec 2017 18:40:49 UTC (567 KB)"
"1045","Use of Deep Learning in Modern Recommendation System: A Summary of Recent Works","Ayush Singhal, Pradeep Sinha, Rakesh Pant","Machine Learning (cs.LG); Information Retrieval (cs.IR)","With the exponential increase in the amount of digital information over the internet, online shops, online music, video and image libraries, search engines and recommendation system have become the most convenient ways to find relevant information within a short time. In the recent times, deep learning's advances have gained significant attention in the field of speech recognition, image processing and natural language processing. Meanwhile, several recent studies have shown the utility of deep learning in the area of recommendation systems and information retrieval as well. In this short review, we cover the recent advances made in the field of recommendation using various variants of deep learning technology. We organize the review in three parts: Collaborative system, Content based system and Hybrid system. The review also discusses the contribution of deep learning integrated recommendation systems into several application domains. The review concludes by discussion of the impact of deep learning in recommendation system in various domain and whether deep learning has shown any significant improvement over the conventional systems for recommendation. Finally, we also provide future directions of research which are possible based on the current state of use of deep learning in recommendation systems.","Wed, 20 Dec 2017 15:25:31 UTC (444 KB)"
"1046","Real-value and confidence prediction of protein backbone dihedral angles through a hybrid method of clustering and deep learning","Yujuan Gao, Sheng Wang, Minghua Deng, Jinbo Xu","Biomolecules (q-bio.BM)","Background. Protein dihedral angles provide a detailed description of protein local conformation. Predicted dihedral angles can be used to narrow down the conformational space of the whole polypeptide chain significantly, thus aiding protein tertiary structure prediction. However, direct angle prediction from sequence alone is challenging. Method. In this study, we present a novel method to predict real-valued angles by combining clustering and deep learning. That is, we first generate certain clusters of angles (each assigned a label) and then apply a deep residual neural network to predict the label posterior probability. Finally, we output real-valued prediction by a mixture of the clusters with their predicted probabilities. At the same time, we also estimate the bound of the prediction errors at each residue from the predicted label probabilities. Result. In this article, we present a novel method (named RaptorX-Angle) to predict real-valued angles by combining clustering and deep learning. Tested on a subset of PDB25 and the targets in the latest two Critical Assessment of protein Structure Prediction (CASP), our method outperforms the existing state-of-art method SPIDER2 in terms of Pearson Correlation Coefficient (PCC) and Mean Absolute Error (MAE). Our result also shows approximately linear relationship between the real prediction errors and our estimated bounds. That is, the real prediction error can be well approximated by our estimated bounds. Conclusions. Our study provides an alternative and more accurate prediction of dihedral angles, which may facilitate protein structure prediction and functional study.","Tue, 19 Dec 2017 22:33:13 UTC (500 KB)"
"1047","Adversarial Examples: Attacks and Defenses for Deep Learning","Xiaoyong Yuan, Pan He, Qile Zhu, Xiaolin Li","Machine Learning (cs.LG); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","With rapid progress and significant successes in a wide spectrum of applications, deep learning is being applied in many safety-critical environments. However, deep neural networks have been recently found vulnerable to well-designed input samples, called adversarial examples. Adversarial examples are imperceptible to human but can easily fool deep neural networks in the testing/deploying stage. The vulnerability to adversarial examples becomes one of the major risks for applying deep neural networks in safety-critical environments. Therefore, attacks and defenses on adversarial examples draw great attention. In this paper, we review recent findings on adversarial examples for deep neural networks, summarize the methods for generating adversarial examples, and propose a taxonomy of these methods. Under the taxonomy, applications for adversarial examples are investigated. We further elaborate on countermeasures for adversarial examples and explore the challenges and the potential solutions.","Tue, 19 Dec 2017 18:44:07 UTC (8,019 KB)[v2] Fri, 5 Jan 2018 15:51:54 UTC (8,021 KB)[v3] Sat, 7 Jul 2018 02:32:57 UTC (8,024 KB)"
"1048","Development and evaluation of a deep learning model for protein-ligand binding affinity prediction","Marta M. Stepniewska-Dziubinska, Piotr Zielenkiewicz, Pawel Siedlecki","Machine Learning (stat.ML); Machine Learning (cs.LG); Biomolecules (q-bio.BM)","Structure based ligand discovery is one of the most successful approaches for augmenting the drug discovery process. Currently, there is a notable shift towards machine learning (ML) methodologies to aid such procedures. Deep learning has recently gained considerable attention as it allows the model to ""learn"" to extract features that are relevant for the task at hand. We have developed a novel deep neural network estimating the binding affinity of ligand-receptor complexes. The complex is represented with a 3D grid, and the model utilizes a 3D convolution to produce a feature map of this representation, treating the atoms of both proteins and ligands in the same manner. Our network was tested on the CASF ""scoring power"" benchmark and Astex Diverse Set and outperformed classical scoring functions. The model, together with usage instructions and examples, is available as a git repository at this http URL","Tue, 19 Dec 2017 16:49:01 UTC (1,010 KB)[v2] Wed, 3 Jan 2018 16:15:15 UTC (1,010 KB)"
"1049","DeepNorm-A Deep Learning Approach to Text Normalization","Maryam Zare, Shaurya Rohatgi","Computation and Language (cs.CL)","This paper presents an simple yet sophisticated approach to the challenge by Sproat and Jaitly (2016)- given a large corpus of written text aligned to its normalized spoken form, train an RNN to learn the correct normalization function. Text normalization for a token seems very straightforward without it's context. But given the context of the used token and then normalizing becomes tricky for some classes. We present a novel approach in which the prediction of our classification algorithm is used by our sequence to sequence model to predict the normalized text of the input token. Our approach takes very less time to learn and perform well unlike what has been reported by Google (5 days on their GPU cluster). We have achieved an accuracy of 97.62 which is impressive given the resources we use. Our approach is using the best of both worlds, gradient boosting - state of the art in most classification tasks and sequence to sequence learning - state of the art in machine translation. We present our experiments and report results with various parameter settings.","Sun, 17 Dec 2017 18:31:26 UTC (1,377 KB)"
"1050","Multi-modal Face Pose Estimation with Multi-task Manifold Deep Learning","Chaoqun Hong, Jun Yu","Computer Vision and Pattern Recognition (cs.CV)","Human face pose estimation aims at estimating the gazing direction or head postures with 2D images. It gives some very important information such as communicative gestures, saliency detection and so on, which attracts plenty of attention recently. However, it is challenging because of complex background, various orientations and face appearance visibility. Therefore, a descriptive representation of face images and mapping it to poses are critical. In this paper, we make use of multi-modal data and propose a novel face pose estimation method that uses a novel deep learning framework named Multi-task Manifold Deep Learning $M^2DL$. It is based on feature extraction with improved deep neural networks and multi-modal mapping relationship with multi-task learning. In the proposed deep learning based framework, Manifold Regularized Convolutional Layers (MRCL) improve traditional convolutional layers by learning the relationship among outputs of neurons. Besides, in the proposed mapping relationship learning method, different modals of face representations are naturally combined to learn the mapping function from face images to poses. In this way, the computed mapping model with multiple tasks is improved. Experimental results on three challenging benchmark datasets DPOSE, HPID and BKHPD demonstrate the outstanding performance of $M^2DL$.","Mon, 18 Dec 2017 15:22:26 UTC (2,109 KB)"
"1051","SchNet - a deep learning architecture for molecules and materials","Kristof T. Schutt, Huziel E. Sauceda, Pieter-Jan Kindermans, Alexandre Tkatchenko, Klaus-Robert Muller","Chemical Physics (physics.chem-ph); Materials Science (cond-mat.mtrl-sci)","Deep learning has led to a paradigm shift in artificial intelligence, including web, text and image search, speech recognition, as well as bioinformatics, with growing impact in chemical physics. Machine learning in general and deep learning in particular is ideally suited for representing quantum-mechanical interactions, enabling to model nonlinear potential-energy surfaces or enhancing the exploration of chemical compound space. Here we present the deep learning architecture SchNet that is specifically designed to model atomistic systems by making use of continuous-filter convolutional layers. We demonstrate the capabilities of SchNet by accurately predicting a range of properties across chemical space for \emph{molecules and materials} where our model learns chemically plausible embeddings of atom types across the periodic table. Finally, we employ SchNet to predict potential-energy surfaces and energy-conserving force fields for molecular dynamics simulations of small molecules and perform an exemplary study of the quantum-mechanical properties of C$_{20}$-fullerene that would have been infeasible with regular ab initio molecular dynamics.","Sun, 17 Dec 2017 13:55:03 UTC (3,393 KB)[v2] Wed, 7 Mar 2018 12:42:19 UTC (3,353 KB)[v3] Thu, 22 Mar 2018 11:12:43 UTC (3,353 KB)"
"1052","Railway Track Specific Traffic Signal Selection Using Deep Learning","S Ritika, Shruti Mittal, Dattaraj Rao","Computer Vision and Pattern Recognition (cs.CV)","With the railway transportation Industry moving actively towards automation, accurate location and inventory of wayside track assets like traffic signals, crossings, switches, mileposts, etc. is of extreme importance. With the new Positive Train Control (PTC) regulation coming into effect, many railway safety rules will be tied directly to location of assets like mileposts and signals. Newer speed regulations will be enforced based on location of the Train with respect to a wayside asset. Hence it is essential for the railroads to have an accurate database of the types and locations of these assets. This paper talks about a real-world use-case of detecting railway signals from a camera mounted on a moving locomotive and tracking their locations. The camera is engineered to withstand the environment factors on a moving train and provide a consistent steady image at around 30 frames per second. Using advanced image analysis and deep learning techniques, signals are detected in these camera images and a database of their locations is created. Railway signals differ a lot from road signals in terms of shapes and rules for placement with respect to track. Due to space constraint and traffic densities in urban areas signals are not placed on the same side of the track and multiple lines can run in parallel. Hence there is need to associate signal detected with the track on which the train runs. We present a method to associate the signals to the specific track they belong to using a video feed from the front facing camera mounted on the lead locomotive. A pipeline of track detection, region of interest selection, signal detection has been implemented which gives an overall accuracy of 94.7% on a route covering 150km with 247 signals.","Sun, 17 Dec 2017 13:00:25 UTC (1,279 KB)"
"1053","Efficient B-mode Ultrasound Image Reconstruction from Sub-sampled RF Data using Deep Learning","Yeo Hun Yoon, Shujaat Khan, Jaeyoung Huh, Jong Chul Ye","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","In portable, three dimensional, and ultra-fast ultrasound imaging systems, there is an increasing demand for the reconstruction of high quality images from a limited number of radio-frequency (RF) measurements due to receiver (Rx) or transmit (Xmit) event sub-sampling. However, due to the presence of side lobe artifacts from RF sub-sampling, the standard beamformer often produces blurry images with less contrast, which are unsuitable for diagnostic purposes. Existing compressed sensing approaches often require either hardware changes or computationally expensive algorithms, but their quality improvements are limited. To address this problem, here we propose a novel deep learning approach that directly interpolates the missing RF data by utilizing redundancy in the Rx-Xmit plane. Our extensive experimental results using sub-sampled RF data from a multi-line acquisition B-mode system confirm that the proposed method can effectively reduce the data rate without sacrificing image quality.","Sun, 17 Dec 2017 12:15:08 UTC (5,069 KB)[v2] Thu, 21 Dec 2017 03:58:18 UTC (5,069 KB)[v3] Tue, 7 Aug 2018 09:19:13 UTC (8,397 KB)"
"1054","Deep Learning for Distant Speech Recognition","Mirco Ravanelli","Computation and Language (cs.CL); Sound (cs.SD); Audio and Speech Processing (eess.AS)","Deep learning is an emerging technology that is considered one of the most promising directions for reaching higher levels of artificial intelligence. Among the other achievements, building computers that understand speech represents a crucial leap towards intelligent machines. Despite the great efforts of the past decades, however, a natural and robust human-machine speech interaction still appears to be out of reach, especially when users interact with a distant microphone in noisy and reverberant environments. The latter disturbances severely hamper the intelligibility of a speech signal, making Distant Speech Recognition (DSR) one of the major open challenges in the field. This thesis addresses the latter scenario and proposes some novel techniques, architectures, and algorithms to improve the robustness of distant-talking acoustic models. We first elaborate on methodologies for realistic data contamination, with a particular emphasis on DNN training with simulated data. We then investigate on approaches for better exploiting speech contexts, proposing some original methodologies for both feed-forward and recurrent neural networks. Lastly, inspired by the idea that cooperation across different DNNs could be the key for counteracting the harmful effects of noise and reverberation, we propose a novel deep learning paradigm called network of deep neural networks. The analysis of the original concepts were based on extensive experimental validations conducted on both real and simulated data, considering different corpora, microphone configurations, environments, noisy conditions, and ASR tasks.","Sun, 17 Dec 2017 10:29:15 UTC (5,440 KB)"
"1055","Using Deep learning methods for generation of a personalized list of shuffled songs","Rushin Gindra (1 and 2), Srushti Kotak (1 and 2), Asmita Natekar (1 and 2), Grishma Sharma (1 and 3) ((1) K. J. Somaiya College of Engineering, (2) Undergraduate Scholar, (3) Assistant Professor and Project Adviser)","Information Retrieval (cs.IR); Machine Learning (cs.LG)","The shuffle mode, where songs are played in a randomized order that is decided upon for all tracks at once, is widely found and known to exist in music player systems. There are only few music enthusiasts who use this mode since it either is too random to suit their mood or it keeps on repeating the same list every time. In this paper, we propose to build a convolutional deep belief network(CDBN) that is trained to perform genre recognition based on audio features retrieved from the records of the Million Song Dataset. The learned parameters shall be used to initialize a multi-layer perceptron which takes extracted features of user's playlist as input alongside the metadata to classify to various categories. These categories will be shuffled retrospectively based on the metadata to autonomously provide with a list that is efficacious in playing songs that are desired by humans in normal conditions.","Sun, 17 Dec 2017 09:18:20 UTC (456 KB)"
"1056","Cyberattack Detection in Mobile Cloud Computing: A Deep Learning Approach","Khoi Khac Nguyen, Dinh Thai Hoang, Dusit Niyato, Ping Wang, Diep Nguyen, Eryk Dutkiewicz","Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","With the rapid growth of mobile applications and cloud computing, mobile cloud computing has attracted great interest from both academia and industry. However, mobile cloud applications are facing security issues such as data integrity, users' confidentiality, and service availability. A preventive approach to such problems is to detect and isolate cyber threats before they can cause serious impacts to the mobile cloud computing system. In this paper, we propose a novel framework that leverages a deep learning approach to detect cyberattacks in mobile cloud environment. Through experimental results, we show that our proposed framework not only recognizes diverse cyberattacks, but also achieves a high accuracy (up to 97.11%) in detecting the attacks. Furthermore, we present the comparisons with current machine learning-based approaches to demonstrate the effectiveness of our proposed solution.","Sat, 16 Dec 2017 07:24:55 UTC (1,627 KB)"
"1057","Study on a Poisson's Equation Solver Based On Deep Learning Technique","Tao Shan, Wei Tang, Xunwang Dang, Maokun Li, Fan Yang, Shenheng Xu, Ji Wu","Computational Physics (physics.comp-ph); Numerical Analysis (cs.NA)","In this work, we investigated the feasibility of applying deep learning techniques to solve Poisson's equation. A deep convolutional neural network is set up to predict the distribution of electric potential in 2D or 3D cases. With proper training data generated from a finite difference solver, the strong approximation capability of the deep convolutional neural network allows it to make correct prediction given information of the source and distribution of permittivity. With applications of L2 regularization, numerical experiments show that the predication error of 2D cases can reach below 1.5\% and the predication of 3D cases can reach below 3\%, with a significant reduction in CPU time compared with the traditional solver based on finite difference methods.","Fri, 15 Dec 2017 06:51:47 UTC (4,263 KB)"
"1058","Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning","Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, Dawn Song","Cryptography and Security (cs.CR); Machine Learning (cs.LG)","Deep learning models have achieved high performance on many tasks, and thus have been applied to many security-critical scenarios. For example, deep learning-based face recognition systems have been used to authenticate users to access many security-sensitive applications like payment apps. Such usages of deep learning systems provide the adversaries with sufficient incentives to perform attacks against these systems for their adversarial purposes. In this work, we consider a new type of attacks, called backdoor attacks, where the attacker's goal is to create a backdoor into a learning-based authentication system, so that he can easily circumvent the system by leveraging the backdoor. Specifically, the adversary aims at creating backdoor instances, so that the victim learning system will be misled to classify the backdoor instances as a target label specified by the adversary. In particular, we study backdoor poisoning attacks, which achieve backdoor attacks using poisoning strategies. Different from all existing work, our studied poisoning strategies can apply under a very weak threat model: (1) the adversary has no knowledge of the model and the training set used by the victim system; (2) the attacker is allowed to inject only a small amount of poisoning samples; (3) the backdoor key is hard to notice even by human beings to achieve stealthiness. We conduct evaluation to demonstrate that a backdoor adversary can inject only around 50 poisoning samples, while achieving an attack success rate of above 90%. We are also the first work to show that a data poisoning attack can create physically implementable backdoors without touching the training process. Our work demonstrates that backdoor poisoning attacks pose real threats to a learning system, and thus highlights the importance of further investigation and proposing defense strategies against them.","Fri, 15 Dec 2017 04:26:26 UTC (5,214 KB)"
"1059","DLR : Toward a deep learned rhythmic representation for music content analysis","Yeonwoo Jeong, Keunwoo Choi, Hosan Jeong","Sound (cs.SD)","In the use of deep neural networks, it is crucial to provide appropriate input representations for the network to learn from. In this paper, we propose an approach to learn a representation that focus on rhythmic representation which is named as DLR (Deep Learning Rhythmic representation). The proposed approach aims to learn DLR from the raw audio signal and use it for other music informatics tasks. A 1-dimensional convolutional network is utilised in the learning of DLR. In the experiment, we present the results from the source task and the target task as well as visualisations of DLRs. The results reveals that DLR provides compact rhythmic information which can be used on multi-tagging task.","Thu, 14 Dec 2017 08:13:02 UTC (557 KB)"
"1060","Identifying Exoplanets with Deep Learning: A Five Planet Resonant Chain around Kepler-80 and an Eighth Planet around Kepler-90","Christopher J. Shallue, Andrew Vanderburg","Earth and Planetary Astrophysics (astro-ph.EP); Instrumentation and Methods for Astrophysics (astro-ph.IM)","NASA's Kepler Space Telescope was designed to determine the frequency of Earth-sized planets orbiting Sun-like stars, but these planets are on the very edge of the mission's detection sensitivity. Accurately determining the occurrence rate of these planets will require automatically and accurately assessing the likelihood that individual candidates are indeed planets, even at low signal-to-noise ratios. We present a method for classifying potential planet signals using deep learning, a class of machine learning algorithms that have recently become state-of-the-art in a wide variety of tasks. We train a deep convolutional neural network to predict whether a given signal is a transiting exoplanet or a false positive caused by astrophysical or instrumental phenomena. Our model is highly effective at ranking individual candidates by the likelihood that they are indeed planets: 98.8% of the time it ranks plausible planet signals higher than false positive signals in our test set. We apply our model to a new set of candidate signals that we identified in a search of known Kepler multi-planet systems. We statistically validate two new planets that are identified with high confidence by our model. One of these planets is part of a five-planet resonant chain around Kepler-80, with an orbital period closely matching the prediction by three-body Laplace relations. The other planet orbits Kepler-90, a star which was previously known to host seven transiting planets. Our discovery of an eighth planet brings Kepler-90 into a tie with our Sun as the star known to host the most planets.","Wed, 13 Dec 2017 23:21:48 UTC (3,297 KB)"
"1061","FFT-Based Deep Learning Deployment in Embedded Systems","Sheng Lin, Ning Liu, Mahdi Nazemi, Hongjia Li, Caiwen Ding, Yanzhi Wang, Massoud Pedram","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning has delivered its powerfulness in many application domains, especially in image and speech recognition. As the backbone of deep learning, deep neural networks (DNNs) consist of multiple layers of various types with hundreds to thousands of neurons. Embedded platforms are now becoming essential for deep learning deployment due to their portability, versatility, and energy efficiency. The large model size of DNNs, while providing excellent accuracy, also burdens the embedded platforms with intensive computation and storage. Researchers have investigated on reducing DNN model size with negligible accuracy loss. This work proposes a Fast Fourier Transform (FFT)-based DNN training and inference model suitable for embedded platforms with reduced asymptotic complexity of both computation and storage, making our approach distinguished from existing approaches. We develop the training and inference algorithms based on FFT as the computing kernel and deploy the FFT-based inference model on embedded platforms achieving extraordinary processing speed.","Wed, 13 Dec 2017 18:26:17 UTC (2,218 KB)"
"1062","Mathematics of Deep Learning","Rene Vidal, Joan Bruna, Raja Giryes, Stefano Soatto","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)","Recently there has been a dramatic increase in the performance of recognition systems due to the introduction of deep architectures for representation learning and classification. However, the mathematical reasons for this success remain elusive. This tutorial will review recent work that aims to provide a mathematical justification for several properties of deep networks, such as global optimality, geometric stability, and invariance of the learned representations.","Wed, 13 Dec 2017 12:44:46 UTC (717 KB)"
"1063","The Effectiveness of Data Augmentation in Image Classification using Deep Learning","Luis Perez, Jason Wang","Computer Vision and Pattern Recognition (cs.CV)","In this paper, we explore and compare multiple solutions to the problem of data augmentation in image classification. Previous work has demonstrated the effectiveness of data augmentation through simple techniques, such as cropping, rotating, and flipping input images. We artificially constrain our access to data to a small subset of the ImageNet dataset, and compare each data augmentation technique in turn. One of the more successful data augmentations strategies is the traditional transformations mentioned above. We also experiment with GANs to generate images of different styles. Finally, we propose a method to allow a neural net to learn augmentations that best improve the classifier, which we call neural augmentation. We discuss the successes and shortcomings of this method on various datasets.","Wed, 13 Dec 2017 06:41:00 UTC (1,221 KB)"
"1064","Over the Air Deep Learning Based Radio Signal Classification","Timothy J. O'Shea, Tamoghna Roy, T. Charles Clancy","Machine Learning (cs.LG); Signal Processing (eess.SP)","We conduct an in depth study on the performance of deep learning based radio signal classification for radio communications signals. We consider a rigorous baseline method using higher order moments and strong boosted gradient tree classification and compare performance between the two approaches across a range of configurations and channel impairments. We consider the effects of carrier frequency offset, symbol rate, and multi-path fading in simulation and conduct over-the-air measurement of radio classification performance in the lab using software radios and compare performance and training strategies for both. Finally we conclude with a discussion of remaining problems, and design considerations for using such techniques.","Wed, 13 Dec 2017 00:24:26 UTC (2,480 KB)"
"1065","Music Generation by Deep Learning - Challenges and Directions","Jean-Pierre Briot, Francois Pachet","Sound (cs.SD); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)","In addition to traditional tasks such as prediction, classification and translation, deep learning is receiving growing attention as an approach for music generation, as witnessed by recent research groups such as Magenta at Google and CTRL (Creator Technology Research Lab) at Spotify. The motivation is in using the capacity of deep learning architectures and training techniques to automatically learn musical styles from arbitrary musical corpora and then to generate samples from the estimated distribution. However, a direct application of deep learning to generate content rapidly reaches limits as the generated content tends to mimic the training set without exhibiting true creativity. Moreover, deep learning architectures do not offer direct ways for controlling generation (e.g., imposing some tonality or other arbitrary constraints). Furthermore, deep learning architectures alone are autistic automata which generate music autonomously without human user interaction, far from the objective of interactively assisting musicians to compose and refine music. Issues such as: control, structure, creativity and interactivity are the focus of our analysis. In this paper, we select some limitations of a direct application of deep learning to music generation, analyze why the issues are not fulfilled and how to address them by possible approaches. Various examples of recent systems are cited as examples of promising directions.","Sat, 9 Dec 2017 14:57:47 UTC (4,524 KB)[v2] Sun, 30 Sep 2018 15:06:19 UTC (2,697 KB)"
"1066","Predicting Yelp Star Reviews Based on Network Structure with Deep Learning","Luis Perez","Machine Learning (cs.LG); Machine Learning (stat.ML)","In this paper, we tackle the real-world problem of predicting Yelp star-review rating based on business features (such as images, descriptions), user features (average previous ratings), and, of particular interest, network properties (which businesses has a user rated before). We compare multiple models on different sets of features -- from simple linear regression on network features only to deep learning models on network and item features. In recent years, breakthroughs in deep learning have led to increased accuracy in common supervised learning tasks, such as image classification, captioning, and language understanding. However, the idea of combining deep learning with network feature and structure appears to be novel. While the problem of predicting future interactions in a network has been studied at length, these approaches have often ignored either node-specific data or global structure. We demonstrate that taking a mixed approach combining both node-level features and network information can effectively be used to predict Yelp-review star ratings. We evaluate on the Yelp dataset by splitting our data along the time dimension (as would naturally occur in the real-world) and comparing our model against others which do no take advantage of the network structure and/or deep learning.","Mon, 11 Dec 2017 18:54:23 UTC (2,752 KB)"
"1067","Deep Learning for IoT Big Data and Streaming Analytics: A Survey","Mehdi Mohammadi, Ala Al-Fuqaha, Sameh Sorour, Mohsen Guizani","Networking and Internet Architecture (cs.NI); Databases (cs.DB); Machine Learning (cs.LG)","In the era of the Internet of Things (IoT), an enormous amount of sensing devices collect and/or generate various sensory data over time for a wide range of fields and applications. Based on the nature of the application, these devices will result in big or fast/real-time data streams. Applying analytics over such data streams to discover new information, predict future insights, and make control decisions is a crucial process that makes IoT a worthy paradigm for businesses and a quality-of-life improving technology. In this paper, we provide a thorough overview on using a class of advanced machine learning techniques, namely Deep Learning (DL), to facilitate the analytics and learning in the IoT domain. We start by articulating IoT data characteristics and identifying two major treatments for IoT data from a machine learning perspective, namely IoT big data analytics and IoT streaming data analytics. We also discuss why DL is a promising approach to achieve the desired analytics in these types of data and applications. The potential of using emerging DL techniques for IoT data analytics are then discussed, and its promises and challenges are introduced. We present a comprehensive background on different DL architectures and algorithms. We also analyze and summarize major reported research attempts that leveraged DL in the IoT domain. The smart IoT devices that have incorporated DL in their intelligence background are also discussed. DL implementation approaches on the fog and cloud centers in support of IoT applications are also surveyed. Finally, we shed light on some challenges and potential directions for future research. At the end of each section, we highlight the lessons learned based on our experiments and review of the recent literature.","Sat, 9 Dec 2017 06:13:43 UTC (2,523 KB)[v2] Tue, 5 Jun 2018 03:30:38 UTC (1,476 KB)"
"1068","Deep learning enhanced mobile-phone microscopy","Yair Rivenson, Hatice Ceylan Koydemir, Hongda Wang, Zhensong Wei, Zhengshuang Ren, Harun Gunaydin, Yibo Zhang, Zoltan Gorocs, Kyle Liang, Derek Tseng, Aydogan Ozcan","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)","Mobile-phones have facilitated the creation of field-portable, cost-effective imaging and sensing technologies that approach laboratory-grade instrument performance. However, the optical imaging interfaces of mobile-phones are not designed for microscopy and produce spatial and spectral distortions in imaging microscopic specimens. Here, we report on the use of deep learning to correct such distortions introduced by mobile-phone-based microscopes, facilitating the production of high-resolution, denoised and colour-corrected images, matching the performance of benchtop microscopes with high-end objective lenses, also extending their limited depth-of-field. After training a convolutional neural network, we successfully imaged various samples, including blood smears, histopathology tissue sections, and parasites, where the recorded images were highly compressed to ease storage and transmission for telemedicine applications. This method is applicable to other low-cost, aberrated imaging systems, and could offer alternatives for costly and bulky microscopes, while also providing a framework for standardization of optical images for clinical and biomedical applications.","Tue, 12 Dec 2017 06:03:27 UTC (5,213 KB)"
"1069","Deep Learning for Reliable Mobile Edge Analytics in Intelligent Transportation Systems","Aidin Ferdowsi, Ursula Challita, Walid Saad","Information Theory (cs.IT); Machine Learning (stat.ML)","Intelligent transportation systems (ITSs) will be a major component of tomorrow's smart cities. However, realizing the true potential of ITSs requires ultra-low latency and reliable data analytics solutions that can combine, in real-time, a heterogeneous mix of data stemming from the ITS network and its environment. Such data analytics capabilities cannot be provided by conventional cloud-centric data processing techniques whose communication and computing latency can be high. Instead, edge-centric solutions that are tailored to the unique ITS environment must be developed. In this paper, an edge analytics architecture for ITSs is introduced in which data is processed at the vehicle or roadside smart sensor level in order to overcome the ITS latency and reliability challenges. With a higher capability of passengers' mobile devices and intra-vehicle processors, such a distributed edge computing architecture can leverage deep learning techniques for reliable mobile sensing in ITSs. In this context, the ITS mobile edge analytics challenges pertaining to heterogeneous data, autonomous control, vehicular platoon control, and cyber-physical security are investigated. Then, different deep learning solutions for such challenges are proposed. The proposed deep learning solutions will enable ITS edge analytics by endowing the ITS devices with powerful computer vision and signal processing functions. Preliminary results show that the proposed edge analytics architecture, coupled with the power of deep learning algorithms, can provide a reliable, secure, and truly smart transportation environment.","Tue, 12 Dec 2017 05:12:44 UTC (2,112 KB)"
"1070","200x Low-dose PET Reconstruction using Deep Learning","Junshen Xu, Enhao Gong, John Pauly, Greg Zaharchuk","Computer Vision and Pattern Recognition (cs.CV)","Positron emission tomography (PET) is widely used in various clinical applications, including cancer diagnosis, heart disease and neuro disorders. The use of radioactive tracer in PET imaging raises concerns due to the risk of radiation exposure. To minimize this potential risk in PET imaging, efforts have been made to reduce the amount of radio-tracer usage. However, lowing dose results in low Signal-to-Noise-Ratio (SNR) and loss of information, both of which will heavily affect clinical diagnosis. Besides, the ill-conditioning of low-dose PET image reconstruction makes it a difficult problem for iterative reconstruction algorithms. Previous methods proposed are typically complicated and slow, yet still cannot yield satisfactory results at significantly low dose. Here, we propose a deep learning method to resolve this issue with an encoder-decoder residual deep network with concatenate skip connections. Experiments shows the proposed method can reconstruct low-dose PET image to a standard-dose quality with only two-hundredth dose. Different cost functions for training model are explored. Multi-slice input strategy is introduced to provide the network with more structural information and make it more robust to noise. Evaluation on ultra-low-dose clinical data shows that the proposed method can achieve better result than the state-of-the-art methods and reconstruct images with comparable quality using only 0.5% of the original regular dose.","Tue, 12 Dec 2017 04:13:27 UTC (3,517 KB)"
"1071","End-to-end Learning from Spectrum Data: A Deep Learning approach for Wireless Signal Identification in Spectrum Monitoring applications","Merima Kulin, Tarik Kazaz, Ingrid Moerman, Eli de Poorter","Networking and Internet Architecture (cs.NI)","This paper presents end-to-end learning from spectrum data - an umbrella term for new sophisticated wireless signal identification approaches in spectrum monitoring applications based on deep neural networks. End-to-end learning allows to (i) automatically learn features directly from simple wireless signal representations, without requiring design of hand-crafted expert features like higher order cyclic moments, and (ii) train wireless signal classifiers in one end-to-end step which eliminates the need for complex multi-stage machine learning processing pipelines. The purpose of this article is to present the conceptual framework of end-to-end learning for spectrum monitoring and systematically introduce a generic methodology to easily design and implement wireless signal classifiers. Furthermore, we investigate the importance of the choice of wireless data representation to various spectrum monitoring tasks. In particular, two case studies are elaborated (i) modulation recognition and (ii) wireless technology interference detection. For each case study three convolutional neural networks are evaluated for the following wireless signal representations: temporal IQ data, the amplitude/phase representation and the frequency domain representation. From our analysis we prove that the wireless data representation impacts the accuracy depending on the specifics and similarities of the wireless signals that need to be differentiated, with different data representations resulting in accuracy variations of up to 29%. Experimental results show that using the amplitude/phase representation for recognizing modulation formats can lead to performance improvements up to 2% and 12% for medium to high SNR compared to IQ and frequency domain data, respectively. For the task of detecting interference, frequency domain representation outperformed amplitude/phase and IQ data representation up to 20%.","Mon, 11 Dec 2017 19:02:51 UTC (935 KB)"
"1072","StrassenNets: Deep Learning with a Multiplication Budget","Michael Tschannen, Aran Khanna, Anima Anandkumar","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)","A large fraction of the arithmetic operations required to evaluate deep neural networks (DNNs) consists of matrix multiplications, in both convolution and fully connected layers. We perform end-to-end learning of low-cost approximations of matrix multiplications in DNN layers by casting matrix multiplications as 2-layer sum-product networks (SPNs) (arithmetic circuits) and learning their (ternary) edge weights from data. The SPNs disentangle multiplication and addition operations and enable us to impose a budget on the number of multiplication operations. Combining our method with knowledge distillation and applying it to image classification DNNs (trained on ImageNet) and language modeling DNNs (using LSTMs), we obtain a first-of-a-kind reduction in number of multiplications (over 99.5%) while maintaining the predictive performance of the full-precision models. Finally, we demonstrate that the proposed framework is able to rediscover Strassen's matrix multiplication algorithm, learning to multiply $2 \times 2$ matrices using only 7 multiplications instead of 8.","Mon, 11 Dec 2017 18:49:07 UTC (397 KB)[v2] Fri, 23 Feb 2018 12:59:10 UTC (207 KB)[v3] Fri, 8 Jun 2018 10:59:23 UTC (202 KB)"
"1073","Importance and construction of features in identifying new physics signals with deep learning","Chang-Wei Loh, Rui Zhang, Yong-Heng Xu, Zhi-Qiang Qian, Si-Cheng Chen, He-Yang Long, You-Hang Liu, De-Wen Cao, Wei Wang, Ming Qi","High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph)","Advances in machine learning have led to an emergence of new paradigms in the analysis of large data which could assist traditional approaches in the search for new physics amongst the immense Standard Model backgrounds at the Large Hadron Collider. Deep learning is one such paradigm. In this work, we first study feature importance ranking of signal-background classification features with deep learning for two Beyond Standard Model benchmark cases: a multi-Higgs and a supersymmetry scenario. We find that the discovery reach for the multi-Higgs scenario could still increase with additional features. In addition, we also present a deep learning-based approach to construct new features to separate signals from backgrounds using the ATLAS detector as a specific example. We show that the constructed feature is more effective in signal-background separation than commonly used features, and thus is better for physics searches in the detector. As a side application, the constructed feature may be used to identify any momentum bias in a detector. We also utilize a convolutional neural network as part of the momentum bias checking approach.","Mon, 11 Dec 2017 15:03:29 UTC (3,238 KB)"
"1074","DeePMD-kit: A deep learning package for many-body potential energy representation and molecular dynamics","Han Wang, Linfeng Zhang, Jiequn Han, Weinan E","Computational Physics (physics.comp-ph); Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)","Recent developments in many-body potential energy representation via deep learning have brought new hopes to addressing the accuracy-versus-efficiency dilemma in molecular simulations. Here we describe DeePMD-kit, a package written in Python/C++ that has been designed to minimize the effort required to build deep learning based representation of potential energy and force field and to perform molecular dynamics. Potential applications of DeePMD-kit span from finite molecules to extended systems and from metallic systems to chemically bonded systems. DeePMD-kit is interfaced with TensorFlow, one of the most popular deep learning frameworks, making the training process highly automatic and efficient. On the other end, DeePMD-kit is interfaced with high-performance classical molecular dynamics and quantum (path-integral) molecular dynamics packages, i.e., LAMMPS and the i-PI, respectively. Thus, upon training, the potential energy and force field models can be used to perform efficient molecular simulations for different purposes. As an example of the many potential applications of the package, we use DeePMD-kit to learn the interatomic potential energy and forces of a water model using data obtained from density functional theory. We demonstrate that the resulted molecular dynamics model reproduces accurately the structural information contained in the original model.","Mon, 11 Dec 2017 04:16:43 UTC (333 KB)[v2] Sun, 31 Dec 2017 03:48:06 UTC (333 KB)"
"1075","Gradient Normalization & Depth Based Decay For Deep Learning","Robert Kwiatkowski, Oscar Chang","Machine Learning (cs.LG); Machine Learning (stat.ML)","In this paper we introduce a novel method of gradient normalization and decay with respect to depth. Our method leverages the simple concept of normalizing all gradients in a deep neural network, and then decaying said gradients with respect to their depth in the network. Our proposed normalization and decay techniques can be used in conjunction with most current state of the art optimizers and are a very simple addition to any network. This method, although simple, showed improvements in convergence time on state of the art networks such as DenseNet and ResNet on image classification tasks, as well as on an LSTM for natural language processing tasks.","Sun, 10 Dec 2017 23:01:13 UTC (223 KB)[v2] Wed, 28 Feb 2018 15:56:52 UTC (0 KB)"
"1076","Music Transcription by Deep Learning with Data and ""Artificial Semantic"" Augmentation","Vladyslav Sarnatskyi, Vadym Ovcharenko, Mariia Tkachenko, Sergii Stirenko, Yuri Gordienko, Anis Rojbi","Sound (cs.SD); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)","In this progress paper the previous results of the single note recognition by deep learning are presented. The several ways for data augmentation and ""artificial semantic"" augmentation are proposed to enhance efficiency of deep learning approaches for monophonic and polyphonic note recognition by increase of dimensions of training data, their lossless and lossy transformations.","Fri, 8 Dec 2017 11:18:22 UTC (244 KB)"
"1077","Class Rectification Hard Mining for Imbalanced Deep Learning","Qi Dong, Shaogang Gong, Xiatian Zhu","Computer Vision and Pattern Recognition (cs.CV)","Recognising detailed facial or clothing attributes in images of people is a challenging task for computer vision, especially when the training data are both in very large scale and extremely imbalanced among different attribute classes. To address this problem, we formulate a novel scheme for batch incremental hard sample mining of minority attribute classes from imbalanced large scale training data. We develop an end-to-end deep learning framework capable of avoiding the dominant effect of majority classes by discovering sparsely sampled boundaries of minority classes. This is made possible by introducing a Class Rectification Loss (CRL) regularising algorithm. We demonstrate the advantages and scalability of CRL over existing state-of-the-art attribute recognition and imbalanced data learning models on two large scale imbalanced benchmark datasets, the CelebA facial attribute dataset and the X-Domain clothing attribute dataset.","Fri, 8 Dec 2017 16:32:56 UTC (8,664 KB)"
"1078","Enabling Cooperative Inference of Deep Learning on Wearables and Smartphones","Mengwei Xu, Feng Qian, Saumay Pushp","Computers and Society (cs.CY); Machine Learning (cs.LG)","Deep Learning (DL) algorithm is the state-of-the-art algorithm of many computer science fields and applied on many intelligent mobile applications. In this paper, we propose a system called CoINF, a practical, adaptive, and flexible deep learning framework that enables cooperative inference between wearable devices (e.g., smartwatches and smart glasses) and handhelds. Our framework accelerates the processing and saves the energy consumption of generic deep learning models inference on wearables via judiciously offloading the workloads to paired handhelds at fine granularity in considering of the system environment, the application requirements, and user preference. Deployed as a user-space library, CoINF offers developer-friendly APIs that are as simple as those in traditional DL libraries such as TensorFlow, with all complicated offloading details hidden. We have implemented a prototype of CoINF on Android OS, and used real deep learning models to evaluate its performance on commercial off-the-shelf smartphone and smartwatches. The experimental results show that our framework can achieve substantial execution speedup and energy saving compared to wearable-only and handheld-only strategies.","Fri, 1 Dec 2017 16:58:32 UTC (3,453 KB)"
"1079","Representations of Sound in Deep Learning of Audio Features from Music","Sergey Shuvaev, Hamza Giaffar, Alexei A. Koulakov","Sound (cs.SD); Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS); Neurons and Cognition (q-bio.NC)","The work of a single musician, group or composer can vary widely in terms of musical style. Indeed, different stylistic elements, from performance medium and rhythm to harmony and texture, are typically exploited and developed across an artist's lifetime. Yet, there is often a discernable character to the work of, for instance, individual composers at the perceptual level - an experienced listener can often pick up on subtle clues in the music to identify the composer or performer. Here we suggest that a convolutional network may learn these subtle clues or features given an appropriate representation of the music. In this paper, we apply a deep convolutional neural network to a large audio dataset and empirically evaluate its performance on audio classification tasks. Our trained network demonstrates accurate performance on such classification tasks when presented with 5 s examples of music obtained by simple transformations of the raw audio waveform. A particularly interesting example is the spectral representation of music obtained by application of a logarithmically spaced filter bank, mirroring the early stages of auditory signal transduction in mammals. The most successful representation of music to facilitate discrimination was obtained via a random matrix transform (RMT). Networks based on logarithmic filter banks and RMT were able to correctly guess the one composer out of 31 possibilities in 68 and 84 percent of cases respectively.","Fri, 8 Dec 2017 00:37:23 UTC (908 KB)"
"1080","MoDL: Model Based Deep Learning Architecture for Inverse Problems","Hemant Kumar Aggarwal, Merry P. Mani, Mathews Jacob","Computer Vision and Pattern Recognition (cs.CV)","We introduce a model-based image reconstruction framework with a convolution neural network (CNN) based regularization prior. The proposed formulation provides a systematic approach for deriving deep architectures for inverse problems with the arbitrary structure. Since the forward model is explicitly accounted for, a smaller network with fewer parameters is sufficient to capture the image information compared to black-box deep learning approaches, thus reducing the demand for training data and training time. Since we rely on end-to-end training, the CNN weights are customized to the forward model, thus offering improved performance over approaches that rely on pre-trained denoisers. The main difference of the framework from existing end-to-end training strategies is the sharing of the network weights across iterations and channels. Our experiments show that the decoupling of the number of iterations from the network complexity offered by this approach provides benefits including lower demand for training data, reduced risk of overfitting, and implementations with significantly reduced memory footprint. We propose to enforce data-consistency by using numerical optimization blocks such as conjugate gradients algorithm within the network; this approach offers faster convergence per iteration, compared to methods that rely on proximal gradients steps to enforce data consistency. Our experiments show that the faster convergence translates to improved performance, especially when the available GPU memory restricts the number of iterations.","Thu, 7 Dec 2017 21:13:13 UTC (7,949 KB)[v2] Sun, 22 Apr 2018 20:24:37 UTC (5,524 KB)[v3] Fri, 10 Aug 2018 18:41:30 UTC (2,489 KB)"
"1081","Deep learning Approach for Classifying, Detecting and Predicting Photometric Redshifts of Quasars in the Sloan Digital Sky Survey Stripe 82","Johanna Pasquet-Itam, Jerome Pasquet","Instrumentation and Methods for Astrophysics (astro-ph.IM)","We apply a convolutional neural network (CNN) to classify and detect quasars in the Sloan Digital Sky Survey Stripe 82 and also to predict the photometric redshifts of quasars. The network takes the variability of objects into account by converting light curves into images. The width of the images, noted w, corresponds to the five magnitudes ugriz and the height of the images, noted h, represents the date of the observation. The CNN provides good results since its precision is 0.988 for a recall of 0.90, compared to a precision of 0.985 for the same recall with a random forest classifier. Moreover 175 new quasar candidates are found with the CNN considering a fixed recall of 0.97. The combination of probabilities given by the CNN and the random forest makes good performance even better with a precision of 0.99 for a recall of 0.90. For the redshift predictions, the CNN presents excellent results which are higher than those obtained with a feature extraction step and different classifiers (a K-nearest-neighbors, a support vector machine, a random forest and a gaussian process classifier). Indeed, the accuracy of the CNN within |ツz|<0.1 can reach 78.09%, within |ツz|<0.2 reaches 86.15%, within |ツz|<0.3 reaches 91.2% and the value of rms is 0.359. The performance of the KNN decreases for the three |ツz| regions, since within the accuracy of |ツz|<0.1, |ツz|<0.2 and |ツz|<0.3 is 73.72%, 82.46% and 90.09% respectively, and the value of rms amounts to 0.395. So the CNN successfully reduces the dispersion and the catastrophic redshifts of quasars. This new method is very promising for the future of big databases like the Large Synoptic Survey Telescope.","Thu, 7 Dec 2017 18:49:53 UTC (4,013 KB)"
"1082","Solving internal covariate shift in deep learning with linked neurons","Carles Roger Riera Molina, Oriol Pujol Vila","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","This work proposes a novel solution to the problem of internal covariate shift and dying neurons using the concept of linked neurons. We define the neuron linkage in terms of two constraints: first, all neuron activations in the linkage must have the same operating point. That is to say, all of them share input weights. Secondly, a set of neurons is linked if and only if there is at least one member of the linkage that has a non-zero gradient in regard to the input of the activation function. This means that for any input in the activation function, there is at least one member of the linkage that operates in a non-flat and non-zero area. This simple change has profound implications in the network learning dynamics. In this article we explore the consequences of this proposal and show that by using this kind of units, internal covariate shift is implicitly solved. As a result of this, the use of linked neurons allows to train arbitrarily large networks without any architectural or algorithmic trick, effectively removing the need of using re-normalization schemes such as Batch Normalization, which leads to halving the required training time. It also solves the problem of the need for standarized input data. Results show that the units using the linkage not only do effectively solve the aforementioned problems, but are also a competitive alternative with respect to state-of-the-art with very promising results.","Thu, 7 Dec 2017 13:26:26 UTC (36 KB)"
"1083","A trans-disciplinary review of deep learning research for water resources scientists","Chaopeng Shen","Machine Learning (stat.ML); Machine Learning (cs.LG)","Deep learning (DL), a new-generation of artificial neural network research, has transformed industries, daily lives and various scientific disciplines in recent years. DL represents significant progress in the ability of neural networks to automatically engineer problem-relevant features and capture highly complex data distributions. I argue that DL can help address several major new and old challenges facing research in water sciences such as inter-disciplinarity, data discoverability, hydrologic scaling, equifinality, and needs for parameter regionalization. This review paper is intended to provide water resources scientists and hydrologists in particular with a simple technical overview, trans-disciplinary progress update, and a source of inspiration about the relevance of DL to water. The review reveals that various physical and geoscientific disciplines have utilized DL to address data challenges, improve efficiency, and gain scientific insights. DL is especially suited for information extraction from image-like data and sequential data. Techniques and experiences presented in other disciplines are of high relevance to water research. Meanwhile, less noticed is that DL may also serve as a scientific exploratory tool. A new area termed 'AI neuroscience,' where scientists interpret the decision process of deep networks and derive insights, has been born. This budding sub-discipline has demonstrated methods including correlation-based analysis, inversion of network-extracted features, reduced-order approximations by interpretable models, and attribution of network decisions to inputs. Moreover, DL can also use data to condition neurons that mimic problem-specific fundamental organizing units, thus revealing emergent behaviors of these units. Vast opportunities exist for DL to propel advances in water sciences.","Wed, 6 Dec 2017 12:44:27 UTC (910 KB)[v2] Thu, 7 Dec 2017 14:15:13 UTC (735 KB)[v3] Fri, 24 Aug 2018 15:12:46 UTC (984 KB)"
"1084","Listening to Chaotic Whispers: A Deep Learning Framework for News-oriented Stock Trend Prediction","Ziniu Hu, Weiqing Liu, Jiang Bian, Xuanzhe Liu, Tie-Yan Liu","Social and Information Networks (cs.SI); Machine Learning (cs.LG); Statistical Finance (q-fin.ST)","Stock trend prediction plays a critical role in seeking maximized profit from stock investment. However, precise trend prediction is very difficult since the highly volatile and non-stationary nature of stock market. Exploding information on Internet together with advancing development of natural language processing and text mining techniques have enable investors to unveil market trends and volatility from online content. Unfortunately, the quality, trustworthiness and comprehensiveness of online content related to stock market varies drastically, and a large portion consists of the low-quality news, comments, or even rumors. To address this challenge, we imitate the learning process of human beings facing such chaotic online news, driven by three principles: sequential content dependency, diverse influence, and effective and efficient learning. In this paper, to capture the first two principles, we designed a Hybrid Attention Networks to predict the stock trend based on the sequence of recent related news. Moreover, we apply the self-paced learning mechanism to imitate the third principle. Extensive experiments on real-world stock market data demonstrate the effectiveness of our approach.","Wed, 6 Dec 2017 11:33:21 UTC (2,968 KB)[v2] Fri, 16 Mar 2018 17:32:11 UTC (0 KB)"
"1085","OLE: Orthogonal Low-rank Embedding, A Plug and Play Geometric Loss for Deep Learning","Jose Lezama, Qiang Qiu, Pablo Muse, Guillermo Sapiro","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep neural networks trained using a softmax layer at the top and the cross-entropy loss are ubiquitous tools for image classification. Yet, this does not naturally enforce intra-class similarity nor inter-class margin of the learned deep representations. To simultaneously achieve these two goals, different solutions have been proposed in the literature, such as the pairwise or triplet losses. However, such solutions carry the extra task of selecting pairs or triplets, and the extra computational burden of computing and learning for many combinations of them. In this paper, we propose a plug-and-play loss term for deep networks that explicitly reduces intra-class variance and enforces inter-class margin simultaneously, in a simple and elegant geometric manner. For each class, the deep features are collapsed into a learned linear subspace, or union of them, and inter-class subspaces are pushed to be as orthogonal as possible. Our proposed Orthogonal Low-rank Embedding (OLE) does not require carefully crafting pairs or triplets of samples for training, and works standalone as a classification loss, being the first reported deep metric learning framework of its kind. Because of the improved margin between features of different classes, the resulting deep networks generalize better, are more discriminative, and more robust. We demonstrate improved classification performance in general object recognition, plugging the proposed loss term into existing off-the-shelf architectures. In particular, we show the advantage of the proposed loss in the small data/model scenario, and we significantly advance the state-of-the-art on the Stanford STL-10 benchmark.","Tue, 5 Dec 2017 16:03:56 UTC (7,785 KB)"
"1086","Autonomous development and learning in artificial intelligence and robotics: Scaling up deep learning to human--like learning","Pierre-Yves Oudeyer (Flowers)","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Neurons and Cognition (q-bio.NC)","Autonomous lifelong development and learning is a fundamental capability of humans, differentiating them from current deep learning systems. However, other branches of artificial intelligence have designed crucial ingredients towards autonomous learning: curiosity and intrinsic motivation, social learning and natural interaction with peers, and embodiment. These mechanisms guide exploration and autonomous choice of goals, and integrating them with deep learning opens stimulating perspectives. Deep learning (DL) approaches made great advances in artificial intelligence, but are still far away from human learning. As argued convincingly by Lake et al., differences include human capabilities to learn causal models of the world from very little data, leveraging compositional representations and priors like intuitive physics and psychology. However, there are other fundamental differences between current DL systems and human learning, as well as technical ingredients to fill this gap, that are either superficially, or not adequately, discussed by Lake et al. These fundamental mechanisms relate to autonomous development and learning. They are bound to play a central role in artificial intelligence in the future. Current DL systems require engineers to manually specify a task-specific objective function for every new task, and learn through off-line processing of large training databases. On the contrary, humans learn autonomously open-ended repertoires of skills, deciding for themselves which goals to pursue or value, and which skills to explore, driven by intrinsic motivation/curiosity and social learning through natural interaction with peers. Such learning processes are incremental, online, and progressive. Human child development involves a progressive increase of complexity in a curriculum of learning where skills are explored, acquired, and built on each other, through particular ordering and timing. Finally, human learning happens in the physical world, and through bodily and physical experimentation, under severe constraints on energy, time, and computational resources. In the two last decades, the field of Developmental and Cognitive Robotics (Cangelosi and Schlesinger, 2015, Asada et al., 2009), in strong interaction with developmental psychology and neuroscience, has achieved significant advances in computational","Tue, 5 Dec 2017 14:03:56 UTC (145 KB)"
"1087","Deep Learning for automatic sale receipt understanding","Rizlene Raoui-Outach (LISTIC), Cecile Million-Rousseau (LISTIC), Alexandre Benoit (LISTIC), Patrick Lambert (LISTIC)","Computer Vision and Pattern Recognition (cs.CV)","As a general rule, data analytics are now mandatory for companies. Scanned document analysis brings additional challenges introduced by paper damages and scanning quality.In an industrial context, this work focuses on the automatic understanding of sale receipts which enable access to essential and accurate consumption statistics. Given an image acquired with a smart-phone, the proposed work mainly focuses on the first steps of the full tool chain which aims at providing essential information such as the store brand, purchased products and related prices with the highest possible confidence. To get this high confidence level, even if scanning is not perfectly controlled, we propose a double check processing tool-chain using Deep Convolutional Neural Networks (DCNNs) on one hand and more classical image and text processings on another hand.The originality of this work relates in this double check processing and in the joint use of DCNNs for different applications and text analysis.","Tue, 5 Dec 2017 12:40:20 UTC (742 KB)"
"1088","Deep learning for semantic segmentation of remote sensing images with rich spectral content","A Hamida, A. Benoit (IPNL), P. Lambert (LISTIC), L Klein, C Amar, N. Audebert (ONERA), S. Lefevre (VALORIA)","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","With the rapid development of Remote Sensing acquisition techniques, there is a need to scale and improve processing tools to cope with the observed increase of both data volume and richness. Among popular techniques in remote sensing, Deep Learning gains increasing interest but depends on the quality of the training data. Therefore, this paper presents recent Deep Learning approaches for fine or coarse land cover semantic segmentation estimation. Various 2D architectures are tested and a new 3D model is introduced in order to jointly process the spatial and spectral dimensions of the data. Such a set of networks enables the comparison of the different spectral fusion schemes. Besides, we also assess the use of a "" noisy ground truth "" (i.e. outdated and low spatial resolution labels) for training and testing the networks.","Tue, 5 Dec 2017 12:25:43 UTC (919 KB)"
"1089","Beyond Grand Theft Auto V for Training, Testing and Enhancing Deep Learning in Self Driving Cars","Mark Martinez, Chawin Sitawarin, Kevin Finch, Lennart Meincke, Alex Yablonski, Alain Kornhauser","Computer Vision and Pattern Recognition (cs.CV)","As an initial assessment, over 480,000 labeled virtual images of normal highway driving were readily generated in Grand Theft Auto V's virtual environment. Using these images, a CNN was trained to detect following distance to cars/objects ahead, lane markings, and driving angle (angular heading relative to lane centerline): all variables necessary for basic autonomous driving. Encouraging results were obtained when tested on over 50,000 labeled virtual images from substantially different GTA-V driving environments. This initial assessment begins to define both the range and scope of the labeled images needed for training as well as the range and scope of labeled images needed for testing the definition of boundaries and limitations of trained networks. It is the efficacy and flexibility of a ""GTA-V""-like virtual environment that is expected to provide an efficient well-defined foundation for the training and testing of Convolutional Neural Networks for safe driving. Additionally, described is the Princeton Virtual Environment (PVE) for the training, testing and enhancement of safe driving AI, which is being developed using the video-game engine Unity. PVE is being developed to recreate rare but critical corner cases that can be used in re-training and enhancing machine learning models and understanding the limitations of current self driving models. The Florida Tesla crash is being used as an initial reference.","Mon, 4 Dec 2017 22:41:46 UTC (6,995 KB)"
"1090","Iterative Deep Learning for Network Topology Extraction","Carles Ventura, Jordi Pont-Tuset, Sergi Caelles, Kevis-Kokitsi Maninis, Luc Van Gool","Computer Vision and Pattern Recognition (cs.CV)","This paper tackles the task of estimating the topology of filamentary networks such as retinal vessels and road networks. Building on top of a global model that performs a dense semantical classification of the pixels of the image, we design a Convolutional Neural Network (CNN) that predicts the local connectivity between the central pixel of an input patch and its border points. By iterating this local connectivity we sweep the whole image and infer the global topology of the filamentary network, inspired by a human delineating a complex network with the tip of their finger. We perform an extensive and comprehensive qualitative and quantitative evaluation on two tasks: retinal veins and arteries topology extraction and road network estimation. In both cases, represented by two publicly available datasets (DRIVE and Massachusetts Roads), we show superior performance to very strong baselines.","Mon, 4 Dec 2017 17:45:55 UTC (8,283 KB)"
"1091","Deep Learning Can Reverse Photon Migration for Diffuse Optical Tomography","Jaejun Yoo, Sohail Sabir, Duchang Heo, Kee Hyun Kim, Abdul Wahab, Yoonseok Choi, Seul-I Lee, Eun Young Chae, Hak Hee Kim, Young Min Bae, Young-wook Choi, Seungryong Cho, Jong Chul Ye","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","Can artificial intelligence (AI) learn complicated non-linear physics? Here we propose a novel deep learning approach that learns non-linear photon scattering physics and obtains accurate 3D distribution of optical anomalies. In contrast to the traditional black-box deep learning approaches to inverse problems, our deep network learns to invert the Lippmann-Schwinger integral equation which describes the essential physics of photon migration of diffuse near-infrared (NIR) photons in turbid media. As an example for clinical relevance, we applied the method to our prototype diffuse optical tomography (DOT). We show that our deep neural network, trained with only simulation data, can accurately recover the location of anomalies within biomimetic phantoms and live animals without the use of an exogenous contrast agent.","Mon, 4 Dec 2017 05:47:10 UTC (3,131 KB)"
"1092","A Deep Learning Approach to Drone Monitoring","Yueru Chen, Pranav Aggarwal, Jongmoo Choi, C.-C. Jay Kuo","Computer Vision and Pattern Recognition (cs.CV)","A drone monitoring system that integrates deep-learning-based detection and tracking modules is proposed in this work. The biggest challenge in adopting deep learning methods for drone detection is the limited amount of training drone images. To address this issue, we develop a model-based drone augmentation technique that automatically generates drone images with a bounding box label on drone's location. To track a small flying drone, we utilize the residual information between consecutive image frames. Finally, we present an integrated detection and tracking system that outperforms the performance of each individual module containing detection or tracking only. The experiments show that, even being trained on synthetic data, the proposed system performs well on real world drone images with complex background. The USC drone detection and tracking dataset with user labeled bounding boxes is available to the public.","Mon, 4 Dec 2017 00:30:58 UTC (8,825 KB)"
"1093","Fruit recognition from images using deep learning","Horea Mure<U+015F>an, Mihai Oltean","Computer Vision and Pattern Recognition (cs.CV)","In this paper we introduce a new, high-quality, dataset of images containing fruits. We also present the results of some numerical experiment for training a neural network to detect fruits. We discuss the reason why we chose to use fruits in this project by proposing a few applications that could use this kind of neural network.","Sat, 2 Dec 2017 09:48:37 UTC (827 KB)[v2] Thu, 7 Jun 2018 07:08:33 UTC (1,054 KB)[v3] Thu, 14 Jun 2018 14:34:09 UTC (1,054 KB)[v4] Sat, 21 Jul 2018 08:12:45 UTC (1,055 KB)[v5] Sun, 2 Sep 2018 19:28:53 UTC (1,056 KB)[v6] Fri, 14 Sep 2018 12:03:30 UTC (1,108 KB)[v7] Thu, 18 Oct 2018 08:27:42 UTC (1,109 KB)"
"1094","Anesthesiologist-level forecasting of hypoxemia with only SpO2 data using deep learning","Gabriel Erion, Hugh Chen, Scott M. Lundberg, Su-In Lee","Machine Learning (cs.LG); Applications (stat.AP); Machine Learning (stat.ML)","We use a deep learning model trained only on a patient's blood oxygenation data (measurable with an inexpensive fingertip sensor) to predict impending hypoxemia (low blood oxygen) more accurately than trained anesthesiologists with access to all the data recorded in a modern operating room. We also provide a simple way to visualize the reason why a patient's risk is low or high by assigning weight to the patient's past blood oxygen values. This work has the potential to provide cutting-edge clinical decision support in low-resource settings, where rates of surgical complication and death are substantially greater than in high-resource areas.","Sat, 2 Dec 2017 07:27:28 UTC (697 KB)"
"1095","Deep Learning Scaling is Predictable, Empirically","Joel Hestness, Sharan Narang, Newsha Ardalani, Gregory Diamos, Heewoo Jun, Hassan Kianinejad, Md. Mostofa Ali Patwary, Yang Yang, Yanqi Zhou","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning (DL) creates impactful advances following a virtuous recipe: model architecture search, creating large training data sets, and scaling computation. It is widely believed that growing training sets and models should improve accuracy and result in better products. As DL application domains grow, we would like a deeper understanding of the relationships between training set size, computational scale, and model accuracy improvements to advance the state-of-the-art. This paper presents a large scale empirical characterization of generalization error and model size growth as training sets grow. We introduce a methodology for this measurement and test four machine learning domains: machine translation, language modeling, image processing, and speech recognition. Our empirical results show power-law generalization error scaling across a breadth of factors, resulting in power-law exponents---the ""steepness"" of the learning curve---yet to be explained by theoretical work. Further, model improvements only shift the error but do not appear to affect the power-law exponent. We also show that model size scales sublinearly with data size. These scaling relationships have significant implications on deep learning research, practice, and systems. They can assist model debugging, setting accuracy targets, and decisions about data set growth. They can also guide computing system design and underscore the importance of continued computational scaling.","Fri, 1 Dec 2017 17:13:14 UTC (227 KB)"
"1096","Deep Learning with Permutation-invariant Operator for Multi-instance Histopathology Classification","Jakub M. Tomczak, Maximilian Ilse, Max Welling","Machine Learning (cs.LG); Machine Learning (stat.ML)","The computer-aided analysis of medical scans is a longstanding goal in the medical imaging field. Currently, deep learning has became a dominant methodology for supporting pathologists and radiologist. Deep learning algorithms have been successfully applied to digital pathology and radiology, nevertheless, there are still practical issues that prevent these tools to be widely used in practice. The main obstacles are low number of available cases and large size of images (a.k.a. the small n, large p problem in machine learning), and a very limited access to annotation at a pixel level that can lead to severe overfitting and large computational requirements. We propose to handle these issues by introducing a framework that processes a medical image as a collection of small patches using a single, shared neural network. The final diagnosis is provided by combining scores of individual patches using a permutation-invariant operator (combination). In machine learning community such approach is called a multi-instance learning (MIL).","Fri, 1 Dec 2017 13:30:36 UTC (468 KB)[v2] Tue, 5 Dec 2017 11:29:27 UTC (468 KB)"
"1097","Deep Learning for Metagenomic Data: using 2D Embeddings and Convolutional Neural Networks","Thanh Hai Nguyen, Yann Chevaleyre, Edi Prifti, Nataliya Sokolovska, Jean-Daniel Zucker","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Deep learning (DL) techniques have had unprecedented success when applied to images, waveforms, and texts to cite a few. In general, when the sample size (N) is much greater than the number of features (d), DL outperforms previous machine learning (ML) techniques, often through the use of convolution neural networks (CNNs). However, in many bioinformatics ML tasks, we encounter the opposite situation where d is greater than N. In these situations, applying DL techniques (such as feed-forward networks) would lead to severe overfitting. Thus, sparse ML techniques (such as LASSO e.g.) usually yield the best results on these tasks. In this paper, we show how to apply CNNs on data which do not have originally an image structure (in particular on metagenomic data). Our first contribution is to show how to map metagenomic data in a meaningful way to 1D or 2D images. Based on this representation, we then apply a CNN, with the aim of predicting various diseases. The proposed approach is applied on six different datasets including in total over 1000 samples from various diseases. This approach could be a promising one for prediction tasks in the bioinformatics field.","Fri, 1 Dec 2017 09:18:04 UTC (867 KB)"
"1098","A Deep Learning Framework for Short-term Power Load Forecasting","Tinghui Ouyang, Yusen He, Huajin Li, Zhiyu Sun, Stephen Baek","Computational Engineering, Finance, and Science (cs.CE)","The scheduling and operation of power system becomes prominently complex and uncertain, especially with the penetration of distributed power. Load forecasting matters to the effective operation of power system. This paper proposes a novel deep learning framework to forecast the short-term grid load. First, the load data is processed by Box-Cox transformation, and two parameters (electricity price and temperature) are investigated. Then, to quantify the tail-dependence of power load on the two parameters, parametric Copula models are fitted and the threshold of peak load are computed. Next, a deep belief network is built to forecast the hourly load of the power grid. One year grid load data collected from an urbanized area in Texas, United States is utilized in the case studies. Short-term load forecasting are examined in four seasons independently. Day-ahead and week-ahead load forecasting experiments are conducted in each season using the proposed framework. The proposed framework is compared with classical neural networks, support vector regression machine, extreme learning machine, and classical deep belief networks. The load forecasting performances are assessed by mean absolute percentage error, root mean square error, and hit rate. Computational results confirm the effectiveness of the proposed data-driven deep learning framework. The prediction accuracies of both day-ahead forecasting and week-ahead forecasting demonstrate that the proposed framework outperforms the tested algorithms.","Thu, 30 Nov 2017 17:12:54 UTC (339 KB)[v2] Fri, 1 Dec 2017 22:39:28 UTC (339 KB)"
"1099","Embedded Real-Time Fall Detection Using Deep Learning For Elderly Care","Hyunwoo Lee, Jooyoung Kim, Dojun Yang, Joon-Ho Kim","Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)","This paper proposes a real-time embedded fall detection system using a DVS(Dynamic Vision Sensor) that has never been used for traditional fall detection, a dataset for fall detection using that, and a DVS-TN(DVS-Temporal Network). The first contribution is building a DVS Falls Dataset, which made our network to recognize a much greater variety of falls than the existing datasets that existed before and solved privacy issues using the DVS. Secondly, we introduce the DVS-TN : optimized deep learning network to detect falls using DVS. Finally, we implemented a fall detection system which can run on low-computing H/W with real-time, and tested on DVS Falls Dataset that takes into account various falls situations. Our approach achieved 95.5% on the F1-score and operates at 31.25 FPS on NVIDIA Jetson TX1 board.","Thu, 30 Nov 2017 03:07:14 UTC (348 KB)"
"1100","A Semantic Loss Function for Deep Learning with Symbolic Knowledge","Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, Guy Van den Broeck","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic in Computer Science (cs.LO); Machine Learning (stat.ML)","This paper develops a novel methodology for using symbolic knowledge in deep learning. From first principles, we derive a semantic loss function that bridges between neural output vectors and logical constraints. This loss function captures how close the neural network is to satisfying the constraints on its output. An experimental evaluation shows that it effectively guides the learner to achieve (near-)state-of-the-art results on semi-supervised multi-class classification. Moreover, it significantly increases the ability of the neural network to predict structured objects, such as rankings and paths. These discrete concepts are tremendously difficult to learn, and benefit from a tight integration of deep learning and symbolic reasoning methods.","Wed, 29 Nov 2017 23:49:55 UTC (878 KB)[v2] Fri, 8 Jun 2018 00:05:58 UTC (159 KB)"
"1101","Deep Learning for identifying radiogenomic associations in breast cancer","Zhe Zhu, Ehab Albadawy, Ashirbani Saha, Jun Zhang, Michael R. Harowicz, Maciej A. Mazurowski","Computer Vision and Pattern Recognition (cs.CV)","Purpose: To determine whether deep learning models can distinguish between breast cancer molecular subtypes based on dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI). Materials and methods: In this institutional review board-approved single-center study, we analyzed DCE-MR images of 270 patients at our institution. Lesions of interest were identified by radiologists. The task was to automatically determine whether the tumor is of the Luminal A subtype or of another subtype based on the MR image patches representing the tumor. Three different deep learning approaches were used to classify the tumor according to their molecular subtypes: learning from scratch where only tumor patches were used for training, transfer learning where networks pre-trained on natural images were fine-tuned using tumor patches, and off-the-shelf deep features where the features extracted by neural networks trained on natural images were used for classification with a support vector machine. Network architectures utilized in our experiments were GoogleNet, VGG, and CIFAR. We used 10-fold crossvalidation method for validation and area under the receiver operating characteristic (AUC) as the measure of performance. Results: The best AUC performance for distinguishing molecular subtypes was 0.65 (95% CI:[0.57,0.71]) and was achieved by the off-the-shelf deep features approach. The highest AUC performance for training from scratch was 0.58 (95% CI:[0.51,0.64]) and the best AUC performance for transfer learning was 0.60 (95% CI:[0.52,0.65]) respectively. For the off-the-shelf approach, the features extracted from the fully connected layer performed the best. Conclusion: Deep learning may play a role in discovering radiogenomic associations in breast cancer.","Wed, 29 Nov 2017 20:41:05 UTC (1,026 KB)"
"1102","Detection-aided liver lesion segmentation using deep learning","Miriam Bellver, Kevis-Kokitsi Maninis, Jordi Pont-Tuset, Xavier Giro-i-Nieto, Jordi Torres, Luc Van Gool","Computer Vision and Pattern Recognition (cs.CV)","A fully automatic technique for segmenting the liver and localizing its unhealthy tissues is a convenient tool in order to diagnose hepatic diseases and assess the response to the according treatments. In this work we propose a method to segment the liver and its lesions from Computed Tomography (CT) scans using Convolutional Neural Networks (CNNs), that have proven good results in a variety of computer vision tasks, including medical imaging. The network that segments the lesions consists of a cascaded architecture, which first focuses on the region of the liver in order to segment the lesions on it. Moreover, we train a detector to localize the lesions, and mask the results of the segmentation network with the positive detections. The segmentation architecture is based on DRIU, a Fully Convolutional Network (FCN) with side outputs that work on feature maps of different resolutions, to finally benefit from the multi-scale information learned by different stages of the network. The main contribution of this work is the use of a detector to localize the lesions, which we show to be beneficial to remove false positives triggered by the segmentation network. Source code and models are available at this https URL .","Wed, 29 Nov 2017 19:27:40 UTC (2,929 KB)"
"1103","Security Risks in Deep Learning Implementations","Qixue Xiao, Kang Li, Deyue Zhang, Weilin Xu","Cryptography and Security (cs.CR)","Advance in deep learning algorithms overshadows their security risk in software implementations. This paper discloses a set of vulnerabilities in popular deep learning frameworks including Caffe, TensorFlow, and Torch. Contrast to the small code size of deep learning models, these deep learning frameworks are complex and contain heavy dependencies on numerous open source packages. This paper considers the risks caused by these vulnerabilities by studying their impact on common deep learning applications such as voice recognition and image classifications. By exploiting these framework implementations, attackers can launch denial-of-service attacks that crash or hang a deep learning application, or control-flow hijacking attacks that cause either system compromise or recognition evasions. The goal of this paper is to draw attention on the software implementations and call for the community effort to improve the security of deep learning frameworks.","Wed, 29 Nov 2017 18:33:27 UTC (341 KB)"
"1104","Deep learning analysis of breast MRIs for prediction of occult invasive disease in ductal carcinoma in situ","Zhe Zhu, Michael Harowicz, Jun Zhang, Ashirbani Saha, Lars J. Grimm, E.Shelley Hwang, Maciej A. Mazurowski","Computer Vision and Pattern Recognition (cs.CV)","Purpose: To determine whether deep learning-based algorithms applied to breast MR images can aid in the prediction of occult invasive disease following the di- agnosis of ductal carcinoma in situ (DCIS) by core needle biopsy. Material and Methods: In this institutional review board-approved study, we analyzed dynamic contrast-enhanced fat-saturated T1-weighted MRI sequences of 131 patients at our institution with a core needle biopsy-confirmed diagnosis of DCIS. The patients had no preoperative therapy before breast MRI and no prior history of breast cancer. We explored two different deep learning approaches to predict whether there was a hidden (occult) invasive component in the analyzed tumors that was ultimately detected at surgical excision. In the first approach, we adopted the transfer learning strategy, in which a network pre-trained on a large dataset of natural images is fine-tuned with our DCIS images. Specifically, we used the GoogleNet model pre-trained on the ImageNet dataset. In the second approach, we used a pre-trained network to extract deep features, and a support vector machine (SVM) that utilizes these features to predict the upstaging of the DCIS. We used 10-fold cross validation and the area under the ROC curve (AUC) to estimate the performance of the predictive models. Results: The best classification performance was obtained using the deep features approach with GoogleNet model pre-trained on ImageNet as the feature extractor and a polynomial kernel SVM used as the classifier (AUC = 0.70, 95% CI: 0.58- 0.79). For the transfer learning based approach, the highest AUC obtained was 0.53 (95% CI: 0.41-0.62). Conclusion: Convolutional neural networks could potentially be used to identify occult invasive disease in patients diagnosed with DCIS at the initial core needle biopsy.","Tue, 28 Nov 2017 21:52:49 UTC (1,269 KB)"
"1105","Physics Informed Deep Learning (Part II): Data-driven Discovery of Nonlinear Partial Differential Equations","Maziar Raissi, Paris Perdikaris, George Em Karniadakis","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Analysis of PDEs (math.AP); Numerical Analysis (math.NA); Machine Learning (stat.ML)","We introduce physics informed neural networks -- neural networks that are trained to solve supervised learning tasks while respecting any given law of physics described by general nonlinear partial differential equations. In this second part of our two-part treatise, we focus on the problem of data-driven discovery of partial differential equations. Depending on whether the available data is scattered in space-time or arranged in fixed temporal snapshots, we introduce two main classes of algorithms, namely continuous time and discrete time models. The effectiveness of our approach is demonstrated using a wide range of benchmark problems in mathematical physics, including conservation laws, incompressible fluid flow, and the propagation of nonlinear shallow-water waves.","Tue, 28 Nov 2017 21:29:35 UTC (7,849 KB)"
"1106","Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations","Maziar Raissi, Paris Perdikaris, George Em Karniadakis","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Numerical Analysis (cs.NA); Dynamical Systems (math.DS); Machine Learning (stat.ML)","We introduce physics informed neural networks -- neural networks that are trained to solve supervised learning tasks while respecting any given law of physics described by general nonlinear partial differential equations. In this two part treatise, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct classes of algorithms, namely continuous time and discrete time models. The resulting neural networks form a new class of data-efficient universal function approximators that naturally encode any underlying physical laws as prior information. In this first part, we demonstrate how these networks can be used to infer solutions to partial differential equations, and obtain physics-informed surrogate models that are fully differentiable with respect to all input coordinates and free parameters.","Tue, 28 Nov 2017 21:21:59 UTC (7,852 KB)"
"1107","Parameters Optimization of Deep Learning Models using Particle Swarm Optimization","Basheer Qolomany, Majdi Maabreh, Ala Al-Fuqaha, Ajay Gupta, Driss Benhaddou","Neural and Evolutionary Computing (cs.NE)","Deep learning has been successfully applied in several fields such as machine translation, manufacturing, and pattern recognition. However, successful application of deep learning depends upon appropriately setting its parameters to achieve high quality results. The number of hidden layers and the number of neurons in each layer of a deep machine learning network are two key parameters, which have main influence on the performance of the algorithm. Manual parameter setting and grid search approaches somewhat ease the users tasks in setting these important parameters. Nonetheless, these two techniques can be very time consuming. In this paper, we show that the Particle swarm optimization (PSO) technique holds great potential to optimize parameter settings and thus saves valuable computational resources during the tuning process of deep learning models. Specifically, we use a dataset collected from a Wi-Fi campus network to train deep learning models to predict the number of occupants and their locations. Our preliminary experiments indicate that PSO provides an efficient approach for tuning the optimal number of hidden layers and the number of neurons in each layer of the deep learning algorithm when compared to the grid search method. Our experiments illustrate that the exploration process of the landscape of configurations to find the optimal parameters is decreased by 77%-85%. In fact, the PSO yields even better accuracy results.","Tue, 28 Nov 2017 15:43:51 UTC (564 KB)"
"1108","Providing theoretical learning guarantees to Deep Learning Networks","Rodrigo Fernandes de Mello, Martha Dais Ferreira, Moacir Antonelli Ponti","Machine Learning (cs.LG)","Deep Learning (DL) is one of the most common subjects when Machine Learning and Data Science approaches are considered. There are clearly two movements related to DL: the first aggregates researchers in quest to outperform other algorithms from literature, trying to win contests by considering often small decreases in the empirical risk; and the second investigates overfitting evidences, questioning the learning capabilities of DL classifiers. Motivated by such opposed points of view, this paper employs the Statistical Learning Theory (SLT) to study the convergence of Deep Neural Networks, with particular interest in Convolutional Neural Networks. In order to draw theoretical conclusions, we propose an approach to estimate the Shattering coefficient of those classification algorithms, providing a lower bound for the complexity of their space of admissible functions, a.k.a. algorithm bias. Based on such estimator, we generalize the complexity of network biases, and, next, we study AlexNet and VGG16 architectures in the point of view of their Shattering coefficients, and number of training examples required to provide theoretical learning guarantees. From our theoretical formulation, we show the conditions which Deep Neural Networks learn as well as point out another issue: DL benchmarks may be strictly driven by empirical risks, disregarding the complexity of algorithms biases.","Tue, 28 Nov 2017 13:54:56 UTC (54 KB)"
"1109","Homomorphic Parameter Compression for Distributed Deep Learning Training","Jaehee Jang, Byungook Na, Sungroh Yoon","Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","Distributed training of deep neural networks has received significant research interest, and its major approaches include implementations on multiple GPUs and clusters. Parallelization can dramatically improve the efficiency of training deep and complicated models with large-scale data. A fundamental barrier against the speedup of DNN training, however, is the trade-off between computation and communication time. In other words, increasing the number of worker nodes decreases the time consumed in computation while simultaneously increasing communication overhead under constrained network bandwidth, especially in commodity hardware environments. To alleviate this trade-off, we suggest the idea of homomorphic parameter compression, which compresses parameters with the least expense and trains the DNN with the compressed representation. Although the specific method is yet to be discovered, we demonstrate that there is a high probability that the homomorphism can reduce the communication overhead, thanks to little compression and decompression times. We also provide theoretical speedup of homomorphic compression.","Tue, 28 Nov 2017 04:47:59 UTC (2,288 KB)"
"1110","Denoising Gravitational Waves using Deep Learning with Recurrent Denoising Autoencoders","Hongyu Shen, Daniel George, E. A. Huerta, Zhizhen Zhao","General Relativity and Quantum Cosmology (gr-qc); High Energy Astrophysical Phenomena (astro-ph.HE); Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Gravitational wave astronomy is a rapidly growing field of modern astrophysics, with observations being made frequently by the LIGO detectors. Gravitational wave signals are often extremely weak and the data from the detectors, such as LIGO, is contaminated with non-Gaussian and non-stationary noise, often containing transient disturbances which can obscure real signals. Traditional denoising methods, such as principal component analysis and dictionary learning, are not optimal for dealing with this non-Gaussian noise, especially for low signal-to-noise ratio gravitational wave signals. Furthermore, these methods are computationally expensive on large datasets. To overcome these issues, we apply state-of-the-art signal processing techniques, based on recent groundbreaking advancements in deep learning, to denoise gravitational wave signals embedded either in Gaussian noise or in real LIGO noise. We introduce SMTDAE, a Staired Multi-Timestep Denoising Autoencoder, based on sequence-to-sequence bi-directional Long-Short-Term-Memory recurrent neural networks. We demonstrate the advantages of using our unsupervised deep learning approach and show that, after training only using simulated Gaussian noise, SMTDAE achieves superior recovery performance for gravitational wave signals embedded in real non-Gaussian LIGO noise.","Mon, 27 Nov 2017 19:00:09 UTC (1,477 KB)"
"1111","A Big Data Analysis Framework Using Apache Spark and Deep Learning","Anand Gupta, Hardeo Thakur, Ritvik Shrivastava, Pulkit Kumar, Sreyashi Nag","Databases (cs.DB); Machine Learning (cs.LG); Machine Learning (stat.ML)","With the spreading prevalence of Big Data, many advances have recently been made in this field. Frameworks such as Apache Hadoop and Apache Spark have gained a lot of traction over the past decades and have become massively popular, especially in industries. It is becoming increasingly evident that effective big data analysis is key to solving artificial intelligence problems. Thus, a multi-algorithm library was implemented in the Spark framework, called MLlib. While this library supports multiple machine learning algorithms, there is still scope to use the Spark setup efficiently for highly time-intensive and computationally expensive procedures like deep learning. In this paper, we propose a novel framework that combines the distributive computational abilities of Apache Spark and the advanced machine learning architecture of a deep multi-layer perceptron (MLP), using the popular concept of Cascade Learning. We conduct empirical analysis of our framework on two real world datasets. The results are encouraging and corroborate our proposed framework, in turn proving that it is an improvement over traditional big data analysis methods that use either Spark or Deep learning as individual elements.","Sat, 25 Nov 2017 20:11:41 UTC (1,772 KB)"
"1112","Micro-Doppler Based Human-Robot Classification Using Ensemble and Deep Learning Approaches","Sherif Abdulatif, Qian Wei, Fady Aziz, Bernhard Kleiner, Urs Schneider","Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP)","Radar sensors can be used for analyzing the induced frequency shifts due to micro-motions in both range and velocity dimensions identified as micro-Doppler ($\boldsymbolレ$-D) and micro-Range ($\boldsymbolレ$-R), respectively. Different moving targets will have unique $\boldsymbolレ$-D and $\boldsymbolレ$-R signatures that can be used for target classification. Such classification can be used in numerous fields, such as gait recognition, safety and surveillance. In this paper, a 25 GHz FMCW Single-Input Single-Output (SISO) radar is used in industrial safety for real-time human-robot identification. Due to the real-time constraint, joint Range-Doppler (R-D) maps are directly analyzed for our classification problem. Furthermore, a comparison between the conventional classical learning approaches with handcrafted extracted features, ensemble classifiers and deep learning approaches is presented. For ensemble classifiers, restructured range and velocity profiles are passed directly to ensemble trees, such as gradient boosting and random forest without feature extraction. Finally, a Deep Convolutional Neural Network (DCNN) is used and raw R-D images are directly fed into the constructed network. DCNN shows a superior performance of 99\% accuracy in identifying humans from robots on a single R-D map.","Sat, 25 Nov 2017 01:38:03 UTC (3,395 KB)[v2] Fri, 1 Dec 2017 01:15:48 UTC (3,405 KB)[v3] Mon, 26 Feb 2018 09:13:32 UTC (319 KB)"
"1113","An Exploration of Word Embedding Initialization in Deep-Learning Tasks","Tom Kocmi, Ond<U+0159>ej Bojar","Computation and Language (cs.CL)","Word embeddings are the interface between the world of discrete units of text processing and the continuous, differentiable world of neural networks. In this work, we examine various random and pretrained initialization methods for embeddings used in deep networks and their effect on the performance on four NLP tasks with both recurrent and convolutional architectures. We confirm that pretrained embeddings are a little better than random initialization, especially considering the speed of learning. On the other hand, we do not see any significant difference between various methods of random initialization, as long as the variance is kept reasonably low. High-variance initialization prevents the network to use the space of embeddings and forces it to use other free parameters to accomplish the task. We support this hypothesis by observing the performance in learning lexical relations and by the fact that the network can learn to perform reasonably in its task even with fixed random embeddings.","Fri, 24 Nov 2017 22:31:01 UTC (1,148 KB)"
"1114","SplineCNN: Fast Geometric Deep Learning with Continuous B-Spline Kernels","Matthias Fey, Jan Eric Lenssen, Frank Weichert, Heinrich Muller","Computer Vision and Pattern Recognition (cs.CV)","We present Spline-based Convolutional Neural Networks (SplineCNNs), a variant of deep neural networks for irregular structured and geometric input, e.g., graphs or meshes. Our main contribution is a novel convolution operator based on B-splines, that makes the computation time independent from the kernel size due to the local support property of the B-spline basis functions. As a result, we obtain a generalization of the traditional CNN convolution operator by using continuous kernel functions parametrized by a fixed number of trainable weights. In contrast to related approaches that filter in the spectral domain, the proposed method aggregates features purely in the spatial domain. In addition, SplineCNN allows entire end-to-end training of deep architectures, using only the geometric structure as input, instead of handcrafted feature descriptors. For validation, we apply our method on tasks from the fields of image graph classification, shape correspondence and graph node classification, and show that it outperforms or pars state-of-the-art approaches while being significantly faster and having favorable properties like domain-independence.","Fri, 24 Nov 2017 10:33:05 UTC (3,982 KB)[v2] Wed, 23 May 2018 08:57:29 UTC (3,620 KB)"
"1115","Deep learning analysis of the myocardium in coronary CT angiography for identification of patients with functionally significant coronary artery stenosis","Majd Zreik, Nikolas Lessmann, Robbert W. van Hamersvelt, Jelmer M. Wolterink, Michiel Voskuil, Max A. Viergever, Tim Leiner, Ivana I<U+0161>gum","Computer Vision and Pattern Recognition (cs.CV)","In patients with coronary artery stenoses of intermediate severity, the functional significance needs to be determined. Fractional flow reserve (FFR) measurement, performed during invasive coronary angiography (ICA), is most often used in clinical practice. To reduce the number of ICA procedures, we present a method for automatic identification of patients with functionally significant coronary artery stenoses, employing deep learning analysis of the left ventricle (LV) myocardium in rest coronary CT angiography (CCTA). The study includes consecutively acquired CCTA scans of 166 patients with FFR measurements. To identify patients with a functionally significant coronary artery stenosis, analysis is performed in several stages. First, the LV myocardium is segmented using a multiscale convolutional neural network (CNN). To characterize the segmented LV myocardium, it is subsequently encoded using unsupervised convolutional autoencoder (CAE). Thereafter, patients are classified according to the presence of functionally significant stenosis using an SVM classifier based on the extracted and clustered encodings. Quantitative evaluation of LV myocardium segmentation in 20 images resulted in an average Dice coefficient of 0.91 and an average mean absolute distance between the segmented and reference LV boundaries of 0.7 mm. Classification of patients was evaluated in the remaining 126 CCTA scans in 50 10-fold cross-validation experiments and resulted in an area under the receiver operating characteristic curve of 0.74 +- 0.02. At sensitivity levels 0.60, 0.70 and 0.80, the corresponding specificity was 0.77, 0.71 and 0.59, respectively. The results demonstrate that automatic analysis of the LV myocardium in a single CCTA scan acquired at rest, without assessment of the anatomy of the coronary arteries, can be used to identify patients with functionally significant coronary artery stenosis.","Fri, 24 Nov 2017 10:27:36 UTC (6,035 KB)[v2] Wed, 6 Dec 2017 09:22:49 UTC (6,035 KB)"
"1116","Deep Learning for Real-Time Crime Forecasting and its Ternarization","Bao Wang, Penghang Yin, Andrea L. Bertozzi, P. Jeffrey Brantingham, Stanley J. Osher, Jack Xin","Machine Learning (cs.LG); Numerical Analysis (math.NA); Machine Learning (stat.ML)","Real-time crime forecasting is important. However, accurate prediction of when and where the next crime will happen is difficult. No known physical model provides a reasonable approximation to such a complex system. Historical crime data are sparse in both space and time and the signal of interests is weak. In this work, we first present a proper representation of crime data. We then adapt the spatial temporal residual network on the well represented data to predict the distribution of crime in Los Angeles at the scale of hours in neighborhood-sized parcels. These experiments as well as comparisons with several existing approaches to prediction demonstrate the superiority of the proposed model in terms of accuracy. Finally, we present a ternarization technique to address the resource consumption issue for its deployment in real world. This work is an extension of our short conference proceeding paper [Wang et al, Arxiv 1707.03340].","Thu, 23 Nov 2017 21:39:40 UTC (761 KB)"
"1117","RGB-D-based Human Motion Recognition with Deep Learning: A Survey","Pichao Wang, Wanqing Li, Philip Ogunbona, Jun Wan, Sergio Escalera","Computer Vision and Pattern Recognition (cs.CV)","Human motion recognition is one of the most important branches of human-centered research activities. In recent years, motion recognition based on RGB-D data has attracted much attention. Along with the development in artificial intelligence, deep learning techniques have gained remarkable success in computer vision. In particular, convolutional neural networks (CNN) have achieved great success for image-based tasks, and recurrent neural networks (RNN) are renowned for sequence-based problems. Specifically, deep learning methods based on the CNN and RNN architectures have been adopted for motion recognition using RGB-D data. In this paper, a detailed overview of recent advances in RGB-D-based motion recognition is presented. The reviewed methods are broadly categorized into four groups, depending on the modality adopted for recognition: RGB-based, depth-based, skeleton-based and RGB+D-based. As a survey focused on the application of deep learning to RGB-D-based motion recognition, we explicitly discuss the advantages and limitations of existing techniques. Particularly, we highlighted the methods of encoding spatial-temporal-structural information inherent in video sequence, and discuss potential directions for future research.","Tue, 31 Oct 2017 09:21:23 UTC (8,150 KB)[v2] Tue, 24 Apr 2018 23:58:12 UTC (8,158 KB)"
"1118","DeepSign: Deep Learning for Automatic Malware Signature Generation and Classification","Eli David, Nathan S. Netanyahu","Cryptography and Security (cs.CR); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","This paper presents a novel deep learning based method for automatic malware signature generation and classification. The method uses a deep belief network (DBN), implemented with a deep stack of denoising autoencoders, generating an invariant compact representation of the malware behavior. While conventional signature and token based methods for malware detection do not detect a majority of new variants for existing malware, the results presented in this paper show that signatures generated by the DBN allow for an accurate classification of new malware variants. Using a dataset containing hundreds of variants for several major malware families, our method achieves 98.6% classification accuracy using the signatures generated by the DBN. The presented method is completely agnostic to the type of malware behavior that is logged (e.g., API calls and their parameters, registry entries, websites and ports accessed, etc.), and can use any raw input from a sandbox to successfully train the deep neural network which is used to generate malware signatures.","Tue, 21 Nov 2017 07:22:58 UTC (322 KB)[v2] Thu, 23 Nov 2017 16:27:18 UTC (322 KB)"
"1119","Adversarial Phenomenon in the Eyes of Bayesian Deep Learning","Ambrish Rawat, Martin Wistuba, Maria-Irina Nicolae","Machine Learning (stat.ML); Machine Learning (cs.LG)","Deep Learning models are vulnerable to adversarial examples, i.e.\ images obtained via deliberate imperceptible perturbations, such that the model misclassifies them with high confidence. However, class confidence by itself is an incomplete picture of uncertainty. We therefore use principled Bayesian methods to capture model uncertainty in prediction for observing adversarial misclassification. We provide an extensive study with different Bayesian neural networks attacked in both white-box and black-box setups. The behaviour of the networks for noise, attacks and clean test data is compared. We observe that Bayesian neural networks are uncertain in their predictions for adversarial perturbations, a behaviour similar to the one observed for random Gaussian perturbations. Thus, we conclude that Bayesian neural networks can be considered for detecting adversarial examples.","Wed, 22 Nov 2017 12:02:53 UTC (820 KB)"
"1120","A multiobjective deep learning approach for predictive classification in Neuroblastoma","Valerio Maggio, Marco Chierici, Giuseppe Jurman, Cesare Furlanello","Quantitative Methods (q-bio.QM); Machine Learning (cs.LG)","Neuroblastoma is a strongly heterogeneous cancer with very diverse clinical courses that may vary from spontaneous regression to fatal progression; an accurate patient's risk estimation at diagnosis is essential to design appropriate tumor treatment strategies. Neuroblastoma is a paradigm disease where different diagnostic and prognostic endpoints should be predicted from common molecular and clinical information, with increasing complexity, as shown in the FDA MAQC-II study. Here we introduce the novel multiobjective deep learning architecture CDRP (Concatenated Diagnostic Relapse Prognostic) composed by 8 layers to obtain a combined diagnostic and prognostic prediction from high-throughput transcriptomics data. Two distinct loss functions are optimized for the Event Free Survival (EFS) and Overall Survival (OS) prognosis, respectively. We use the High-Risk (HR) diagnostic information as an additional input generated by an autoencoder embedding. The latter is used as network regulariser, based on a clinical algorithm commonly adopted for stratifying patients from cancer stage, age at insurgence of disease, and MYCN, the specific molecular marker. The architecture was applied to Illumina HiSeq2000 RNA-Seq for 498 neuroblastoma patients (176 at high risk) from the Sequencing Quality Control (SEQC) study, obtaining state-of-art on the diagnostic endpoint and improving prediction of prognosis over the HR cohort.","Wed, 22 Nov 2017 09:54:48 UTC (56 KB)[v2] Fri, 1 Dec 2017 13:38:22 UTC (61 KB)[v3] Thu, 22 Feb 2018 18:43:29 UTC (185 KB)"
"1121","Accurate Real Time Localization Tracking in A Clinical Environment using Bluetooth Low Energy and Deep Learning","Zohaib Iqbal, Da Luo, Peter Henry, Samaneh Kazemifar, Timothy Rozario, Yulong Yan, Kenneth Westover, Weiguo Lu, Dan Nguyen, Troy Long, Jing Wang, Hak Choy, Steve Jiang","Medical Physics (physics.med-ph); Machine Learning (cs.LG)","Deep learning has started to revolutionize several different industries, and the applications of these methods in medicine are now becoming more commonplace. This study focuses on investigating the feasibility of tracking patients and clinical staff wearing Bluetooth Low Energy (BLE) tags in a radiation oncology clinic using artificial neural networks (ANNs) and convolutional neural networks (CNNs). The performance of these networks was compared to relative received signal strength indicator (RSSI) thresholding and triangulation. By utilizing temporal information, a combined CNN+ANN network was capable of correctly identifying the location of the BLE tag with an accuracy of 99.9%. It outperformed a CNN model (accuracy = 94%), a thresholding model employing majority voting (accuracy = 95%), and a triangulation classifier utilizing majority voting (accuracy = 95%). Future studies will seek to deploy this affordable real time location system in hospitals to improve clinical workflow, efficiency, and patient safety.","Wed, 22 Nov 2017 06:32:13 UTC (228 KB)[v2] Thu, 17 May 2018 19:22:44 UTC (383 KB)[v3] Mon, 15 Oct 2018 15:26:47 UTC (4,351 KB)"
"1122","Finding Algebraic Structure of Care in Time: A Deep Learning Approach","Phuoc Nguyen, Truyen Tran, Svetha Venkatesh","Machine Learning (cs.LG)","Understanding the latent processes from Electronic Medical Records could be a game changer in modern healthcare. However, the processes are complex due to the interaction between at least three dynamic components: the illness, the care and the recording practice. Existing methods are inadequate in capturing the dynamic structure of care. We propose an end-to-end model that reads medical record and predicts future risk. The model adopts the algebraic view in that discrete medical objects are embedded into continuous vectors lying in the same space. The bag of disease and comorbidities recorded at each hospital visit are modeled as function of sets. The same holds for the bag of treatments. The interaction between diseases and treatments at a visit is modeled as the residual of the diseases minus the treatments. Finally, the health trajectory, which is a sequence of visits, is modeled using a recurrent neural network. We report preliminary results on chronic diseases - diabetes and mental health - for predicting unplanned readmission.","Tue, 21 Nov 2017 03:41:05 UTC (454 KB)"
"1123","Deep Learning for Physical Processes: Incorporating Prior Scientific Knowledge","Emmanuel de Bezenac, Arthur Pajot, Patrick Gallinari","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","We consider the use of Deep Learning methods for modeling complex phenomena like those occurring in natural physical processes. With the large amount of data gathered on these phenomena the data intensive paradigm could begin to challenge more traditional approaches elaborated over the years in fields like maths or physics. However, despite considerable successes in a variety of application domains, the machine learning field is not yet ready to handle the level of complexity required by such problems. Using an example application, namely Sea Surface Temperature Prediction, we show how general background knowledge gained from physics could be used as a guideline for designing efficient Deep Learning models. In order to motivate the approach and to assess its generality we demonstrate a formal link between the solution of a class of differential equations underlying a large family of physical phenomena and the proposed model. Experiments and comparison with series of baselines including a state of the art numerical approach is then provided.","Tue, 21 Nov 2017 18:49:47 UTC (2,750 KB)[v2] Tue, 9 Jan 2018 16:43:39 UTC (2,652 KB)"
"1124","Deep Learning for Real-time Gravitational Wave Detection and Parameter Estimation with LIGO Data","Daniel George, E. A. Huerta","General Relativity and Quantum Cosmology (gr-qc); High Energy Astrophysical Phenomena (astro-ph.HE); Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","The recent Nobel-prize-winning detections of gravitational waves from merging black holes and the subsequent detection of the collision of two neutron stars in coincidence with electromagnetic observations have inaugurated a new era of multimessenger astrophysics. To enhance the scope of this emergent science, we proposed the use of deep convolutional neural networks for the detection and characterization of gravitational wave signals in real-time. This method, Deep Filtering, was initially demonstrated using simulated LIGO noise. In this article, we present the extension of Deep Filtering using real data from the first observing run of LIGO, for both detection and parameter estimation of gravitational waves from binary black hole mergers with continuous data streams from multiple LIGO detectors. We show for the first time that machine learning can detect and estimate the true parameters of a real GW event observed by LIGO. Our comparisons show that Deep Filtering is far more computationally efficient than matched-filtering, while retaining similar sensitivity and lower errors, allowing real-time processing of weak time-series signals in non-stationary non-Gaussian noise, with minimal resources, and also enables the detection of new classes of gravitational wave sources that may go unnoticed with existing detection algorithms. This approach is uniquely suited to enable coincident detection campaigns of gravitational waves and their multimessenger counterparts in real-time.","Tue, 21 Nov 2017 18:45:01 UTC (1,716 KB)[v2] Mon, 11 Dec 2017 19:36:44 UTC (1,717 KB)"
"1125","Understanding Deep Learning Generalization by Maximum Entropy","Guanhua Zheng, Jitao Sang, Changsheng Xu","Machine Learning (cs.LG)","Deep learning achieves remarkable generalization capability with overwhelming number of model parameters. Theoretical understanding of deep learning generalization receives recent attention yet remains not fully explored. This paper attempts to provide an alternative understanding from the perspective of maximum entropy. We first derive two feature conditions that softmax regression strictly apply maximum entropy principle. DNN is then regarded as approximating the feature conditions with multilayer feature learning, and proved to be a recursive solution towards maximum entropy principle. The connection between DNN and maximum entropy well explains why typical designs such as shortcut and regularization improves model generalization, and provides instructions for future model development.","Tue, 21 Nov 2017 13:03:12 UTC (90 KB)"
"1126","A deep learning-based method for relative location prediction in CT scan images","Jiajia Guo, Hongwei Du, Bensheng Qiu, Xiao Liang","Computer Vision and Pattern Recognition (cs.CV)","Relative location prediction in computed tomography (CT) scan images is a challenging problem. In this paper, a regression model based on one-dimensional convolutional neural networks is proposed to determine the relative location of a CT scan image both robustly and precisely. A public dataset is employed to validate the performance of the study's proposed method using a 5-fold cross validation. Experimental results demonstrate an excellent performance of the proposed model when compared with the state-of-the-art techniques, achieving a median absolute error of 1.04 cm and mean absolute error of 1.69 cm.","Tue, 21 Nov 2017 04:11:37 UTC (403 KB)"
"1127","Detection of Tooth caries in Bitewing Radiographs using Deep Learning","Muktabh Mayank Srivastava, Pratyush Kumar, Lalit Pradhan, Srikrishna Varadarajan","Computer Vision and Pattern Recognition (cs.CV)","We develop a Computer Aided Diagnosis (CAD) system, which enhances the performance of dentists in detecting wide range of dental caries. The CAD System achieves this by acting as a second opinion for the dentists with way higher sensitivity on the task of detecting cavities than the dentists themselves. We develop annotated dataset of more than 3000 bitewing radiographs and utilize it for developing a system for automated diagnosis of dental caries. Our system consists of a deep fully convolutional neural network (FCNN) consisting 100+ layers, which is trained to mark caries on bitewing radiographs. We have compared the performance of our proposed system with three certified dentists for marking dental caries. We exceed the average performance of the dentists in both recall (sensitivity) and F1-Score (agreement with truth) by a very large margin. Working example of our system is shown in Figure 1.","Mon, 20 Nov 2017 14:12:32 UTC (697 KB)[v2] Thu, 23 Nov 2017 16:08:27 UTC (698 KB)"
"1128","Pseudo Dual Energy CT Imaging using Deep Learning Based Framework: Initial Study","Sui Li, Yongbo Wang, Yuting Liao, Ji He, Dong Zeng, Zhaoying Bian, Jianhua Ma","Medical Physics (physics.med-ph)","Dual energy computed tomography (DECT) has become of particular interest in clinic recent years. The DECT scan comprises two images, corresponding to two photon attenuation coefficients maps of the objects. Meanwhile, the DECT images are less accessible sometimes, compared to the conventional single energy CT (SECT). This motivates us to simulate pseudo DECT (pDECT) images from the SECT images. Inspired by recent advances in deep learning, we present a deep learning based framework to yield pDECT images from SECT images, utilizing the intrinsic characteristics underlying DECT images, i.e., global correlation and high similarity. To demonstrate the performance of the deep learning based framework, a cascade deep ConvNet (CD-ConvNet) approach is specifically presented in the deep learning framework. In the training step, the CD-ConvNet is designed to learn the non-linear mapping from the measured energy-specific (i.e., low-energy) CT images to the desired energy-specific (i.e., high-energy) CT images. In the testing step, the trained CD-ConvNet can be used to yield desired high-energy CT images from the low-energy CT images, and then produce accurate basic material maps. Clinical patient data were employed to validate and evaluate the presented CD-ConvNet approach performance. Both visual and quantitative results demonstrate the presented CD-ConvNet approach can yield high quality pDECT images and basic material maps.","Mon, 20 Nov 2017 01:45:55 UTC (1,953 KB)"
"1129","Deep learning for inferring cause of data anomalies","V. Azzolini, M. Borisyak, G. Cerminara, D. Derkach, G. Franzoni, F. De Guio, O. Koval, M. Pierini, A. Pol, F. Ratnikov, F. Siroky, A. Ustyuzhanin, J-R. Vlimant","Data Analysis, Statistics and Probability (physics.data-an); Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)","Daily operation of a large-scale experiment is a resource consuming task, particularly from perspectives of routine data quality monitoring. Typically, data comes from different sub-detectors and the global quality of data depends on the combinatorial performance of each of them. In this paper, the problem of identifying channels in which anomalies occurred is considered. We introduce a generic deep learning model and prove that, under reasonable assumptions, the model learns to identify 'channels' which are affected by an anomaly. Such model could be used for data quality manager cross-check and assistance and identifying good channels in anomalous data samples. The main novelty of the method is that the model does not require ground truth labels for each channel, only global flag is used. This effectively distinguishes the model from classical classification methods. Being applied to CMS data collected in the year 2010, this approach proves its ability to decompose anomaly by separate channels.","Sun, 19 Nov 2017 16:51:31 UTC (981 KB)"
"1130","MIT Autonomous Vehicle Technology Study: Large-Scale Deep Learning Based Analysis of Driver Behavior and Interaction with Automation","Lex Fridman, Daniel E. Brown, Michael Glazer, William Angell, Spencer Dodd, Benedikt Jenik, Jack Terwilliger, Julia Kindelsberger, Li Ding, Sean Seaman, Hillary Abraham, Alea Mehler, Andrew Sipperley, Anthony Pettinato, Bobbie Seppelt, Linda Angell, Bruce Mehler, Bryan Reimer","Computers and Society (cs.CY); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)","For the foreseeble future, human beings will likely remain an integral part of the driving task, monitoring the AI system as it performs anywhere from just over 0% to just under 100% of the driving. The governing objectives of the MIT Autonomous Vehicle Technology (MIT-AVT) study are to (1) undertake large-scale real-world driving data collection that includes high-definition video to fuel the development of deep learning based internal and external perception systems, (2) gain a holistic understanding of how human beings interact with vehicle automation technology by integrating video data with vehicle state data, driver characteristics, mental models, and self-reported experiences with technology, and (3) identify how technology and other factors related to automation adoption and use can be improved in ways that save lives. In pursuing these objectives, we have instrumented 21 Tesla Model S and Model X vehicles, 2 Volvo S90 vehicles, 2 Range Rover Evoque, and 2 Cadillac CT6 vehicles for both long-term (over a year per driver) and medium term (one month per driver) naturalistic driving data collection. Furthermore, we are continually developing new methods for analysis of the massive-scale dataset collected from the instrumented vehicle fleet. The recorded data streams include IMU, GPS, CAN messages, and high-definition video streams of the driver face, the driver cabin, the forward roadway, and the instrument cluster (on select vehicles). The study is on-going and growing. To date, we have 99 participants, 11,846 days of participation, 405,807 miles, and 5.5 billion video frames. This paper presents the design of the study, the data collection hardware, the processing of the data, and the computer vision algorithms currently being used to extract actionable knowledge from the data.","Sun, 19 Nov 2017 06:46:21 UTC (5,165 KB)[v2] Sun, 30 Sep 2018 04:02:20 UTC (3,819 KB)"
"1131","BPGrad: Towards Global Optimality in Deep Learning via Branch and Pruning","Ziming Zhang, Yuanwei Wu, Guanghui Wang","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Understanding the global optimality in deep learning (DL) has been attracting more and more attention recently. Conventional DL solvers, however, have not been developed intentionally to seek for such global optimality. In this paper we propose a novel approximation algorithm, BPGrad, towards optimizing deep models globally via branch and pruning. Our BPGrad algorithm is based on the assumption of Lipschitz continuity in DL, and as a result it can adaptively determine the step size for current gradient given the history of previous updates, wherein theoretically no smaller steps can achieve the global optimality. We prove that, by repeating such branch-and-pruning procedure, we can locate the global optimality within finite iterations. Empirically an efficient solver based on BPGrad for DL is proposed as well, and it outperforms conventional DL solvers such as Adagrad, Adadelta, RMSProp, and Adam in the tasks of object recognition, detection, and segmentation.","Sun, 19 Nov 2017 02:44:31 UTC (459 KB)"
"1132","DLTK: State of the Art Reference Implementations for Deep Learning on Medical Images","Nick Pawlowski, Sofia Ira Ktena, Matthew C.H. Lee, Bernhard Kainz, Daniel Rueckert, Ben Glocker, Martin Rajchl","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","We present DLTK, a toolkit providing baseline implementations for efficient experimentation with deep learning methods on biomedical images. It builds on top of TensorFlow and its high modularity and easy-to-use examples allow for a low-threshold access to state-of-the-art implementations for typical medical imaging problems. A comparison of DLTK's reference implementations of popular network architectures for image segmentation demonstrates new top performance on the publicly available challenge data ""Multi-Atlas Labeling Beyond the Cranial Vault"". The average test Dice similarity coefficient of $81.5$ exceeds the previously best performing CNN ($75.7$) and the accuracy of the challenge winning method ($79.0$).","Sat, 18 Nov 2017 12:31:10 UTC (1,194 KB)"
"1133","Training Simplification and Model Simplification for Deep Learning: A Minimal Effort Back Propagation Method","Xu Sun, Xuancheng Ren, Shuming Ma, Bingzhen Wei, Wei Li, Houfeng Wang","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)","We propose a simple yet effective technique to simplify the training and the resulting model of neural networks. In back propagation, only a small subset of the full gradient is computed to update the model parameters. The gradient vectors are sparsified in such a way that only the top-$k$ elements (in terms of magnitude) are kept. As a result, only $k$ rows or columns (depending on the layout) of the weight matrix are modified, leading to a linear reduction in the computational cost. Based on the sparsified gradients, we further simplify the model by eliminating the rows or columns that are seldom updated, which will reduce the computational cost both in the training and decoding, and potentially accelerate decoding in real-world applications. Surprisingly, experimental results demonstrate that most of time we only need to update fewer than 5% of the weights at each back propagation pass. More interestingly, the accuracy of the resulting models is actually improved rather than degraded, and a detailed analysis is given. The model simplification results show that we could adaptively simplify the model which could often be reduced by around 9x, without any loss on accuracy or even with improved accuracy.","Fri, 17 Nov 2017 13:36:51 UTC (349 KB)"
"1134","Vision Based Railway Track Monitoring using Deep Learning","Shruti Mittal, Dattaraj Rao","Computer Vision and Pattern Recognition (cs.CV)","Computer vision based methods have been explored in the past for detection of railway track defects, but full automation has always been a challenge because both traditional image processing methods and deep learning classifiers trained from scratch fail to generalize that well to infinite novel scenarios seen in the real world, given limited amount of labeled data. Advancements have been made recently to make machine learning models utilize knowledge from a different but related domain. In this paper, we show that even though similar domain data is not available, transfer learning provides the model understanding of other real world objects and enables training production scale deep learning classifiers for uncontrolled real world data. Our models efficiently detect both track defects like sunkinks, loose ballast and railway assets like switches and signals. Models were validated with hours of track videos recorded in different continents resulting in different weather conditions, different ambience and surroundings. A track health index concept has also been proposed to monitor complete rail network.","Fri, 17 Nov 2017 06:16:41 UTC (975 KB)[v2] Sun, 25 Nov 2018 14:25:54 UTC (805 KB)"
"1135","Improving Palliative Care with Deep Learning","Anand Avati, Kenneth Jung, Stephanie Harman, Lance Downing, Andrew Ng, Nigam H. Shah","Computers and Society (cs.CY); Machine Learning (cs.LG); Machine Learning (stat.ML)","Improving the quality of end-of-life care for hospitalized patients is a priority for healthcare organizations. Studies have shown that physicians tend to over-estimate prognoses, which in combination with treatment inertia results in a mismatch between patients wishes and actual care at the end of life. We describe a method to address this problem using Deep Learning and Electronic Health Record (EHR) data, which is currently being piloted, with Institutional Review Board approval, at an academic medical center. The EHR data of admitted patients are automatically evaluated by an algorithm, which brings patients who are likely to benefit from palliative care services to the attention of the Palliative Care team. The algorithm is a Deep Neural Network trained on the EHR data from previous years, to predict all-cause 3-12 month mortality of patients as a proxy for patients that could benefit from palliative care. Our predictions enable the Palliative Care team to take a proactive approach in reaching out to such patients, rather than relying on referrals from treating physicians, or conduct time consuming chart reviews of all patients. We also present a novel interpretation technique which we use to provide explanations of the model's predictions.","Fri, 17 Nov 2017 04:46:17 UTC (290 KB)"
"1136","Towards Deep Learning Models for Psychological State Prediction using Smartphone Data: Challenges and Opportunities","Gatis Mikelsons, Matthew Smith, Abhinav Mehrotra, Mirco Musolesi","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","There is an increasing interest in exploiting mobile sensing technologies and machine learning techniques for mental health monitoring and intervention. Researchers have effectively used contextual information, such as mobility, communication and mobile phone usage patterns for quantifying individuals' mood and wellbeing. In this paper, we investigate the effectiveness of neural network models for predicting users' level of stress by using the location information collected by smartphones. We characterize the mobility patterns of individuals using the GPS metrics presented in the literature and employ these metrics as input to the network. We evaluate our approach on the open-source StudentLife dataset. Moreover, we discuss the challenges and trade-offs involved in building machine learning models for digital mental health and highlight potential future work in this direction.","Thu, 16 Nov 2017 23:18:03 UTC (245 KB)"
"1137","Performance Modeling and Evaluation of Distributed Deep Learning Frameworks on GPUs","Shaohuai Shi, Qiang Wang, Xiaowen Chu","Distributed, Parallel, and Cluster Computing (cs.DC)","Deep learning frameworks have been widely deployed on GPU servers for deep learning applications in both academia and industry. In training deep neural networks (DNNs), there are many standard processes or algorithms, such as convolution and stochastic gradient descent (SGD), but the running performance of different frameworks might be different even running the same deep model on the same GPU hardware. In this study, we evaluate the running performance of four state-of-the-art distributed deep learning frameworks (i.e., Caffe-MPI, CNTK, MXNet, and TensorFlow) over single-GPU, multi-GPU, and multi-node environments. We first build performance models of standard processes in training DNNs with SGD, and then we benchmark the running performance of these frameworks with three popular convolutional neural networks (i.e., AlexNet, GoogleNet and ResNet-50), after that, we analyze what factors that result in the performance gap among these four frameworks. Through both analytical and experimental analysis, we identify bottlenecks and overheads which could be further optimized. The main contribution is that the proposed performance models and the analysis provide further optimization directions in both algorithmic design and system configuration.","Thu, 16 Nov 2017 08:20:13 UTC (453 KB)[v2] Fri, 8 Dec 2017 06:47:47 UTC (454 KB)[v3] Mon, 20 Aug 2018 06:18:07 UTC (650 KB)"
"1138","Improving galaxy morphologies for SDSS with Deep Learning","H. Dominguez Sanchez, M. Huertas-Company, M. Bernardi, D. Tuccillo, J. L. Fischer","Astrophysics of Galaxies (astro-ph.GA)","We present a morphological catalogue for $\sim$ 670,000 galaxies in the Sloan Digital Sky Survey in two flavours: T-Type, related to the Hubble sequence, and Galaxy Zoo 2 (GZ2 hereafter) classification scheme. By combining accurate existing visual classification catalogues with machine learning, we provide the largest and most accurate morphological catalogue up to date. The classifications are obtained with Deep Learning algorithms using Convolutional Neural Networks (CNNs). We use two visual classification catalogues, GZ2 and Nair & Abraham (2010), for training CNNs with colour images in order to obtain T-Types and a series of GZ2 type questions (disk/features, edge-on galaxies, bar signature, bulge prominence, roundness and mergers). We also provide an additional probability enabling a separation between pure elliptical (E) from S0, where the T-Type model is not so efficient. For the T-Type, our results show smaller offset and scatter than previous models trained with support vector machines. For the GZ2 type questions, our models have large accuracy (> 97\%), precision and recall values (> 90\%) when applied to a test sample with the same characteristics as the one used for training. The catalogue is publicly released with the paper.","Wed, 15 Nov 2017 19:00:03 UTC (1,739 KB)[v2] Wed, 7 Feb 2018 19:00:03 UTC (1,778 KB)"
"1139","Deep Epitome for Unravelling Generalized Hamming Network: A Fuzzy Logic Interpretation of Deep Learning","Lixin Fan","Computer Vision and Pattern Recognition (cs.CV)","This paper gives a rigorous analysis of trained Generalized Hamming Networks(GHN) proposed by Fan (2017) and discloses an interesting finding about GHNs, i.e., stacked convolution layers in a GHN is equivalent to a single yet wide convolution layer. The revealed equivalence, on the theoretical side, can be regarded as a constructive manifestation of the universal approximation theorem Cybenko(1989); Hornik (1991). In practice, it has profound and multi-fold implications. For network visualization, the constructed deep epitomes at each layer provide a visualization of network internal representation that does not rely on the input data. Moreover, deep epitomes allows the direct extraction of features in just one step, without resorting to regularized optimizations used in existing visualization tools.","Wed, 15 Nov 2017 03:36:06 UTC (976 KB)"
"1140","Optimizing Kernel Machines using Deep Learning","Huan Song, Jayaraman J. Thiagarajan, Prasanna Sattigeri, Andreas Spanias","Machine Learning (stat.ML); Machine Learning (cs.LG)","Building highly non-linear and non-parametric models is central to several state-of-the-art machine learning systems. Kernel methods form an important class of techniques that induce a reproducing kernel Hilbert space (RKHS) for inferring non-linear models through the construction of similarity functions from data. These methods are particularly preferred in cases where the training data sizes are limited and when prior knowledge of the data similarities is available. Despite their usefulness, they are limited by the computational complexity and their inability to support end-to-end learning with a task-specific objective. On the other hand, deep neural networks have become the de facto solution for end-to-end inference in several learning paradigms. In this article, we explore the idea of using deep architectures to perform kernel machine optimization, for both computational efficiency and end-to-end inferencing. To this end, we develop the DKMO (Deep Kernel Machine Optimization) framework, that creates an ensemble of dense embeddings using Nystrom kernel approximations and utilizes deep learning to generate task-specific representations through the fusion of the embeddings. Intuitively, the filters of the network are trained to fuse information from an ensemble of linear subspaces in the RKHS. Furthermore, we introduce the kernel dropout regularization to enable improved training convergence. Finally, we extend this framework to the multiple kernel case, by coupling a global fusion layer with pre-trained deep kernel machines for each of the constituent kernels. Using case studies with limited training data, and lack of explicit feature sources, we demonstrate the effectiveness of our framework over conventional model inferencing techniques.","Wed, 15 Nov 2017 01:30:58 UTC (3,217 KB)"
"1141","A Deep Learning Approach for Expert Identification in Question Answering Communities","Chen Zheng, Shuangfei Zhai, Zhongfei Zhang","Computation and Language (cs.CL)","In this paper, we describe an effective convolutional neural network framework for identifying the expert in question answering community. This approach uses the convolutional neural network and combines user feature representations with question feature representations to compute scores that the user who gets the highest score is the expert on this question. Unlike prior work, this method does not measure expert based on measure answer content quality to identify the expert but only require question sentence and user embedding feature to identify the expert. Remarkably, Our model can be applied to different languages and different domains. The proposed framework is trained on two datasets, The first dataset is Stack Overflow and the second one is Zhihu. The Top-1 accuracy results of our experiments show that our framework outperforms the best baseline framework for expert identification.","Tue, 14 Nov 2017 23:10:59 UTC (237 KB)"
"1142","CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning","Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, Matthew P. Lungren, Andrew Y. Ng","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","We develop an algorithm that can detect pneumonia from chest X-rays at a level exceeding practicing radiologists. Our algorithm, CheXNet, is a 121-layer convolutional neural network trained on ChestX-ray14, currently the largest publicly available chest X-ray dataset, containing over 100,000 frontal-view X-ray images with 14 diseases. Four practicing academic radiologists annotate a test set, on which we compare the performance of CheXNet to that of radiologists. We find that CheXNet exceeds average radiologist performance on the F1 metric. We extend CheXNet to detect all 14 diseases in ChestX-ray14 and achieve state of the art results on all 14 diseases.","Tue, 14 Nov 2017 17:58:50 UTC (16,273 KB)[v2] Sat, 25 Nov 2017 04:21:27 UTC (321 KB)[v3] Mon, 25 Dec 2017 11:09:06 UTC (321 KB)"
"1143","Resurrecting the sigmoid in deep learning through dynamical isometry: theory and practice","Jeffrey Pennington, Samuel S. Schoenholz, Surya Ganguli","Machine Learning (cs.LG); Machine Learning (stat.ML)","It is well known that the initialization of weights in deep neural networks can have a dramatic impact on learning speed. For example, ensuring the mean squared singular value of a network's input-output Jacobian is $O(1)$ is essential for avoiding the exponential vanishing or explosion of gradients. The stronger condition that all singular values of the Jacobian concentrate near $1$ is a property known as dynamical isometry. For deep linear networks, dynamical isometry can be achieved through orthogonal weight initialization and has been shown to dramatically speed up learning; however, it has remained unclear how to extend these results to the nonlinear setting. We address this question by employing powerful tools from free probability theory to compute analytically the entire singular value distribution of a deep network's input-output Jacobian. We explore the dependence of the singular value distribution on the depth of the network, the weight initialization, and the choice of nonlinearity. Intriguingly, we find that ReLU networks are incapable of dynamical isometry. On the other hand, sigmoidal networks can achieve isometry, but only with orthogonal weight initialization. Moreover, we demonstrate empirically that deep nonlinear networks achieving dynamical isometry learn orders of magnitude faster than networks that do not. Indeed, we show that properly-initialized deep sigmoidal networks consistently outperform deep ReLU networks. Overall, our analysis reveals that controlling the entire distribution of Jacobian singular values is an important design consideration in deep learning.","Mon, 13 Nov 2017 18:06:09 UTC (1,341 KB)"
"1144","Financial Time Series Prediction Using Deep Learning","Ariel Navon, Yosi Keller","Signal Processing (eess.SP); Statistical Finance (q-fin.ST)","In this work we present a data-driven end-to-end Deep Learning approach for time series prediction, applied to financial time series. A Deep Learning scheme is derived to predict the temporal trends of stocks and ETFs in NYSE or NASDAQ. Our approach is based on a neural network (NN) that is applied to raw financial data inputs, and is trained to predict the temporal trends of stocks and ETFs. In order to handle commission-based trading, we derive an investment strategy that utilizes the probabilistic outputs of the NN, and optimizes the average return. The proposed scheme is shown to provide statistically significant accurate predictions of financial market trends, and the investment strategy is shown to be profitable under this challenging setup. The performance compares favorably with contemporary benchmarks along two-years of back-testing.","Sat, 11 Nov 2017 17:33:42 UTC (426 KB)"
"1145","Towards Automated ICD Coding Using Deep Learning","Haoran Shi, Pengtao Xie, Zhiting Hu, Ming Zhang, Eric P. Xing","Computation and Language (cs.CL)","International Classification of Diseases(ICD) is an authoritative health care classification system of different diseases and conditions for clinical and management purposes. Considering the complicated and dedicated process to assign correct codes to each patient admission based on overall diagnosis, we propose a hierarchical deep learning model with attention mechanism which can automatically assign ICD diagnostic codes given written diagnosis. We utilize character-aware neural language models to generate hidden representations of written diagnosis descriptions and ICD codes, and design an attention mechanism to address the mismatch between the numbers of descriptions and corresponding codes. Our experimental results show the strong potential of automated ICD coding from diagnosis descriptions. Our best model achieves 0.53 and 0.90 of F1 score and area under curve of receiver operating characteristic respectively. The result outperforms those achieved using character-unaware encoding method or without attention mechanism. It indicates that our proposed deep learning model can code automatically in a reasonable way and provide a framework for computer-auxiliary ICD coding.","Sat, 11 Nov 2017 04:34:51 UTC (362 KB)[v2] Tue, 28 Nov 2017 01:48:29 UTC (360 KB)[v3] Thu, 30 Nov 2017 16:16:11 UTC (360 KB)"
"1146","Applications of Deep Learning and Reinforcement Learning to Biological Data","Mufti Mahmud, M. Shamim Kaiser, Amir Hussain, Stefano Vassanelli","Machine Learning (cs.LG); Machine Learning (stat.ML)","Rapid advances of hardware-based technologies during the past decades have opened up new possibilities for Life scientists to gather multimodal data in various application domains (e.g., Omics, Bioimaging, Medical Imaging, and [Brain/Body]-Machine Interfaces), thus generating novel opportunities for development of dedicated data intensive machine learning techniques. Overall, recent research in Deep learning (DL), Reinforcement learning (RL), and their combination (Deep RL) promise to revolutionize Artificial Intelligence. The growth in computational power accompanied by faster and increased data storage and declining computing costs have already allowed scientists in various fields to apply these techniques on datasets that were previously intractable for their size and complexity. This review article provides a comprehensive survey on the application of DL, RL, and Deep RL techniques in mining Biological data. In addition, we compare performances of DL techniques when applied to different datasets across various application domains. Finally, we outline open issues in this challenging research area and discuss future development perspectives.","Fri, 10 Nov 2017 19:06:46 UTC (1,312 KB)[v2] Sun, 7 Jan 2018 07:06:20 UTC (1,312 KB)"
"1147","Online Deep Learning: Learning Deep Neural Networks on the Fly","Doyen Sahoo, Quang Pham, Jing Lu, Steven C.H. Hoi","Machine Learning (cs.LG)","Deep Neural Networks (DNNs) are typically trained by backpropagation in a batch learning setting, which requires the entire training data to be made available prior to the learning task. This is not scalable for many real-world scenarios where new data arrives sequentially in a stream form. We aim to address an open challenge of ""Online Deep Learning"" (ODL) for learning DNNs on the fly in an online setting. Unlike traditional online learning that often optimizes some convex objective function with respect to a shallow model (e.g., a linear/kernel-based hypothesis), ODL is significantly more challenging since the optimization of the DNN objective function is non-convex, and regular backpropagation does not work well in practice, especially for online learning settings. In this paper, we present a new online deep learning framework that attempts to tackle the challenges by learning DNN models of adaptive depth from a sequence of training data in an online learning setting. In particular, we propose a novel Hedge Backpropagation (HBP) method for online updating the parameters of DNN effectively, and validate the efficacy of our method on large-scale data sets, including both stationary and concept drifting scenarios.","Fri, 10 Nov 2017 05:54:14 UTC (342 KB)"
"1148","p-FP: Extraction, Classification, and Prediction of Website Fingerprints with Deep Learning","Se Eun Oh, Saikrishna Sunkam, Nicholas Hopper","Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)","Recent advances in learning Deep Neural Network (DNN) architectures have received a great deal of attention due to their ability to outperform state-of-the-art classifiers across a wide range of applications, with little or no feature engineering. In this paper, we broadly study the applicability of deep learning to website fingerprinting. We show that unsupervised DNNs can be used to extract low-dimensional feature vectors that improve the performance of state-of-the-art website fingerprinting attacks. When used as classifiers, we show that they can match or exceed performance of existing attacks across a range of application scenarios, including fingerprinting Tor website traces, fingerprinting search engine queries over Tor, defeating fingerprinting defenses, and fingerprinting TLS-encrypted websites. Finally, we show that DNNs can be used to predict the fingerprintability of a website based on its contents, achieving 99% accuracy on a data set of 4500 website downloads.","Fri, 10 Nov 2017 00:56:20 UTC (4,306 KB)[v2] Mon, 2 Apr 2018 15:48:04 UTC (2,515 KB)"
"1149","Stochastic Deep Learning in Memristive Networks","Anakha V Babu, Bipin Rajendran","Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","We study the performance of stochastically trained deep neural networks (DNNs) whose synaptic weights are implemented using emerging memristive devices that exhibit limited dynamic range, resolution, and variability in their programming characteristics. We show that a key device parameter to optimize the learning efficiency of DNNs is the variability in its programming characteristics. DNNs with such memristive synapses, even with dynamic range as low as $15$ and only $32$ discrete levels, when trained based on stochastic updates suffer less than $3\%$ loss in accuracy compared to floating point software baseline. We also study the performance of stochastic memristive DNNs when used as inference engines with noise corrupted data and find that if the device variability can be minimized, the relative degradation in performance for the Stochastic DNN is better than that of the software baseline. Hence, our study presents a new optimization corner for memristive devices for building large noise-immune deep learning systems.","Thu, 9 Nov 2017 23:09:36 UTC (232 KB)"
"1150","What Really is Deep Learning Doing?","Chuyu Xiong","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Deep learning has achieved a great success in many areas, from computer vision to natural language processing, to game playing, and much more. Yet, what deep learning is really doing is still an open question. There are a lot of works in this direction. For example, [5] tried to explain deep learning by group renormalization, and [6] tried to explain deep learning from the view of functional approximation. In order to address this very crucial question, here we see deep learning from perspective of mechanical learning and learning machine (see [1], [2]). From this particular angle, we can see deep learning much better and answer with confidence: What deep learning is really doing? why it works well, how it works, and how much data is necessary for learning. We also will discuss advantages and disadvantages of deep learning at the end of this work.","Mon, 6 Nov 2017 23:00:13 UTC (44 KB)"
"1151","DLPaper2Code: Auto-generation of Code from Deep Learning Research Papers","Akshay Sethi, Anush Sankaran, Naveen Panwar, Shreya Khare, Senthil Mani","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","With an abundance of research papers in deep learning, reproducibility or adoption of the existing works becomes a challenge. This is due to the lack of open source implementations provided by the authors. Further, re-implementing research papers in a different library is a daunting task. To address these challenges, we propose a novel extensible approach, DLPaper2Code, to extract and understand deep learning design flow diagrams and tables available in a research paper and convert them to an abstract computational graph. The extracted computational graph is then converted into execution ready source code in both Keras and Caffe, in real-time. An arXiv-like website is created where the automatically generated designs is made publicly available for 5,000 research papers. The generated designs could be rated and edited using an intuitive drag-and-drop UI framework in a crowdsourced manner. To evaluate our approach, we create a simulated dataset with over 216,000 valid design visualizations using a manually defined grammar. Experiments on the simulated dataset show that the proposed framework provide more than $93\%$ accuracy in flow diagram content extraction.","Thu, 9 Nov 2017 10:00:19 UTC (1,715 KB)"
"1152","Performance Evaluation of Deep Learning Tools in Docker Containers","Pengfei Xu, Shaohuai Shi, Xiaowen Chu","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Performance (cs.PF)","With the success of deep learning techniques in a broad range of application domains, many deep learning software frameworks have been developed and are being updated frequently to adapt to new hardware features and software libraries, which bring a big challenge for end users and system administrators. To address this problem, container techniques are widely used to simplify the deployment and management of deep learning software. However, it remains unknown whether container techniques bring any performance penalty to deep learning applications. The purpose of this work is to systematically evaluate the impact of docker container on the performance of deep learning applications. We first benchmark the performance of system components (IO, CPU and GPU) in a docker container and the host system and compare the results to see if there's any difference. According to our results, we find that computational intensive jobs, either running on CPU or GPU, have small overhead indicating docker containers can be applied to deep learning programs. Then we evaluate the performance of some popular deep learning tools deployed in a docker container and the host system. It turns out that the docker container will not cause noticeable drawbacks while running those deep learning tools. So encapsulating deep learning tool in a container is a feasible solution.","Thu, 9 Nov 2017 14:28:12 UTC (585 KB)"
"1153","A Separation Principle for Control in the Age of Deep Learning","Alessandro Achille, Stefano Soatto","Machine Learning (stat.ML); Machine Learning (cs.LG)","We review the problem of defining and inferring a ""state"" for a control system based on complex, high-dimensional, highly uncertain measurement streams such as videos. Such a state, or representation, should contain all and only the information needed for control, and discount nuisance variability in the data. It should also have finite complexity, ideally modulated depending on available resources. This representation is what we want to store in memory in lieu of the data, as it ""separates"" the control task from the measurement process. For the trivial case with no dynamics, a representation can be inferred by minimizing the Information Bottleneck Lagrangian in a function class realized by deep neural networks. The resulting representation has much higher dimension than the data, already in the millions, but it is smaller in the sense of information content, retaining only what is needed for the task. This process also yields representations that are invariant to nuisance factors and having maximally independent components. We extend these ideas to the dynamic case, where the representation is the posterior density of the task variable given the measurements up to the current time, which is in general much simpler than the prediction density maintained by the classical Bayesian filter. Again this can be finitely-parametrized using a deep neural network, and already some applications are beginning to emerge. No explicit assumption of Markovianity is needed; instead, complexity trades off approximation of an optimal representation, including the degree of Markovianity.","Thu, 9 Nov 2017 11:10:24 UTC (37 KB)"
"1154","Multi-stage Suture Detection for Robot Assisted Anastomosis based on Deep Learning","Yang Hu, Yun Gu, Jie Yang, Guang-Zhong Yang","Computer Vision and Pattern Recognition (cs.CV)","In robotic surgery, task automation and learning from demonstration combined with human supervision is an emerging trend for many new surgical robot platforms. One such task is automated anastomosis, which requires bimanual needle handling and suture detection. Due to the complexity of the surgical environment and varying patient anatomies, reliable suture detection is difficult, which is further complicated by occlusion and thread topologies. In this paper, we propose a multi-stage framework for suture thread detection based on deep learning. Fully convolutional neural networks are used to obtain the initial detection and the overlapping status of suture thread, which are later fused with the original image to learn a gradient road map of the thread. Based on the gradient road map, multiple segments of the thread are extracted and linked to form the whole thread using a curvilinear structure detector. Experiments on two different types of sutures demonstrate the accuracy of the proposed framework.","Wed, 8 Nov 2017 21:44:14 UTC (874 KB)"
"1155","Shallow Transits - Deep Learning I: Feasibility Study of Deep Learning to Detect Periodic Transits of Exoplanets","Shay Zucker, Raja Giryes (Tel Aviv University, Tel Aviv, Israel)","Instrumentation and Methods for Astrophysics (astro-ph.IM)","Transits of habitable planets around solar-like stars are expected to be shallow, and to have long periods, which means low information content. The current bottleneck in the detection of such transits is caused in large part by the presence of red (correlated) noise in the light curves obtained from the dedicated space telescopes. Based on the groundbreaking results deep learning achieves in many signal and image processing applications, we propose to use deep neural networks to solve this problem. We present a feasibility study, in which we applied a convolutional neural network on a simulated training set. The training set comprised light curves received from a hypothetical high-cadence space-based telescope. We simulated the red noise by using Gaussian Processes with a wide variety of hyperparameters. We then tested the network on a completely different test set simulated in the same way. Our study proves that very difficult cases can indeed be detected. Furthermore, we show how detection trends can be studied, and detection biases be quantified. We have also checked the robustness of the neural-network performance against practical artifacts such as outliers and discontinuities, which are known to affect space-based high-cadence light curves. Future work will allow us to use the neural networks to characterize the transit model and identify individual transits. This new approach will certainly be an indispensable tool for the detection of habitable planets in the future planet-detection space missions such as PLATO.","Wed, 8 Nov 2017 21:00:11 UTC (422 KB)[v2] Wed, 7 Feb 2018 12:55:31 UTC (518 KB)"
"1156","Deep Learning for Real-time Gravitational Wave Detection and Parameter Estimation: Results with Advanced LIGO Data","Daniel George, E. A. Huerta","General Relativity and Quantum Cosmology (gr-qc); High Energy Astrophysical Phenomena (astro-ph.HE); Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","The recent Nobel-prize-winning detections of gravitational waves from merging black holes and the subsequent detection of the collision of two neutron stars in coincidence with electromagnetic observations have inaugurated a new era of multimessenger astrophysics. To enhance the scope of this emergent field of science, we pioneered the use of deep learning with convolutional neural networks, that take time-series inputs, for rapid detection and characterization of gravitational wave signals. This approach, Deep Filtering, was initially demonstrated using simulated LIGO noise. In this article, we present the extension of Deep Filtering using real data from LIGO, for both detection and parameter estimation of gravitational waves from binary black hole mergers using continuous data streams from multiple LIGO detectors. We demonstrate for the first time that machine learning can detect and estimate the true parameters of real events observed by LIGO. Our results show that Deep Filtering achieves similar sensitivities and lower errors compared to matched-filtering while being far more computationally efficient and more resilient to glitches, allowing real-time processing of weak time-series signals in non-stationary non-Gaussian noise with minimal resources, and also enables the detection of new classes of gravitational wave sources that may go unnoticed with existing detection algorithms. This unified framework for data analysis is ideally suited to enable coincident detection campaigns of gravitational waves and their multimessenger counterparts in real-time.","Wed, 8 Nov 2017 19:05:28 UTC (2,370 KB)"
"1157","Deep learning for galaxy surface brightness profile fitting","D. Tuccillo, M. Huertas-Company, E. Decenciere, S. Velasco-Forero, H. Dominguez Sanchez, P. Dimauro","Astrophysics of Galaxies (astro-ph.GA)","Numerous ongoing and future large area surveys (e.g. DES, EUCLID, LSST, WFIRST), will increase by several orders of magnitude the volume of data that can be exploited for galaxy morphology studies. The full potential of these surveys can only be unlocked with the development of automated, fast and reliable analysis methods. In this paper we present DeepLeGATo, a new method for two-dimensional photometric galaxy profile modeling, based on convolutional neural networks. Our code is trained and validated on analytic profiles (HST/CANDELS F160W filter) and it is able to retrieve the full set of parameters of one- component Sersic models: total magnitude, effective radius, Sersic index, axis ratio. We show detailed comparisons between our code and GALFIT. On simulated data, our method is more accurate than GALFIT and 3000 time faster on GPU (50 times when run on the same CPU). On real data, DeepLeGATo trained on simulations behaves similarly to GALFIT on isolated galaxies. With a fast domain adaptation step made with the 0.1 - 0.8 per cent the size of the training set, our code is easily capable to reproduce the results obtained with GALFIT even on crowded regions. DeepLeGATo does not require any human intervention beyond the training step, rendering it much automated than traditional profiling methods. The development of this method for more complex models (two-component galaxies, variable PSF, dense sky regions) could constitute a fundamental tool in the era of big data in astronomy.","Wed, 8 Nov 2017 19:00:04 UTC (5,623 KB)[v2] Wed, 20 Dec 2017 14:14:37 UTC (8,334 KB)"
"1158","DLVM: A modern compiler infrastructure for deep learning systems","Richard Wei, Lane Schwartz, Vikram Adve","Programming Languages (cs.PL); Machine Learning (cs.LG); Mathematical Software (cs.MS)","Deep learning software demands reliability and performance. However, many of the existing deep learning frameworks are software libraries that act as an unsafe DSL in Python and a computation graph interpreter. We present DLVM, a design and implementation of a compiler infrastructure with a linear algebra intermediate representation, algorithmic differentiation by adjoint code generation, domain-specific optimizations and a code generator targeting GPU via LLVM. Designed as a modern compiler infrastructure inspired by LLVM, DLVM is more modular and more generic than existing deep learning compiler frameworks, and supports tensor DSLs with high expressivity. With our prototypical staged DSL embedded in Swift, we argue that the DLVM system enables a form of modular, safe and performant frameworks for deep learning.","Wed, 8 Nov 2017 15:33:23 UTC (23 KB)[v2] Thu, 9 Nov 2017 14:47:33 UTC (23 KB)[v3] Wed, 6 Dec 2017 01:55:59 UTC (20 KB)[v4] Mon, 11 Dec 2017 21:49:48 UTC (21 KB)[v5] Fri, 2 Feb 2018 21:07:25 UTC (27 KB)"
"1159","Optimal Auction For Edge Computing Resource Management in Mobile Blockchain Networks: A Deep Learning Approach","Nguyen Cong Luong, Zehui Xiong, Ping Wang, Dusit Niyato","Computer Science and Game Theory (cs.GT)","Blockchain has recently been applied in many applications such as bitcoin, smart grid, and Internet of Things (IoT) as a public ledger of transactions. However, the use of blockchain in mobile environments is still limited because the mining process consumes too much computing and energy resources on mobile devices. Edge computing offered by the Edge Computing Service Provider can be adopted as a viable solution for offloading the mining tasks from the mobile devices, i.e., miners, in the mobile blockchain environment. However, a mechanism needs to be designed for edge resource allocation to maximize the revenue for the Edge Computing Service Provider and to ensure incentive compatibility and individual rationality is still open. In this paper, we develop an optimal auction based on deep learning for the edge resource allocation. Specifically, we construct a multi-layer neural network architecture based on an analytical solution of the optimal auction. The neural networks first perform monotone transformations of the miners' bids. Then, they calculate allocation and conditional payment rules for the miners. We use valuations of the miners as the data training to adjust parameters of the neural networks so as to optimize the loss function which is the expected, negated revenue of the Edge Computing Service Provider. We show the experimental results to confirm the benefits of using the deep learning for deriving the optimal auction for mobile blockchain with high revenue","Wed, 8 Nov 2017 06:11:07 UTC (6,103 KB)[v2] Fri, 17 Nov 2017 03:09:47 UTC (6,918 KB)"
"1160","Revealing structure components of the retina by deep learning networks","Qi Yan, Zhaofei Yu, Feng Chen, Jian K. Liu","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)","Deep convolutional neural networks (CNNs) have demonstrated impressive performance on visual object classification tasks. In addition, it is a useful model for predication of neuronal responses recorded in visual system. However, there is still no clear understanding of what CNNs learn in terms of visual neuronal circuits. Visualizing CNN's features to obtain possible connections to neuronscience underpinnings is not easy due to highly complex circuits from the retina to higher visual cortex. Here we address this issue by focusing on single retinal ganglion cells with a simple model and electrophysiological recordings from salamanders. By training CNNs with white noise images to predicate neural responses, we found that convolutional filters learned in the end are resembling to biological components of the retinal circuit. Features represented by these filters tile the space of conventional receptive field of retinal ganglion cells. These results suggest that CNN could be used to reveal structure components of neuronal circuits.","Wed, 8 Nov 2017 05:35:27 UTC (2,378 KB)"
"1161","Traffic Prediction Based on Random Connectivity in Deep Learning with Long Short-Term Memory","Yuxiu Hua, Zhifeng Zhao, Rongpeng Li, Xianfu Chen, Zhiming Liu, Honggang Zhang","Networking and Internet Architecture (cs.NI); Neural and Evolutionary Computing (cs.NE)","Traffic prediction plays an important role in evaluating the performance of telecommunication networks and attracts intense research interests. A significant number of algorithms and models have been put forward to analyse traffic data and make prediction. In the recent big data era, deep learning has been exploited to mine the profound information hidden in the data. In particular, Long Short-Term Memory (LSTM), one kind of Recurrent Neural Network (RNN) schemes, has attracted a lot of attentions due to its capability of processing the long-range dependency embedded in the sequential traffic data. However, LSTM has considerable computational cost, which can not be tolerated in tasks with stringent latency requirement. In this paper, we propose a deep learning model based on LSTM, called Random Connectivity LSTM (RCLSTM). Compared to the conventional LSTM, RCLSTM makes a notable breakthrough in the formation of neural network, which is that the neurons are connected in a stochastic manner rather than full connected. So, the RCLSTM, with certain intrinsic sparsity, have many neural connections absent (distinguished from the full connectivity) and which leads to the reduction of the parameters to be trained and the computational cost. We apply the RCLSTM to predict traffic and validate that the RCLSTM with even 35% neural connectivity still shows a satisfactory performance. When we gradually add training samples, the performance of RCLSTM becomes increasingly closer to the baseline LSTM. Moreover, for the input traffic sequences of enough length, the RCLSTM exhibits even superior prediction accuracy than the baseline LSTM.","Wed, 8 Nov 2017 05:11:37 UTC (511 KB)[v2] Tue, 3 Apr 2018 04:47:10 UTC (690 KB)"
"1162","Sequential Keystroke Behavioral Biometrics for Mobile User Identification via Multi-view Deep Learning","Lichao Sun, Yuqi Wang, Bokai Cao, Philip S. Yu, Witawas Srisa-an, Alex D Leow","Cryptography and Security (cs.CR)","With the rapid growth in smartphone usage, more organizations begin to focus on providing better services for mobile users. User identification can help these organizations to identify their customers and then cater services that have been customized for them. Currently, the use of cookies is the most common form to identify users. However, cookies are not easily transportable (e.g., when a user uses a different login account, cookies do not follow the user). This limitation motivates the need to use behavior biometric for user identification. In this paper, we propose DEEPSERVICE, a new technique that can identify mobile users based on user's keystroke information captured by a special keyboard or web browser. Our evaluation results indicate that DEEPSERVICE is highly accurate in identifying mobile users (over 93% accuracy). The technique is also efficient and only takes less than 1 ms to perform identification.","Tue, 7 Nov 2017 19:57:33 UTC (391 KB)[v2] Tue, 14 Nov 2017 20:38:34 UTC (391 KB)"
"1163","Deep Learning and Model Predictive Control for Self-Tuning Mode-Locked Lasers","Thomas Baumeister, Steven L. Brunton, J. Nathan Kutz","Machine Learning (cs.LG); Pattern Formation and Solitons (nlin.PS)","Self-tuning optical systems are of growing importance in technological applications such as mode-locked fiber lasers. Such self-tuning paradigms require {\em intelligent} algorithms capable of inferring approximate models of the underlying physics and discovering appropriate control laws in order to maintain robust performance for a given objective. In this work, we demonstrate the first integration of a {\em deep learning} (DL) architecture with {\em model predictive control} (MPC) in order to self-tune a mode-locked fiber laser. Not only can our DL-MPC algorithmic architecture approximate the unknown fiber birefringence, it also builds a dynamical model of the laser and appropriate control law for maintaining robust, high-energy pulses despite a stochastically drifting birefringence. We demonstrate the effectiveness of this method on a fiber laser which is mode-locked by nonlinear polarization rotation. The method advocated can be broadly applied to a variety of optical systems that require robust controllers.","Thu, 2 Nov 2017 20:25:40 UTC (2,227 KB)"
"1164","An Unsupervised Deep Learning Approach for Scenario Forecasts","Yize Chen, Xiyu Wang, Baosen Zhang","Optimization and Control (math.OC)","In this paper, we propose a novel scenario forecasts approach which can be applied to a broad range of power system operations (e.g., wind, solar, load) over various forecasts horizons and prediction intervals. This approach is model-free and data-driven, producing a set of scenarios that represent possible future behaviors based only on historical observations and point forecasts. It first applies a newly-developed unsupervised deep learning framework, the generative adversarial networks, to learn the intrinsic patterns in historical renewable generation data. Then by solving an optimization problem, we are able to quickly generate large number of realistic future scenarios. The proposed method has been applied to a wind power generation and forecasting dataset from national renewable energy laboratory. Simulation results indicate our method is able to generate scenarios that capture spatial and temporal correlations. Our code and simulation datasets are freely available online.","Tue, 7 Nov 2017 01:25:19 UTC (3,185 KB)[v2] Mon, 19 Mar 2018 20:46:03 UTC (3,027 KB)"
"1165","Distributed Representation for Traditional Chinese Medicine Herb via Deep Learning Models","Wei Li, Zheng Yang","Computation and Language (cs.CL)","Traditional Chinese Medicine (TCM) has accumulated a big amount of precious resource in the long history of development. TCM prescriptions that consist of TCM herbs are an important form of TCM treatment, which are similar to natural language documents, but in a weakly ordered fashion. Directly adapting language modeling style methods to learn the embeddings of the herbs can be problematic as the herbs are not strictly in order, the herbs in the front of the prescription can be connected to the very last ones. In this paper, we propose to represent TCM herbs with distributed representations via Prescription Level Language Modeling (PLLM). In one of our experiments, the correlation between our calculated similarity between medicines and the judgment of professionals achieves a Spearman score of 55.35 indicating a strong correlation, which surpasses human beginners (TCM related field bachelor student) by a big margin (over 10%).","Mon, 6 Nov 2017 03:05:05 UTC (33 KB)"
"1166","The Case for Meta-Cognitive Machine Learning: On Model Entropy and Concept Formation in Deep Learning","Johan Loeckx","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","Machine learning is usually defined in behaviourist terms, where external validation is the primary mechanism of learning. In this paper, I argue for a more holistic interpretation in which finding more probable, efficient and abstract representations is as central to learning as performance. In other words, machine learning should be extended with strategies to reason over its own learning process, leading to so-called meta-cognitive machine learning. As such, the de facto definition of machine learning should be reformulated in these intrinsically multi-objective terms, taking into account not only the task performance but also internal learning objectives. To this end, we suggest a ""model entropy function"" to be defined that quantifies the efficiency of the internal learning processes. It is conjured that the minimization of this model entropy leads to concept formation. Besides philosophical aspects, some initial illustrations are included to support the claims.","Sat, 4 Nov 2017 12:54:35 UTC (214 KB)"
"1167","Predicting Discharge Medications at Admission Time Based on Deep Learning","Yuan Yang, Pengtao Xie, Xin Gao, Carol Cheng, Christy Li, Hongbao Zhang, Eric Xing","Computation and Language (cs.CL)","Predicting discharge medications right after a patient being admitted is an important clinical decision, which provides physicians with guidance on what type of medication regimen to plan for and what possible changes on initial medication may occur during an inpatient stay. It also facilitates medication reconciliation process with easy detection of medication discrepancy at discharge time to improve patient safety. However, since the information available upon admission is limited and patients' condition may evolve during an inpatient stay, these predictions could be a difficult decision for physicians to make. In this work, we investigate how to leverage deep learning technologies to assist physicians in predicting discharge medications based on information documented in the admission note. We build a convolutional neural network which takes an admission note as input and predicts the medications placed on the patient at discharge time. Our method is able to distill semantic patterns from unstructured and noisy texts, and is capable of capturing the pharmacological correlations among medications. We evaluate our method on 25K patient visits and compare with 4 strong baselines. Our methods demonstrate a 20% increase in macro-averaged F1 score than the best baseline.","Sat, 4 Nov 2017 03:04:40 UTC (1,082 KB)[v2] Sat, 25 Nov 2017 19:33:22 UTC (1,082 KB)[v3] Tue, 5 Dec 2017 17:13:56 UTC (1,082 KB)"
"1168","Deep Learning-Based Dynamic Watermarking for Secure Signal Authentication in the Internet of Things","Aidin Ferdowsi, Walid Saad","Information Theory (cs.IT); Cryptography and Security (cs.CR); Multimedia (cs.MM)","Securing the Internet of Things (IoT) is a necessary milestone toward expediting the deployment of its applications and services. In particular, the functionality of the IoT devices is extremely dependent on the reliability of their message transmission. Cyber attacks such as data injection, eavesdropping, and man-in-the-middle threats can lead to security challenges. Securing IoT devices against such attacks requires accounting for their stringent computational power and need for low-latency operations. In this paper, a novel deep learning method is proposed for dynamic watermarking of IoT signals to detect cyber attacks. The proposed learning framework, based on a long short-term memory (LSTM) structure, enables the IoT devices to extract a set of stochastic features from their generated signal and dynamically watermark these features into the signal. This method enables the IoT's cloud center, which collects signals from the IoT devices, to effectively authenticate the reliability of the signals. Furthermore, the proposed method prevents complicated attack scenarios such as eavesdropping in which the cyber attacker collects the data from the IoT devices and aims to break the watermarking algorithm. Simulation results show that, with an attack detection delay of under 1 second the messages can be transmitted from IoT devices with an almost 100% reliability.","Fri, 3 Nov 2017 19:12:23 UTC (1,742 KB)"
"1169","In-Bed Pose Estimation: Deep Learning with Shallow Dataset","Shuangjun Liu, Yu Yin, Sarah Ostadabbas","Computer Vision and Pattern Recognition (cs.CV)","Although human pose estimation for various computer vision (CV) applications has been studied extensively in the last few decades, yet in-bed pose estimation using camera-based vision methods has been ignored by the CV community because it is assumed to be identical to the general purpose pose estimation methods. However, in-bed pose estimation has its own specialized aspects and comes with specific challenges including the notable differences in lighting conditions throughout a day and also having different pose distribution from the common human surveillance viewpoint. In this paper, we demonstrate that these challenges significantly lessen the effectiveness of existing general purpose pose estimation models. In order to address the lighting variation challenge, infrared selective (IRS) image acquisition technique is proposed to provide uniform quality data under various lighting conditions. In addition, to deal with unconventional pose perspective, a 2-end histogram of oriented gradient (HOG) rectification method is presented. In this work, we explored the idea of employing a pre-trained convolutional neural network (CNN) model trained on large public datasets of general human poses and fine-tuning the model using our own shallow in-bed IRS dataset. We developed an IRS imaging system and collected IRS image data from several realistic life-size mannequins in a simulated hospital room environment. A pre-trained CNN called convolutional pose machine (CPM) was repurposed for in-bed pose estimation by fine-tuning its specific intermediate layers. Using the HOG rectification method, the pose estimation performance of CPM significantly improved by 26.4% in PCK0.1 criteria compared to the model without such rectification.","Fri, 3 Nov 2017 03:05:05 UTC (2,054 KB)[v2] Tue, 3 Apr 2018 03:32:39 UTC (2,135 KB)[v3] Sat, 7 Jul 2018 20:37:06 UTC (2,135 KB)"
"1170","Using Deep Learning to Examine the Association between the Built Environment and Neighborhood Adult Obesity Prevalence","Adyasha Maharana, Elaine O. Nsoesie","Computers and Society (cs.CY)","More than one-third of the adult population in the United States is obese. Obesity has been linked to factors such as, genetics, diet, physical activity and the environment. However, evidence indicating associations between the built environment and obesity has varied across studies and geographical contexts. Here, we used deep learning and approximately 150,000 high resolution satellite images to extract features of the built environment. We then developed linear regression models to consistently quantify the association between the extracted features and obesity prevalence at the census tract level for six cities in the United States. The extracted features of the built environment explained 72% to 90% of the variation in obesity prevalence across cities. Outof-sample predictions were considerably high with correlations greater than 80% between predicted and true obesity prevalence across all census tracts. This study supports a strong association between the built environment and obesity prevalence. Additionally, it also illustrates that features of the built environment extracted from satellite images can be useful for studying health indicators, such as obesity. Understanding the association between specific features of the built environment and obesity prevalence can lead to structural changes that could encourage physical activity and decreases in obesity prevalence.","Thu, 2 Nov 2017 18:51:32 UTC (592 KB)"
"1171","Deep Learning the Effects of Photon Sensors on the Event Reconstruction Performance in an Antineutrino Detector","Chang-Wei Loh, Zhi-Qiang Qian, You-Hang Liu, De-Wen Cao, Rui Zhang, Wei Wang, Hai-Bo Yang, Ming Qi","Data Analysis, Statistics and Probability (physics.data-an); High Energy Physics - Experiment (hep-ex)","We provide a fast approach incorporating the usage of deep learning for evaluating the effects of photon sensors in an antineutrino detector on the event reconstruction performance therein. This work is an attempt to harness the power of deep learning for detector designing and upgrade planning. Using the Daya Bay detector as a benchmark case and the vertex reconstruction performance as the objective for the deep neural network, we find that the photomultiplier tubes (PMTs) have different relative importance to the vertex reconstruction. More importantly, the vertex position resolutions for the Daya Bay detector follow approximately a multi-exponential relationship with respect to the number of PMTs and hence, the coverage. This could also assist in deciding on the merits of installing additional PMTs for future detector plans. The approach could easily be used with other objectives in place of vertex reconstruction.","Thu, 2 Nov 2017 03:37:59 UTC (1,031 KB)[v2] Sun, 24 Dec 2017 07:35:54 UTC (1,023 KB)[v3] Thu, 5 Jul 2018 15:33:12 UTC (1,024 KB)"
"1172","Deep Learning from Noisy Image Labels with Quality Embedding","Jiangchao Yao, Jiajie Wang, Ivor Tsang, Ya Zhang, Jun Sun, Chengqi Zhang, Rui Zhang","Computer Vision and Pattern Recognition (cs.CV)","There is an emerging trend to leverage noisy image datasets in many visual recognition tasks. However, the label noise among the datasets severely degenerates the \mbox{performance of deep} learning approaches. Recently, one mainstream is to introduce the latent label to handle label noise, which has shown promising improvement in the network designs. Nevertheless, the mismatch between latent labels and noisy labels still affects the predictions in such methods. To address this issue, we propose a quality embedding model, which explicitly introduces a quality variable to represent the trustworthiness of noisy labels. Our key idea is to identify the mismatch between the latent and noisy labels by embedding the quality variables into different subspaces, which effectively minimizes the noise effect. At the same time, the high-quality labels is still able to be applied for training. To instantiate the model, we further propose a Contrastive-Additive Noise network (CAN), which consists of two important layers: (1) the contrastive layer estimates the quality variable in the embedding space to reduce noise effect; and (2) the additive layer aggregates the prior predictions and noisy labels as the posterior to train the classifier. Moreover, to tackle the optimization difficulty, we deduce an SGD algorithm with the reparameterization tricks, which makes our method scalable to big data. We conduct the experimental evaluation of the proposed method over a range of noisy image datasets. Comprehensive results have demonstrated CAN outperforms the state-of-the-art deep learning approaches.","Thu, 2 Nov 2017 01:19:25 UTC (2,216 KB)"
"1173","Active Clothing Material Perception using Tactile Sensing and Deep Learning","Wenzhen Yuan, Yuchen Mo, Shaoxiong Wang, Edward Adelson","Robotics (cs.RO)","Humans represent and discriminate the objects in the same category using their properties, and an intelligent robot should be able to do the same. In this paper, we build a robot system that can autonomously perceive the object properties through touch. We work on the common object category of clothing. The robot moves under the guidance of an external Kinect sensor, and squeezes the clothes with a GelSight tactile sensor, then it recognizes the 11 properties of the clothing according to the tactile data. Those properties include the physical properties, like thickness, fuzziness, softness and durability, and semantic properties, like wearing season and preferred washing methods. We collect a dataset of 153 varied pieces of clothes, and conduct 6616 robot exploring iterations on them. To extract the useful information from the high-dimensional sensory output, we applied Convolutional Neural Networks (CNN) on the tactile data for recognizing the clothing properties, and on the Kinect depth images for selecting exploration locations. Experiments show that using the trained neural networks, the robot can autonomously explore the unknown clothes and learn their properties. This work proposes a new framework for active tactile perception system with vision-touch system, and has potential to enable robots to help humans with varied clothing related housework.","Thu, 2 Nov 2017 00:23:23 UTC (9,064 KB)[v2] Sun, 25 Feb 2018 21:49:05 UTC (7,313 KB)"
"1174","A multitask deep learning model for real-time deployment in embedded systems","Miquel Marti, Atsuto Maki","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","We propose an approach to Multitask Learning (MTL) to make deep learning models faster and lighter for applications in which multiple tasks need to be solved simultaneously, which is particularly useful in embedded, real-time systems. We develop a multitask model for both Object Detection and Semantic Segmentation and analyze the challenges that appear during its training. Our multitask network is 1.6x faster, lighter and uses less memory than deploying the single-task models in parallel. We conclude that MTL has the potential to give superior performance in exchange of a more complex training process that introduces challenges not present in single-task models.","Tue, 31 Oct 2017 23:59:23 UTC (5,083 KB)"
"1175","Separation of Water and Fat Magnetic Resonance Imaging Signals Using Deep Learning with Convolutional Neural Networks","James W Goldfarb","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","Purpose: A new method for magnetic resonance (MR) imaging water-fat separation using a convolutional neural network (ConvNet) and deep learning (DL) is presented. Feasibility of the method with complex and magnitude images is demonstrated with a series of patient studies and accuracy of predicted quantitative values is analyzed. Methods: Water-fat separation of 1200 gradient-echo acquisitions from 90 imaging sessions (normal, acute and chronic myocardial infarction) was performed using a conventional model based method with modeling of R2* and off-resonance and a multi-peak fat spectrum. A U-Net convolutional neural network for calculation of water-only, fat-only, R2* and off-resonance images was trained with 900 gradient-echo Multiple and single-echo complex and magnitude input data algorithms were studied and compared to conventional extended echo modeling. Results: The U-Net ConvNet was easily trained and provided water-fat separation results visually comparable to conventional methods. Myocardial fat deposition in chronic myocardial infarction and intramyocardial hemorrhage in acute myocardial infarction were well visualized in the DL results. Predicted values for R2*, off-resonance, water and fat signal intensities were well correlated with conventional model based water fat separation (R2>=0.97, p<0.001). DL images had a 14% higher signal-to-noise ratio (p<0.001) when compared to the conventional method. Conclusion: Deep learning utilizing ConvNets is a feasible method for MR water-fat separationimaging with complex, magnitude and single echo image data. A trained U-Net can be efficiently used for MR water-fat separation, providing results comparable to conventional model based methods.","Fri, 27 Oct 2017 17:36:36 UTC (3,220 KB)"
"1176","Deep Learning as a Mixed Convex-Combinatorial Optimization Problem","Abram L. Friesen, Pedro Domingos","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)","As neural networks grow deeper and wider, learning networks with hard-threshold activations is becoming increasingly important, both for network quantization, which can drastically reduce time and energy requirements, and for creating large integrated systems of deep networks, which may have non-differentiable components and must avoid vanishing and exploding gradients for effective learning. However, since gradient descent is not applicable to hard-threshold functions, it is not clear how to learn networks of them in a principled way. We address this problem by observing that setting targets for hard-threshold hidden units in order to minimize loss is a discrete optimization problem, and can be solved as such. The discrete optimization goal is to find a set of targets such that each unit, including the output, has a linearly separable problem to solve. Given these targets, the network decomposes into individual perceptrons, which can then be learned with standard convex approaches. Based on this, we develop a recursive mini-batch algorithm for learning deep hard-threshold networks that includes the popular but poorly justified straight-through estimator as a special case. Empirically, we show that our algorithm improves classification accuracy in a number of settings, including for AlexNet and ResNet-18 on ImageNet, when compared to the straight-through estimator.","Tue, 31 Oct 2017 16:42:44 UTC (411 KB)[v2] Wed, 1 Nov 2017 17:58:16 UTC (411 KB)[v3] Mon, 16 Apr 2018 20:46:14 UTC (593 KB)"
"1177","DeepQuality: Mass Spectra Quality Assessment via Compressed Sensing and Deep Learning","Chunwei Ma","Quantitative Methods (q-bio.QM)","Motivation: Mass spectrometry-based proteomics is among the most commonly used methods for scrutinizing proteomic profiles in different organs for biological or medical researches. All the proteomic analyses including peptide/protein identification and quantification, differential expression analysis, biomarker discovery and so on are all based on the matching of mass spectra with peptide sequences, which is significantly influenced by the quality of the spectra, such as the peak numbers, noisy peaks, signal-to-noise ratios, etc. Hence, it is crucial to assess the quality of the spectra in order for filtering and/or post-processing after identification. The handcrafted features representing spectra quality, however, need human expertise to design and are difficult to optimize, and thus the existing assessing algorithms are still lacking in accuracy. Thus, there is a critical need for the robust and adaptive algorithm for mass spectra quality assessment. Results: We have developed a novel mass spectrum assessment software DeepQuality, based on the state-of-the-art compressed sensing and deep learning algorithms. We evaluated the algorithm on two publicly available tandem MS data sets, resulting in the AUC of 0.96 and 0.92, respectively, a significant improvement compared with the AUC of 0.85 and 0.91 of the existing method SpectrumQuality v2.0. Availability: Software available at this https URL","Tue, 31 Oct 2017 12:23:26 UTC (347 KB)"
"1178","ChainerMN: Scalable Distributed Deep Learning Framework","Takuya Akiba, Keisuke Fukuda, Shuji Suzuki","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","One of the keys for deep learning to have made a breakthrough in various fields was to utilize high computing powers centering around GPUs. Enabling the use of further computing abilities by distributed processing is essential not only to make the deep learning bigger and faster but also to tackle unsolved challenges. We present the design, implementation, and evaluation of ChainerMN, the distributed deep learning framework we have developed. We demonstrate that ChainerMN can scale the learning process of the ResNet-50 model to the ImageNet dataset up to 128 GPUs with the parallel efficiency of 90%.","Tue, 31 Oct 2017 07:13:29 UTC (172 KB)"
"1179","Resolution and Relevance Trade-offs in Deep Learning","Juyong Song, Matteo Marsili, Junghyo Jo","Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)","Deep learning has been successfully applied to various tasks, but its underlying mechanism remains unclear. Neural networks associate similar inputs in the visible layer to the same state of hidden variables in deep layers. The fraction of inputs that are associated to the same state is a natural measure of similarity and is simply related to the cost in bits required to represent these inputs. The degeneracy of states with the same information cost provides instead a natural measure of noise and is simply related the entropy of the frequency of states, that we call relevance. Representations with minimal noise, at a given level of similarity (resolution), are those that maximise the relevance. A signature of such efficient representations is that frequency distributions follow power laws. We show, in extensive numerical experiments, that deep neural networks extract a hierarchy of efficient representations from data, because they i) achieve low levels of noise (i.e. high relevance) and ii) exhibit power law distributions. We also find that the layer that is most efficient to reliably generate patterns of training data is the one for which relevance and resolution are traded at the same price, which implies that frequency distribution follows Zipf's law.","Tue, 31 Oct 2017 04:33:56 UTC (594 KB)[v2] Tue, 20 Mar 2018 01:23:24 UTC (1,113 KB)"
"1180","Deep Learning for Frame Error Probability Prediction in BICM-OFDM Systems","Vidit Saxena, Joakim Jalden, Mats Bengtsson, Hugo Tullberg","Signal Processing (eess.SP)","In the context of wireless communications, we propose a deep learning approach to learn the mapping from the instantaneous state of a frequency selective fading channel to the corresponding frame error probability (FEP) for an arbitrary set of transmission parameters. We propose an abstract model of a bit interleaved coded modulation (BICM) orthogonal frequency division multiplexing (OFDM) link chain and show that the maximum likelihood (ML) estimator of the model parameters estimates the true FEP distribution. Further, we exploit deep neural networks as a general purpose tool to implement our model and propose a training scheme for which, even while training with the binary frame error events (i.e., ACKs / NACKs), the network outputs converge to the FEP conditioned on the input channel state. We provide simulation results that demonstrate gains in the FEP prediction accuracy with our approach as compared to the traditional effective exponential SIR metric (EESM) approach for a range of channel code rates, and show that these gains can be exploited to increase the link throughput.","Mon, 30 Oct 2017 23:39:24 UTC (247 KB)"
"1181","Time-lagged autoencoders: Deep learning of slow collective variables for molecular kinetics","Christoph Wehmeyer, Frank Noe","Machine Learning (stat.ML); Machine Learning (cs.LG); Biological Physics (physics.bio-ph); Chemical Physics (physics.chem-ph)","Inspired by the success of deep learning techniques in the physical and chemical sciences, we apply a modification of an autoencoder type deep neural network to the task of dimension reduction of molecular dynamics data. We can show that our time-lagged autoencoder reliably finds low-dimensional embeddings for high-dimensional feature spaces which capture the slow dynamics of the underlying stochastic processes - beyond the capabilities of linear dimension reduction techniques.","Mon, 30 Oct 2017 21:06:11 UTC (1,456 KB)"
"1182","Deep Learning and Conditional Random Fields-based Depth Estimation and Topographical Reconstruction from Conventional Endoscopy","Faisal Mahmood, Nicholas J. Durr","Computer Vision and Pattern Recognition (cs.CV)","Colorectal cancer is the fourth leading cause of cancer deaths worldwide and the second leading cause in the United States. The risk of colorectal cancer can be mitigated by the identification and removal of premalignant lesions through optical colonoscopy. Unfortunately, conventional colonoscopy misses more than 20% of the polyps that should be removed, due in part to poor contrast of lesion topography. Imaging tissue topography during a colonoscopy is difficult because of the size constraints of the endoscope and the deforming mucosa. Most existing methods make geometric assumptions or incorporate a priori information, which limits accuracy and sensitivity. In this paper, we present a method that avoids these restrictions, using a joint deep convolutional neural network-conditional random field (CNN-CRF) framework. Estimated depth is used to reconstruct the topography of the surface of the colon from a single image. We train the unary and pairwise potential functions of a CRF in a CNN on synthetic data, generated by developing an endoscope camera model and rendering over 100,000 images of an anatomically-realistic colon. We validate our approach with real endoscopy images from a porcine colon, transferred to a synthetic-like domain, with ground truth from registered computed tomography measurements. The CNN-CRF approach estimates depths with a relative error of 0.152 for synthetic endoscopy images and 0.242 for real endoscopy images. We show that the estimated depth maps can be used for reconstructing the topography of the mucosa from conventional colonoscopy images. This approach can easily be integrated into existing endoscopy systems and provides a foundation for improving computer-aided detection algorithms for detection, segmentation and classification of lesions.","Mon, 30 Oct 2017 19:56:52 UTC (8,795 KB)[v2] Fri, 3 Nov 2017 13:34:27 UTC (7,690 KB)[v3] Mon, 27 Nov 2017 20:42:13 UTC (9,112 KB)"
"1183","How deep learning works --The geometry of deep learning","Xiao Dong, Jiasong Wu, Ling Zhou","Machine Learning (cs.LG); Machine Learning (stat.ML)","Why and how that deep learning works well on different tasks remains a mystery from a theoretical perspective. In this paper we draw a geometric picture of the deep learning system by finding its analogies with two existing geometric structures, the geometry of quantum computations and the geometry of the diffeomorphic template matching. In this framework, we give the geometric structures of different deep learning systems including convolutional neural networks, residual networks, recursive neural networks, recurrent neural networks and the equilibrium prapagation framework. We can also analysis the relationship between the geometrical structures and their performance of different networks in an algorithmic level so that the geometric framework may guide the design of the structures and algorithms of deep learning systems.","Mon, 30 Oct 2017 06:42:23 UTC (2,757 KB)"
"1184","On Pre-Trained Image Features and Synthetic Images for Deep Learning","Stefan Hinterstoisser, Vincent Lepetit, Paul Wohlhart, Kurt Konolige","Computer Vision and Pattern Recognition (cs.CV)","Deep Learning methods usually require huge amounts of training data to perform at their full potential, and often require expensive manual labeling. Using synthetic images is therefore very attractive to train object detectors, as the labeling comes for free, and several approaches have been proposed to combine synthetic and real images for training. In this paper, we show that a simple trick is sufficient to train very effectively modern object detectors with synthetic images only: We freeze the layers responsible for feature extraction to generic layers pre-trained on real images, and train only the remaining layers with plain OpenGL rendering. Our experiments with very recent deep architectures for object recognition (Faster-RCNN, R-FCN, Mask-RCNN) and image feature extractors (InceptionResnet and Resnet) show this simple approach performs surprisingly well.","Sun, 29 Oct 2017 22:48:58 UTC (3,927 KB)[v2] Thu, 16 Nov 2017 21:46:24 UTC (4,245 KB)"
"1185","Regularization for Deep Learning: A Taxonomy","Jan Kuka<U+010D>ka, Vladimir Golkov, Daniel Cremers","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","Regularization is one of the crucial ingredients of deep learning, yet the term regularization has various definitions, and regularization methods are often studied separately from each other. In our work we present a systematic, unifying taxonomy to categorize existing methods. We distinguish methods that affect data, network architectures, error terms, regularization terms, and optimization procedures. We do not provide all details about the listed methods; instead, we present an overview of how the methods can be sorted into meaningful categories and sub-categories. This helps revealing links and fundamental similarities between them. Finally, we include practical recommendations both for users and for developers of new regularization methods.","Sun, 29 Oct 2017 20:27:51 UTC (92 KB)"
"1186","Automatic Knee Osteoarthritis Diagnosis from Plain Radiographs: A Deep Learning-Based Approach","Aleksei Tiulpin, Jerome Thevenot, Esa Rahtu, Petri Lehenkari, Simo Saarakkala","Computer Vision and Pattern Recognition (cs.CV)","Knee osteoarthritis (OA) is the most common musculoskeletal disorder. OA diagnosis is currently conducted by assessing symptoms and evaluating plain radiographs, but this process suffers from subjectivity. In this study, we present a new transparent computer-aided diagnosis method based on the Deep Siamese Convolutional Neural Network to automatically score knee OA severity according to the Kellgren-Lawrence grading scale. We trained our method using the data solely from the Multicenter Osteoarthritis Study and validated it on randomly selected 3,000 subjects (5,960 knees) from Osteoarthritis Initiative dataset. Our method yielded a quadratic Kappa coefficient of 0.83 and average multiclass accuracy of 66.71\% compared to the annotations given by a committee of clinical experts. Here, we also report a radiological OA diagnosis area under the ROC curve of 0.93. We also present attention maps -- given as a class probability distribution -- highlighting the radiological features affecting the network decision. This information makes the decision process transparent for the practitioner, which builds better trust toward automatic methods. We believe that our model is useful for clinical decision making and for OA research; therefore, we openly release our training codes and the data set created in this study.","Sun, 29 Oct 2017 10:11:14 UTC (3,322 KB)"
"1187","Topic Based Sentiment Analysis Using Deep Learning","Sharath T. S., Shubhangi Tandon","Computation and Language (cs.CL); Information Retrieval (cs.IR)","In this paper , we tackle Sentiment Analysis conditioned on a Topic in Twitter data using Deep Learning . We propose a 2-tier approach : In the first phase we create our own Word Embeddings and see that they do perform better than state-of-the-art embeddings when used with standard classifiers. We then perform inference on these embeddings to learn more about a word with respect to all the topics being considered, and also the top n-influencing words for each topic. In the second phase we use these embeddings to predict the sentiment of the tweet with respect to a given topic, and all other topics under discussion.","Sat, 28 Oct 2017 17:13:49 UTC (867 KB)"
"1188","Deep Learning for Accelerated Ultrasound Imaging","Yeo Hun Yoon, Jong Chul Ye","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","In portable, 3-D, or ultra-fast ultrasound (US) imaging systems, there is an increasing demand to reconstruct high quality images from limited number of data. However, the existing solutions require either hardware changes or computationally expansive algorithms. To overcome these limitations, here we propose a novel deep learning approach that interpolates the missing RF data by utilizing the sparsity of the RF data in the Fourier domain. Extensive experimental results from sub-sampled RF data from a real US system confirmed that the proposed method can effectively reduce the data rate without sacrificing the image quality.","Fri, 27 Oct 2017 06:49:37 UTC (1,305 KB)"
"1189","Improving Deep Learning by Inverse Square Root Linear Units (ISRLUs)","Brad Carlile, Guy Delamarter, Paul Kinney, Akiko Marti, Brian Whitney","Machine Learning (cs.LG)","We introduce the ""inverse square root linear unit"" (ISRLU) to speed up learning in deep neural networks. ISRLU has better performance than ELU but has many of the same benefits. ISRLU and ELU have similar curves and characteristics. Both have negative values, allowing them to push mean unit activation closer to zero, and bring the normal gradient closer to the unit natural gradient, ensuring a noise-robust deactivation state, lessening the over fitting risk. The significant performance advantage of ISRLU on traditional CPUs also carry over to more efficient HW implementations on HW/SW codesign for CNNs/RNNs. In experiments with TensorFlow, ISRLU leads to faster learning and better generalization than ReLU on CNNs. This work also suggests a computationally efficient variant called the ""inverse square root unit"" (ISRU) which can be used for RNNs. Many RNNs use either long short-term memory (LSTM) and gated recurrent units (GRU) which are implemented with tanh and sigmoid activation functions. ISRU has less com- putational complexity but still has a similar curve to tanh and sigmoid.","Fri, 27 Oct 2017 02:01:28 UTC (33 KB)[v2] Thu, 9 Nov 2017 21:59:39 UTC (33 KB)"
"1190","A Deep Learning Approach to the Citywide Traffic Accident Risk Prediction","Honglei Ren, You Song, Jingwen Wang, Yucheng Hu, Jinzhi Lei","Computers and Society (cs.CY)","With the rapid development of urbanization, the boom of vehicle numbers has resulted in serious traffic accidents, which led to casualties and huge economic losses. The ability to predict the risk of traffic accident is important in the prevention of the occurrence of accidents and to reduce the damages caused by accidents in a proactive way. However, traffic accident risk prediction with high spatiotemporal resolution is difficult, mainly due to the complex traffic environment, human behavior, and lack of real-time traffic-related data. In this study, we collected big traffic accident data. By analyzing the spatial and temporal patterns of traffic accident frequency, we presented the spatiotemporal correlation of traffic accidents. Based on the patterns we found in analysis, we proposed a high accurate deep learning model based on recurrent neural network toward the prediction of traffic accident risk. The predictive accident risk can be potential applied to the traffic accident warning system. The proposed method can be integrated into an intelligent traffic control system toward a more reasonable traffic prediction and command organization.","Thu, 26 Oct 2017 04:54:14 UTC (5,917 KB)[v2] Sun, 15 Apr 2018 15:21:37 UTC (4,268 KB)"
"1191","Maximum Principle Based Algorithms for Deep Learning","Qianxiao Li, Long Chen, Cheng Tai, Weinan E","Machine Learning (cs.LG); Machine Learning (stat.ML)","The continuous dynamical system approach to deep learning is explored in order to devise alternative frameworks for training algorithms. Training is recast as a control problem and this allows us to formulate necessary optimality conditions in continuous time using the Pontryagin's maximum principle (PMP). A modification of the method of successive approximations is then used to solve the PMP, giving rise to an alternative training algorithm for deep learning. This approach has the advantage that rigorous error estimates and convergence results can be established. We also show that it may avoid some pitfalls of gradient-based methods, such as slow convergence on flat landscapes near saddle points. Furthermore, we demonstrate that it obtains favorable initial convergence rate per-iteration, provided Hamiltonian maximization can be efficiently carried out - a step which is still in need of improvement. Overall, the approach opens up new avenues to attack problems associated with deep learning, such as trapping in slow manifolds and inapplicability of gradient-based methods for discrete trainable variables.","Thu, 26 Oct 2017 02:04:33 UTC (555 KB)[v2] Mon, 27 Nov 2017 01:17:39 UTC (629 KB)[v3] Thu, 8 Mar 2018 12:55:37 UTC (592 KB)[v4] Sat, 2 Jun 2018 08:50:02 UTC (587 KB)"
"1192","InterpNET: Neural Introspection for Interpretable Deep Learning","Shane Barratt","Machine Learning (stat.ML); Machine Learning (cs.LG)","Humans are able to explain their reasoning. On the contrary, deep neural networks are not. This paper attempts to bridge this gap by introducing a new way to design interpretable neural networks for classification, inspired by physiological evidence of the human visual system's inner-workings. This paper proposes a neural network design paradigm, termed InterpNET, which can be combined with any existing classification architecture to generate natural language explanations of the classifications. The success of the module relies on the assumption that the network's computation and reasoning is represented in its internal layer activations. While in principle InterpNET could be applied to any existing classification architecture, it is evaluated via an image classification and explanation task. Experiments on a CUB bird classification and explanation dataset show qualitatively and quantitatively that the model is able to generate high-quality explanations. While the current state-of-the-art METEOR score on this dataset is 29.2, InterpNET achieves a much higher METEOR score of 37.9.","Thu, 26 Oct 2017 02:01:12 UTC (4,511 KB)[v2] Thu, 16 Nov 2017 21:25:25 UTC (1,829 KB)"
"1193","Real-Time Automatic Fetal Brain Extraction in Fetal MRI by Deep Learning","Seyed Sadegh Mohseni Salehi, Seyed Raein Hashemi, Clemente Velasco-Annis, Abdelhakim Ouaalam, Judy A. Estroff, Deniz Erdogmus, Simon K. Warfield, Ali Gholipour","Computer Vision and Pattern Recognition (cs.CV)","Brain segmentation is a fundamental first step in neuroimage analysis. In the case of fetal MRI, it is particularly challenging and important due to the arbitrary orientation of the fetus, organs that surround the fetal head, and intermittent fetal motion. Several promising methods have been proposed but are limited in their performance in challenging cases and in real-time segmentation. We aimed to develop a fully automatic segmentation method that independently segments sections of the fetal brain in 2D fetal MRI slices in real-time. To this end, we developed and evaluated a deep fully convolutional neural network based on 2D U-net and autocontext, and compared it to two alternative fast methods based on 1) a voxelwise fully convolutional network and 2) a method based on SIFT features, random forest and conditional random field. We trained the networks with manual brain masks on 250 stacks of training images, and tested on 17 stacks of normal fetal brain images as well as 18 stacks of extremely challenging cases based on extreme motion, noise, and severely abnormal brain shape. Experimental results show that our U-net approach outperformed the other methods and achieved average Dice metrics of 96.52% and 78.83% in the normal and challenging test sets, respectively. With an unprecedented performance and a test run time of about 1 second, our network can be used to segment the fetal brain in real-time while fetal MRI slices are being acquired. This can enable real-time motion tracking, motion detection, and 3D reconstruction of fetal brain MRI.","Wed, 25 Oct 2017 16:54:44 UTC (6,683 KB)"
"1194","An Efficient Deep Learning Technique for the Navier-Stokes Equations: Application to Unsteady Wake Flow Dynamics","Tharindu P. Miyanawala, Rajeev K. Jaiman","Fluid Dynamics (physics.flu-dyn)","We present an efficient deep learning technique for the model reduction of the Navier-Stokes equations for unsteady flow problems. The proposed technique relies on the Convolutional Neural Network (CNN) and the stochastic gradient descent method. Of particular interest is to predict the unsteady fluid forces for different bluff body shapes at low Reynolds number. The discrete convolution process with a nonlinear rectification is employed to approximate the mapping between the bluff-body shape and the fluid forces. The deep neural network is fed by the Euclidean distance function as the input and the target data generated by the full-order Navier-Stokes computations for primitive bluff body shapes. The convolutional networks are iteratively trained using the stochastic gradient descent method with the momentum term to predict the fluid force coefficients of different geometries and the results are compared with the full-order computations. We attempt to provide a physical analogy of the stochastic gradient method with the momentum term with the simplified form of the incompressible Navier-Stokes momentum equation. We also construct a direct relationship between the CNN-based deep learning and the Mori-Zwanzig formalism for the model reduction of a fluid dynamical system. A systematic convergence and sensitivity study is performed to identify the effective dimensions of the deep-learned CNN process such as the convolution kernel size, the number of kernels and the convolution layers. Within the error threshold, the prediction based on our deep convolutional network has a speed-up nearly four orders of magnitude compared to the full-order results and consumes an insignificant fraction of computational resources. The proposed CNN-based approximation procedure has a profound impact on the parametric design of bluff bodies and the feedback control of separated flows.","Wed, 25 Oct 2017 07:50:02 UTC (5,257 KB)[v2] Sat, 11 Nov 2017 11:45:06 UTC (5,260 KB)[v3] Wed, 15 Aug 2018 15:34:32 UTC (3,265 KB)"
"1195","Interpretable Deep Learning applied to Plant Stress Phenotyping","Sambuddha Ghosal, David Blystone, Asheesh K. Singh, Baskar Ganapathysubramanian, Arti Singh, Soumik Sarkar","Machine Learning (stat.ML); Machine Learning (cs.LG)","Availability of an explainable deep learning model that can be applied to practical real world scenarios and in turn, can consistently, rapidly and accurately identify specific and minute traits in applicable fields of biological sciences, is scarce. Here we consider one such real world example viz., accurate identification, classification and quantification of biotic and abiotic stresses in crop research and production. Up until now, this has been predominantly done manually by visual inspection and require specialized training. However, such techniques are hindered by subjectivity resulting from inter- and intra-rater cognitive variability. Here, we demonstrate the ability of a machine learning framework to identify and classify a diverse set of foliar stresses in the soybean plant with remarkable accuracy. We also present an explanation mechanism using gradient-weighted class activation mapping that isolates the visual symptoms used by the model to make predictions. This unsupervised identification of unique visual symptoms for each stress provides a quantitative measure of stress severity, allowing for identification, classification and quantification in one framework. The learnt model appears to be agnostic to species and make good predictions for other (non-soybean) species, demonstrating an ability of transfer learning.","Tue, 24 Oct 2017 06:49:03 UTC (1,234 KB)[v2] Wed, 25 Oct 2017 21:33:19 UTC (1,239 KB)[v3] Sat, 28 Oct 2017 22:10:09 UTC (2,266 KB)"
"1196","Benchmark of Deep Learning Models on Large Healthcare MIMIC Datasets","Sanjay Purushotham, Chuizheng Meng, Zhengping Che, Yan Liu","Machine Learning (cs.LG); Computers and Society (cs.CY); Machine Learning (stat.ML)","Deep learning models (aka Deep Neural Networks) have revolutionized many fields including computer vision, natural language processing, speech recognition, and is being increasingly used in clinical healthcare applications. However, few works exist which have benchmarked the performance of the deep learning models with respect to the state-of-the-art machine learning models and prognostic scoring systems on publicly available healthcare datasets. In this paper, we present the benchmarking results for several clinical prediction tasks such as mortality prediction, length of stay prediction, and ICD-9 code group prediction using Deep Learning models, ensemble of machine learning models (Super Learner algorithm), SAPS II and SOFA scores. We used the Medical Information Mart for Intensive Care III (MIMIC-III) (v1.4) publicly available dataset, which includes all patients admitted to an ICU at the Beth Israel Deaconess Medical Center from 2001 to 2012, for the benchmarking tasks. Our results show that deep learning models consistently outperform all the other approaches especially when the `raw' clinical time series data is used as input features to the models.","Mon, 23 Oct 2017 22:23:34 UTC (500 KB)"
"1197","Serving deep learning models in a serverless platform","Vatche Ishakian, Vinod Muthusamy, Aleksander Slominski","Distributed, Parallel, and Cluster Computing (cs.DC)","Serverless computing has emerged as a compelling paradigm for the development and deployment of a wide range of event based cloud applications. At the same time, cloud providers and enterprise companies are heavily adopting machine learning and Artificial Intelligence to either differentiate themselves, or provide their customers with value added services. In this work we evaluate the suitability of a serverless computing environment for the inferencing of large neural network models. Our experimental evaluations are executed on the AWS Lambda environment using the MxNet deep learning framework. Our experimental results show that while the inferencing latency can be within an acceptable range, longer delays due to cold starts can skew the latency distribution and hence risk violating more stringent SLAs.","Mon, 23 Oct 2017 19:01:10 UTC (1,123 KB)[v2] Fri, 9 Feb 2018 21:41:18 UTC (473 KB)"
"1198","Silver Standard Masks for Data Augmentation Applied to Deep-Learning-Based Skull-Stripping","Oeslle Lucena, Roberto Souza, Leticia Rittner, Richard Frayne, Roberto Lotufo","Image and Video Processing (eess.IV)","The bottleneck of convolutional neural networks (CNN) for medical imaging is the number of annotated data required for training. Manual segmentation is considered to be the ""gold-standard"". However, medical imaging datasets with expert manual segmentation are scarce as this step is time-consuming and expensive. We propose in this work the use of what we refer to as silver standard masks for data augmentation in deep-learning-based skull-stripping also known as brain extraction. We generated the silver standard masks using the consensus algorithm Simultaneous Truth and Performance Level Estimation (STAPLE). We evaluated CNN models generated by the silver and gold standard masks. Then, we validated the silver standard masks for CNNs training in one dataset, and showed its generalization to two other datasets. Our results indicated that models generated with silver standard masks are comparable to models generated with gold standard masks and have better generalizability. Moreover, our results also indicate that silver standard masks could be used to augment the input dataset at training stage, reducing the need for manual segmentation at this step.","Mon, 23 Oct 2017 15:57:45 UTC (476 KB)"
"1199","Computational ghost imaging using deep learning","Tomoyoshi Shimobaba, Yutaka Endo, Takashi Nishitsuji, Takayuki Takahashi, Yuki Nagahama, Satoki Hasegawa, Marie Sano, Ryuji Hirayama, Takashi Kakue, Atsushi Shiraki, Tomoyoshi Ito","Computer Vision and Pattern Recognition (cs.CV); Optics (physics.optics)","Computational ghost imaging (CGI) is a single-pixel imaging technique that exploits the correlation between known random patterns and the measured intensity of light transmitted (or reflected) by an object. Although CGI can obtain two- or three- dimensional images with a single or a few bucket detectors, the quality of the reconstructed images is reduced by noise due to the reconstruction of images from random patterns. In this study, we improve the quality of CGI images using deep learning. A deep neural network is used to automatically learn the features of noise-contaminated CGI images. After training, the network is able to predict low-noise images from new noise-contaminated CGI images.","Thu, 19 Oct 2017 01:54:52 UTC (1,350 KB)"
"1200","Content Based Document Recommender using Deep Learning","Nishant Nikhil, Muktabh Mayank Srivastava","Computation and Language (cs.CL); Information Retrieval (cs.IR)","With the recent advancements in information technology there has been a huge surge in amount of data available. But information retrieval technology has not been able to keep up with this pace of information generation resulting in over spending of time for retrieving relevant information. Even though systems exist for assisting users to search a database along with filtering and recommending relevant information, but recommendation system which uses content of documents for recommendation still have a long way to mature. Here we present a Deep Learning based supervised approach to recommend similar documents based on the similarity of content. We combine the C-DSSM model with Word2Vec distributed representations of words to create a novel model to classify a document pair as relevant/irrelavant by assigning a score to it. Using our model retrieval of documents can be done in O(1) time and the memory complexity is O(n), where n is number of documents.","Mon, 23 Oct 2017 15:08:38 UTC (328 KB)"
"1201","Deep Learning applied to Road Traffic Speed forecasting","Thomas Epelbaum (IPHT), Fabrice Gamboa (IMT), Jean-Michel Loubes (IMT), Jessica Martin","Applications (stat.AP); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","In this paper, we propose deep learning architectures (FNN, CNN and LSTM) to forecast a regression model for time dependent data. These algorithm's are designed to handle Floating Car Data (FCD) historic speeds to predict road traffic data. For this we aggregate the speeds into the network inputs in an innovative way. We compare the RMSE thus obtained with the results of a simpler physical model, and show that the latter achieves better RMSE accuracy. We also propose a new indicator, which evaluates the algorithms improvement when compared to a benchmark prediction. We conclude by questioning the interest of using deep learning methods for this specific regression task.","Mon, 2 Oct 2017 14:27:38 UTC (978 KB)"
"1202","An efficient deep learning hashing neural network for mobile visual search","Heng Qi, Wu Liu, Liang Liu","Computer Vision and Pattern Recognition (cs.CV)","Mobile visual search applications are emerging that enable users to sense their surroundings with smart phones. However, because of the particular challenges of mobile visual search, achieving a high recognition bitrate has becomes a consistent target of previous related works. In this paper, we propose a few-parameter, low-latency, and high-accuracy deep hashing approach for constructing binary hash codes for mobile visual search. First, we exploit the architecture of the MobileNet model, which significantly decreases the latency of deep feature extraction by reducing the number of model parameters while maintaining accuracy. Second, we add a hash-like layer into MobileNet to train the model on labeled mobile visual data. Evaluations show that the proposed system can exceed state-of-the-art accuracy performance in terms of the MAP. More importantly, the memory consumption is much less than that of other deep learning models. The proposed method requires only $13$ MB of memory for the neural network and achieves a MAP of $97.80\%$ on the mobile location recognition dataset used for testing.","Sat, 21 Oct 2017 04:37:23 UTC (615 KB)"
"1203","Deep Learning Based NLOS Identification with Commodity WLAN Devices","Jeong-Sik Choi, Woong-Hee Lee, Jae-Hyun Lee, Jong-Ho Lee, Seong-Cheol Kim","Networking and Internet Architecture (cs.NI)","Identifying line-of-sight (LOS) and non-LOS (NLOS) channel conditions can improve the performance of many wireless applications, such as signal strength-based localization algorithms. For this purpose, channel state information (CSI) obtained by commodity IEEE 802.11n devices can be used, because it contains information about channel impulse response (CIR). However, because of the limited sampling rate of the devices, a high-resolution CIR is not available, and it is difficult to detect the existence of an LOS path from a single CSI measurement, but it can be inferred from the variation pattern of CSI over time. To this end, we propose a recurrent neural network (RNN) model, which takes a series of CSI to identify the corresponding channel condition. We collect numerous measurement data under an indoor office environment, train the proposed RNN model, and compare the performance with those of existing schemes that use handcrafted features. The proposed method efficiently learns a non-linear relationship between input and output, and thus, yields high accuracy even for data obtained in a very short period.","Fri, 20 Oct 2017 08:28:21 UTC (1,393 KB)[v2] Fri, 8 Dec 2017 20:42:13 UTC (1,393 KB)"
"1204","Unified Backpropagation for Multi-Objective Deep Learning","Arash Shahriari","Machine Learning (cs.LG); Machine Learning (stat.ML)","A common practice in most of deep convolutional neural architectures is to employ fully-connected layers followed by Softmax activation to minimize cross-entropy loss for the sake of classification. Recent studies show that substitution or addition of the Softmax objective to the cost functions of support vector machines or linear discriminant analysis is highly beneficial to improve the classification performance in hybrid neural networks. We propose a novel paradigm to link the optimization of several hybrid objectives through unified backpropagation. This highly alleviates the burden of extensive boosting for independent objective functions or complex formulation of multiobjective gradients. Hybrid loss functions are linked by basic probability assignment from evidence theory. We conduct our experiments for a variety of scenarios and standard datasets to evaluate the advantage of our proposed unification approach to deliver consistent improvements into the classification performance of deep convolutional neural networks.","Fri, 20 Oct 2017 07:31:12 UTC (2,221 KB)"
"1205","Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning","Stefan Depeweg, Jose Miguel Hernandez-Lobato, Finale Doshi-Velez, Steffen Udluft","Machine Learning (stat.ML); Machine Learning (cs.LG)","Bayesian neural networks with latent variables are scalable and flexible probabilistic models: They account for uncertainty in the estimation of the network weights and, by making use of latent variables, can capture complex noise patterns in the data. We show how to extract and decompose uncertainty into epistemic and aleatoric components for decision-making purposes. This allows us to successfully identify informative points for active learning of functions with heteroscedastic and bimodal noise. Using the decomposition we further define a novel risk-sensitive criterion for reinforcement learning to identify policies that balance expected cost, model-bias and noise aversion.","Thu, 19 Oct 2017 16:21:10 UTC (4,501 KB)[v2] Sat, 11 Nov 2017 19:09:45 UTC (4,501 KB)[v3] Thu, 22 Feb 2018 00:13:06 UTC (6,067 KB)[v4] Fri, 15 Jun 2018 21:56:12 UTC (6,072 KB)"
"1206","Asymptotic Expansion as Prior Knowledge in Deep Learning Method for high dimensional BSDEs","Masaaki Fujii, Akihiko Takahashi, Masayuki Takahashi","Computational Finance (q-fin.CP); Mathematical Finance (q-fin.MF)","We demonstrate that the use of asymptotic expansion as prior knowledge in the ""deep BSDE solver"", which is a deep learning method for high dimensional BSDEs proposed by Weinan E, Han & Jentzen (2017), drastically reduces the loss function and accelerates the speed of convergence. We illustrate the technique and its implications by Bergman's model with different lending and borrowing rates, and a class of quadratic-growth BSDEs. We also present an extension of the deep BSDE solver for reflected BSDEs using an American basket option as an example.","Thu, 19 Oct 2017 08:04:05 UTC (145 KB)[v2] Sat, 28 Oct 2017 08:09:39 UTC (216 KB)"
"1207","Feature versus Raw Sequence: Deep Learning Comparative Study on Predicting Pre-miRNA","Jaya Thomas, Sonia Thomas, Lee Sael","Machine Learning (cs.LG); Genomics (q-bio.GN)","Should we input known genome sequence features or input sequence itself in deep learning framework? As deep learning more popular in various applications, researchers often come to question whether to generate features or use raw sequences for deep learning. To answer this question, we study the prediction accuracy of precursor miRNA prediction of feature-based deep belief network and sequence-based convolution neural network. Tested on a variant of six-layer convolution neural net and three-layer deep belief network, we find the raw sequence input based convolution neural network model performs similar or slightly better than feature based deep belief networks with best accuracy values of 0.995 and 0.990, respectively. Both the models outperform existing benchmarks models. The results shows us that if provided large enough data, well devised raw sequence based deep learning models can replace feature based deep learning models. However, construction of well behaved deep learning model can be very challenging. In cased features can be easily extracted, feature-based deep learning models may be a better alternative.","Tue, 17 Oct 2017 14:09:00 UTC (317 KB)"
"1208","Multi-Task Domain Adaptation for Deep Learning of Instance Grasping from Simulation","Kuan Fang, Yunfei Bai, Stefan Hinterstoisser, Silvio Savarese, Mrinal Kalakrishnan","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","Learning-based approaches to robotic manipulation are limited by the scalability of data collection and accessibility of labels. In this paper, we present a multi-task domain adaptation framework for instance grasping in cluttered scenes by utilizing simulated robot experiments. Our neural network takes monocular RGB images and the instance segmentation mask of a specified target object as inputs, and predicts the probability of successfully grasping the specified object for each candidate motor command. The proposed transfer learning framework trains a model for instance grasping in simulation and uses a domain-adversarial loss to transfer the trained model to real robots using indiscriminate grasping data, which is available both in simulation and the real world. We evaluate our model in real-world robot experiments, comparing it with alternative model architectures as well as an indiscriminate grasping baseline.","Tue, 17 Oct 2017 17:54:50 UTC (7,674 KB)[v2] Sun, 4 Mar 2018 04:08:58 UTC (8,679 KB)"
"1209","Towards CT-quality Ultrasound Imaging using Deep Learning","Sanketh Vedula, Ortal Senouf, Alex M. Bronstein, Oleg V. Michailovich, Michael Zibulevsky","Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV); Medical Physics (physics.med-ph)","The cost-effectiveness and practical harmlessness of ultrasound imaging have made it one of the most widespread tools for medical diagnosis. Unfortunately, the beam-forming based image formation produces granular speckle noise, blurring, shading and other artifacts. To overcome these effects, the ultimate goal would be to reconstruct the tissue acoustic properties by solving a full wave propagation inverse problem. In this work, we make a step towards this goal, using Multi-Resolution Convolutional Neural Networks (CNN). As a result, we are able to reconstruct CT-quality images from the reflected ultrasound radio-frequency(RF) data obtained by simulation from real CT scans of a human body. We also show that CNN is able to imitate existing computationally heavy despeckling methods, thereby saving orders of magnitude in computations and making them amenable to real-time applications.","Tue, 17 Oct 2017 14:11:57 UTC (368 KB)"
"1210","VAMPnets: Deep learning of molecular kinetics","Andreas Mardt, Luca Pasquali, Hao Wu, Frank Noe","Machine Learning (stat.ML); Biological Physics (physics.bio-ph); Chemical Physics (physics.chem-ph); Computational Physics (physics.comp-ph)","There is an increasing demand for computing the relevant structures, equilibria and long-timescale kinetics of biomolecular processes, such as protein-drug binding, from high-throughput molecular dynamics simulations. Current methods employ transformation of simulated coordinates into structural features, dimension reduction, clustering the dimension-reduced data, and estimation of a Markov state model or related model of the interconversion rates between molecular structures. This handcrafted approach demands a substantial amount of modeling expertise, as poor decisions at any step will lead to large modeling errors. Here we employ the variational approach for Markov processes (VAMP) to develop a deep learning framework for molecular kinetics using neural networks, dubbed VAMPnets. A VAMPnet encodes the entire mapping from molecular coordinates to Markov states, thus combining the whole data processing pipeline in a single end-to-end framework. Our method performs equally or better than state-of-the art Markov modeling methods and provides easily interpretable few-state kinetic models.","Mon, 16 Oct 2017 22:21:22 UTC (5,976 KB)[v2] Wed, 20 Dec 2017 16:17:47 UTC (6,111 KB)"
"1211","Intention-Net: Integrating Planning and Deep Learning for Goal-Directed Autonomous Navigation","Wei Gao, David Hsu, Wee Sun Lee, Shengmei Shen, Karthikk Subramanian","Artificial Intelligence (cs.AI)","How can a delivery robot navigate reliably to a destination in a new office building, with minimal prior information? To tackle this challenge, this paper introduces a two-level hierarchical approach, which integrates model-free deep learning and model-based path planning. At the low level, a neural-network motion controller, called the intention-net, is trained end-to-end to provide robust local navigation. The intention-net maps images from a single monocular camera and ""intentions"" directly to robot controls. At the high level, a path planner uses a crude map, e.g., a 2-D floor plan, to compute a path from the robot's current location to the goal. The planned path provides intentions to the intention-net. Preliminary experiments suggest that the learned motion controller is robust against perceptual uncertainty and by integrating with a path planner, it generalizes effectively to new environments and goals.","Mon, 16 Oct 2017 11:22:32 UTC (8,142 KB)[v2] Tue, 17 Oct 2017 02:24:06 UTC (8,142 KB)"
"1212","Using Deep Learning and Satellite Imagery to Quantify the Impact of the Built Environment on Neighborhood Crime Rates","Adyasha Maharana, Quynh C. Nguyen, Elaine O. Nsoesie","Computers and Society (cs.CY)","The built environment has been postulated to have an impact on neighborhood crime rates, however, measures of the built environment can be subjective and differ across studies leading to varying observations on its association with crime rates. Here, we illustrate an accurate and straightforward approach to quantify the impact of the built environment on neighborhood crime rates from high-resolution satellite imagery. Using geo-referenced crime reports and satellite images for three United States cities, we demonstrate how image features consistently identified using a convolutional neural network can explain up to 82% of the variation in neighborhood crime rates. Our results suggest the built environment is a strong predictor of crime rates, and this can lead to structural interventions shown to reduce crime incidence in urban settings.","Mon, 16 Oct 2017 03:05:05 UTC (1,033 KB)"
"1213","Generalization in Deep Learning","Kenji Kawaguchi, Leslie Pack Kaelbling, Yoshua Bengio","Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","With a direct analysis of neural networks, this paper presents a mathematically tight generalization theory to partially address an open problem regarding the generalization of deep learning. Unlike previous bound-based theory, our main theory is quantitatively as tight as possible for every dataset individually, while producing qualitative insights competitively. Our results give insight into why and how deep learning can generalize well, despite its large capacity, complexity, possible algorithmic instability, nonrobustness, and sharp minima, answering to an open question in the literature. We also discuss limitations of our results and propose additional open problems.","Mon, 16 Oct 2017 02:21:24 UTC (659 KB)[v2] Sun, 24 Dec 2017 19:44:43 UTC (223 KB)[v3] Thu, 22 Feb 2018 23:39:50 UTC (258 KB)"
"1214","Deep Learning for Wireless Physical Layer: Opportunities and Challenges","Tianqi Wang, Chao-Kai Wen, Hanqing Wang, Feifei Gao, Tao Jiang, Shi Jin","Information Theory (cs.IT)","Machine learning (ML) has been widely applied to the upper layers of wireless communication systems for various purposes, such as deployment of cognitive radio and communication network. However, its application to the physical layer is hampered by sophisticated channel environments and limited learning ability of conventional ML algorithms. Deep learning (DL) has been recently applied for many fields, such as computer vision and natural language processing, given its expressive capacity and convenient optimization capability. The potential application of DL to the physical layer has also been increasingly recognized because of the new features for future communications, such as complex scenarios with unknown channel models, high speed and accurate processing requirements; these features challenge conventional communication theories. This paper presents a comprehensive overview of the emerging studies on DL-based physical layer processing, including leveraging DL to redesign a module of the conventional communication system (for modulation recognition, channel decoding, and detection) and replace the communication system with a radically new architecture based on an autoencoder. These DL-based methods show promising performance improvements but have certain limitations, such as lack of solid analytical tools and use of architectures that are specifically designed for communication and implementation research, thereby motivating future research in this field.","Sun, 15 Oct 2017 10:32:33 UTC (504 KB)[v2] Fri, 27 Oct 2017 10:49:36 UTC (2,895 KB)"
"1215","Data-Driven and Deep Learning Methodology for Deceptive Advertising and Phone Scams Detection","TonTon Hsien-De Huang, Chia-Mu Yu, Hung-Yu Kao","Cryptography and Security (cs.CR); Computers and Society (cs.CY)","The advance of smartphones and cellular networks boosts the need of mobile advertising and targeted marketing. However, it also triggers the unseen security threats. We found that the phone scams with fake calling numbers of very short lifetime are increasingly popular and have been used to trick the users. The harm is worldwide. On the other hand, deceptive advertising (deceptive ads), the fake ads that tricks users to install unnecessary apps via either alluring or daunting texts and pictures, is an emerging threat that seriously harms the reputation of the advertiser. To counter against these two new threats, the conventional blacklist (or whitelist) approach and the machine learning approach with predefined features have been proven useless. Nevertheless, due to the success of deep learning in developing the highly intelligent program, our system can efficiently and effectively detect phone scams and deceptive ads by taking advantage of our unified framework on deep neural network (DNN) and convolutional neural network (CNN). The proposed system has been deployed for operational use and the experimental results proved the effectiveness of our proposed system. Furthermore, we keep our research results and release experiment material on this http URL and this http URL if there is any update.","Sun, 15 Oct 2017 09:50:53 UTC (3,959 KB)"
"1216","Object Classification in Images of Neoclassical Artifacts Using Deep Learning","Bernhard Bermeitinger, Maria Christoforaki, Simon Donig, Siegfried Handschuh","Computer Vision and Pattern Recognition (cs.CV)","In this paper, we report on our efforts for using Deep Learning for classifying artifacts and their features in digital visuals as a part of the Neoclassica framework. It was conceived to provide scholars with new methods for analyzing and classifying artifacts and aesthetic forms from the era of Classicism. The framework accommodates both traditional knowledge representation as a formal ontology and data-driven knowledge discovery, where cultural patterns will be identified by means of algorithms in statistical analysis and machine learning. We created a Deep Learning approach trained on photographs to classify the objects inside these photographs. In a next step, we will apply a different Deep Learning approach. It is capable of locating multiple objects inside an image and classifying them with a high accuracy.","Fri, 13 Oct 2017 14:35:27 UTC (89 KB)"
"1217","RADNET: Radiologist Level Accuracy using Deep Learning for HEMORRHAGE detection in CT Scans","Monika Grewal, Muktabh Mayank Srivastava, Pulkit Kumar, Srikrishna Varadarajan","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","We describe a deep learning approach for automated brain hemorrhage detection from computed tomography (CT) scans. Our model emulates the procedure followed by radiologists to analyse a 3D CT scan in real-world. Similar to radiologists, the model sifts through 2D cross-sectional slices while paying close attention to potential hemorrhagic regions. Further, the model utilizes 3D context from neighboring slices to improve predictions at each slice and subsequently, aggregates the slice-level predictions to provide diagnosis at CT level. We refer to our proposed approach as Recurrent Attention DenseNet (RADnet) as it employs original DenseNet architecture along with adding the components of attention for slice level predictions and recurrent neural network layer for incorporating 3D context. The real-world performance of RADnet has been benchmarked against independent analysis performed by three senior radiologists for 77 brain CTs. RADnet demonstrates 81.82% hemorrhage prediction accuracy at CT level that is comparable to radiologists. Further, RADnet achieves higher recall than two of the three radiologists, which is remarkable.","Fri, 13 Oct 2017 14:14:39 UTC (102 KB)[v2] Wed, 3 Jan 2018 12:05:54 UTC (102 KB)"
"1218","Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network that Explains Its Predictions","Oscar Li, Hao Liu, Chaofan Chen, Cynthia Rudin","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep neural networks are widely used for classification. These deep models often suffer from a lack of interpretability -- they are particularly difficult to understand because of their non-linear nature. As a result, neural networks are often treated as ""black box"" models, and in the past, have been trained purely to optimize the accuracy of predictions. In this work, we create a novel network architecture for deep learning that naturally explains its own reasoning for each prediction. This architecture contains an autoencoder and a special prototype layer, where each unit of that layer stores a weight vector that resembles an encoded training input. The encoder of the autoencoder allows us to do comparisons within the latent space, while the decoder allows us to visualize the learned prototypes. The training objective has four terms: an accuracy term, a term that encourages every prototype to be similar to at least one encoded input, a term that encourages every encoded input to be close to at least one prototype, and a term that encourages faithful reconstruction by the autoencoder. The distances computed in the prototype layer are used as part of the classification process. Since the prototypes are learned during training, the learned network naturally comes with explanations for each prediction, and the explanations are loyal to what the network actually computes.","Fri, 13 Oct 2017 05:12:03 UTC (573 KB)[v2] Tue, 21 Nov 2017 06:43:01 UTC (374 KB)"
"1219","Deep Learning in Multiple Multistep Time Series Prediction","Chuanyun Zang","Machine Learning (stat.ML); Machine Learning (cs.LG)","The project aims to research on combining deep learning specifically Long-Short Memory (LSTM) and basic statistics in multiple multistep time series prediction. LSTM can dive into all the pages and learn the general trends of variation in a large scope, while the well selected medians for each page can keep the special seasonality of different pages so that the future trend will not fluctuate too much from the reality. A recent Kaggle competition on 145K Web Traffic Time Series Forecasting [1] is used to thoroughly illustrate and test this idea.","Thu, 12 Oct 2017 05:28:05 UTC (1,686 KB)"
"1220","NeuroTrainer: An Intelligent Memory Module for Deep Learning Training","Duckhwan Kim, Taesik Na, Sudhakar Yalamanchili, Saibal Mukhopadhyay","Hardware Architecture (cs.AR)","This paper presents, NeuroTrainer, an intelligent memory module with in-memory accelerators that forms the building block of a scalable architecture for energy efficient training for deep neural networks. The proposed architecture is based on integration of a homogeneous computing substrate composed of multiple processing engines in the logic layer of a 3D memory module. NeuroTrainer utilizes a programmable data flow based execution model to optimize memory mapping and data re-use during different phases of training operation. A programming model and supporting architecture utilizes the flexible data flow to efficiently accelerate training of various types of DNNs. The cycle level simulation and synthesized design in 15nm FinFET showspower efficiency of 500 GFLOPS/W, and almost similar throughput for a wide range of DNNs including convolutional, recurrent, multi-layer-perceptron, and mixed (CNN+RNN) networks","Thu, 12 Oct 2017 02:56:37 UTC (1,373 KB)"
"1221","Interactive Medical Image Segmentation using Deep Learning with Image-specific Fine-tuning","Guotai Wang, Wenqi Li, Maria A. Zuluaga, Rosalind Pratt, Premal A. Patel, Michael Aertsen, Tom Doel, Anna L. David, Jan Deprest, Sebastien Ourselin, Tom Vercauteren","Computer Vision and Pattern Recognition (cs.CV)","Convolutional neural networks (CNNs) have achieved state-of-the-art performance for automatic medical image segmentation. However, they have not demonstrated sufficiently accurate and robust results for clinical use. In addition, they are limited by the lack of image-specific adaptation and the lack of generalizability to previously unseen object classes. To address these problems, we propose a novel deep learning-based framework for interactive segmentation by incorporating CNNs into a bounding box and scribble-based segmentation pipeline. We propose image-specific fine-tuning to make a CNN model adaptive to a specific test image, which can be either unsupervised (without additional user interactions) or supervised (with additional scribbles). We also propose a weighted loss function considering network and interaction-based uncertainty for the fine-tuning. We applied this framework to two applications: 2D segmentation of multiple organs from fetal MR slices, where only two types of these organs were annotated for training; and 3D segmentation of brain tumor core (excluding edema) and whole brain tumor (including edema) from different MR sequences, where only tumor cores in one MR sequence were annotated for training. Experimental results show that 1) our model is more robust to segment previously unseen objects than state-of-the-art CNNs; 2) image-specific fine-tuning with the proposed weighted loss function significantly improves segmentation accuracy; and 3) our method leads to accurate results with fewer user interactions and less user time than traditional interactive segmentation methods.","Wed, 11 Oct 2017 12:57:52 UTC (4,588 KB)"
"1222","Deep learning in remote sensing: a review","Xiao Xiang Zhu, Devis Tuia, Lichao Mou, Gui-Song Xia, Liangpei Zhang, Feng Xu, Friedrich Fraundorfer","Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)","Standing at the paradigm shift towards data-intensive science, machine learning techniques are becoming increasingly important. In particular, as a major breakthrough in the field, deep learning has proven as an extremely powerful tool in many fields. Shall we embrace deep learning as the key to all? Or, should we resist a 'black-box' solution? There are controversial opinions in the remote sensing community. In this article, we analyze the challenges of using deep learning for remote sensing data analysis, review the recent advances, and provide resources to make deep learning in remote sensing ridiculously simple to start with. More importantly, we advocate remote sensing scientists to bring their expertise into deep learning, and use it as an implicit general model to tackle unprecedented large-scale influential challenges, such as climate change and urbanization.","Wed, 11 Oct 2017 08:35:05 UTC (8,439 KB)"
"1223","Application of Deep Learning in Neuroradiology: Automated Detection of Basal Ganglia Hemorrhage using 2D-Convolutional Neural Networks","Vishal Desai, Adam E. Flanders, Paras Lakhani","Computer Vision and Pattern Recognition (cs.CV)","Background: Deep learning techniques have achieved high accuracy in image classification tasks, and there is interest in applicability to neuroimaging critical findings. This study evaluates the efficacy of 2D deep convolutional neural networks (DCNNs) for detecting basal ganglia (BG) hemorrhage on noncontrast head CT. Materials and Methods: 170 unique de-identified HIPAA-compliant noncontrast head CTs were obtained, those with and without BG hemorrhage. 110 cases were held-out for test, and 60 were split into training (45) and validation (15), consisting of 20 right, 20 left, and 20 no BG hemorrhage. Data augmentation was performed to increase size and variation of the training dataset by 48-fold. Two DCNNs were used to classify the images-AlexNet and GoogLeNet-using untrained networks and those pre-trained on ImageNet. Area under the curves (AUC) for the receiver-operator characteristic (ROC) curves were calculated, using the DeLong method for statistical comparison of ROCs. Results: The best performing model was the pre-trained augmented GoogLeNet, which had an AUC of 1.00 in classification of hemorrhage. Preprocessing augmentation increased accuracy for all networks (p<0.001), and pretrained networks outperformed untrained ones (p<0.001) for the unaugmented models. The best performing GoogLeNet model (AUC 1.00) outperformed the best performing AlexNet model (AUC 0.95)(p=0.01). Conclusion: For this dataset, the best performing DCNN identified BG hemorrhage on noncontrast head CT with an AUC of 1.00. Pretrained networks and data augmentation increased classifier accuracy. Future prospective research would be important to determine if the accuracy can be maintained on a larger cohort of patients and for very small hemorrhages.","Tue, 10 Oct 2017 21:13:58 UTC (1,136 KB)[v2] Fri, 27 Oct 2017 16:23:02 UTC (1,138 KB)"
"1224","End-to-End Deep Learning for Steering Autonomous Vehicles Considering Temporal Dependencies","Hesham M. Eraqi, Mohamed N. Moustafa, Jens Honer","Machine Learning (cs.LG)","Steering a car through traffic is a complex task that is difficult to cast into algorithms. Therefore, researchers turn to training artificial neural networks from front-facing camera data stream along with the associated steering angles. Nevertheless, most existing solutions consider only the visual camera frames as input, thus ignoring the temporal relationship between frames. In this work, we propose a Convolutional Long Short-Term Memory Recurrent Neural Network (C-LSTM), that is end-to-end trainable, to learn both visual and dynamic temporal dependencies of driving. Additionally, We introduce posing the steering angle regression problem as classification while imposing a spatial relationship between the output layer neurons. Such method is based on learning a sinusoidal function that encodes steering angles. To train and validate our proposed methods, we used the publicly available Comma.ai dataset. Our solution improved steering root mean square error by 35% over recent methods, and led to a more stable steering by 87%.","Tue, 10 Oct 2017 20:10:25 UTC (896 KB)[v2] Sat, 18 Nov 2017 18:11:30 UTC (815 KB)[v3] Wed, 22 Nov 2017 13:03:45 UTC (815 KB)"
"1225","Monochromatic CT Image Reconstruction from Current-Integrating Data via Deep Learning","Wenxiang Cong, Ge Wang","Medical Physics (physics.med-ph)","In clinical CT, the x-ray source emits polychromatic x-rays, which are detected in the current-integrating mode. This physical process is accurately described by an energy-dependent non-linear integral model on the basis of the Beer-Lambert law. However, the non-linear model is too complicated to be directly solved for the image reconstruction, and is often approximated to a linear integral model in the form of the Radon transform, basically ignoring energy-dependent information. This model approximation would generate inaccurate quantification of attenuation image and significant beam-hardening artifacts. In this paper, we develop a deep-learning-based CT image reconstruction method to address the mismatch of computing model to physical model. Our method learns a nonlinear transformation from big data to correct measured projection data to accurately match the linear integral model, realize monochromatic imaging and overcome beam hardening effectively. The deep-learning network is trained and tested using clinical dual-energy dataset to demonstrate the feasibility of the proposed methodology. Results show that the proposed method can achieve a high accuracy of the projection correction with a relative error of less than 0.2%.","Tue, 10 Oct 2017 18:59:48 UTC (781 KB)[v2] Tue, 9 Jan 2018 19:03:15 UTC (637 KB)"
"1226","Joint Weakly and Semi-Supervised Deep Learning for Localization and Classification of Masses in Breast Ultrasound Images","Seung Yeon Shin, Soochahn Lee, Il Dong Yun, Kyoung Mu Lee","Computer Vision and Pattern Recognition (cs.CV)","We propose a framework for localization and classification of masses in breast ultrasound (BUS) images. In particular, we simultaneously use a weakly annotated dataset and a relatively small strongly annotated dataset to train a convolutional neural network detector. We have experimentally found that mass detectors trained with small, strongly annotated datasets are easily overfitted, whereas those trained with large, weakly annotated datasets present a non-trivial problem. To overcome these problems, we jointly use datasets with different characteristics in a hybrid manner. Consequently, a sophisticated weakly and semi-supervised training scenario is introduced with appropriate training loss selection. Experimental results show that the proposed method successfully localizes and classifies masses while requiring less effort in annotation work. The influences of each component in the proposed framework are also validated by conducting an ablative analysis. Although the proposed method is intended for masses in BUS images, it can also be applied as a general framework to train computer-aided detection and diagnosis systems for a wide variety of image modalities, target organs, and diseases.","Tue, 10 Oct 2017 18:39:24 UTC (3,150 KB)"
"1227","Status of a Deep Learning Based Measurement of the Inclusive Muon Neutrino Charged-current Cross Section in the NOvA Near Detector","Biswaranjan Behera","High Energy Physics - Experiment (hep-ex)","NOvA is a long-baseline neutrino oscillation experiment. It uses the NuMI beam from Fermilab and two sampling calorimeter detectors placed off-axis from the beam. The 293 ton Near Detector measures the unoscillated neutrino energy spectrum, which can be used to predict the neutrino energy spectrum observed at the 14 kton Far Detector. The Near Detector also provides an excellent opportunity to measure neutrino interaction cross sections with high statistics, which will benefit current and future long-baseline neutrino oscillation experiments. This analysis implements new algorithms to identify $ロ_レ$ charge-current events by using visual deep learning tools such as convolutional neural networks. We present the status of a measurement of the inclusive $ロ_レ$ CC cross section in the NOvA Near Detector.","Tue, 10 Oct 2017 18:02:40 UTC (483 KB)"
"1228","Function space analysis of deep learning representation layers","Oren Elisha, Shai Dekel","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","In this paper we propose a function space approach to Representation Learning and the analysis of the representation layers in deep learning architectures. We show how to compute a weak-type Besov smoothness index that quantifies the geometry of the clustering in the feature space. This approach was already applied successfully to improve the performance of machine learning algorithms such as the Random Forest and tree-based Gradient Boosting. Our experiments demonstrate that in well-known and well-performing trained networks, the Besov smoothness of the training set, measured in the corresponding hidden layer feature map representation, increases from layer to layer. We also contribute to the understanding of generalization by showing how the Besov smoothness of the representations, decreases as we add more mis-labeling to the training data. We hope this approach will contribute to the de-mystification of some aspects of deep learning.","Mon, 9 Oct 2017 18:52:42 UTC (209 KB)"
"1229","Deep Learning Paradigm with Transformed Monolingual Word Embeddings for Multilingual Sentiment Analysis","Yujie Lu, Tatsunori Mori","Computation and Language (cs.CL)","The surge of social media use brings huge demand of multilingual sentiment analysis (MSA) for unveiling cultural difference. So far, traditional methods resorted to machine translation---translating texts in other languages to English, and then adopt the methods once worked in English. However, this paradigm is conditioned by the quality of machine translation. In this paper, we propose a new deep learning paradigm to assimilate the differences between languages for MSA. We first pre-train monolingual word embeddings separately, then map word embeddings in different spaces into a shared embedding space, and then finally train a parameter-sharing deep neural network for MSA. The experimental results show that our paradigm is effective. Especially, our CNN model outperforms a state-of-the-art baseline by around 2.1% in terms of classification accuracy.","Mon, 9 Oct 2017 17:30:12 UTC (244 KB)[v2] Tue, 10 Oct 2017 00:51:23 UTC (191 KB)"
"1230","An automatic deep learning approach for coronary artery calcium segmentation","G. Santini, D. Della Latta, N. Martini, G. Valvano, A. Gori, A. Ripoli, C.L. Susini, L. Landini, D. Chiappino","Computer Vision and Pattern Recognition (cs.CV)","Coronary artery calcium (CAC) is a significant marker of atherosclerosis and cardiovascular events. In this work we present a system for the automatic quantification of calcium score in ECG-triggered non-contrast enhanced cardiac computed tomography (CT) images. The proposed system uses a supervised deep learning algorithm, i.e. convolutional neural network (CNN) for the segmentation and classification of candidate lesions as coronary or not, previously extracted in the region of the heart using a cardiac atlas. We trained our network with 45 CT volumes; 18 volumes were used to validate the model and 56 to test it. Individual lesions were detected with a sensitivity of 91.24%, a specificity of 95.37% and a positive predicted value (PPV) of 90.5%; comparing calcium score obtained by the system and calcium score manually evaluated by an expert operator, a Pearson coefficient of 0.983 was obtained. A high agreement (Cohen's k = 0.879) between manual and automatic risk prediction was also observed. These results demonstrated that convolutional neural networks can be effectively applied for the automatic segmentation and classification of coronary calcifications.","Mon, 9 Oct 2017 10:48:13 UTC (1,317 KB)"
"1231","Protein identification with deep learning: from abc to xyz","Ngoc Hieu Tran, Zachariah Levine, Lei Xin, Baozhen Shan, Ming Li","Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG); Biomolecules (q-bio.BM)","Proteins are the main workhorses of biological functions in a cell, a tissue, or an organism. Identification and quantification of proteins in a given sample, e.g. a cell type under normal/disease conditions, are fundamental tasks for the understanding of human health and disease. In this paper, we present DeepNovo, a deep learning-based tool to address the problem of protein identification from tandem mass spectrometry data. The idea was first proposed in the context of de novo peptide sequencing [1] in which convolutional neural networks and recurrent neural networks were applied to predict the amino acid sequence of a peptide from its spectrum, a similar task to generating a caption from an image. We further develop DeepNovo to perform sequence database search, the main technique for peptide identification that greatly benefits from numerous existing protein databases. We combine two modules de novo sequencing and database search into a single deep learning framework for peptide identification, and integrate de Bruijn graph assembly technique to offer a complete solution to reconstruct protein sequences from tandem mass spectrometry data. This paper describes a comprehensive protocol of DeepNovo for protein identification, including training neural network models, dynamic programming search, database querying, estimation of false discovery rate, and de Bruijn graph assembly. Training and testing data, model implementations, and comprehensive tutorials in form of IPython notebooks are available in our GitHub repository (this https URL).","Sun, 8 Oct 2017 01:23:18 UTC (997 KB)"
"1232","Real-Time Illegal Parking Detection System Based on Deep Learning","Xuemei Xie, Chenye Wang, Shu Chen, Guangming Shi, Zhifu Zhao","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","The increasing illegal parking has become more and more serious. Nowadays the methods of detecting illegally parked vehicles are based on background segmentation. However, this method is weakly robust and sensitive to environment. Benefitting from deep learning, this paper proposes a novel illegal vehicle parking detection system. Illegal vehicles captured by camera are firstly located and classified by the famous Single Shot MultiBox Detector (SSD) algorithm. To improve the performance, we propose to optimize SSD by adjusting the aspect ratio of default box to accommodate with our dataset better. After that, a tracking and analysis of movement is adopted to judge the illegal vehicles in the region of interest (ROI). Experiments show that the system can achieve a 99% accuracy and real-time (25FPS) detection with strong robustness in complex environments.","Thu, 5 Oct 2017 07:57:29 UTC (1,133 KB)"
"1233","Model-free prediction of noisy chaotic time series by deep learning","Kyongmin Yeo","Machine Learning (cs.LG); Computational Physics (physics.comp-ph); Data Analysis, Statistics and Probability (physics.data-an)","We present a deep neural network for a model-free prediction of a chaotic dynamical system from noisy observations. The proposed deep learning model aims to predict the conditional probability distribution of a state variable. The Long Short-Term Memory network (LSTM) is employed to model the nonlinear dynamics and a softmax layer is used to approximate a probability distribution. The LSTM model is trained by minimizing a regularized cross-entropy function. The LSTM model is validated against delay-time chaotic dynamical systems, Mackey-Glass and Ikeda equations. It is shown that the present LSTM makes a good prediction of the nonlinear dynamics by effectively filtering out the noise. It is found that the prediction uncertainty of a multiple-step forecast of the LSTM model is not a monotonic function of time; the predicted standard deviation may increase or decrease dynamically in time.","Fri, 29 Sep 2017 20:36:02 UTC (1,937 KB)"
"1234","Strengths and Weaknesses of Deep Learning Models for Face Recognition Against Image Degradations","Klemen Grm, Vitomir <U+0160>truc, Anais Artiges, Matthieu Caron, Hazim Kemal Ekenel","Machine Learning (stat.ML)","Deep convolutional neural networks (CNNs) based approaches are the state-of-the-art in various computer vision tasks, including face recognition. Considerable research effort is currently being directed towards further improving deep CNNs by focusing on more powerful model architectures and better learning techniques. However, studies systematically exploring the strengths and weaknesses of existing deep models for face recognition are still relatively scarce in the literature. In this paper, we try to fill this gap and study the effects of different covariates on the verification performance of four recent deep CNN models using the Labeled Faces in the Wild (LFW) dataset. Specifically, we investigate the influence of covariates related to: image quality -- blur, JPEG compression, occlusion, noise, image brightness, contrast, missing pixels; and model characteristics -- CNN architecture, color information, descriptor computation; and analyze their impact on the face verification performance of AlexNet, VGG-Face, GoogLeNet, and SqueezeNet. Based on comprehensive and rigorous experimentation, we identify the strengths and weaknesses of the deep learning models, and present key areas for potential future research. Our results indicate that high levels of noise, blur, missing pixels, and brightness have a detrimental effect on the verification performance of all models, whereas the impact of contrast changes and compression artifacts is limited. It has been found that the descriptor computation strategy and color information does not have a significant influence on performance.","Wed, 4 Oct 2017 08:03:41 UTC (4,914 KB)"
"1235","Deep learning for source camera identification on mobile devices","David Freire-Obregon, Fabio Narducci, Silvio Barra, Modesto Castrillon-Santana","Computer Vision and Pattern Recognition (cs.CV)","In the present paper, we propose a source camera identification method for mobile devices based on deep learning. Recently, convolutional neural networks (CNNs) have shown a remarkable performance on several tasks such as image recognition, video analysis or natural language processing. A CNN consists on a set of layers where each layer is composed by a set of high pass filters which are applied all over the input image. This convolution process provides the unique ability to extract features automatically from data and to learn from those features. Our proposal describes a CNN architecture which is able to infer the noise pattern of mobile camera sensors (also known as camera fingerprint) with the aim at detecting and identifying not only the mobile device used to capture an image (with a 98\% of accuracy), but also from which embedded camera the image was captured. More specifically, we provide an extensive analysis on the proposed architecture considering different configurations. The experiment has been carried out using the images captured from different mobile devices cameras (MICHE-I Dataset was used) and the obtained results have proved the robustness of the proposed method.","Sat, 30 Sep 2017 11:34:10 UTC (1,233 KB)[v2] Fri, 13 Oct 2017 17:03:52 UTC (1,106 KB)"
"1236","Reducing Complexity of HEVC: A Deep Learning Approach","Mai Xu, Tianyi Li, Zulin Wang, Xin Deng, Ren Yang, Zhenyu Guan","Computer Vision and Pattern Recognition (cs.CV)","High Efficiency Video Coding (HEVC) significantly reduces bit-rates over the proceeding H.264 standard but at the expense of extremely high encoding complexity. In HEVC, the quad-tree partition of coding unit (CU) consumes a large proportion of the HEVC encoding complexity, due to the bruteforce search for rate-distortion optimization (RDO). Therefore, this paper proposes a deep learning approach to predict the CU partition for reducing the HEVC complexity at both intra- and inter-modes, which is based on convolutional neural network (CNN) and long- and short-term memory (LSTM) network. First, we establish a large-scale database including substantial CU partition data for HEVC intra- and inter-modes. This enables deep learning on the CU partition. Second, we represent the CU partition of an entire coding tree unit (CTU) in the form of a hierarchical CU partition map (HCPM). Then, we propose an early-terminated hierarchical CNN (ETH-CNN) for learning to predict the HCPM. Consequently, the encoding complexity of intra-mode HEVC can be drastically reduced by replacing the brute-force search with ETH-CNN to decide the CU partition. Third, an early-terminated hierarchical LSTM (ETH-LSTM) is proposed to learn the temporal correlation of the CU partition. Then, we combine ETH-LSTM and ETH-CNN to predict the CU partition for reducing the HEVC complexity for inter-mode. Finally, experimental results show that our approach outperforms other state-of-the-art approaches in reducing the HEVC complexity at both intra- and inter-modes.","Tue, 19 Sep 2017 02:02:00 UTC (2,274 KB)[v2] Thu, 18 Jan 2018 07:48:00 UTC (3,307 KB)[v3] Thu, 22 Mar 2018 11:13:05 UTC (3,307 KB)"
"1237","Identifying Nominals with No Head Match Co-references Using Deep Learning","M. Stone, R. Arora","Computation and Language (cs.CL)","Identifying nominals with no head match is a long-standing challenge in coreference resolution with current systems performing significantly worse than humans. In this paper we present a new neural network architecture which outperforms the current state-of-the-art system on the English portion of the CoNLL 2012 Shared Task. This is done by using a logistic regression on features produced by two submodels, one of which is has the architecture proposed in [CM16a] while the other combines domain specific embeddings of the antecedent and the mention. We also propose some simple additional features which seem to improve performance for all models substantially, increasing F1 by almost 4% on basic logistic regression and other complex models.","Mon, 2 Oct 2017 23:02:17 UTC (352 KB)"
"1238","Deep Learning for Unsupervised Insider Threat Detection in Structured Cybersecurity Data Streams","Aaron Tuor, Samuel Kaplan, Brian Hutchinson, Nicole Nichols, Sean Robinson","Neural and Evolutionary Computing (cs.NE); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)","Analysis of an organization's computer network activity is a key component of early detection and mitigation of insider threat, a growing concern for many organizations. Raw system logs are a prototypical example of streaming data that can quickly scale beyond the cognitive power of a human analyst. As a prospective filter for the human analyst, we present an online unsupervised deep learning approach to detect anomalous network activity from system logs in real time. Our models decompose anomaly scores into the contributions of individual user behavior features for increased interpretability to aid analysts reviewing potential cases of insider threat. Using the CERT Insider Threat Dataset v6.2 and threat detection recall as our performance metric, our novel deep and recurrent neural network models outperform Principal Component Analysis, Support Vector Machine and Isolation Forest based anomaly detection baselines. For our best model, the events labeled as insider threat activity in our dataset had an average anomaly score in the 95.53 percentile, demonstrating our approach's potential to greatly reduce analyst workloads.","Mon, 2 Oct 2017 17:54:28 UTC (370 KB)[v2] Fri, 15 Dec 2017 20:53:03 UTC (370 KB)"
"1239","Margin Sample Mining Loss: A Deep Learning Based Method for Person Re-identification","Qiqi Xiao, Hao Luo, Chi Zhang","Computer Vision and Pattern Recognition (cs.CV)","Person re-identification (ReID) is an important task in computer vision. Recently, deep learning with a metric learning loss has become a common framework for ReID. In this paper, we also propose a new metric learning loss with hard sample mining called margin smaple mining loss (MSML) which can achieve better accuracy compared with other metric learning losses, such as triplet loss. In experi- ments, our proposed methods outperforms most of the state-of-the-art algorithms on Market1501, MARS, CUHK03 and CUHK-SYSU.","Mon, 2 Oct 2017 04:27:07 UTC (1,846 KB)[v2] Wed, 4 Oct 2017 03:36:22 UTC (1,902 KB)[v3] Sat, 7 Oct 2017 03:21:22 UTC (1,902 KB)"
"1240","MicroBooNE Investigation of Low-Energy Excess Using Deep Learning Algorithms","Lauren E. Yates","Instrumentation and Detectors (physics.ins-det); High Energy Physics - Experiment (hep-ex)","MicroBooNE is a neutrino experiment based at Fermilab which consists of a liquid argon time-projection chamber in the Booster Neutrino Beam (BNB). The experiment aims to investigate the excess of electron-neutrino-like events seen by the MiniBooNE experiment, also located in the BNB, which is potential evidence for new non-Standard Model physics such as sterile neutrinos. I discuss the status of a search for low-energy electron-neutrino interactions within the MicroBooNE detector. This analysis features a hybrid approach of traditional reconstruction methods along with the use of convolutional neural networks (CNNs), a type of deep learning algorithm highly adept at pattern recognition. I describe the identification of events and the ways in which the CNNs are used. I also outline the ways that we are addressing issues related to applying CNNs, which are trained on simulated data, to data from the detector.","Mon, 2 Oct 2017 03:10:25 UTC (889 KB)"
"1241","DeepWheat: Estimating Phenotypic Traits from Crop Images with Deep Learning","Shubhra Aich, Anique Josuttes, Ilya Ovsyannikov, Keegan Strueby, Imran Ahmed, Hema Sudhakar Duddu, Curtis Pozniak, Steve Shirtliffe, Ian Stavness","Computer Vision and Pattern Recognition (cs.CV)","In this paper, we investigate estimating emergence and biomass traits from color images and elevation maps of wheat field plots. We employ a state-of-the-art deconvolutional network for segmentation and convolutional architectures, with residual and Inception-like layers, to estimate traits via high dimensional nonlinear regression. Evaluation was performed on two different species of wheat, grown in field plots for an experimental plant breeding study. Our framework achieves satisfactory performance with mean and standard deviation of absolute difference of 1.05 and 1.40 counts for emergence and 1.45 and 2.05 for biomass estimation. Our results for counting wheat plants from field images are better than the accuracy reported for the similar, but arguably less difficult, task of counting leaves from indoor images of rosette plants. Our results for biomass estimation, even with a very small dataset, improve upon all previously proposed approaches in the literature.","Sat, 30 Sep 2017 18:31:53 UTC (7,284 KB)[v2] Fri, 26 Jan 2018 19:14:00 UTC (8,339 KB)"
"1242","The Deep Ritz method: A deep learning-based numerical algorithm for solving variational problems","Weinan E, Bing Yu","Machine Learning (cs.LG); Machine Learning (stat.ML)","We propose a deep learning based method, the Deep Ritz Method, for numerically solving variational problems, particularly the ones that arise from partial differential equations. The Deep Ritz method is naturally nonlinear, naturally adaptive and has the potential to work in rather high dimensions. The framework is quite simple and fits well with the stochastic gradient descent method used in deep learning. We illustrate the method on several problems including some eigenvalue problems.","Sat, 30 Sep 2017 15:06:14 UTC (146 KB)"
"1243","Impact of Three-Dimensional Video Scalability on Multi-View Activity Recognition using Deep Learning","Jun-Ho Choi, Manri Cheon, Min-Su Choi, Jong-Seok Lee","Multimedia (cs.MM)","Human activity recognition is one of the important research topics in computer vision and video understanding. It is often assumed that high quality video sequences are available for recognition. However, relaxing such a requirement and implementing robust recognition using videos having reduced data rates can achieve efficiency in storing and transmitting video data. Three-dimensional video scalability, which refers to the possibility of reducing spatial, temporal, and quality resolutions of videos, is an effective way for flexible representation and management of video data. In this paper, we investigate the impact of the video scalability on multi-view activity recognition. We employ both a spatiotemporal feature extraction-based method and a deep learning-based method using convolutional and recurrent neural networks. The recognition performance of the two methods is examined, along with in-depth analysis regarding how their performance vary with respect to various scalability combinations. In particular, we demonstrate that the deep learning-based method can achieve significantly improved robustness in comparison to the feature-based method. Furthermore, we investigate optimal scalability combinations with respect to bitrate in order to provide useful guidelines for an optimal operation policy in resource-constrained activity recognition systems.","Fri, 29 Sep 2017 00:39:48 UTC (3,364 KB)"
"1244","Deep Learning Assisted Heuristic Tree Search for the Container Pre-marshalling Problem","Andre Hottung, Shunji Tanaka, Kevin Tierney","Artificial Intelligence (cs.AI)","One of the key challenges for operations researchers solving real-world problems is designing and implementing high-quality heuristics to guide their search procedures. In the past, machine learning techniques have failed to play a major role in operations research approaches, especially in terms of guiding branching and pruning decisions. We integrate deep neural networks into a heuristic tree search procedure to decide which branch to choose next and to estimate a bound for pruning the search tree of an optimization problem. We call our approach Deep Learning assisted heuristic Tree Search (DLTS) and apply it to a well-known problem from the container terminals literature, the container pre-marshalling problem (CPMP). Our approach is able to learn heuristics customized to the CPMP solely through analyzing the solutions to CPMP instances, and applies this knowledge within a heuristic tree search to produce the highest quality heuristic solutions to the CPMP to date.","Thu, 28 Sep 2017 14:06:28 UTC (515 KB)"
"1245","Dose Prediction with U-net: A Feasibility Study for Predicting Dose Distributions from Contours using Deep Learning on Prostate IMRT Patients","Dan Nguyen, Troy Long, Xun Jia, Weiguo Lu, Xuejun Gu, Zohaib Iqbal, Steve Jiang","Medical Physics (physics.med-ph); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","With the advancement of treatment modalities in radiation therapy for cancer patients, outcomes have improved, but at the cost of increased treatment plan complexity and planning time. The accurate prediction of dose distributions would alleviate this issue by guiding clinical plan optimization to save time and maintain high quality plans. We have modified a convolutional deep network model, U-net (originally designed for segmentation purposes), for predicting dose from patient image contours. We show that, as an example, we are able to accurately predict the dose of intensity-modulated radiation therapy (IMRT) for prostate cancer patients, where the average dice similarity coefficient is 0.91 when comparing the predicted vs. true isodose volumes between 0% and 100% of the prescription dose. The average value of the absolute differences in [max, mean] dose is found to be under 5% of the prescription dose, specifically for each structure is [1.80%, 1.03%](PTV), [1.94%, 4.22%](Bladder), [1.80%, 0.48%](Body), [3.87%, 1.79%](L Femoral Head), [5.07%, 2.55%](R Femoral Head), and [1.26%, 1.62%](Rectum) of the prescription dose. We thus managed to map a desired radiation dose distribution from a patient's PTV and OAR contours. As an additional advantage, relatively little data was used in the techniques and models described in this paper.","Tue, 26 Sep 2017 19:43:29 UTC (1,457 KB)[v2] Mon, 26 Mar 2018 06:26:06 UTC (1,449 KB)[v3] Wed, 23 May 2018 23:45:25 UTC (1,625 KB)"
"1246","A Deep Learning Model for Traffic Flow State Classification Based on Smart Phone Sensor Data","Wenwen Tu, Feng Xiao, Liping Fu, Guangyuan Pan","Machine Learning (cs.LG)","This study proposes a Deep Belief Network model to classify traffic flow states. The model is capable of processing massive, high-density, and noise-contaminated data sets generated from smartphone sensors. The statistical features of Vehicle acceleration, angular acceleration, and GPS speed data, recorded by smartphone software, are analyzed, and then used as input for traffic flow state classification. Data from a five-day experiment is used to train and test the proposed model. A total of 747,856 sets of data are generated and used for both traffic flow states classification and sensitivity analysis of input variables. The result shows that the proposed Deep Belief Network model is superior to traditional machine learning methods in both classification performance and computational efficiency.","Tue, 26 Sep 2017 03:48:41 UTC (1,190 KB)"
"1247","Machine and deep learning techniques in heavy-ion collisions with ALICE","Rudiger Haake (for the ALICE Collaboration)","Data Analysis, Statistics and Probability (physics.data-an); Nuclear Experiment (nucl-ex)","Over the last years, machine learning tools have been successfully applied to a wealth of problems in high-energy physics. A typical example is the classification of physics objects. Supervised machine learning methods allow for significant improvements in classification problems by taking into account observable correlations and by learning the optimal selection from examples, e.g. from Monte Carlo simulations. Even more promising is the usage of deep learning techniques. Methods like deep convolutional networks might be able to catch features from low-level parameters that are not exploited by default cut-based methods. These ideas could be particularly beneficial for measurements in heavy-ion collisions, because of the very large multiplicities. Indeed, machine learning methods potentially perform much better in systems with a large number of degrees of freedom compared to cut-based methods. Moreover, many key heavy-ion observables are most interesting at low transverse momentum where the underlying event is dominant and the signal-to-noise ratio is quite low. In this work, recent developments of machine- and deep learning applications in heavy-ion collisions with ALICE will be presented, with focus on a deep learning-based b-jet tagging approach and the measurement of low-mass dielectrons. While the b-jet tagger is based on a mixture of shallow fully-connected and deep convolutional networks, the low-mass dielectron measurement uses gradient boosting and shallow neural networks. Both methods are very promising compared to default cut-based methods.","Fri, 22 Sep 2017 14:38:36 UTC (129 KB)"
"1248","Deep Learning Based Cryptographic Primitive Classification","Gregory D. Hill, Xavier J. A. Bellekens","Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)","Cryptovirological augmentations present an immediate, incomparable threat. Over the last decade, the substantial proliferation of crypto-ransomware has had widespread consequences for consumers and organisations alike. Established preventive measures perform well, however, the problem has not ceased. Reverse engineering potentially malicious software is a cumbersome task due to platform eccentricities and obfuscated transmutation mechanisms, hence requiring smarter, more efficient detection strategies. The following manuscript presents a novel approach for the classification of cryptographic primitives in compiled binary executables using deep learning. The model blueprint, a DCNN, is fittingly configured to learn from variable-length control flow diagnostics output from a dynamic trace. To rival the size and variability of contemporary data compendiums, hence feeding the model cognition, a methodology for the procedural generation of synthetic cryptographic binaries is defined, utilising core primitives from OpenSSL with multivariate obfuscation, to draw a vastly scalable distribution. The library, CryptoKnight, rendered an algorithmic pool of AES, RC4, Blowfish, MD5 and RSA to synthesis combinable variants which are automatically fed in its core model. Converging at 91% accuracy, CryptoKnight is successfully able to classify the sample algorithms with minimal loss.","Mon, 25 Sep 2017 09:07:30 UTC (241 KB)"
"1249","HDLTex: Hierarchical Deep Learning for Text Classification","Kamran Kowsari, Donald E. Brown, Mojtaba Heidarysafa, Kiana Jafari Meimandi, Matthew S. Gerber, Laura E. Barnes","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR)","The continually increasing number of documents produced each year necessitates ever improving information processing methods for searching, retrieving, and organizing text. Central to these information processing methods is document classification, which has become an important application for supervised learning. Recently the performance of these traditional classifiers has degraded as the number of documents has increased. This is because along with this growth in the number of documents has come an increase in the number of categories. This paper approaches this problem differently from current document classification methods that view the problem as multi-class classification. Instead we perform hierarchical classification using an approach we call Hierarchical Deep Learning for Text classification (HDLTex). HDLTex employs stacks of deep learning architectures to provide specialized understanding at each level of the document hierarchy.","Sun, 24 Sep 2017 21:58:12 UTC (6,354 KB)[v2] Fri, 6 Oct 2017 18:16:31 UTC (6,354 KB)"
"1250","A Hybrid DSP/Deep Learning Approach to Real-Time Full-Band Speech Enhancement","Jean-Marc Valin","Sound (cs.SD); Audio and Speech Processing (eess.AS)","Despite noise suppression being a mature area in signal processing, it remains highly dependent on fine tuning of estimator algorithms and parameters. In this paper, we demonstrate a hybrid DSP/deep learning approach to noise suppression. A deep neural network with four hidden layers is used to estimate ideal critical band gains, while a more traditional pitch filter attenuates noise between pitch harmonics. The approach achieves significantly higher quality than a traditional minimum mean squared error spectral estimator, while keeping the complexity low enough for real-time operation at 48 kHz on a low-power processor.","Sun, 24 Sep 2017 19:23:22 UTC (1,249 KB)[v2] Sat, 28 Oct 2017 17:04:33 UTC (1,252 KB)[v3] Thu, 31 May 2018 21:39:13 UTC (1,253 KB)"
"1251","Deep Learning for Secure Mobile Edge Computing","Yuanfang Chen, Yan Zhang, Sabita Maharjan","Cryptography and Security (cs.CR); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)","Mobile edge computing (MEC) is a promising approach for enabling cloud-computing capabilities at the edge of cellular networks. Nonetheless, security is becoming an increasingly important issue in MEC-based applications. In this paper, we propose a deep-learning-based model to detect security threats. The model uses unsupervised learning to automate the detection process, and uses location information as an important feature to improve the performance of detection. Our proposed model can be used to detect malicious applications at the edge of a cellular network, which is a serious security threat. Extensive experiments are carried out with 10 different datasets, the results of which illustrate that our deep-learning-based model achieves an average gain of 6% accuracy compared with state-of-the-art machine learning algorithms.","Sat, 23 Sep 2017 08:59:49 UTC (1,591 KB)"
"1252","AffordanceNet: An End-to-End Deep Learning Approach for Object Affordance Detection","Thanh-Toan Do, Anh Nguyen, Ian Reid","Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","We propose AffordanceNet, a new deep learning approach to simultaneously detect multiple objects and their affordances from RGB images. Our AffordanceNet has two branches: an object detection branch to localize and classify the object, and an affordance detection branch to assign each pixel in the object to its most probable affordance label. The proposed framework employs three key components for effectively handling the multiclass problem in the affordance mask: a sequence of deconvolutional layers, a robust resizing strategy, and a multi-task loss function. The experimental results on the public datasets show that our AffordanceNet outperforms recent state-of-the-art methods by a fair margin, while its end-to-end architecture allows the inference at the speed of 150ms per image. This makes our AffordanceNet well suitable for real-time robotic applications. Furthermore, we demonstrate the effectiveness of AffordanceNet in different testing environments and in real robotic applications. The source code is available at this https URL","Thu, 21 Sep 2017 13:48:49 UTC (3,844 KB)[v2] Tue, 3 Oct 2017 22:27:40 UTC (3,845 KB)[v3] Sun, 4 Mar 2018 14:04:29 UTC (3,844 KB)"
"1253","Open Source Dataset and Deep Learning Models for Online Digit Gesture Recognition on Touchscreens","Philip J. Corr, Guenole C. Silvestre, Chris J. Bleakley","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)","This paper presents an evaluation of deep neural networks for recognition of digits entered by users on a smartphone touchscreen. A new large dataset of Arabic numerals was collected for training and evaluation of the network. The dataset consists of spatial and temporal touch data recorded for 80 digits entered by 260 users. Two neural network models were investigated. The first model was a 2D convolutional neural (ConvNet) network applied to bitmaps of the glpyhs created by interpolation of the sensed screen touches and its topology is similar to that of previously published models for offline handwriting recognition from scanned images. The second model used a 1D ConvNet architecture but was applied to the sequence of polar vectors connecting the touch points. The models were found to provide accuracies of 98.50% and 95.86%, respectively. The second model was much simpler, providing a reduction in the number of parameters from 1,663,370 to 287,690. The dataset has been made available to the community as an open source resource.","Wed, 20 Sep 2017 14:02:55 UTC (1,000 KB)"
"1254","UnDeepVO: Monocular Visual Odometry through Unsupervised Deep Learning","Ruihao Li, Sen Wang, Zhiqiang Long, Dongbing Gu","Computer Vision and Pattern Recognition (cs.CV)","We propose a novel monocular visual odometry (VO) system called UnDeepVO in this paper. UnDeepVO is able to estimate the 6-DoF pose of a monocular camera and the depth of its view by using deep neural networks. There are two salient features of the proposed UnDeepVO: one is the unsupervised deep learning scheme, and the other is the absolute scale recovery. Specifically, we train UnDeepVO by using stereo image pairs to recover the scale but test it by using consecutive monocular images. Thus, UnDeepVO is a monocular system. The loss function defined for training the networks is based on spatial and temporal dense information. A system overview is shown in Fig. 1. The experiments on KITTI dataset show our UnDeepVO achieves good performance in terms of pose accuracy.","Wed, 20 Sep 2017 12:54:26 UTC (1,453 KB)[v2] Wed, 21 Feb 2018 14:44:30 UTC (1,453 KB)"
"1255","Updating the silent speech challenge benchmark with deep learning","Yan Ji, Licheng Liu, Hongcui Wang, Zhilei Liu, Zhibin Niu, Bruce Denby","Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)","The 2010 Silent Speech Challenge benchmark is updated with new results obtained in a Deep Learning strategy, using the same input features and decoding strategy as in the original article. A Word Error Rate of 6.4% is obtained, compared to the published value of 17.4%. Additional results comparing new auto-encoder-based features with the original features at reduced dimensionality, as well as decoding scenarios on two different language models, are also presented. The Silent Speech Challenge archive has been updated to contain both the original and the new auto-encoder features, in addition to the original raw data.","Wed, 20 Sep 2017 11:28:40 UTC (3,054 KB)"
"1256","Dex-Net 3.0: Computing Robust Robot Vacuum Suction Grasp Targets in Point Clouds using a New Analytic Model and Deep Learning","Jeffrey Mahler, Matthew Matl, Xinyu Liu, Albert Li, David Gealy, Ken Goldberg","Robotics (cs.RO)","Vacuum-based end effectors are widely used in industry and are often preferred over parallel-jaw and multifinger grippers due to their ability to lift objects with a single point of contact. Suction grasp planners often target planar surfaces on point clouds near the estimated centroid of an object. In this paper, we propose a compliant suction contact model that computes the quality of the seal between the suction cup and local target surface and a measure of the ability of the suction grasp to resist an external gravity wrench. To characterize grasps, we estimate robustness to perturbations in end-effector and object pose, material properties, and external wrenches. We analyze grasps across 1,500 3D object models to generate Dex-Net 3.0, a dataset of 2.8 million point clouds, suction grasps, and grasp robustness labels. We use Dex-Net 3.0 to train a Grasp Quality Convolutional Neural Network (GQ-CNN) to classify robust suction targets in point clouds containing a single object. We evaluate the resulting system in 350 physical trials on an ABB YuMi fitted with a pneumatic suction gripper. When evaluated on novel objects that we categorize as Basic (prismatic or cylindrical), Typical (more complex geometry), and Adversarial (with few available suction-grasp points) Dex-Net 3.0 achieves success rates of 98$\%$, 82$\%$, and 58$\%$ respectively, improving to 81$\%$ in the latter case when the training set includes only adversarial objects. Code, datasets, and supplemental material can be found at this http URL .","Tue, 19 Sep 2017 22:55:58 UTC (4,541 KB)[v2] Fri, 13 Apr 2018 05:27:01 UTC (5,761 KB)"
"1257","When 3D-Aided 2D Face Recognition Meets Deep Learning: An extended UR2D for Pose-Invariant Face Recognition","Xiang Xu, Pengfei Dou, Ha A. Le, Ioannis A. Kakadiaris","Computer Vision and Pattern Recognition (cs.CV)","Most of the face recognition works focus on specific modules or demonstrate a research idea. This paper presents a pose-invariant 3D-aided 2D face recognition system (UR2D) that is robust to pose variations as large as 90? by leveraging deep learning technology. The architecture and the interface of UR2D are described, and each module is introduced in detail. Extensive experiments are conducted on the UHDB31 and IJB-A, demonstrating that UR2D outperforms existing 2D face recognition systems such as VGG-Face, FaceNet, and a commercial off-the-shelf software (COTS) by at least 9% on the UHDB31 dataset and 3% on the IJB-A dataset on average in face identification tasks. UR2D also achieves state-of-the-art performance of 85% on the IJB-A dataset by comparing the Rank-1 accuracy score from template matching. It fills a gap by providing a 3D-aided 2D face recognition system that has compatible results with 2D face recognition systems using deep learning techniques.","Tue, 19 Sep 2017 17:02:15 UTC (1,237 KB)"
"1258","A Deep Learning-based Framework for Conducting Stealthy Attacks in Industrial Control Systems","Cheng Feng, Tingting Li, Zhanxing Zhu, Deeph Chana","Cryptography and Security (cs.CR)","Industrial control systems (ICS), which in many cases are components of critical national infrastructure, are increasingly being connected to other networks and the wider internet motivated by factors such as enhanced operational functionality and improved efficiency. However, set in this context, it is easy to see that the cyber attack surface of these systems is expanding, making it more important than ever that innovative solutions for securing ICS be developed and that the limitations of these solutions are well understood. The development of anomaly based intrusion detection techniques has provided capability for protecting ICS from the serious physical damage that cyber breaches are capable of delivering to them by monitoring sensor and control signals for abnormal activity. Recently, the use of so-called stealthy attacks has been demonstrated where the injection of false sensor measurements can be used to mimic normal control system signals, thereby defeating anomaly detectors whilst still delivering attack objectives. In this paper we define a deep learning-based framework which allows an attacker to conduct stealthy attacks with minimal a-priori knowledge of the target ICS. Specifically, we show that by intercepting the sensor and/or control signals in an ICS for a period of time, a malicious program is able to automatically learn to generate high-quality stealthy attacks which can achieve specific attack goals whilst bypassing a black box anomaly detector. Furthermore, we demonstrate the effectiveness of our framework for conducting stealthy attacks using two real-world ICS case studies. We contend that our results motivate greater attention on this area by the security community as we demonstrate that currently assumed barriers for the successful execution of such attacks are relaxed.","Tue, 19 Sep 2017 13:23:15 UTC (5,021 KB)"
"1259","Deep Learning for Automatic Stereotypical Motor Movement Detection using Wearable Sensors in Autism Spectrum Disorders","Nastaran Mohammadian Rad, Seyed Mostafa Kia, Calogero Zarbo, Twan van Laarhoven, Giuseppe Jurman, Paola Venuti, Elena Marchiori, Cesare Furlanello","Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)","Autism Spectrum Disorders are associated with atypical movements, of which stereotypical motor movements (SMMs) interfere with learning and social interaction. The automatic SMM detection using inertial measurement units (IMU) remains complex due to the strong intra and inter-subject variability, especially when handcrafted features are extracted from the signal. We propose a new application of the deep learning to facilitate automatic SMM detection using multi-axis IMUs. We use a convolutional neural network (CNN) to learn a discriminative feature space from raw data. We show how the CNN can be used for parameter transfer learning to enhance the detection rate on longitudinal data. We also combine the long short-term memory (LSTM) with CNN to model the temporal patterns in a sequence of multi-axis signals. Further, we employ ensemble learning to combine multiple LSTM learners into a more robust SMM detector. Our results show that: 1) feature learning outperforms handcrafted features; 2) parameter transfer learning is beneficial in longitudinal settings; 3) using LSTM to learn the temporal dynamic of signals enhances the detection rate especially for skewed training data; 4) an ensemble of LSTMs provides more accurate and stable detectors. These findings provide a significant step toward accurate SMM detection in real-time scenarios.","Thu, 14 Sep 2017 20:41:45 UTC (2,081 KB)"
"1260","AJILE Movement Prediction: Multimodal Deep Learning for Natural Human Neural Recordings and Video","Nancy Xin Ru Wang, Ali Farhadi, Rajesh Rao, Bingni Brunton","Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)","Developing useful interfaces between brains and machines is a grand challenge of neuroengineering. An effective interface has the capacity to not only interpret neural signals, but predict the intentions of the human to perform an action in the near future; prediction is made even more challenging outside well-controlled laboratory experiments. This paper describes our approach to detect and to predict natural human arm movements in the future, a key challenge in brain computer interfacing that has never before been attempted. We introduce the novel Annotated Joints in Long-term ECoG (AJILE) dataset; AJILE includes automatically annotated poses of 7 upper body joints for four human subjects over 670 total hours (more than 72 million frames), along with the corresponding simultaneously acquired intracranial neural recordings. The size and scope of AJILE greatly exceeds all previous datasets with movements and electrocorticography (ECoG), making it possible to take a deep learning approach to movement prediction. We propose a multimodal model that combines deep convolutional neural networks (CNN) with long short-term memory (LSTM) blocks, leveraging both ECoG and video modalities. We demonstrate that our models are able to detect movements and predict future movements up to 800 msec before movement initiation. Further, our multimodal movement prediction models exhibit resilience to simulated ablation of input neural signals. We believe a multimodal approach to natural neural decoding that takes context into account is critical in advancing bioelectronic technologies and human neuroscience.","Wed, 13 Sep 2017 01:28:44 UTC (9,616 KB)[v2] Thu, 1 Mar 2018 22:40:58 UTC (9,616 KB)"
"1261","Institutionally Distributed Deep Learning Networks","Ken Chang, Niranjan Balachandar, Carson K Lam, Darvin Yi, James M Brown, Andrew Beers, Bruce R Rosen, Daniel L Rubin, Jayashree Kalpathy-Cramer","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Medical Physics (physics.med-ph)","Deep learning has become a promising approach for automated medical diagnoses. When medical data samples are limited, collaboration among multiple institutions is necessary to achieve high algorithm performance. However, sharing patient data often has limitations due to technical, legal, or ethical concerns. In such cases, sharing a deep learning model is a more attractive alternative. The best method of performing such a task is unclear, however. In this study, we simulate the dissemination of learning deep learning network models across four institutions using various heuristics and compare the results with a deep learning model trained on centrally hosted patient data. The heuristics investigated include ensembling single institution models, single weight transfer, and cyclical weight transfer. We evaluated these approaches for image classification in three independent image collections (retinal fundus photos, mammography, and ImageNet). We find that cyclical weight transfer resulted in a performance (testing accuracy = 77.3%) that was closest to that of centrally hosted patient data (testing accuracy = 78.7%). We also found that there is an improvement in the performance of cyclical weight transfer heuristic with high frequency of weight transfer.","Sun, 10 Sep 2017 15:36:17 UTC (1,745 KB)"
"1262","Estimating regional ground-level PM2.5 directly from satellite top-of-atmosphere reflectance using deep learning","Huanfeng Shen, Tongwen Li, Qiangqiang Yuan, Liangpei Zhang","Atmospheric and Oceanic Physics (physics.ao-ph)","Almost all remote sensing atmospheric PM2.5 estimation methods need satellite aerosol optical depth (AOD) products, which are often retrieved from top-of-atmosphere (TOA) reflectance via an atmospheric radiative transfer model. Then, is it possible to estimate ground-level PM2.5 directly from satellite TOA reflectance without a physical model? In this study, this challenging work are achieved based on a machine learning model. Specifically, we establish the relationship between PM2.5, satellite TOA reflectance, observation angles, and meteorological factors in a deep learning architecture (denoted as Ref-PM modeling). Taking the Wuhan Urban Agglomeration (WUA) as a case study, the results demonstrate that compared with the AOD-PM modeling, the Ref-PM modeling obtains a competitive performance, with out-of-sample cross-validated R2 and RMSE values of 0.87 and 9.89 ug/m3 respectively. Also, the TOA-reflectance-derived PM2.5 have a finer resolution and larger spatial coverage than the AOD-derived PM2.5. This work updates the traditional cognition of remote sensing PM2.5 estimation and has the potential to promote the application in atmospheric environmental monitoring.","Mon, 18 Sep 2017 13:26:25 UTC (1,468 KB)[v2] Tue, 6 Feb 2018 08:57:21 UTC (1,602 KB)"
"1263","Exploring deep learning as an event classification method for the Cherenkov Telescope Array","D. Nieto, A. Brill, B. Kim, T. B. Humensky, for the Cherenkov Telescope Array","Instrumentation and Methods for Astrophysics (astro-ph.IM)","Telescopes based on the imaging atmospheric Cherenkov technique (IACTs) detect images of the atmospheric showers generated by gamma rays and cosmic rays as they are absorbed by the atmosphere. The much more frequent cosmic-ray events form the main background when looking for gamma-ray sources, and therefore IACT sensitivity is significantly driven by the capability to distinguish between these two types of events. Supervised learning algorithms, like random forests and boosted decision trees, have been shown to effectively classify IACT events. In this contribution we present results from exploratory work using deep learning as an event classification method for the Cherenkov Telescope Array (CTA). CTA, conceived as an array of tens of IACTs, is an international project for a next-generation ground-based gamma-ray observatory, aiming to improve on the sensitivity of current-generation experiments by an order of magnitude and provide energy coverage from 20 GeV to more than 300 TeV.","Mon, 18 Sep 2017 12:17:34 UTC (138 KB)"
"1264","IBM Deep Learning Service","Bishwaranjan Bhattacharjee, Scott Boag, Chandani Doshi, Parijat Dube, Ben Herta, Vatche Ishakian, K. R. Jayaram, Rania Khalaf, Avesh Krishna, Yu Bo Li, Vinod Muthusamy, Ruchir Puri, Yufei Ren, Florian Rosenberg, Seetharami R. Seelam, Yandong Wang, Jian Ming Zhang, Li Zhang","Distributed, Parallel, and Cluster Computing (cs.DC)","Deep learning driven by large neural network models is overtaking traditional machine learning methods for understanding unstructured and perceptual data domains such as speech, text, and vision. At the same time, the ""as-a-Service""-based business model on the cloud is fundamentally transforming the information technology industry. These two trends: deep learning, and ""as-a-service"" are colliding to give rise to a new business model for cognitive application delivery: deep learning as a service in the cloud. In this paper, we will discuss the details of the software architecture behind IBM's deep learning as a service (DLaaS). DLaaS provides developers the flexibility to use popular deep learning libraries such as Caffe, Torch and TensorFlow, in the cloud in a scalable and resilient manner with minimal effort. The platform uses a distribution and orchestration layer that facilitates learning from a large amount of data in a reasonable amount of time across compute nodes. A resource provisioning layer enables flexible job management on heterogeneous resources, such as graphics processing units (GPUs) and central processing units (CPUs), in an infrastructure as a service (IaaS) cloud.","Mon, 18 Sep 2017 11:40:48 UTC (610 KB)"
"1265","ZhuSuan: A Library for Bayesian Deep Learning","Jiaxin Shi, Jianfei Chen, Jun Zhu, Shengyang Sun, Yucen Luo, Yihong Gu, Yuhao Zhou","Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Computation (stat.CO)","In this paper we introduce ZhuSuan, a python probabilistic programming library for Bayesian deep learning, which conjoins the complimentary advantages of Bayesian methods and deep learning. ZhuSuan is built upon Tensorflow. Unlike existing deep learning libraries, which are mainly designed for deterministic neural networks and supervised tasks, ZhuSuan is featured for its deep root into Bayesian inference, thus supporting various kinds of probabilistic models, including both the traditional hierarchical Bayesian models and recent deep generative models. We use running examples to illustrate the probabilistic programming on ZhuSuan, including Bayesian logistic regression, variational auto-encoders, deep sigmoid belief networks and Bayesian recurrent neural networks.","Mon, 18 Sep 2017 11:30:08 UTC (655 KB)"
"1266","Adaptive Laplace Mechanism: Differential Privacy Preservation in Deep Learning","NhatHai Phan, Xintao Wu, Han Hu, Dejing Dou","Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)","In this paper, we focus on developing a novel mechanism to preserve differential privacy in deep neural networks, such that: (1) The privacy budget consumption is totally independent of the number of training steps; (2) It has the ability to adaptively inject noise into features based on the contribution of each to the output; and (3) It could be applied in a variety of different deep neural networks. To achieve this, we figure out a way to perturb affine transformations of neurons, and loss functions used in deep neural networks. In addition, our mechanism intentionally adds ""more noise"" into features which are ""less relevant"" to the model output, and vice-versa. Our theoretical analysis further derives the sensitivities and error bounds of our mechanism. Rigorous experiments conducted on MNIST and CIFAR-10 datasets show that our mechanism is highly effective and outperforms existing solutions.","Mon, 18 Sep 2017 02:37:40 UTC (927 KB)[v2] Mon, 23 Apr 2018 02:45:14 UTC (1,487 KB)"
"1267","Multi-scale Deep Learning Architectures for Person Re-identification","Xuelin Qian, Yanwei Fu, Yu-Gang Jiang, Tao Xiang, Xiangyang Xue","Computer Vision and Pattern Recognition (cs.CV)","Person Re-identification (re-id) aims to match people across non-overlapping camera views in a public space. It is a challenging problem because many people captured in surveillance videos wear similar clothes. Consequently, the differences in their appearance are often subtle and only detectable at the right location and scales. Existing re-id models, particularly the recently proposed deep learning based ones match people at a single scale. In contrast, in this paper, a novel multi-scale deep learning model is proposed. Our model is able to learn deep discriminative feature representations at different scales and automatically determine the most suitable scales for matching. The importance of different spatial locations for extracting discriminative features is also learned explicitly. Experiments are carried out to demonstrate that the proposed model outperforms the state-of-the art on a number of benchmarks","Fri, 15 Sep 2017 11:53:59 UTC (7,020 KB)"
"1268","Accelerating SGD for Distributed Deep-Learning Using Approximated Hessian Matrix","Sebastien M. R. Arnold, Chunming Wang","Machine Learning (cs.LG)","We introduce a novel method to compute a rank $m$ approximation of the inverse of the Hessian matrix in the distributed regime. By leveraging the differences in gradients and parameters of multiple Workers, we are able to efficiently implement a distributed approximation of the Newton-Raphson method. We also present preliminary results which underline advantages and challenges of second-order methods for large stochastic optimization problems. In particular, our work suggests that novel strategies for combining gradients provide further information on the loss surface.","Fri, 15 Sep 2017 06:27:49 UTC (105 KB)"
"1269","Deep Learning of Quasar Spectra to Discover and Characterize Damped Lya Systems","David Parks, J. Xavier Prochaska, Shawfeng Dong, Zheng Cai","Astrophysics of Galaxies (astro-ph.GA)","We have designed, developed, and applied a convolutional neural network (CNN) architecture using multi-task learning to search for and characterize strong HI Lya absorption in quasar spectra. Without any explicit modeling of the quasar continuum nor application of the predicted line-profile for Lya from quantum mechanics, our algorithm predicts the presence of strong HI absorption and estimates the corresponding redshift zabs and HI column density NHI, with emphasis on damped Lya systems (DLAs, absorbers with log NHI > 20.3). We tuned the CNN model using a custom training set of DLAs injected into DLA-free quasar spectra from the Sloan Digital Sky Survey (SDSS), data release 5 (DR5). Testing on a held-back validation set demonstrates a high incidence of DLAs recovered by the algorithm (97.4% as DLAs and 99% as an HI absorber with log NHI > 19.5) and excellent estimates for zabs and NHI. Similar results are obtained against a human-generated survey of the SDSS DR5 dataset. The algorithm yields a low incidence of false positives and negatives but is challenged by overlapping DLAs and/or very high NHI systems. We have applied this CNN model to the quasar spectra of SDSS-DR7 and the Baryonic Oscillation Spectroscopic Survey (BOSS, data release 12) and provide catalogs of 4,913 and 50,969 DLAs respectively (including 1,659 and 9,230 high-confidence DLAs that were previously unpublished). This work validates the application of deep learning techniques to astronomical spectra for both classification and quantitative measurements.","Thu, 14 Sep 2017 20:11:57 UTC (2,820 KB)"
"1270","Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting","Bing Yu, Haoteng Yin, Zhanxing Zhu","Machine Learning (cs.LG); Machine Learning (stat.ML)","Timely accurate traffic forecast is crucial for urban traffic control and guidance. Due to the high nonlinearity and complexity of traffic flow, traditional methods cannot satisfy the requirements of mid-and-long term prediction tasks and often neglect spatial and temporal dependencies. In this paper, we propose a novel deep learning framework, Spatio-Temporal Graph Convolutional Networks (STGCN), to tackle the time series prediction problem in traffic domain. Instead of applying regular convolutional and recurrent units, we formulate the problem on graphs and build the model with complete convolutional structures, which enable much faster training speed with fewer parameters. Experiments show that our model STGCN effectively captures comprehensive spatio-temporal correlations through modeling multi-scale traffic networks and consistently outperforms state-of-the-art baselines on various real-world traffic datasets.","Thu, 14 Sep 2017 16:54:41 UTC (1,050 KB)[v2] Mon, 25 Sep 2017 09:17:45 UTC (1,006 KB)[v3] Thu, 1 Feb 2018 13:52:01 UTC (560 KB)[v4] Thu, 12 Jul 2018 07:55:09 UTC (514 KB)"
"1271","An Exploration of 2D and 3D Deep Learning Techniques for Cardiac MR Image Segmentation","Christian F. Baumgartner, Lisa M. Koch, Marc Pollefeys, Ender Konukoglu","Computer Vision and Pattern Recognition (cs.CV)","Accurate segmentation of the heart is an important step towards evaluating cardiac function. In this paper, we present a fully automated framework for segmentation of the left (LV) and right (RV) ventricular cavities and the myocardium (Myo) on short-axis cardiac MR images. We investigate various 2D and 3D convolutional neural network architectures for this task. We investigate the suitability of various state-of-the art 2D and 3D convolutional neural network architectures, as well as slight modifications thereof, for this task. Experiments were performed on the ACDC 2017 challenge training dataset comprising cardiac MR images of 100 patients, where manual reference segmentations were made available for end-diastolic (ED) and end-systolic (ES) frames. We find that processing the images in a slice-by-slice fashion using 2D networks is beneficial due to a relatively large slice thickness. However, the exact network architecture only plays a minor role. We report mean Dice coefficients of $0.950$ (LV), $0.893$ (RV), and $0.899$ (Myo), respectively with an average evaluation time of 1.1 seconds per volume on a modern GPU.","Wed, 13 Sep 2017 18:36:48 UTC (1,549 KB)[v2] Tue, 10 Oct 2017 08:09:31 UTC (2,353 KB)"
"1272","A Tutorial on Deep Learning for Music Information Retrieval","Keunwoo Choi, Gyorgy Fazekas, Kyunghyun Cho, Mark Sandler","Computer Vision and Pattern Recognition (cs.CV); Sound (cs.SD)","Following their success in Computer Vision and other areas, deep learning techniques have recently become widely adopted in Music Information Retrieval (MIR) research. However, the majority of works aim to adopt and assess methods that have been shown to be effective in other domains, while there is still a great need for more original research focusing on music primarily and utilising musical knowledge and insight. The goal of this paper is to boost the interest of beginners by providing a comprehensive tutorial and reducing the barriers to entry into deep learning for MIR. We lay out the basic principles and review prominent works in this hard to navigate the field. We then outline the network structures that have been successful in MIR problems and facilitate the selection of building blocks for the problems at hand. Finally, guidelines for new tasks and some advanced topics in deep learning are discussed to stimulate new research in this fascinating field.","Wed, 13 Sep 2017 16:05:51 UTC (1,406 KB)[v2] Thu, 3 May 2018 06:29:55 UTC (1,406 KB)"
"1273","Action Schema Networks: Generalised Policies with Deep Learning","Sam Toyer, Felipe Trevizan, Sylvie Thiebaux, Lexing Xie","Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","In this paper, we introduce the Action Schema Network (ASNet): a neural network architecture for learning generalised policies for probabilistic planning problems. By mimicking the relational structure of planning problems, ASNets are able to adopt a weight-sharing scheme which allows the network to be applied to any problem from a given planning domain. This allows the cost of training the network to be amortised over all problems in that domain. Further, we propose a training method which balances exploration and supervised training on small problems to produce a policy which remains robust when evaluated on larger problems. In experiments, we show that ASNet's learning capability allows it to significantly outperform traditional non-learning planners in several challenging domains.","Wed, 13 Sep 2017 12:15:52 UTC (1,188 KB)[v2] Fri, 22 Dec 2017 07:59:26 UTC (1,320 KB)"
"1274","Co-training for Demographic Classification Using Deep Learning from Label Proportions","Ehsan Mohammady Ardehaly, Aron Culotta","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning algorithms have recently produced state-of-the-art accuracy in many classification tasks, but this success is typically dependent on access to many annotated training examples. For domains without such data, an attractive alternative is to train models with light, or distant supervision. In this paper, we introduce a deep neural network for the Learning from Label Proportion (LLP) setting, in which the training data consist of bags of unlabeled instances with associated label distributions for each bag. We introduce a new regularization layer, Batch Averager, that can be appended to the last layer of any deep neural network to convert it from supervised learning to LLP. This layer can be implemented readily with existing deep learning packages. To further support domains in which the data consist of two conditionally independent feature views (e.g. image and text), we propose a co-training algorithm that iteratively generates pseudo bags and refits the deep LLP model to improve classification accuracy. We demonstrate our models on demographic attribute classification (gender and race/ethnicity), which has many applications in social media analysis, public health, and marketing. We conduct experiments to predict demographics of Twitter users based on their tweets and profile image, without requiring any user-level annotations for training. We find that the deep LLP approach outperforms baselines for both text and image features separately. Additionally, we find that co-training algorithm improves image and text classification by 4% and 8% absolute F1, respectively. Finally, an ensemble of text and image classifiers further improves the absolute F1 measure by 4% on average.","Wed, 13 Sep 2017 02:06:19 UTC (3,564 KB)"
"1275","Interpreting Shared Deep Learning Models via Explicable Boundary Trees","Huijun Wu, Chen Wang, Jie Yin, Kai Lu, Liming Zhu","Machine Learning (cs.LG); Human-Computer Interaction (cs.HC)","Despite outperforming the human in many tasks, deep neural network models are also criticized for the lack of transparency and interpretability in decision making. The opaqueness results in uncertainty and low confidence when deploying such a model in model sharing scenarios, when the model is developed by a third party. For a supervised machine learning model, sharing training process including training data provides an effective way to gain trust and to better understand model predictions. However, it is not always possible to share all training data due to privacy and policy constraints. In this paper, we propose a method to disclose a small set of training data that is just sufficient for users to get the insight of a complicated model. The method constructs a boundary tree using selected training data and the tree is able to approximate the complicated model with high fidelity. We show that traversing data points in the tree gives users significantly better understanding of the model and paves the way for trustworthy model sharing.","Tue, 12 Sep 2017 08:13:24 UTC (3,494 KB)"
"1276","NiftyNet: a deep-learning platform for medical imaging","Eli Gibson, Wenqi Li, Carole Sudre, Lucas Fidon, Dzhoshkun I. Shakir, Guotai Wang, Zach Eaton-Rosen, Robert Gray, Tom Doel, Yipeng Hu, Tom Whyntie, Parashkev Nachev, Marc Modat, Dean C. Barratt, Sebastien Ourselin, M. Jorge Cardoso, Tom Vercauteren","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Medical image analysis and computer-assisted intervention problems are increasingly being addressed with deep-learning-based solutions. Established deep-learning platforms are flexible but do not provide specific functionality for medical image analysis and adapting them for this application requires substantial implementation effort. Thus, there has been substantial duplication of effort and incompatible infrastructure developed across many research groups. This work presents the open-source NiftyNet platform for deep learning in medical imaging. The ambition of NiftyNet is to accelerate and simplify the development of these solutions, and to provide a common mechanism for disseminating research outputs for the community to use, adapt and build upon. NiftyNet provides a modular deep-learning pipeline for a range of medical imaging applications including segmentation, regression, image generation and representation learning applications. Components of the NiftyNet pipeline including data loading, data augmentation, network architectures, loss functions and evaluation metrics are tailored to, and take advantage of, the idiosyncracies of medical image analysis and computer-assisted intervention. NiftyNet is built on TensorFlow and supports TensorBoard visualization of 2D and 3D images and computational graphs by default. We present 3 illustrative medical image analysis applications built using NiftyNet: (1) segmentation of multiple abdominal organs from computed tomography; (2) image regression to predict computed tomography attenuation maps from brain magnetic resonance images; and (3) generation of simulated ultrasound images for specified anatomical poses. NiftyNet enables researchers to rapidly develop and distribute deep learning solutions for segmentation, regression, image generation and representation learning applications, or extend the platform to new applications.","Mon, 11 Sep 2017 17:42:10 UTC (1,370 KB)[v2] Mon, 16 Oct 2017 13:46:31 UTC (1,599 KB)"
"1277","What does fault tolerant Deep Learning need from MPI?","Vinay Amatya, Abhinav Vishnu, Charles Siegel, Jeff Daily","Distributed, Parallel, and Cluster Computing (cs.DC)","Deep Learning (DL) algorithms have become the de facto Machine Learning (ML) algorithm for large scale data analysis. DL algorithms are computationally expensive - even distributed DL implementations which use MPI require days of training (model learning) time on commonly studied datasets. Long running DL applications become susceptible to faults - requiring development of a fault tolerant system infrastructure, in addition to fault tolerant DL algorithms. This raises an important question: What is needed from MPI for de- signing fault tolerant DL implementations? In this paper, we address this problem for permanent faults. We motivate the need for a fault tolerant MPI specification by an in-depth consideration of recent innovations in DL algorithms and their properties, which drive the need for specific fault tolerance features. We present an in-depth discussion on the suitability of different parallelism types (model, data and hybrid); a need (or lack thereof) for check-pointing of any critical data structures; and most importantly, consideration for several fault tolerance proposals (user-level fault mitigation (ULFM), Reinit) in MPI and their applicability to fault tolerant DL implementations. We leverage a distributed memory implementation of Caffe, currently available under the Machine Learning Toolkit for Extreme Scale (MaTEx). We implement our approaches by ex- tending MaTEx-Caffe for using ULFM-based implementation. Our evaluation using the ImageNet dataset and AlexNet, and GoogLeNet neural network topologies demonstrates the effectiveness of the proposed fault tolerant DL implementation using OpenMPI based ULFM.","Mon, 11 Sep 2017 10:08:24 UTC (382 KB)"
"1278","Fully Optical Spacecraft Communications: Implementing an Omnidirectional PV-Cell Receiver and 8Mb/s LED Visible Light Downlink with Deep Learning Error Correction","Sihao Huang, Haowen Lin","Networking and Internet Architecture (cs.NI)","Free space optical communication techniques have been the subject of numerous investigations in recent years, with multiple missions expected to fly in the near future. Existing methods require high pointing accuracies, drastically driving up overall system cost. Recent developments in LED-based visible light communication (VLC) and past in-orbit experiments have convinced us that the technology has reached a critical level of maturity. On these premises, we propose a new optical communication system utilizing a VLC downlink and a high throughput, omnidirectional photovoltaic cell receiver system. By performing error-correction via deep learning methods and by utilizing phase-delay interference, the system is able to deliver data rates that match those of traditional laser-based solutions. A prototype of the proposed system has been constructed, demonstrating the scheme to be a feasible alternative to laser-based methods. This creates an opportunity for the full scale development of optical communication techniques on small spacecraft as a backup telemetry beacon or as a high throughput link.","Mon, 11 Sep 2017 02:51:08 UTC (6,096 KB)[v2] Wed, 3 Jan 2018 04:17:19 UTC (6,097 KB)"
"1279","Robust Emotion Recognition from Low Quality and Low Bit Rate Video: A Deep Learning Approach","Bowen Cheng, Zhangyang Wang, Zhaobin Zhang, Zhu Li, Ding Liu, Jianchao Yang, Shuai Huang, Thomas S. Huang","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","Emotion recognition from facial expressions is tremendously useful, especially when coupled with smart devices and wireless multimedia applications. However, the inadequate network bandwidth often limits the spatial resolution of the transmitted video, which will heavily degrade the recognition reliability. We develop a novel framework to achieve robust emotion recognition from low bit rate video. While video frames are downsampled at the encoder side, the decoder is embedded with a deep network model for joint super-resolution (SR) and recognition. Notably, we propose a novel max-mix training strategy, leading to a single ""One-for-All"" model that is remarkably robust to a vast range of downsampling factors. That makes our framework well adapted for the varied bandwidths in real transmission scenarios, without hampering scalability or efficiency. The proposed framework is evaluated on the AVEC 2016 benchmark, and demonstrates significantly improved stand-alone recognition performance, as well as rate-distortion (R-D) performance, than either directly recognizing from LR frames, or separating SR and recognition.","Sun, 10 Sep 2017 16:31:56 UTC (206 KB)"
"1280","Urban morphology meets deep learning: Exploring urban forms in one million cities, town and villages across the planet","Vahid Moosavi","Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)","Study of urban form is an important area of research in urban planning/design that contributes to our understanding of how cities function and evolve. However, classical approaches are based on very limited observations and inconsistent methods. As an alternative, availability of massive urban data collections such as Open Street Map from the one hand and the recent advancements in machine learning methods such as deep learning techniques on the other have opened up new possibilities to automatically investigate urban forms at the global scale. In this work for the first time, by collecting a large data set of street networks in more than one million cities, towns and villages all over the world, we trained a deep convolutional auto-encoder, that automatically learns the hierarchical structures of urban forms and represents them via dense and comparable vectors. We showed how the learned urban vectors could be used for different investigations. Using the learned urban vectors, one is able to easily find and compare similar urban forms all over the world, considering their overall spatial structure and other factors such as orientation, graphical structure, and density and partial deformations. Further cluster analysis reveals the distribution of the main patterns of urban forms all over the planet.","Sat, 9 Sep 2017 10:06:48 UTC (7,469 KB)[v2] Tue, 12 Sep 2017 10:30:20 UTC (7,469 KB)"
"1281","Deep Packet: A Novel Approach For Encrypted Traffic Classification Using Deep Learning","Mohammad Lotfollahi, Ramin Shirali Hossein Zade, Mahdi Jafari Siavoshani, Mohammdsadegh Saberian","Machine Learning (cs.LG); Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI)","Internet traffic classification has become more important with rapid growth of current Internet network and online applications. There have been numerous studies on this topic which have led to many different approaches. Most of these approaches use predefined features extracted by an expert in order to classify network traffic. In contrast, in this study, we propose a \emph{deep learning} based approach which integrates both feature extraction and classification phases into one system. Our proposed scheme, called ""Deep Packet,"" can handle both \emph{traffic characterization} in which the network traffic is categorized into major classes (\eg, FTP and P2P) and application identification in which end-user applications (\eg, BitTorrent and Skype) identification is desired. Contrary to most of the current methods, Deep Packet can identify encrypted traffic and also distinguishes between VPN and non-VPN network traffic. After an initial pre-processing phase on data, packets are fed into Deep Packet framework that embeds stacked autoencoder and convolution neural network in order to classify network traffic. Deep packet with CNN as its classification model achieved recall of $0.98$ in application identification task and $0.94$ in traffic categorization task. To the best of our knowledge, Deep Packet outperforms all of the proposed classification methods on UNB ISCX VPN-nonVPN dataset.","Fri, 8 Sep 2017 11:40:37 UTC (848 KB)[v2] Sun, 24 Sep 2017 12:13:18 UTC (218 KB)[v3] Wed, 4 Jul 2018 07:54:04 UTC (392 KB)"
"1282","Deep learning for undersampled MRI reconstruction","Chang Min Hyun, Hwa Pyung Kim, Sung Min Lee, Sungchul Lee, Jin Keun Seo","Machine Learning (stat.ML); Machine Learning (cs.LG); Medical Physics (physics.med-ph)","This paper presents a deep learning method for faster magnetic resonance imaging (MRI) by reducing k-space data with sub-Nyquist sampling strategies and provides a rationale for why the proposed approach works well. Uniform subsampling is used in the time-consuming phase-encoding direction to capture high-resolution image information, while permitting the image-folding problem dictated by the Poisson summation formula. To deal with the localization uncertainty due to image folding, very few low-frequency k-space data are added. Training the deep learning net involves input and output images that are pairs of Fourier transforms of the subsampled and fully sampled k-space data. Numerous experiments show the remarkable performance of the proposed method; only 29% of k-space data can generate images of high quality as effectively as standard MRI reconstruction with fully sampled data.","Fri, 8 Sep 2017 07:35:58 UTC (1,869 KB)[v2] Mon, 11 Sep 2017 00:38:47 UTC (1,869 KB)"
"1283","DeepFense: Online Accelerated Defense Against Adversarial Deep Learning","Bita Darvish Rouhani, Mohammad Samragh, Mojan Javaheripi, Tara Javidi, Farinaz Koushanfar","Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)","Recent advances in adversarial Deep Learning (DL) have opened up a largely unexplored surface for malicious attacks jeopardizing the integrity of autonomous DL systems. With the wide-spread usage of DL in critical and time-sensitive applications, including unmanned vehicles, drones, and video surveillance systems, online detection of malicious inputs is of utmost importance. We propose DeepFense, the first end-to-end automated framework that simultaneously enables efficient and safe execution of DL models. DeepFense formalizes the goal of thwarting adversarial attacks as an optimization problem that minimizes the rarely observed regions in the latent feature space spanned by a DL network. To solve the aforementioned minimization problem, a set of complementary but disjoint modular redundancies are trained to validate the legitimacy of the input samples in parallel with the victim DL model. DeepFense leverages hardware/software/algorithm co-design and customized acceleration to achieve just-in-time performance in resource-constrained settings. The proposed countermeasure is unsupervised, meaning that no adversarial sample is leveraged to train modular redundancies. We further provide an accompanying API to reduce the non-recurring engineering cost and ensure automated adaptation to various platforms. Extensive evaluations on FPGAs and GPUs demonstrate up to two orders of magnitude performance improvement while enabling online adversarial sample detection.","Fri, 8 Sep 2017 04:53:51 UTC (8,397 KB)[v2] Fri, 22 Dec 2017 01:37:12 UTC (4,014 KB)[v3] Sun, 1 Apr 2018 18:30:00 UTC (3,616 KB)[v4] Tue, 21 Aug 2018 02:54:23 UTC (1,302 KB)"
"1284","Deep Learning the Physics of Transport Phenomena","Amir Barati Farimani, Joseph Gomes, Vijay S. Pande","Machine Learning (cs.LG); Computational Physics (physics.comp-ph)","We have developed a new data-driven paradigm for the rapid inference, modeling and simulation of the physics of transport phenomena by deep learning. Using conditional generative adversarial networks (cGAN), we train models for the direct generation of solutions to steady state heat conduction and incompressible fluid flow purely on observation without knowledge of the underlying governing equations. Rather than using iterative numerical methods to approximate the solution of the constitutive equations, cGANs learn to directly generate the solutions to these phenomena, given arbitrary boundary conditions and domain, with high test accuracy (MAE$<$1\%) and state-of-the-art computational performance. The cGAN framework can be used to learn causal models directly from experimental observations where the underlying physical model is complex or unknown.","Thu, 7 Sep 2017 19:57:26 UTC (3,760 KB)"
"1285","Insightful classification of crystal structures using deep learning","A. Ziletti, D. Kumar, M. Scheffler, L. M. Ghiringhelli","Materials Science (cond-mat.mtrl-sci); Disordered Systems and Neural Networks (cond-mat.dis-nn)","Computational methods that automatically extract knowledge from data are critical for enabling data-driven materials science. A reliable identification of lattice symmetry is a crucial first step for materials characterization and analytics. Current methods require a user-specified threshold, and are unable to detect average symmetries for defective structures. Here, we propose a machine-learning-based approach to automatically classify structures by crystal symmetry. First, we represent crystals by calculating a diffraction image, then construct a deep-learning neural-network model for classification. Our approach is able to correctly classify a dataset comprising more than 100 000 simulated crystal structures, including heavily defective ones. The internal operations of the neural network are unraveled through attentive response maps, demonstrating that it uses the same landmarks a materials scientist would use, although never explicitly instructed to do so. Our study paves the way for crystal-structure recognition of - possibly noisy and incomplete - three-dimensional structural data in big-data materials science.","Thu, 7 Sep 2017 15:09:27 UTC (2,376 KB)[v2] Wed, 30 May 2018 06:11:23 UTC (4,646 KB)"
"1286","Improving Sonar Image Patch Matching via Deep Learning","Matias Valdenegro-Toro","Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","Matching sonar images with high accuracy has been a problem for a long time, as sonar images are inherently hard to model due to reflections, noise and viewpoint dependence. Autonomous Underwater Vehicles require good sonar image matching capabilities for tasks such as tracking, simultaneous localization and mapping (SLAM) and some cases of object detection/recognition. We propose the use of Convolutional Neural Networks (CNN) to learn a matching function that can be trained from labeled sonar data, after pre-processing to generate matching and non-matching pairs. In a dataset of 39K training pairs, we obtain 0.91 Area under the ROC Curve (AUC) for a CNN that outputs a binary classification matching decision, and 0.89 AUC for another CNN that outputs a matching score. In comparison, classical keypoint matching methods like SIFT, SURF, ORB and AKAZE obtain AUC 0.61 to 0.68. Alternative learning methods obtain similar results, with a Random Forest Classifier obtaining AUC 0.79, and a Support Vector Machine resulting in AUC 0.66.","Thu, 7 Sep 2017 09:25:58 UTC (2,356 KB)"
"1287","Deep Learning Beyond Lefschetz Thimbles","Andrei Alexandru, Paulo Bedaque, Henry Lamm, Scott Lawrence","High Energy Physics - Lattice (hep-lat)","The generalized thimble method to treat field theories with sign problems requires repeatedly solving the computationally-expensive holomorphic flow equations. We present a machine learning technique to bypass this problem. The central idea is to obtain a few field configurations via the flow equations to train a feed-forward neural network. The trained network defines a new manifold of integration which reduces the sign problem and can be rapidly sampled. We present results for the $1+1$ dimensional Thirring model with Wilson fermions on sizable lattices. In addition to the gain in speed, the parameterization of the integration manifold we use avoids the ""trapping"" of Monte Carlo chains which plagues large-flow calculations, a considerable shortcoming of the previous attempts.","Wed, 6 Sep 2017 19:32:34 UTC (569 KB)"
"1288","Implicit Regularization in Deep Learning","Behnam Neyshabur","Machine Learning (cs.LG)","In an attempt to better understand generalization in deep learning, we study several possible explanations. We show that implicit regularization induced by the optimization method is playing a key role in generalization and success of deep learning models. Motivated by this view, we study how different complexity measures can ensure generalization and explain how optimization algorithms can implicitly regularize complexity measures. We empirically investigate the ability of these measures to explain different observed phenomena in deep learning. We further study the invariances in neural networks, suggest complexity measures and optimization algorithms that have similar invariances to those in neural networks and evaluate them on a number of learning tasks.","Wed, 6 Sep 2017 18:12:04 UTC (4,563 KB)[v2] Fri, 8 Sep 2017 03:27:06 UTC (4,563 KB)"
"1289","Deep learning from crowds","Filipe Rodrigues, Francisco Pereira","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)","Over the last few years, deep learning has revolutionized the field of machine learning by dramatically improving the state-of-the-art in various domains. However, as the size of supervised artificial neural networks grows, typically so does the need for larger labeled datasets. Recently, crowdsourcing has established itself as an efficient and cost-effective solution for labeling large sets of data in a scalable manner, but it often requires aggregating labels from multiple noisy contributors with different levels of expertise. In this paper, we address the problem of learning deep neural networks from crowds. We begin by describing an EM algorithm for jointly learning the parameters of the network and the reliabilities of the annotators. Then, a novel general-purpose crowd layer is proposed, which allows us to train deep neural networks end-to-end, directly from the noisy labels of multiple annotators, using only backpropagation. We empirically show that the proposed approach is able to internally capture the reliability and biases of different annotators and achieve new state-of-the-art results for various crowdsourced datasets across different settings, namely classification, regression and sequence labeling.","Wed, 6 Sep 2017 11:41:19 UTC (585 KB)[v2] Mon, 25 Dec 2017 12:30:12 UTC (595 KB)"
"1290","Boosting Deep Learning Risk Prediction with Generative Adversarial Networks for Electronic Health Records","Zhengping Che, Yu Cheng, Shuangfei Zhai, Zhaonan Sun, Yan Liu","Machine Learning (cs.LG); Machine Learning (stat.ML)","The rapid growth of Electronic Health Records (EHRs), as well as the accompanied opportunities in Data-Driven Healthcare (DDH), has been attracting widespread interests and attentions. Recent progress in the design and applications of deep learning methods has shown promising results and is forcing massive changes in healthcare academia and industry, but most of these methods rely on massive labeled data. In this work, we propose a general deep learning framework which is able to boost risk prediction performance with limited EHR data. Our model takes a modified generative adversarial network namely ehrGAN, which can provide plausible labeled EHR data by mimicking real patient records, to augment the training dataset in a semi-supervised learning manner. We use this generative model together with a convolutional neural network (CNN) based prediction model to improve the onset prediction performance. Experiments on two real healthcare datasets demonstrate that our proposed framework produces realistic data samples and achieves significant improvements on classification tasks with the generated data over several stat-of-the-art baselines.","Wed, 6 Sep 2017 01:36:12 UTC (512 KB)"
"1291","Deep Learning Techniques for Music Generation - A Survey","Jean-Pierre Briot, Gaetan Hadjeres, Francois Pachet","Sound (cs.SD); Machine Learning (cs.LG)","This paper is a survey and an analysis of different ways of using deep learning (deep artificial neural networks) to generate musical content. We propose a methodology based on five dimensions for our analysis: - Objective - What musical content is to be generated? E.g., melody, polyphony, accompaniment and counterpoint - For what destination and for what use? To be performed by a human(s) or by a machine. - Representation - What are the concepts to be manipulated? E.g., waveform, spectrogram, note, chord, meter, and beat - What format is to be used? E.g., MIDI, piano roll and text - How will the representation be encoded? E.g., scalar, one-hot, and many-hot. - Architecture - What type of deep neural network is to be used? E.g., feedforward network, recurrent network, autoencoder, and generative adversarial networks. - Challenges - What are the limitations\index and open challenges? E.g., variability, interactivity and creativity. - Strategy - How do we model and control the process of generation? E.g., single-step feedforward, decoder feedforward, sampling and input manipulation. For each dimension, we conduct a comparative analysis of various models and techniques and we propose some tentative multidimensional typology. This typology is bottom-up, based on the analysis of many existing deep-learning based systems for music generation selected from the relevant literature. These systems are described in this survey/analysis and are used to exemplify the various choices of objective, representation, architecture, challenges and strategies. The final part of the paper includes some discussion and some prospects. This paper is a simplified (weak DRM) version of the following book: Jean-Pierre Briot, Gaetan Hadjeres and Francois Pachet, Deep Learning Techniques for Music Generation, Computational Synthesis and Creative Systems, Springer Nature, 2019.","Tue, 5 Sep 2017 23:12:01 UTC (7,376 KB)[v2] Sat, 10 Nov 2018 17:02:35 UTC (8,149 KB)"
"1292","Opening the Black Box of Financial AI with CLEAR-Trade: A CLass-Enhanced Attentive Response Approach for Explaining and Visualizing Deep Learning-Driven Stock Market Prediction","Devinder Kumar, Graham W Taylor, Alexander Wong","Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)","Deep learning has been shown to outperform traditional machine learning algorithms across a wide range of problem domains. However, current deep learning algorithms have been criticized as uninterpretable ""black-boxes"" which cannot explain their decision making processes. This is a major shortcoming that prevents the widespread application of deep learning to domains with regulatory processes such as finance. As such, industries such as finance have to rely on traditional models like decision trees that are much more interpretable but less effective than deep learning for complex problems. In this paper, we propose CLEAR-Trade, a novel financial AI visualization framework for deep learning-driven stock market prediction that mitigates the interpretability issue of deep learning methods. In particular, CLEAR-Trade provides a effective way to visualize and explain decisions made by deep stock market prediction models. We show the efficacy of CLEAR-Trade in enhancing the interpretability of stock market prediction by conducting experiments based on S&P 500 stock index prediction. The results demonstrate that CLEAR-Trade can provide significant insight into the decision-making process of deep learning-driven financial models, particularly for regulatory processes, thus improving their potential uptake in the financial industry.","Tue, 5 Sep 2017 19:56:36 UTC (1,902 KB)"
"1293","Deep learning: Technical introduction","Thomas Epelbaum","Machine Learning (stat.ML); Machine Learning (cs.LG)","This note presents in a technical though hopefully pedagogical way the three most common forms of neural network architectures: Feedforward, Convolutional and Recurrent. For each network, their fundamental building blocks are detailed. The forward pass and the update rules for the backpropagation algorithm are then derived in full.","Tue, 5 Sep 2017 14:27:08 UTC (3,890 KB)[v2] Mon, 11 Sep 2017 11:39:06 UTC (3,890 KB)"
"1294","Multi-Modal Multi-Scale Deep Learning for Large-Scale Image Annotation","Yulei Niu, Zhiwu Lu, Ji-Rong Wen, Tao Xiang, Shih-Fu Chang","Computer Vision and Pattern Recognition (cs.CV)","Image annotation aims to annotate a given image with a variable number of class labels corresponding to diverse visual concepts. In this paper, we address two main issues in large-scale image annotation: 1) how to learn a rich feature representation suitable for predicting a diverse set of visual concepts ranging from object, scene to abstract concept; 2) how to annotate an image with the optimal number of class labels. To address the first issue, we propose a novel multi-scale deep model for extracting rich and discriminative features capable of representing a wide range of visual concepts. Specifically, a novel two-branch deep neural network architecture is proposed which comprises a very deep main network branch and a companion feature fusion network branch designed for fusing the multi-scale features computed from the main branch. The deep model is also made multi-modal by taking noisy user-provided tags as model input to complement the image input. For tackling the second issue, we introduce a label quantity prediction auxiliary task to the main label prediction task to explicitly estimate the optimal label number for a given image. Extensive experiments are carried out on two large-scale image annotation benchmark datasets and the results show that our method significantly outperforms the state-of-the-art.","Tue, 5 Sep 2017 02:50:45 UTC (691 KB)[v2] Fri, 19 Oct 2018 01:35:38 UTC (745 KB)"
"1295","Deep Learning-Guided Image Reconstruction from Incomplete Data","Brendan Kelly, Thomas P. Matthews, Mark A. Anastasio","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","An approach to incorporate deep learning within an iterative image reconstruction framework to reconstruct images from severely incomplete measurement data is presented. Specifically, we utilize a convolutional neural network (CNN) as a quasi-projection operator within a least squares minimization procedure. The CNN is trained to encode high level information about the class of images being imaged; this information is utilized to mitigate artifacts in intermediate images produced by use of an iterative method. The structure of the method was inspired by the proximal gradient descent method, where the proximal operator is replaced by a deep CNN and the gradient descent step is generalized by use of a linear reconstruction operator. It is demonstrated that this approach improves image quality for several cases of limited-view image reconstruction and that using a CNN in an iterative method increases performance compared to conventional image reconstruction approaches. We test our method on several limited-view image reconstruction problems. Qualitative and quantitative results demonstrate state-of-the-art performance.","Sat, 2 Sep 2017 14:15:24 UTC (6,144 KB)"
"1296","PassGAN: A Deep Learning Approach for Password Guessing","Briland Hitaj, Paolo Gasti, Giuseppe Ateniese, Fernando Perez-Cruz","Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)","State-of-the-art password guessing tools, such as HashCat and John the Ripper, enable users to check billions of passwords per second against password hashes. In addition to performing straightforward dictionary attacks, these tools can expand password dictionaries using password generation rules, such as concatenation of words (e.g., ""password123456"") and leet speak (e.g., ""password"" becomes ""p4s5w0rd""). Although these rules work well in practice, expanding them to model further passwords is a laborious task that requires specialized expertise. To address this issue, in this paper we introduce PassGAN, a novel approach that replaces human-generated password rules with theory-grounded machine learning algorithms. Instead of relying on manual password analysis, PassGAN uses a Generative Adversarial Network (GAN) to autonomously learn the distribution of real passwords from actual password leaks, and to generate high-quality password guesses. Our experiments show that this approach is very promising. When we evaluated PassGAN on two large password datasets, we were able to surpass rule-based and state-of-the-art machine learning password guessing tools. However, in contrast with the other tools, PassGAN achieved this result without any a-priori knowledge on passwords or common password structures. Additionally, when we combined the output of PassGAN with the output of HashCat, we were able to match 51%-73% more passwords than with HashCat alone. This is remarkable, because it shows that PassGAN can autonomously extract a considerable number of password properties that current state-of-the art rules do not encode.","Fri, 1 Sep 2017 18:42:00 UTC (142 KB)[v2] Fri, 9 Mar 2018 21:03:46 UTC (476 KB)"
"1297","A Comprehensive Survey of Deep Learning in Remote Sensing: Theories, Tools and Challenges for the Community","John E. Ball, Derek T. Anderson, Chee Seng Chan","Computer Vision and Pattern Recognition (cs.CV)","In recent years, deep learning (DL), a re-branding of neural networks (NNs), has risen to the top in numerous areas, namely computer vision (CV), speech recognition, natural language processing, etc. Whereas remote sensing (RS) possesses a number of unique challenges, primarily related to sensors and applications, inevitably RS draws from many of the same theories as CV; e.g., statistics, fusion, and machine learning, to name a few. This means that the RS community should be aware of, if not at the leading edge of, of advancements like DL. Herein, we provide the most comprehensive survey of state-of-the-art RS DL research. We also review recent new developments in the DL field that can be used in DL for RS. Namely, we focus on theories, tools and challenges for the RS community. Specifically, we focus on unsolved challenges and opportunities as it relates to (i) inadequate data sets, (ii) human-understandable solutions for modelling physical phenomena, (iii) Big Data, (iv) non-traditional heterogeneous data sources, (v) DL architectures and learning algorithms for spectral, spatial and temporal data, (vi) transfer learning, (vii) an improved theoretical understanding of DL systems, (viii) high barriers to entry, and (ix) training and optimizing the DL.","Fri, 1 Sep 2017 13:40:35 UTC (218 KB)[v2] Sun, 24 Sep 2017 06:11:30 UTC (218 KB)"
"1298","EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification","Patrick Helber, Benjamin Bischke, Andreas Dengel, Damian Borth","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","In this paper, we address the challenge of land use and land cover classification using remote sensing satellite images. For this challenging task, we use the openly and freely accessible Sentinel-2 satellite images provided within the scope of the Earth observation program Copernicus. The key contributions are as follows. We present a novel dataset based on satellite images covering 13 different spectral bands and consisting of 10 classes with in total 27,000 labeled images. We evaluate state-of-the-art deep Convolutional Neural Network (CNNs) on this novel dataset with its different spectral bands. We also evaluate deep CNNs on existing remote sensing datasets and compare the obtained results. With the proposed novel dataset, we achieved an overall classification accuracy of 98.57%. The classification system resulting from the proposed research opens a gate towards a number of Earth observation applications. We demonstrate how the classification system can be used for detecting land use or land cover changes and how it can assist in improving geographical maps.","Thu, 31 Aug 2017 18:19:10 UTC (6,256 KB)"
"1299","Predicting Cardiovascular Risk Factors from Retinal Fundus Photographs using Deep Learning","Ryan Poplin, Avinash V. Varadarajan, Katy Blumer, Yun Liu, Michael V. McConnell, Greg S. Corrado, Lily Peng, Dale R. Webster","Computer Vision and Pattern Recognition (cs.CV)","Traditionally, medical discoveries are made by observing associations and then designing experiments to test these hypotheses. However, observing and quantifying associations in images can be difficult because of the wide variety of features, patterns, colors, values, shapes in real data. In this paper, we use deep learning, a machine learning technique that learns its own features, to discover new knowledge from retinal fundus images. Using models trained on data from 284,335 patients, and validated on two independent datasets of 12,026 and 999 patients, we predict cardiovascular risk factors not previously thought to be present or quantifiable in retinal images, such as such as age (within 3.26 years), gender (0.97 AUC), smoking status (0.71 AUC), HbA1c (within 1.39%), systolic blood pressure (within 11.23mmHg) as well as major adverse cardiac events (0.70 AUC). We further show that our models used distinct aspects of the anatomy to generate each prediction, such as the optic disc or blood vessels, opening avenues of further research.","Thu, 31 Aug 2017 17:49:15 UTC (918 KB)[v2] Thu, 21 Sep 2017 22:48:06 UTC (918 KB)"
"1300","Quantum-assisted Helmholtz machines: A quantum-classical deep learning framework for industrial datasets in near-term devices","Marcello Benedetti, John Realpe-Gomez, Alejandro Perdomo-Ortiz","Quantum Physics (quant-ph); Emerging Technologies (cs.ET)","Machine learning has been presented as one of the key applications for near-term quantum technologies, given its high commercial value and wide range of applicability. In this work, we introduce the \textit{quantum-assisted Helmholtz machine:} a hybrid quantum-classical framework with the potential of tackling high-dimensional real-world machine learning datasets on continuous variables. Instead of using quantum computers only to assist deep learning, as previous approaches have suggested, we use deep learning to extract a low-dimensional binary representation of data, suitable for processing on relatively small quantum computers. Then, the quantum hardware and deep learning architecture work together to train an unsupervised generative model. We demonstrate this concept using 1644 quantum bits of a D-Wave 2000Q quantum device to model a sub-sampled version of the MNIST handwritten digit dataset with 16x16 continuous valued pixels. Although we illustrate this concept on a quantum annealer, adaptations to other quantum platforms, such as ion-trap technologies or superconducting gate-model architectures, could be explored within this flexible framework.","Thu, 31 Aug 2017 15:56:18 UTC (284 KB)[v2] Wed, 20 Sep 2017 17:38:38 UTC (373 KB)[v3] Mon, 19 Mar 2018 17:18:32 UTC (284 KB)"
"1301","Texture and Structure Incorporated ScatterNet Hybrid Deep Learning Network (TS-SHDL) For Brain Matter Segmentation","Amarjot Singh, Devamanyu Hazarika, Aniruddha Bhattacharya","Computer Vision and Pattern Recognition (cs.CV)","Automation of brain matter segmentation from MR images is a challenging task due to the irregular boundaries between the grey and white matter regions. In addition, the presence of intensity inhomogeneity in the MR images further complicates the problem. In this paper, we propose a texture and vesselness incorporated version of the ScatterNet Hybrid Deep Learning Network (TS-SHDL) that extracts hierarchical invariant mid-level features, used by fisher vector encoding and a conditional random field (CRF) to perform the desired segmentation. The performance of the proposed network is evaluated by extensive experimentation and comparison with the state-of-the-art methods on several 2D MRI scans taken from the synthetic McGill Brain Web as well as on the MRBrainS dataset of real 3D MRI scans. The advantages of the TS-SHDL network over supervised deep learning networks is also presented in addition to its superior performance over the state-of-the-art.","Wed, 30 Aug 2017 14:38:06 UTC (1,232 KB)"
"1302","ScatterNet Hybrid Deep Learning (SHDL) Network For Object Classification","Amarjot Singh, Nick Kingsbury","Computer Vision and Pattern Recognition (cs.CV)","The paper proposes the ScatterNet Hybrid Deep Learning (SHDL) network that extracts invariant and discriminative image representations for object recognition. SHDL framework is constructed with a multi-layer ScatterNet front-end, an unsupervised learning middle, and a supervised learning back-end module. Each layer of the SHDL network is automatically designed as an explicit optimization problem leading to an optimal deep learning architecture with improved computational performance as compared to the more usual deep network architectures. SHDL network produces the state-of-the-art classification performance against unsupervised and semi-supervised learning (GANs) on two image datasets. Advantages of the SHDL network over supervised methods (NIN, VGG) are also demonstrated with experiments performed on training datasets of reduced size.","Wed, 30 Aug 2017 11:02:20 UTC (1,075 KB)"
"1303","A Deep Learning Approach for Population Estimation from Satellite Imagery","Caleb Robinson, Fred Hohman, Bistra Dilkina","Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)","Knowing where people live is a fundamental component of many decision making processes such as urban development, infectious disease containment, evacuation planning, risk management, conservation planning, and more. While bottom-up, survey driven censuses can provide a comprehensive view into the population landscape of a country, they are expensive to realize, are infrequently performed, and only provide population counts over broad areas. Population disaggregation techniques and population projection methods individually address these shortcomings, but also have shortcomings of their own. To jointly answer the questions of ""where do people live"" and ""how many people live there,"" we propose a deep learning model for creating high-resolution population estimations from satellite imagery. Specifically, we train convolutional neural networks to predict population in the USA at a $0.01^{\circ} \times 0.01^{\circ}$ resolution grid from 1-year composite Landsat imagery. We validate these models in two ways: quantitatively, by comparing our model's grid cell estimates aggregated at a county-level to several US Census county-level population projections, and qualitatively, by directly interpreting the model's predictions in terms of the satellite image inputs. We find that aggregating our model's estimates gives comparable results to the Census county-level population projections and that the predictions made by our model can be directly interpreted, which give it advantages over traditional population disaggregation methods. In general, our model is an example of how machine learning techniques can be an effective tool for extracting information from inherently unstructured, remotely sensed data to provide effective solutions to social problems.","Wed, 30 Aug 2017 02:05:16 UTC (5,138 KB)"
"1304","Deep Learning for Medical Image Analysis","Mina Rezaei, Haojin Yang, Christoph Meinel","Computer Vision and Pattern Recognition (cs.CV)","This report describes my research activities in the Hasso Plattner Institute and summarizes my Ph.D. plan and several novels, end-to-end trainable approaches for analyzing medical images using deep learning algorithm. In this report, as an example, we explore different novel methods based on deep learning for brain abnormality detection, recognition, and segmentation. This report prepared for the doctoral consortium in the AIME-2017 conference.","Thu, 17 Aug 2017 12:09:12 UTC (4,230 KB)"
"1305","Towards Poisoning of Deep Learning Algorithms with Back-gradient Optimization","Luis Munoz-Gonzalez, Battista Biggio, Ambra Demontis, Andrea Paudice, Vasin Wongrassamee, Emil C. Lupu, Fabio Roli","Machine Learning (cs.LG)","A number of online services nowadays rely upon machine learning to extract valuable information from data collected in the wild. This exposes learning algorithms to the threat of data poisoning, i.e., a coordinate attack in which a fraction of the training data is controlled by the attacker and manipulated to subvert the learning process. To date, these attacks have been devised only against a limited class of binary learning algorithms, due to the inherent complexity of the gradient-based procedure used to optimize the poisoning points (a.k.a. adversarial training examples). In this work, we rst extend the de nition of poisoning attacks to multiclass problems. We then propose a novel poisoning algorithm based on the idea of back-gradient optimization, i.e., to compute the gradient of interest through automatic di erentiation, while also reversing the learning procedure to drastically reduce the attack complexity. Compared to current poisoning strategies, our approach is able to target a wider class of learning algorithms, trained with gradient- based procedures, including neural networks and deep learning architectures. We empirically evaluate its e ectiveness on several application examples, including spam ltering, malware detection, and handwritten digit recognition. We nally show that, similarly to adversarial test examples, adversarial training examples can also be transferred across di erent learning algorithms.","Tue, 29 Aug 2017 10:47:38 UTC (1,000 KB)"
"1306","Deep Learning for Accelerated Reliability Analysis of Infrastructure Networks","Mohammad Amin Nabian, Hadi Meidani","Computational Engineering, Finance, and Science (cs.CE); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Natural disasters can have catastrophic impacts on the functionality of infrastructure systems and cause severe physical and socio-economic losses. Given budget constraints, it is crucial to optimize decisions regarding mitigation, preparedness, response, and recovery practices for these systems. This requires accurate and efficient means to evaluate the infrastructure system reliability. While numerous research efforts have addressed and quantified the impact of natural disasters on infrastructure systems, typically using the Monte Carlo approach, they still suffer from high computational cost and, thus, are of limited applicability to large systems. This paper presents a deep learning framework for accelerating infrastructure system reliability analysis. In particular, two distinct deep neural network surrogates are constructed and studied: (1) A classifier surrogate which speeds up the connectivity determination of networks, and (2) An end-to-end surrogate that replaces a number of components such as roadway status realization, connectivity determination, and connectivity averaging. The proposed approach is applied to a simulation-based study of the two-terminal connectivity of a California transportation network subject to extreme probabilistic earthquake events. Numerical results highlight the effectiveness of the proposed approach in accelerating the transportation system two-terminal reliability analysis with extremely high prediction accuracy.","Mon, 28 Aug 2017 22:41:11 UTC (2,769 KB)"
"1307","Power of Deep Learning for Channel Estimation and Signal Detection in OFDM Systems","Hao Ye, Geoffrey Ye Li, Biing-Hwang Fred Juang","Information Theory (cs.IT)","This article presents our initial results in deep learning for channel estimation and signal detection in orthogonal frequency-division multiplexing (OFDM). OFDM has been widely adopted in wireless broadband communications to combat frequency-selective fading in wireless channels. In this article, we take advantage of deep learning in handling wireless OFDM channels in an end-to-end approach. Different from existing OFDM receivers that first estimate CSI explicitly and then detect/recover the transmitted symbols with the estimated CSI, our deep learning based approach estimates CSI implicitly and recovers the transmitted symbols directly. To address channel distortion, a deep learning model is first trained offline using the data generated from the simulation based on the channel statistics and then used for recovering the online transmitted data directly. From our simulation results, the deep learning based approach has the ability to address channel distortions and detect the transmitted symbols with performance comparable to minimum mean-square error (MMSE) estimator. Furthermore, the deep learning based approach is more robust than conventional methods when fewer training pilots are used, the cyclic prefix (CP) is omitted, and nonlinear clipping noise is presented. In summary, deep learning is a promising tool for channel estimation and signal detection in wireless communications with complicated channel distortions and interferences.","Mon, 28 Aug 2017 20:34:50 UTC (1,193 KB)"
"1308","Deep Learning Sparse Ternary Projections for Compressed Sensing of Images","Duc Minh Nguyen, Evaggelia Tsiligianni, Nikos Deligiannis","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","Compressed sensing (CS) is a sampling theory that allows reconstruction of sparse (or compressible) signals from an incomplete number of measurements, using of a sensing mechanism implemented by an appropriate projection matrix. The CS theory is based on random Gaussian projection matrices, which satisfy recovery guarantees with high probability; however, sparse ternary {0, -1, +1} projections are more suitable for hardware implementation. In this paper, we present a deep learning approach to obtain very sparse ternary projections for compressed sensing. Our deep learning architecture jointly learns a pair of a projection matrix and a reconstruction operator in an end-to-end fashion. The experimental results on real images demonstrate the effectiveness of the proposed approach compared to state-of-the-art methods, with significant advantage in terms of complexity.","Mon, 28 Aug 2017 13:51:09 UTC (467 KB)"
"1309","Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models","Wojciech Samek, Thomas Wiegand, Klaus-Robert Muller","Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","With the availability of large databases and recent improvements in deep learning methodology, the performance of AI systems is reaching or even exceeding the human level on an increasing number of complex tasks. Impressive examples of this development can be found in domains such as image classification, sentiment analysis, speech understanding or strategic game playing. However, because of their nested non-linear structure, these highly successful machine learning and artificial intelligence models are usually applied in a black box manner, i.e., no information is provided about what exactly makes them arrive at their predictions. Since this lack of transparency can be a major drawback, e.g., in medical applications, the development of methods for visualizing, explaining and interpreting deep learning models has recently attracted increasing attention. This paper summarizes recent developments in this field and makes a plea for more interpretability in artificial intelligence. Furthermore, it presents two approaches to explaining predictions of deep learning models, one method which computes the sensitivity of the prediction with respect to changes in the input and one approach which meaningfully decomposes the decision in terms of the input variables. These methods are evaluated on three classification tasks.","Mon, 28 Aug 2017 12:53:49 UTC (887 KB)"
"1310","ChainerCV: a Library for Deep Learning in Computer Vision","Yusuke Niitani, Toru Ogawa, Shunta Saito, Masaki Saito","Computer Vision and Pattern Recognition (cs.CV)","Despite significant progress of deep learning in the field of computer vision, there has not been a software library that covers these methods in a unifying manner. We introduce ChainerCV, a software library that is intended to fill this gap. ChainerCV supports numerous neural network models as well as software components needed to conduct research in computer vision. These implementations emphasize simplicity, flexibility and good software engineering practices. The library is designed to perform on par with the results reported in published papers and its tools can be used as a baseline for future research in computer vision. Our implementation includes sophisticated models like Faster R-CNN and SSD, and covers tasks such as object detection and semantic segmentation.","Mon, 28 Aug 2017 02:54:11 UTC (3,836 KB)"
"1311","Facial Expression Recognition using Visual Saliency and Deep Learning","Viraj Mavani, Shanmuganathan Raman, Krishna P Miyapuram","Computer Vision and Pattern Recognition (cs.CV)","We have developed a convolutional neural network for the purpose of recognizing facial expressions in human beings. We have fine-tuned the existing convolutional neural network model trained on the visual recognition dataset used in the ILSVRC2012 to two widely used facial expression datasets - CFEE and RaFD, which when trained and tested independently yielded test accuracies of 74.79% and 95.71%, respectively. Generalization of results was evident by training on one dataset and testing on the other. Further, the image product of the cropped faces and their visual saliency maps were computed using Deep Multi-Layer Network for saliency prediction and were fed to the facial expression recognition CNN. In the most generalized experiment, we observed the top-1 accuracy in the test set to be 65.39%. General confusion trends between different facial expressions as exhibited by humans were also observed.","Sat, 26 Aug 2017 20:03:38 UTC (919 KB)"
"1312","Deep learning with convolutional neural networks for decoding and visualization of EEG pathology","Robin Tibor Schirrmeister, Lukas Gemein, Katharina Eggensperger, Frank Hutter, Tonio Ball","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","We apply convolutional neural networks (ConvNets) to the task of distinguishing pathological from normal EEG recordings in the Temple University Hospital EEG Abnormal Corpus. We use two basic, shallow and deep ConvNet architectures recently shown to decode task-related information from EEG at least as well as established algorithms designed for this purpose. In decoding EEG pathology, both ConvNets reached substantially better accuracies (about 6% better, ~85% vs. ~79%) than the only published result for this dataset, and were still better when using only 1 minute of each recording for training and only six seconds of each recording for testing. We used automated methods to optimize architectural hyperparameters and found intriguingly different ConvNet architectures, e.g., with max pooling as the only nonlinearity. Visualizations of the ConvNet decoding behavior showed that they used spectral power changes in the delta (0-4 Hz) and theta (4-8 Hz) frequency range, possibly alongside other features, consistent with expectations derived from spectral analysis of the EEG data and from the textual medical reports. Analysis of the textual medical reports also highlighted the potential for accuracy increases by integrating contextual information, such as the age of subjects. In summary, the ConvNets and visualization techniques used in this study constitute a next step towards clinically useful automated EEG diagnosis and establish a new baseline for future work on this topic.","Sat, 26 Aug 2017 19:14:47 UTC (1,372 KB)[v2] Thu, 7 Dec 2017 14:56:40 UTC (956 KB)[v3] Thu, 11 Jan 2018 20:11:04 UTC (956 KB)"
"1313","Deep Learning for Target Classification from SAR Imagery: Data Augmentation and Translation Invariance","Hidetoshi Furukawa","Computer Vision and Pattern Recognition (cs.CV)","This report deals with translation invariance of convolutional neural networks (CNNs) for automatic target recognition (ATR) from synthetic aperture radar (SAR) imagery. In particular, the translation invariance of CNNs for SAR ATR represents the robustness against misalignment of target chips extracted from SAR images. To understand the translation invariance of the CNNs, we trained CNNs which classify the target chips from the MSTAR into the ten classes under the condition of with and without data augmentation, and then visualized the translation invariance of the CNNs. According to our results, even if we use a deep residual network, the translation invariance of the CNN without data augmentation using the aligned images such as the MSTAR target chips is not so large. A more important factor of translation invariance is the use of augmented training data. Furthermore, our CNN using augmented training data achieved a state-of-the-art classification accuracy of 99.6%. These results show an importance of domain-specific data augmentation.","Sat, 26 Aug 2017 02:44:09 UTC (1,062 KB)"
"1314","Deep Learning for Video Game Playing","Niels Justesen, Philip Bontrager, Julian Togelius, Sebastian Risi","Artificial Intelligence (cs.AI)","In this article, we review recent Deep Learning advances in the context of how they have been applied to play different types of video games such as first-person shooters, arcade games, and real-time strategy games. We analyze the unique requirements that different game genres pose to a deep learning system and highlight important open challenges in the context of applying these machine learning methods to video games, such as general game playing, dealing with extremely large decision spaces and sparse rewards.","Fri, 25 Aug 2017 22:01:09 UTC (1,428 KB)[v2] Mon, 30 Oct 2017 20:46:01 UTC (1,438 KB)"
"1315","Exploit imaging through opaque wall via deep learning","Meng Lyu, Hao Wang, Guowei Li, Guohai Situ","Neural and Evolutionary Computing (cs.NE); Optics (physics.optics)","Imaging through scattering media is encountered in many disciplines or sciences, ranging from biology, mesescopic physics and astronomy. But it is still a big challenge because light suffers from multiple scattering is such media and can be totally decorrelated. Here, we propose a deep-learning-based method that can retrieve the image of a target behind a thick scattering medium. The method uses a trained deep neural network to fit the way of mapping of objects at one side of a thick scattering medium to the corresponding speckle patterns observed at the other side. For demonstration, we retrieve the images of a set of objects hidden behind a 3mm thick white polystyrene slab, the optical depth of which is 13.4 times of the scattering mean free path. Our work opens up a new way to tackle the longstanding challenge by using the technique of deep learning.","Wed, 9 Aug 2017 13:38:32 UTC (1,353 KB)"
"1316","Evaluation of Deep Learning on an Abstract Image Classification Dataset","Sebastian Stabinger, Antonio Rodriguez-Sanchez","Computer Vision and Pattern Recognition (cs.CV)","Convolutional Neural Networks have become state of the art methods for image classification over the last couple of years. By now they perform better than human subjects on many of the image classification datasets. Most of these datasets are based on the notion of concrete classes (i.e. images are classified by the type of object in the image). In this paper we present a novel image classification dataset, using abstract classes, which should be easy to solve for humans, but variations of it are challenging for CNNs. The classification performance of popular CNN architectures is evaluated on this dataset and variations of the dataset that might be interesting for further research are identified.","Fri, 25 Aug 2017 15:10:22 UTC (1,666 KB)"
"1317","Supervised Speech Separation Based on Deep Learning: An Overview","DeLiang Wang, Jitong Chen","Computation and Language (cs.CL); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Sound (cs.SD)","Speech separation is the task of separating target speech from background interference. Traditionally, speech separation is studied as a signal processing problem. A more recent approach formulates speech separation as a supervised learning problem, where the discriminative patterns of speech, speakers, and background noise are learned from training data. Over the past decade, many supervised separation algorithms have been put forward. In particular, the recent introduction of deep learning to supervised speech separation has dramatically accelerated progress and boosted separation performance. This article provides a comprehensive overview of the research on deep learning based supervised speech separation in the last several years. We first introduce the background of speech separation and the formulation of supervised separation. Then we discuss three main components of supervised separation: learning machines, training targets, and acoustic features. Much of the overview is on separation algorithms where we review monaural methods, including speech enhancement (speech-nonspeech separation), speaker separation (multi-talker separation), and speech dereverberation, as well as multi-microphone techniques. The important issue of generalization, unique to supervised learning, is discussed. This overview provides a historical perspective on how advances are made. In addition, we discuss a number of conceptual issues, including what constitutes the target source.","Thu, 24 Aug 2017 18:51:50 UTC (5,143 KB)[v2] Fri, 15 Jun 2018 03:28:26 UTC (2,177 KB)"
"1318","DGM: A deep learning algorithm for solving partial differential equations","Justin Sirignano, Konstantinos Spiliopoulos","Mathematical Finance (q-fin.MF); Numerical Analysis (math.NA); Computational Finance (q-fin.CP); Machine Learning (stat.ML)","High-dimensional PDEs have been a longstanding computational challenge. We propose to solve high-dimensional PDEs by approximating the solution with a deep neural network which is trained to satisfy the differential operator, initial condition, and boundary conditions. Our algorithm is meshfree, which is key since meshes become infeasible in higher dimensions. Instead of forming a mesh, the neural network is trained on batches of randomly sampled time and space points. The algorithm is tested on a class of high-dimensional free boundary PDEs, which we are able to accurately solve in up to $200$ dimensions. The algorithm is also tested on a high-dimensional Hamilton-Jacobi-Bellman PDE and Burgers' equation. The deep learning algorithm approximates the general solution to the Burgers' equation for a continuum of different boundary conditions and physical conditions (which can be viewed as a high-dimensional space). We call the algorithm a ""Deep Galerkin Method (DGM)"" since it is similar in spirit to Galerkin methods, with the solution approximated by a neural network instead of a linear combination of basis functions. In addition, we prove a theorem regarding the approximation power of neural networks for a class of quasilinear parabolic PDEs.","Thu, 24 Aug 2017 15:50:24 UTC (10 KB)[v2] Tue, 5 Dec 2017 13:56:45 UTC (2,452 KB)[v3] Sat, 16 Dec 2017 19:19:32 UTC (2,452 KB)[v4] Fri, 27 Jul 2018 18:16:30 UTC (5,503 KB)[v5] Wed, 5 Sep 2018 19:39:17 UTC (5,498 KB)"
"1319","Automatic Myocardial Segmentation by Using A Deep Learning Network in Cardiac MRI","Ariel H. Curiale, Flavio D. Colavecchia, Pablo Kaluza, Roberto A. Isoardi, German Mato","Computer Vision and Pattern Recognition (cs.CV)","Cardiac function is of paramount importance for both prognosis and treatment of different pathologies such as mitral regurgitation, ischemia, dyssynchrony and myocarditis. Cardiac behavior is determined by structural and functional features. In both cases, the analysis of medical imaging studies requires to detect and segment the myocardium. Nowadays, magnetic resonance imaging (MRI) is one of the most relevant and accurate non-invasive diagnostic tools for cardiac structure and function. In this work we propose to use a deep learning technique to assist the automatization of myocardial segmentation in cardiac MRI. We present several improvements to previous works in this paper: we propose to use the Jaccard distance as optimization objective function, we integrate a residual learning strategy into the code, and we introduce a batch normalization layer to train the fully convolutional neural network. Our results demonstrate that this architecture outperforms previous approaches based on a similar network architecture, and that provides a suitable approach for myocardial segmentation. Our benchmark shows that the automatic myocardial segmentation takes less than 22 seg. for a volume of 128~x~128~x~13 pixels in a 3.1 GHz intel core i7.","Thu, 24 Aug 2017 15:19:04 UTC (967 KB)"
"1320","Quantum fields as deep learning","Jae-Weon Lee","General Physics (physics.gen-ph); High Energy Physics - Theory (hep-th)","In this essay we conjecture that quantum fields such as the Higgs field is related to a restricted Boltzmann machine for deep neural networks. An accelerating Rindler observer in a flat spacetime sees the quantum fields having a thermal distribution from the quantum entanglement, and a renormalization group process for the thermal fields on a lattice is similar to a deep learning algorithm. This correspondence can be generalized for the KMS states of quantum fields in a curved spacetime like a black hole.","Fri, 18 Aug 2017 17:43:30 UTC (34 KB)"
"1321","Is Deep Learning Safe for Robot Vision? Adversarial Examples against the iCub Humanoid","Marco Melis, Ambra Demontis, Battista Biggio, Gavin Brown, Giorgio Fumera, Fabio Roli","Machine Learning (cs.LG); Robotics (cs.RO); Machine Learning (stat.ML)","Deep neural networks have been widely adopted in recent years, exhibiting impressive performances in several application domains. It has however been shown that they can be fooled by adversarial examples, i.e., images altered by a barely-perceivable adversarial noise, carefully crafted to mislead classification. In this work, we aim to evaluate the extent to which robot-vision systems embodying deep-learning algorithms are vulnerable to adversarial examples, and propose a computationally efficient countermeasure to mitigate this threat, based on rejecting classification of anomalous inputs. We then provide a clearer understanding of the safety properties of deep networks through an intuitive empirical analysis, showing that the mapping learned by such networks essentially violates the smoothness assumption of learning algorithms. We finally discuss the main limitations of this work, including the creation of real-world adversarial examples, and sketch promising research directions.","Wed, 23 Aug 2017 10:01:35 UTC (3,747 KB)"
"1322","Analyzing ャ-rays of the Galactic Center with Deep Learning","Sascha Caron, German A. Gomez-Vargas, Luc Hendriks, Roberto Ruiz de Austri","High Energy Astrophysical Phenomena (astro-ph.HE); High Energy Physics - Phenomenology (hep-ph)","We present a new method to interpret the $ャ$-ray data of our inner Galaxy as measured by the Fermi Large Area Telescope (Fermi LAT). We train and test convolutional neural networks with simulated Fermi-LAT images based on models tuned to real data. We use this method to investigate the origin of an excess emission of GeV $ャ$-rays seen in previous studies. Interpretations of this excess include $ャ$ rays created by the annihilation of dark matter particles and $ャ$ rays originating from a collection of unresolved point sources, such as millisecond pulsars. Our new method allows precise measurements of the contribution and properties of an unresolved population of $ャ$-ray point sources in the interstellar diffuse emission model.","Tue, 22 Aug 2017 16:27:13 UTC (2,498 KB)[v2] Sat, 26 May 2018 12:17:24 UTC (2,145 KB)"
"1323","Automated Website Fingerprinting through Deep Learning","Vera Rimmer, Davy Preuveneers, Marc Juarez, Tom Van Goethem, Wouter Joosen","Cryptography and Security (cs.CR); Machine Learning (cs.LG)","Several studies have shown that the network traffic that is generated by a visit to a website over Tor reveals information specific to the website through the timing and sizes of network packets. By capturing traffic traces between users and their Tor entry guard, a network eavesdropper can leverage this meta-data to reveal which website Tor users are visiting. The success of such attacks heavily depends on the particular set of traffic features that are used to construct the fingerprint. Typically, these features are manually engineered and, as such, any change introduced to the Tor network can render these carefully constructed features ineffective. In this paper, we show that an adversary can automate the feature engineering process, and thus automatically deanonymize Tor traffic by applying our novel method based on deep learning. We collect a dataset comprised of more than three million network traces, which is the largest dataset of web traffic ever used for website fingerprinting, and find that the performance achieved by our deep learning approaches is comparable to known methods which include various research efforts spanning over multiple years. The obtained success rate exceeds 96% for a closed world of 100 websites and 94% for our biggest closed world of 900 classes. In our open world evaluation, the most performant deep learning model is 2% more accurate than the state-of-the-art attack. Furthermore, we show that the implicit features automatically learned by our approach are far more resilient to dynamic changes of web content over time. We conclude that the ability to automatically construct the most relevant traffic features and perform accurate traffic recognition makes our deep learning based approach an efficient, flexible and robust technique for website fingerprinting.","Mon, 21 Aug 2017 18:32:08 UTC (461 KB)[v2] Tue, 5 Dec 2017 17:35:56 UTC (535 KB)"
"1324","nuts-flow/ml: data pre-processing for deep learning","S. Maetschke, R. Tennakoon, C. Vecchiola, R. Garnavi","Machine Learning (cs.LG); Software Engineering (cs.SE)","Data preprocessing is a fundamental part of any machine learning application and frequently the most time-consuming aspect when developing a machine learning solution. Preprocessing for deep learning is characterized by pipelines that lazily load data and perform data transformation, augmentation, batching and logging. Many of these functions are common across applications but require different arrangements for training, testing or inference. Here we introduce a novel software framework named nuts-flow/ml that encapsulates common preprocessing operations as components, which can be flexibly arranged to rapidly construct efficient preprocessing pipelines for deep learning.","Mon, 21 Aug 2017 01:28:37 UTC (60 KB)[v2] Wed, 10 Jan 2018 00:46:13 UTC (60 KB)"
"1325","DeepBreath: Deep Learning of Breathing Patterns for Automatic Stress Recognition using Low-Cost Thermal Imaging in Unconstrained Settings","Youngjun Cho, Nadia Bianchi-Berthouze, Simon J. Julier","Human-Computer Interaction (cs.HC); Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)","We propose DeepBreath, a deep learning model which automatically recognises people's psychological stress level (mental overload) from their breathing patterns. Using a low cost thermal camera, we track a person's breathing patterns as temperature changes around his/her nostril. The paper's technical contribution is threefold. First of all, instead of creating hand-crafted features to capture aspects of the breathing patterns, we transform the uni-dimensional breathing signals into two dimensional respiration variability spectrogram (RVS) sequences. The spectrograms easily capture the complexity of the breathing dynamics. Second, a spatial pattern analysis based on a deep Convolutional Neural Network (CNN) is directly applied to the spectrogram sequences without the need of hand-crafting features. Finally, a data augmentation technique, inspired from solutions for over-fitting problems in deep learning, is applied to allow the CNN to learn with a small-scale dataset from short-term measurements (e.g., up to a few hours). The model is trained and tested with data collected from people exposed to two types of cognitive tasks (Stroop Colour Word Test, Mental Computation test) with sessions of different difficulty levels. Using normalised self-report as ground truth, the CNN reaches 84.59% accuracy in discriminating between two levels of stress and 56.52% in discriminating between three levels. In addition, the CNN outperformed powerful shallow learning methods based on a single layer neural network. Finally, the dataset of labelled thermal images will be open to the community.","Sun, 20 Aug 2017 21:36:30 UTC (2,886 KB)"
"1326","Improving Deep Learning using Generic Data Augmentation","Luke Taylor, Geoff Nitschke","Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep artificial neural networks require a large corpus of training data in order to effectively learn, where collection of such training data is often expensive and laborious. Data augmentation overcomes this issue by artificially inflating the training set with label preserving transformations. Recently there has been extensive use of generic data augmentation to improve Convolutional Neural Network (CNN) task performance. This study benchmarks various popular data augmentation schemes to allow researchers to make informed decisions as to which training methods are most appropriate for their data sets. Various geometric and photometric schemes are evaluated on a coarse-grained data set using a relatively simple CNN. Experimental results, run using 4-fold cross-validation and reported in terms of Top-1 and Top-5 accuracy, indicate that cropping in geometric augmentation significantly increases CNN task performance.","Sun, 20 Aug 2017 21:16:59 UTC (547 KB)"
"1327","Perceptual audio loss function for deep learning","Dan Elbaz, Michael Zibulevsky","Sound (cs.SD); Machine Learning (cs.LG)","PESQ and POLQA , are standards are standards for automated assessment of voice quality of speech as experienced by human beings. The predictions of those objective measures should come as close as possible to subjective quality scores as obtained in subjective listening tests. Wavenet is a deep neural network originally developed as a deep generative model of raw audio wave-forms. Wavenet architecture is based on dilated causal convolutions, which exhibit very large receptive fields. In this short paper we suggest using the Wavenet architecture, in particular its large receptive filed in order to learn PESQ algorithm. By doing so we can use it as a differentiable loss function for speech enhancement.","Sun, 20 Aug 2017 16:18:20 UTC (3 KB)"
"1328","Applying Data Augmentation to Handwritten Arabic Numeral Recognition Using Deep Learning Neural Networks","Akm Ashiquzzaman, Abdul Kawsar Tushar, Ashiqur Rahman","Computer Vision and Pattern Recognition (cs.CV)","Handwritten character recognition has been the center of research and a benchmark problem in the sector of pattern recognition and artificial intelligence, and it continues to be a challenging research topic. Due to its enormous application many works have been done in this field focusing on different languages. Arabic, being a diversified language has a huge scope of research with potential challenges. A convolutional neural network model for recognizing handwritten numerals in Arabic language is proposed in this paper, where the dataset is subject to various augmentation in order to add robustness needed for deep learning approach. The proposed method is empowered by the presence of dropout regularization to do away with the problem of data overfitting. Moreover, suitable change is introduced in activation function to overcome the problem of vanishing gradient. With these modifications, the proposed system achieves an accuracy of 99.4\% which performs better than every previous work on the dataset.","Sun, 20 Aug 2017 14:21:05 UTC (1,696 KB)[v2] Tue, 22 Aug 2017 15:18:37 UTC (1,697 KB)[v3] Thu, 24 Aug 2017 16:29:29 UTC (1,697 KB)[v4] Wed, 27 Sep 2017 14:54:32 UTC (1,697 KB)"
"1329","Simultaneous Detection and Quantification of Retinal Fluid with Deep Learning","Dustin Morley, Hassan Foroosh, Saad Shaikh, Ulas Bagci","Computer Vision and Pattern Recognition (cs.CV)","We propose a new deep learning approach for automatic detection and segmentation of fluid within retinal OCT images. The proposed framework utilizes both ResNet and Encoder-Decoder neural network architectures. When training the network, we apply a novel data augmentation method called myopic warping together with standard rotation-based augmentation to increase the training set size to 45 times the original amount. Finally, the network output is post-processed with an energy minimization algorithm (graph cut) along with a few other knowledge guided morphological operations to finalize the segmentation process. Based on OCT imaging data and its ground truth from the RETOUCH challenge, the proposed system achieves dice indices of 0.522, 0.682, and 0.612, and average absolute volume differences of 0.285, 0.115, and 0.156 mm$^3$ for intaretinal fluid, subretinal fluid, and pigment epithelial detachment respectively.","Thu, 17 Aug 2017 23:31:05 UTC (2,158 KB)"
"1330","Deep Learning at 15PF: Supervised and Semi-Supervised Classification for Scientific Data","Thorsten Kurth, Jian Zhang, Nadathur Satish, Ioannis Mitliagkas, Evan Racah, Mostofa Ali Patwary, Tareq Malas, Narayanan Sundaram, Wahid Bhimji, Mikhail Smorkalov, Jack Deslippe, Mikhail Shiryaev, Srinivas Sridharan, Prabhat, Pradeep Dubey","Performance (cs.PF); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","This paper presents the first, 15-PetaFLOP Deep Learning system for solving scientific pattern classification problems on contemporary HPC architectures. We develop supervised convolutional architectures for discriminating signals in high-energy physics data as well as semi-supervised architectures for localizing and classifying extreme weather in climate data. Our Intelcaffe-based implementation obtains $\sim$2TFLOP/s on a single Cori Phase-II Xeon-Phi node. We use a hybrid strategy employing synchronous node-groups, while using asynchronous communication across groups. We use this strategy to scale training of a single model to $\sim$9600 Xeon-Phi nodes; obtaining peak performance of 11.73-15.07 PFLOP/s and sustained performance of 11.41-13.27 PFLOP/s. At scale, our HEP architecture produces state-of-the-art classification accuracy on a dataset with 10M images, exceeding that achieved by selections on high-level physics-motivated features. Our semi-supervised architecture successfully extracts weather patterns in a 15TB climate dataset. Our results demonstrate that Deep Learning can be optimized and scaled effectively on many-core, HPC systems.","Thu, 17 Aug 2017 13:21:36 UTC (1,193 KB)"
"1331","DARVIZ: Deep Abstract Representation, Visualization, and Verification of Deep Learning Models","Anush Sankaran, Rahul Aralikatte, Senthil Mani, Shreya Khare, Naveen Panwar, Neelamadhav Gantayat","Software Engineering (cs.SE)","Traditional software engineering programming paradigms are mostly object or procedure oriented, driven by deterministic algorithms. With the advent of deep learning and cognitive sciences there is an emerging trend for data-driven programming, creating a shift in the programming paradigm among the software engineering communities. Visualizing and interpreting the execution of a current large scale data-driven software development is challenging. Further, for deep learning development there are many libraries in multiple programming languages such as TensorFlow (Python), CAFFE (C++), Theano (Python), Torch (Lua), and Deeplearning4j (Java), driving a huge need for interoperability across libraries.","Wed, 16 Aug 2017 14:46:27 UTC (1,336 KB)"
"1332","Deep Learning for Passive Synthetic Aperture Radar","Bariscan Yonel, Eric Mason, Birsen Yazc","Computer Vision and Pattern Recognition (cs.CV); Computational Engineering, Finance, and Science (cs.CE)","We introduce a deep learning (DL) framework for inverse problems in imaging, and demonstrate the advantages and applicability of this approach in passive synthetic aperture radar (SAR) image reconstruction. We interpret image recon- struction as a machine learning task and utilize deep networks as forward and inverse solvers for imaging. Specifically, we design a recurrent neural network (RNN) architecture as an inverse solver based on the iterations of proximal gradient descent optimization methods. We further adapt the RNN architecture to image reconstruction problems by transforming the network into a recurrent auto-encoder, thereby allowing for unsupervised training. Our DL based inverse solver is particularly suitable for a class of image formation problems in which the forward model is only partially known. The ability to learn forward models and hyper parameters combined with unsupervised training approach establish our recurrent auto-encoder suitable for real world applications. We demonstrate the performance of our method in passive SAR image reconstruction. In this regime a source of opportunity, with unknown location and transmitted waveform, is used to illuminate a scene of interest. We investigate recurrent auto- encoder architecture based on the 1 and 0 constrained least- squares problem. We present a projected stochastic gradient descent based training scheme which incorporates constraints of the unknown model parameters. We demonstrate through extensive numerical simulations that our DL based approach out performs conventional sparse coding methods in terms of computation and reconstructed image quality, specifically, when no information about the transmitter is available.","Sat, 12 Aug 2017 00:25:10 UTC (1,023 KB)"
"1333","Deep Learning the Ising Model Near Criticality","Alan Morningstar, Roger G. Melko","Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG); Machine Learning (stat.ML)","It is well established that neural networks with deep architectures perform better than shallow networks for many tasks in machine learning. In statistical physics, while there has been recent interest in representing physical data with generative modelling, the focus has been on shallow neural networks. A natural question to ask is whether deep neural networks hold any advantage over shallow networks in representing such data. We investigate this question by using unsupervised, generative graphical models to learn the probability distribution of a two-dimensional Ising system. Deep Boltzmann machines, deep belief networks, and deep restricted Boltzmann networks are trained on thermal spin configurations from this system, and compared to the shallow architecture of the restricted Boltzmann machine. We benchmark the models, focussing on the accuracy of generating energetic observables near the phase transition, where these quantities are most difficult to approximate. Interestingly, after training the generative networks, we observe that the accuracy essentially depends only on the number of neurons in the first hidden layer of the network, and not on other model details such as network depth or model type. This is evidence that shallow networks are more efficient than deep networks at representing physical probability distributions associated with Ising systems near criticality.","Tue, 15 Aug 2017 18:00:01 UTC (1,313 KB)"
"1334","Extractive Summarization using Deep Learning","Sukriti Verma, Vagisha Nidhi","Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)","This paper proposes a text summarization approach for factual reports using a deep learning model. This approach consists of three phases: feature extraction, feature enhancement, and summary generation, which work together to assimilate core information and generate a coherent, understandable summary. We are exploring various features to improve the set of sentences selected for the summary, and are using a Restricted Boltzmann Machine to enhance and abstract those features to improve resultant accuracy without losing any important information. The sentences are scored based on those enhanced features and an extractive summary is constructed. Experimentation carried out on several articles demonstrates the effectiveness of the proposed approach.","Tue, 15 Aug 2017 09:08:50 UTC (158 KB)"
"1335","Graph Classification via Deep Learning with Virtual Nodes","Trang Pham, Truyen Tran, Hoa Dam, Svetha Venkatesh","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","Learning representation for graph classification turns a variable-size graph into a fixed-size vector (or matrix). Such a representation works nicely with algebraic manipulations. Here we introduce a simple method to augment an attributed graph with a virtual node that is bidirectionally connected to all existing nodes. The virtual node represents the latent aspects of the graph, which are not immediately available from the attributes and local connectivity structures. The expanded graph is then put through any node representation method. The representation of the virtual node is then the representation of the entire graph. In this paper, we use the recently introduced Column Network for the expanded graph, resulting in a new end-to-end graph classification model dubbed Virtual Column Network (VCN). The model is validated on two tasks: (i) predicting bio-activity of chemical compounds, and (ii) finding software vulnerability from source code. Results demonstrate that VCN is competitive against well-established rivals.","Mon, 14 Aug 2017 23:47:02 UTC (922 KB)"
"1336","Encoding Multi-Resolution Brain Networks Using Unsupervised Deep Learning","Arash Rahnama, Abdullah Alchihabi, Vijay Gupta, Panos Antsaklis, Fatos T. Yarman Vural","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)","The main goal of this study is to extract a set of brain networks in multiple time-resolutions to analyze the connectivity patterns among the anatomic regions for a given cognitive task. We suggest a deep architecture which learns the natural groupings of the connectivity patterns of human brain in multiple time-resolutions. The suggested architecture is tested on task data set of Human Connectome Project (HCP) where we extract multi-resolution networks, each of which corresponds to a cognitive task. At the first level of this architecture, we decompose the fMRI signal into multiple sub-bands using wavelet decompositions. At the second level, for each sub-band, we estimate a brain network extracted from short time windows of the fMRI signal. At the third level, we feed the adjacency matrices of each mesh network at each time-resolution into an unsupervised deep learning algorithm, namely, a Stacked De- noising Auto-Encoder (SDAE). The outputs of the SDAE provide a compact connectivity representation for each time window at each sub-band of the fMRI signal. We concatenate the learned representations of all sub-bands at each window and cluster them by a hierarchical algorithm to find the natural groupings among the windows. We observe that each cluster represents a cognitive task with a performance of 93% Rand Index and 71% Adjusted Rand Index. We visualize the mean values and the precisions of the networks at each component of the cluster mixture. The mean brain networks at cluster centers show the variations among cognitive tasks and the precision of each cluster shows the within cluster variability of networks, across the subjects.","Sun, 13 Aug 2017 01:43:11 UTC (29,071 KB)"
"1337","Kinship Verification from Videos using Spatio-Temporal Texture Features and Deep Learning","Elhocine Boutellaa, Miguel Bordallo Lopez, Samy Ait-Aoudia, Xiaoyi Feng, Abdenour Hadid","Computer Vision and Pattern Recognition (cs.CV)","Automatic kinship verification using facial images is a relatively new and challenging research problem in computer vision. It consists in automatically predicting whether two persons have a biological kin relation by examining their facial attributes. While most of the existing works extract shallow handcrafted features from still face images, we approach this problem from spatio-temporal point of view and explore the use of both shallow texture features and deep features for characterizing faces. Promising results, especially those of deep features, are obtained on the benchmark UvA-NEMO Smile database. Our extensive experiments also show the superiority of using videos over still images, hence pointing out the important role of facial dynamics in kinship verification. Furthermore, the fusion of the two types of features (i.e. shallow spatio-temporal texture features and deep features) shows significant performance improvements compared to state-of-the-art methods.","Mon, 14 Aug 2017 10:41:33 UTC (70 KB)"
"1338","IoT Data Analytics Using Deep Learning","Xiaofeng Xie, Di Wu, Siping Liu, Renfa Li","Networking and Internet Architecture (cs.NI)","Deep learning is a popular machine learning approach which has achieved a lot of progress in all traditional machine learning areas. Internet of thing (IoT) and Smart City deployments are generating large amounts of time-series sensor data in need of analysis. Applying deep learning to these domains has been an important topic of research. The Long-Short Term Memory (LSTM) network has been proven to be well suited for dealing with and predicting important events with long intervals and delays in the time series. LTSM networks have the ability to maintain long-term memory. In an LTSM network, a stacked LSTM hidden layer also makes it possible to learn a high level temporal feature without the need of any fine tuning and preprocessing which would be required by other techniques. In this paper, we construct a long-short term memory (LSTM) recurrent neural network structure, use the normal time series training set to build the prediction model. And then we use the predicted error from the prediction model to construct a Gaussian naive Bayes model to detect whether the original sample is abnormal. This method is called LSTM-Gauss-NBayes for short. We use three real-world data sets, each of which involve long-term time-dependence or short-term time-dependence, even very weak time dependence. The experimental results show that LSTM-Gauss-NBayes is an effective and robust model.","Sun, 13 Aug 2017 04:58:49 UTC (1,322 KB)"
"1339","Scaling Deep Learning on GPU and Knights Landing clusters","Yang You, Aydin Buluc, James Demmel","Distributed, Parallel, and Cluster Computing (cs.DC)","The speed of deep neural networks training has become a big bottleneck of deep learning research and development. For example, training GoogleNet by ImageNet dataset on one Nvidia K20 GPU needs 21 days. To speed up the training process, the current deep learning systems heavily rely on the hardware accelerators. However, these accelerators have limited on-chip memory compared with CPUs. To handle large datasets, they need to fetch data from either CPU memory or remote processors. We use both self-hosted Intel Knights Landing (KNL) clusters and multi-GPU clusters as our target platforms. From an algorithm aspect, current distributed machine learning systems are mainly designed for cloud systems. These methods are asynchronous because of the slow network and high fault-tolerance requirement on cloud systems. We focus on Elastic Averaging SGD (EASGD) to design algorithms for HPC clusters. Original EASGD used round-robin method for communication and updating. The communication is ordered by the machine rank ID, which is inefficient on HPC clusters. First, we redesign four efficient algorithms for HPC systems to improve EASGD's poor scaling on clusters. Async EASGD, Async MEASGD, and Hogwild EASGD are faster \textcolor{black}{than} their existing counterparts (Async SGD, Async MSGD, and Hogwild SGD, resp.) in all the comparisons. Finally, we design Sync EASGD, which ties for the best performance among all the methods while being deterministic. In addition to the algorithmic improvements, we use some system-algorithm codesign techniques to scale up the algorithms. By reducing the percentage of communication from 87% to 14%, our Sync EASGD achieves 5.3x speedup over original EASGD on the same platform. We get 91.5% weak scaling efficiency on 4253 KNL cores, which is higher than the state-of-the-art implementation.","Wed, 9 Aug 2017 19:49:13 UTC (5,860 KB)"
"1340","Probabilistic Neural Network with Complex Exponential Activation Functions in Image Recognition using Deep Learning Framework","Andrey Savchenko","Computer Vision and Pattern Recognition (cs.CV)","If the training dataset is not very large, image recognition is usually implemented with the transfer learning methods. In these methods the features are extracted using a deep convolutional neural network, which was preliminarily trained with an external very-large dataset. In this paper we consider the nonparametric classification of extracted feature vectors with the probabilistic neural network (PNN). The number of neurons at the pattern layer of the PNN is equal to the database size, which causes the low recognition performance and high memory space complexity of this network. We propose to overcome these drawbacks by replacing the exponential activation function in the Gaussian Parzen kernel to the complex exponential functions in the Fejer kernel. We demonstrate that in this case it is possible to implement the network with the number of neurons in the pattern layer proportional to the cubic root of the database size. Thus, the proposed modification of the PNN makes it possible to significantly decrease runtime and memory complexities without loosing its main advantages, namely, extremely fast training procedure and the convergence to the optimal Bayesian decision. An experimental study in visual object category classification and unconstrained face recognition with contemporary deep neural networks have shown, that our approach obtains very efficient and rather accurate decisions for the small training sample in comparison with the well-known classifiers.","Wed, 9 Aug 2017 06:50:32 UTC (1,751 KB)"
"1341","Sequential Dual Deep Learning with Shape and Texture Features for Sketch Recognition","Qi Jia, Meiyu Yu, Xin Fan, Haojie Li","Computer Vision and Pattern Recognition (cs.CV)","Recognizing freehand sketches with high arbitrariness is greatly challenging. Most existing methods either ignore the geometric characteristics or treat sketches as handwritten characters with fixed structural ordering. Consequently, they can hardly yield high recognition performance even though sophisticated learning techniques are employed. In this paper, we propose a sequential deep learning strategy that combines both shape and texture features. A coded shape descriptor is exploited to characterize the geometry of sketch strokes with high flexibility, while the outputs of constitutional neural networks (CNN) are taken as the abstract texture feature. We develop dual deep networks with memorable gated recurrent units (GRUs), and sequentially feed these two types of features into the dual networks, respectively. These dual networks enable the feature fusion by another gated recurrent unit (GRU), and thus accurately recognize sketches invariant to stroke ordering. The experiments on the TU-Berlin data set show that our method outperforms the average of human and state-of-the-art algorithms even when significant shape and appearance variations occur.","Wed, 9 Aug 2017 04:42:25 UTC (1,037 KB)"
"1342","Recent Trends in Deep Learning Based Natural Language Processing","Tom Young, Devamanyu Hazarika, Soujanya Poria, Erik Cambria","Computation and Language (cs.CL)","Deep learning methods employ multiple processing layers to learn hierarchical representations of data and have produced state-of-the-art results in many domains. Recently, a variety of model designs and methods have blossomed in the context of natural language processing (NLP). In this paper, we review significant deep learning related models and methods that have been employed for numerous NLP tasks and provide a walk-through of their evolution. We also summarize, compare and contrast the various models and put forward a detailed understanding of the past, present and future of deep learning in NLP.","Wed, 9 Aug 2017 04:02:17 UTC (3,173 KB)[v2] Mon, 14 Aug 2017 15:48:19 UTC (3,175 KB)[v3] Tue, 15 Aug 2017 15:28:21 UTC (3,175 KB)[v4] Wed, 16 Aug 2017 04:11:12 UTC (3,175 KB)[v5] Tue, 20 Feb 2018 08:08:36 UTC (3,840 KB)[v6] Sat, 4 Aug 2018 10:22:09 UTC (6,458 KB)[v7] Wed, 10 Oct 2018 13:46:59 UTC (6,459 KB)[v8] Sun, 25 Nov 2018 03:26:49 UTC (6,539 KB)"
"1343","Multibiometric Secure System Based on Deep Learning","Veeru Talreja, Matthew C. Valenti, Nasser M. Nasrabadi","Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Information Theory (cs.IT)","In this paper, we propose a secure multibiometric system that uses deep neural networks and error-correction coding. We present a feature-level fusion framework to generate a secure multibiometric template from each user's multiple biometrics. Two fusion architectures, fully connected architecture and bilinear architecture, are implemented to develop a robust multibiometric shared representation. The shared representation is used to generate a cancelable biometric template that involves the selection of a different set of reliable and discriminative features for each user. This cancelable template is a binary vector and is passed through an appropriate error-correcting decoder to find a closest codeword and this codeword is hashed to generate the final secure template. The efficacy of the proposed approach is shown using a multimodal database where we achieve state-of-the-art matching performance, along with cancelability and security.","Mon, 7 Aug 2017 21:35:26 UTC (306 KB)"
"1344","Identifying 3 moss species by deep learning, using the ""chopped picture"" method","Takeshi Ise, Mari Minagawa, Masanori Onishi","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV)","In general, object identification tends not to work well on ambiguous, amorphous objects such as vegetation. In this study, we developed a simple but effective approach to identify ambiguous objects and applied the method to several moss species. As a result, the model correctly classified test images with accuracy more than 90%. Using this approach will help progress in computer vision studies.","Mon, 7 Aug 2017 04:37:23 UTC (1,478 KB)[v2] Tue, 8 Aug 2017 01:38:37 UTC (1,473 KB)"
"1345","Exploring the Function Space of Deep-Learning Machines","Bo Li, David Saad","Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG)","The function space of deep-learning machines is investigated by studying growth in the entropy of functions of a given error with respect to a reference function, realized by a deep-learning machine. Using physics-inspired methods we study both sparsely and densely-connected architectures to discover a layer-wise convergence of candidate functions, marked by a corresponding reduction in entropy when approaching the reference function, gain insight into the importance of having a large number of layers, and observe phase transitions as the error increases.","Fri, 4 Aug 2017 08:38:20 UTC (541 KB)[v2] Tue, 15 May 2018 11:29:15 UTC (957 KB)[v3] Thu, 9 Aug 2018 08:09:52 UTC (955 KB)"
"1346","Adversarial-Playground: A Visualization Suite Showing How Adversarial Examples Fool Deep Learning","Andrew P. Norton, Yanjun Qi","Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","Recent studies have shown that attackers can force deep learning models to misclassify so-called ""adversarial examples"": maliciously generated images formed by making imperceptible modifications to pixel values. With growing interest in deep learning for security applications, it is important for security experts and users of machine learning to recognize how learning systems may be attacked. Due to the complex nature of deep learning, it is challenging to understand how deep models can be fooled by adversarial examples. Thus, we present a web-based visualization tool, Adversarial-Playground, to demonstrate the efficacy of common adversarial methods against a convolutional neural network (CNN) system. Adversarial-Playground is educational, modular and interactive. (1) It enables non-experts to compare examples visually and to understand why an adversarial example can fool a CNN-based image classifier. (2) It can help security experts explore more vulnerability of deep learning as a software module. (3) Building an interactive visualization is challenging in this domain due to the large feature space of image classification (generating adversarial examples is slow in general and visualizing images are costly). Through multiple novel design choices, our tool can provide fast and accurate responses to user requests. Empirically, we find that our client-server division strategy reduced the response time by an average of 1.5 seconds per sample. Our other innovation, a faster variant of JSMA evasion algorithm, empirically performed twice as fast as JSMA and yet maintains a comparable evasion rate. Project source code and data from our experiments available at: this https URL","Tue, 1 Aug 2017 14:34:35 UTC (258 KB)"
"1347","OmniArt: Multi-task Deep Learning for Artistic Data Analysis","Gjorgji Strezoski, Marcel Worring","Multimedia (cs.MM); Computer Vision and Pattern Recognition (cs.CV)","Vast amounts of artistic data is scattered on-line from both museums and art applications. Collecting, processing and studying it with respect to all accompanying attributes is an expensive process. With a motivation to speed up and improve the quality of categorical analysis in the artistic domain, in this paper we propose an efficient and accurate method for multi-task learning with a shared representation applied in the artistic domain. We continue to show how different multi-task configurations of our method behave on artistic data and outperform handcrafted feature approaches as well as convolutional neural networks. In addition to the method and analysis, we propose a challenge like nature to the new aggregated data set with almost half a million samples and structured meta-data to encourage further research and societal engagement.","Wed, 2 Aug 2017 10:20:22 UTC (5,531 KB)"
"1348","A Deep Learning-based Reconstruction of Cosmic Ray-induced Air Showers","Martin Erdmann, Jonas Glombitza, David Walz","Instrumentation and Methods for Astrophysics (astro-ph.IM); High Energy Astrophysical Phenomena (astro-ph.HE)","We describe a method of reconstructing air showers induced by cosmic rays using deep learning techniques. We simulate an observatory consisting of ground-based particle detectors with fixed locations on a regular grid. The detector's responses to traversing shower particles are signal amplitudes as a function of time, which provide information on transverse and longitudinal shower properties. In order to take advantage of convolutional network techniques specialized in local pattern recognition, we convert all information to the image-like grid of the detectors. In this way, multiple features, such as arrival times of the first particles and optimized characterizations of time traces, are processed by the network. The reconstruction quality of the cosmic ray arrival direction turns out to be competitive with an analytic reconstruction algorithm. The reconstructed shower direction, energy and shower depth show the expected improvement in resolution for higher cosmic ray energy.","Wed, 2 Aug 2017 08:44:21 UTC (1,223 KB)[v2] Tue, 31 Oct 2017 11:28:33 UTC (1,223 KB)"
"1349","Compiling Deep Learning Models for Custom Hardware Accelerators","Andre Xian Ming Chang, Aliasger Zaidy, Vinayak Gokhale, Eugenio Culurciello","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","Convolutional neural networks (CNNs) are the core of most state-of-the-art deep learning algorithms specialized for object detection and classification. CNNs are both computationally complex and embarrassingly parallel. Two properties that leave room for potential software and hardware optimizations for embedded systems. Given a programmable hardware accelerator with a CNN oriented custom instructions set, the compiler's task is to exploit the hardware's full potential, while abiding with the hardware constraints and maintaining generality to run different CNN models with varying workload properties. Snowflake is an efficient and scalable hardware accelerator implemented on programmable logic devices. It implements a control pipeline for a custom instruction set. The goal of this paper is to present Snowflake's compiler that generates machine level instructions from Torch7 model description files. The main software design points explored in this work are: model structure parsing, CNN workload breakdown, loop rearrangement for memory bandwidth optimizations and memory access balancing. The performance achieved by compiler generated instructions matches against hand optimized code for convolution layers. Generated instructions also efficiently execute AlexNet and ResNet18 inference on Snowflake. Snowflake with $256$ processing units was synthesized on Xilinx's Zynq XC7Z045 FPGA. At $250$ MHz, AlexNet achieved in $93.6$ frames/s and $1.2$ GB/s of off-chip memory bandwidth, and $21.4$ frames/s and $2.2$ GB/s for ResNet18. Total on-chip power is $5$ W.","Tue, 1 Aug 2017 01:01:18 UTC (196 KB)[v2] Sun, 10 Dec 2017 18:12:33 UTC (196 KB)"
"1350","Vision-Based Assessment of Parkinsonism and Levodopa-Induced Dyskinesia with Deep Learning Pose Estimation","Michael H. Li, Tiago A. Mestre, Susan H. Fox, Babak Taati","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Objective: To apply deep learning pose estimation algorithms for vision-based assessment of parkinsonism and levodopa-induced dyskinesia (LID). Methods: Nine participants with Parkinson's disease (PD) and LID completed a levodopa infusion protocol, where symptoms were assessed at regular intervals using the Unified Dyskinesia Rating Scale (UDysRS) and Unified Parkinson's Disease Rating Scale (UPDRS). A state-of-the-art deep learning pose estimation method was used to extract movement trajectories from videos of PD assessments. Features of the movement trajectories were used to detect and estimate the severity of parkinsonism and LID using random forest. Communication and drinking tasks were used to assess LID, while leg agility and toe tapping tasks were used to assess parkinsonism. Feature sets from tasks were also combined to predict total UDysRS and UPDRS Part III scores. Results: For LID, the communication task yielded the best results for dyskinesia (severity estimation: r = 0.661, detection: AUC = 0.930). For parkinsonism, leg agility had better results for severity estimation (r = 0.618), while toe tapping was better for detection (AUC = 0.773). UDysRS and UPDRS Part III scores were predicted with r = 0.741 and 0.530, respectively. Conclusion: This paper presents the first application of deep learning for vision-based assessment of parkinsonism and LID and demonstrates promising performance for the future translation of deep learning to PD clinical practices. Significance: The proposed system provides insight into the potential of computer vision and deep learning for clinical application in PD.","Tue, 25 Jul 2017 20:56:22 UTC (459 KB)[v2] Tue, 1 Aug 2017 16:03:22 UTC (459 KB)"
"1351","Optimized Broadcast for Deep Learning Workloads on Dense-GPU InfiniBand Clusters: MPI or NCCL?","Ammar Ahmad Awan, Ching-Hsiang Chu, Hari Subramoni, Dhabaleswar K. Panda","Distributed, Parallel, and Cluster Computing (cs.DC)","Dense Multi-GPU systems have recently gained a lot of attention in the HPC arena. Traditionally, MPI runtimes have been primarily designed for clusters with a large number of nodes. However, with the advent of MPI+CUDA applications and CUDA-Aware MPI runtimes like MVAPICH2 and OpenMPI, it has become important to address efficient communication schemes for such dense Multi-GPU nodes. This coupled with new application workloads brought forward by Deep Learning frameworks like Caffe and Microsoft CNTK pose additional design constraints due to very large message communication of GPU buffers during the training phase. In this context, special-purpose libraries like NVIDIA NCCL have been proposed for GPU-based collective communication on dense GPU systems. In this paper, we propose a pipelined chain (ring) design for the MPI_Bcast collective operation along with an enhanced collective tuning framework in MVAPICH2-GDR that enables efficient intra-/inter-node multi-GPU communication. We present an in-depth performance landscape for the proposed MPI_Bcast schemes along with a comparative analysis of NVIDIA NCCL Broadcast and NCCL-based MPI_Bcast. The proposed designs for MVAPICH2-GDR enable up to 14X and 16.6X improvement, compared to NCCL-based solutions, for intra- and inter-node broadcast latency, respectively. In addition, the proposed designs provide up to 7% improvement over NCCL-based solutions for data parallel training of the VGG network on 128 GPUs using Microsoft CNTK.","Fri, 28 Jul 2017 20:54:06 UTC (77 KB)"
"1352","Tartan: Accelerating Fully-Connected and Convolutional Layers in Deep Learning Networks by Exploiting Numerical Precision Variability","Alberto Delmas, Sayeh Sharify, Patrick Judd, Andreas Moshovos","Neural and Evolutionary Computing (cs.NE)","Tartan (TRT), a hardware accelerator for inference with Deep Neural Networks (DNNs), is presented and evaluated on Convolutional Neural Networks. TRT exploits the variable per layer precision requirements of DNNs to deliver execution time that is proportional to the precision p in bits used per layer for convolutional and fully-connected layers. Prior art has demonstrated an accelerator with the same execution performance only for convolutional layers. Experiments on image classification CNNs show that on average across all networks studied, TRT outperforms a state-of-the-art bit-parallel accelerator by 1:90x without any loss in accuracy while it is 1:17x more energy efficient. TRT requires no network retraining while it enables trading off accuracy for additional improvements in execution performance and energy efficiency. For example, if a 1% relative loss in accuracy is acceptable, TRT is on average 2:04x faster and 1:25x more energy efficient than a conventional bit-parallel accelerator. A Tartan configuration that processes 2-bits at time, requires less area than the 1-bit configuration, improves efficiency to 1:24x over the bit-parallel baseline while being 73% faster for convolutional layers and 60% faster for fully-connected layers is also presented.","Thu, 27 Jul 2017 22:56:13 UTC (2,205 KB)"
"1353","Deep-learned Top Tagging with a Lorentz Layer","Anja Butter, Gregor Kasieczka, Tilman Plehn, Michael Russell","High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Experiment (hep-ex)","We introduce a new and highly efficient tagger for hadronically decaying top quarks, based on a deep neural network working with Lorentz vectors and the Minkowski metric. With its novel machine learning setup and architecture it allows us to identify boosted top quarks not only from calorimeter towers, but also including tracking information. We show how the performance of our tagger compares with QCD-inspired and image-recognition approaches and find that it significantly increases the performance for strongly boosted top quarks.","Thu, 27 Jul 2017 18:00:03 UTC (450 KB)[v2] Tue, 16 Jan 2018 16:26:10 UTC (433 KB)[v3] Mon, 23 Apr 2018 06:24:25 UTC (434 KB)"
"1354","Robust Physical-World Attacks on Deep Learning Models","Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo Li, Amir Rahmati, Chaowei Xiao, Atul Prakash, Tadayoshi Kohno, Dawn Song","Cryptography and Security (cs.CR); Machine Learning (cs.LG)","Recent studies show that the state-of-the-art deep neural networks (DNNs) are vulnerable to adversarial examples, resulting from small-magnitude perturbations added to the input. Given that that emerging physical systems are using DNNs in safety-critical situations, adversarial examples could mislead these systems and cause dangerous situations.Therefore, understanding adversarial examples in the physical world is an important step towards developing resilient learning algorithms. We propose a general attack algorithm,Robust Physical Perturbations (RP2), to generate robust visual adversarial perturbations under different physical conditions. Using the real-world case of road sign classification, we show that adversarial examples generated using RP2 achieve high targeted misclassification rates against standard-architecture road sign classifiers in the physical world under various environmental conditions, including viewpoints. Due to the current lack of a standardized testing method, we propose a two-stage evaluation methodology for robust physical adversarial examples consisting of lab and field tests. Using this methodology, we evaluate the efficacy of physical adversarial manipulations on real objects. Witha perturbation in the form of only black and white stickers,we attack a real stop sign, causing targeted misclassification in 100% of the images obtained in lab settings, and in 84.8%of the captured video frames obtained on a moving vehicle(field test) for the target classifier.","Thu, 27 Jul 2017 17:37:22 UTC (9,143 KB)[v2] Sun, 30 Jul 2017 15:58:21 UTC (9,128 KB)[v3] Mon, 7 Aug 2017 23:52:10 UTC (9,128 KB)[v4] Wed, 13 Sep 2017 03:59:56 UTC (8,067 KB)[v5] Tue, 10 Apr 2018 16:22:47 UTC (1,867 KB)"
"1355","Distributed Deep Learning Models for Wireless Signal Classification with Low-Cost Spectrum Sensors","Sreeraj Rajendran, Wannes Meert, Domenico Giustiniano, Vincent Lenders, Sofie Pollin","Networking and Internet Architecture (cs.NI)","This paper looks into the technology classification problem for a distributed wireless spectrum sensing network. First, a new data-driven model for Automatic Modulation Classification (AMC) based on long short term memory (LSTM) is proposed. The model learns from the time domain amplitude and phase information of the modulation schemes present in the training data without requiring expert features like higher order cyclic moments. Analyses show that the proposed model yields an average classification accuracy of close to 90% at varying SNR conditions ranging from 0dB to 20dB. Further, we explore the utility of this LSTM model for a variable symbol rate scenario. We show that a LSTM based model can learn good representations of variable length time domain sequences, which is useful in classifying modulation signals with different symbol rates. The achieved accuracy of 75% on an input sample length of 64 for which it was not trained, substantiates the representation power of the model. To reduce the data communication overhead from distributed sensors, the feasibility of classification using averaged magnitude spectrum data, or online classification on the low cost sensors is studied. Furthermore, quantized realizations of the proposed models are analyzed for deployment on sensors with low processing power.","Thu, 27 Jul 2017 15:41:25 UTC (2,845 KB)[v2] Wed, 11 Jul 2018 08:43:09 UTC (4,200 KB)"
"1356","TensorLayer: A Versatile Library for Efficient Deep Learning Development","Hao Dong, Akara Supratak, Luo Mai, Fangde Liu, Axel Oehmichen, Simiao Yu, Yike Guo","Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (stat.ML)","Deep learning has enabled major advances in the fields of computer vision, natural language processing, and multimedia among many others. Developing a deep learning system is arduous and complex, as it involves constructing neural network architectures, managing training/trained models, tuning optimization process, preprocessing and organizing data, etc. TensorLayer is a versatile Python library that aims at helping researchers and engineers efficiently develop deep learning systems. It offers rich abstractions for neural networks, model and data management, and parallel workflow mechanism. While boosting efficiency, TensorLayer maintains both performance and scalability. TensorLayer was released in September 2016 on GitHub, and has helped people from academia and industry develop real-world applications of deep learning.","Wed, 26 Jul 2017 17:29:49 UTC (611 KB)[v2] Wed, 2 Aug 2017 10:26:34 UTC (1,527 KB)[v3] Thu, 3 Aug 2017 14:48:16 UTC (1,526 KB)"
"1357","Detecting and classifying lesions in mammograms with Deep Learning","Dezs<U+0151> Ribli, Anna Horvath, Zsuzsa Unger, Peter Pollner, Istvan Csabai","Computer Vision and Pattern Recognition (cs.CV)","In the last two decades Computer Aided Diagnostics (CAD) systems were developed to help radiologists analyze screening mammograms. The benefits of current CAD technologies appear to be contradictory and they should be improved to be ultimately considered useful. Since 2012 deep convolutional neural networks (CNN) have been a tremendous success in image recognition, reaching human performance. These methods have greatly surpassed the traditional approaches, which are similar to currently used CAD solutions. Deep CNN-s have the potential to revolutionize medical image analysis. We propose a CAD system based on one of the most successful object detection frameworks, Faster R-CNN. The system detects and classifies malignant or benign lesions on a mammogram without any human intervention. The proposed method sets the state of the art classification performance on the public INbreast database, AUC = 0.95 . The approach described here has achieved the 2nd place in the Digital Mammography DREAM Challenge with AUC = 0.85 . When used as a detector, the system reaches high sensitivity with very few false positive marks per image on the INbreast dataset. Source code, the trained model and an OsiriX plugin are availaible online at this https URL .","Wed, 26 Jul 2017 12:07:45 UTC (1,435 KB)[v2] Wed, 20 Sep 2017 13:04:51 UTC (1,556 KB)[v3] Thu, 9 Nov 2017 14:31:13 UTC (2,247 KB)"
"1358","Reduction of Overfitting in Diabetes Prediction Using Deep Learning Neural Network","Akm Ashiquzzaman, Abdul Kawsar Tushar, Md. Rashedul Islam, Jong-Myon Kim","Computer Vision and Pattern Recognition (cs.CV)","Augmented accuracy in prediction of diabetes will open up new frontiers in health prognostics. Data overfitting is a performance-degrading issue in diabetes prognosis. In this study, a prediction system for the disease of diabetes is pre-sented where the issue of overfitting is minimized by using the dropout method. Deep learning neural network is used where both fully connected layers are fol-lowed by dropout layers. The output performance of the proposed neural network is shown to have outperformed other state-of-art methods and it is recorded as by far the best performance for the Pima Indians Diabetes Data Set.","Wed, 26 Jul 2017 11:44:55 UTC (384 KB)"
"1359","Dragon: A Computation Graph Virtual Machine Based Deep Learning Framework","Ting Pan","Software Engineering (cs.SE); Machine Learning (cs.LG); Mathematical Software (cs.MS); Neural and Evolutionary Computing (cs.NE)","Deep Learning has made a great progress for these years. However, it is still difficult to master the implement of various models because different researchers may release their code based on different frameworks or interfaces. In this paper, we proposed a computation graph based framework which only aims to introduce well-known interfaces. It will help a lot when reproducing a newly model or transplanting models that were implemented by other frameworks. Additionally, we implement numerous recent models covering both Computer Vision and Nature Language Processing. We demonstrate that our framework will not suffer from model-starving because it is much easier to make full use of the works that are already done.","Wed, 26 Jul 2017 01:16:29 UTC (199 KB)"
"1360","SLEEPNET: Automated Sleep Staging System via Deep Learning","Siddharth Biswal, Joshua Kulas, Haoqi Sun, Balaji Goparaju, M Brandon Westover, Matt T Bianchi, Jimeng Sun","Machine Learning (cs.LG)","Sleep disorders, such as sleep apnea, parasomnias, and hypersomnia, affect 50-70 million adults in the United States (Hillman et al., 2006). Overnight polysomnography (PSG), including brain monitoring using electroencephalography (EEG), is a central component of the diagnostic evaluation for sleep disorders. While PSG is conventionally performed by trained technologists, the recent rise of powerful neural network learning algorithms combined with large physiological datasets offers the possibility of automation, potentially making expert-level sleep analysis more widely available. We propose SLEEPNET (Sleep EEG neural network), a deployed annotation tool for sleep staging. SLEEPNET uses a deep recurrent neural network trained on the largest sleep physiology database assembled to date, consisting of PSGs from over 10,000 patients from the Massachusetts General Hospital (MGH) Sleep Laboratory. SLEEPNET achieves human-level annotation performance on an independent test set of 1,000 EEGs, with an average accuracy of 85.76% and algorithm-expert inter-rater agreement (IRA) of kappa = 79.46%, comparable to expert-expert IRA.","Wed, 26 Jul 2017 00:39:59 UTC (2,176 KB)"
"1361","Deep Forecast: Deep Learning-based Spatio-Temporal Forecasting","Amir Ghaderi, Borhan M. Sanandaji, Faezeh Ghaderi","Machine Learning (cs.LG)","The paper presents a spatio-temporal wind speed forecasting algorithm using Deep Learning (DL)and in particular, Recurrent Neural Networks(RNNs). Motivated by recent advances in renewable energy integration and smart grids, we apply our proposed algorithm for wind speed forecasting. Renewable energy resources (wind and solar)are random in nature and, thus, their integration is facilitated with accurate short-term forecasts. In our proposed framework, we model the spatiotemporal information by a graph whose nodes are data generating entities and its edges basically model how these nodes are interacting with each other. One of the main contributions of our work is the fact that we obtain forecasts of all nodes of the graph at the same time based on one framework. Results of a case study on recorded time series data from a collection of wind mills in the north-east of the U.S. show that the proposed DL-based forecasting algorithm significantly improves the short-term forecasts compared to a set of widely-used benchmarks models.","Mon, 24 Jul 2017 18:56:33 UTC (1,781 KB)"
"1362","Deep Learning Based MIMO Communications","Timothy J. O'Shea, Tugba Erpek, T.Charles Clancy","Information Theory (cs.IT)","We introduce a novel physical layer scheme for single user Multiple-Input Multiple-Output (MIMO) communications based on unsupervised deep learning using an autoencoder. This method extends prior work on the joint optimization of physical layer representation and encoding and decoding processes as a single end-to-end task by expanding transmitter and receivers to the multi-antenna case. We introduce a widely used domain appropriate wireless channel impairment model (Rayleigh fading channel), into the autoencoder optimization problem in order to directly learn a system which optimizes for it. We considered both spatial diversity and spatial multiplexing techniques in our implementation. Our deep learning-based approach demonstrates significant potential for learning schemes which approach and exceed the performance of the methods which are widely used in existing wireless MIMO systems. We discuss how the proposed scheme can be easily adapted for open-loop and closed-loop operation in spatial diversity and multiplexing modes and extended use with only compact binary channel state information (CSI) as feedback.","Tue, 25 Jul 2017 13:28:27 UTC (642 KB)"
"1363","A Deep Learning Approach to Digitally Stain Optical Coherence Tomography Images of the Optic Nerve Head","Sripad Krishna Devalla, Jean-Martial Mari, Tin A. Tun, Nicholas G. Strouthidis, Tin Aung, Alexandre H. Thiery, Michael J. A. Girard","Machine Learning (cs.LG)","Purpose: To develop a deep learning approach to digitally-stain optical coherence tomography (OCT) images of the optic nerve head (ONH). Methods: A horizontal B-scan was acquired through the center of the ONH using OCT (Spectralis) for 1 eye of each of 100 subjects (40 normal & 60 glaucoma). All images were enhanced using adaptive compensation. A custom deep learning network was then designed and trained with the compensated images to digitally stain (i.e. highlight) 6 tissue layers of the ONH. The accuracy of our algorithm was assessed (against manual segmentations) using the Dice coefficient, sensitivity, and specificity. We further studied how compensation and the number of training images affected the performance of our algorithm. Results: For images it had not yet assessed, our algorithm was able to digitally stain the retinal nerve fiber layer + prelamina, the retinal pigment epithelium, all other retinal layers, the choroid, and the peripapillary sclera and lamina cribrosa. For all tissues, the mean dice coefficient was $0.84 \pm 0.03$, the mean sensitivity $0.92 \pm 0.03$, and the mean specificity $0.99 \pm 0.00$. Our algorithm performed significantly better when compensated images were used for training. Increasing the number of images (from 10 to 40) to train our algorithm did not significantly improve performance, except for the RPE. Conclusion. Our deep learning algorithm can simultaneously stain neural and connective tissues in ONH images. Our approach offers a framework to automatically measure multiple key structural parameters of the ONH that may be critical to improve glaucoma management.","Mon, 24 Jul 2017 15:41:45 UTC (1,281 KB)"
"1364","Deep Learning based Recommender System: A Survey and New Perspectives","Shuai Zhang, Lina Yao, Aixin Sun, Yi Tay","Information Retrieval (cs.IR)","With the ever-growing volume of online information, recommender systems have been an effective strategy to overcome such information overload. The utility of recommender systems cannot be overstated, given its widespread adoption in many web applications, along with its potential impact to ameliorate many problems related to over-choice. In recent years, deep learning has garnered considerable interest in many research fields such as computer vision and natural language processing, owing not only to stellar performance but also the attractive property of learning feature representations from scratch. The influence of deep learning is also pervasive, recently demonstrating its effectiveness when applied to information retrieval and recommender systems research. Evidently, the field of deep learning in recommender system is flourishing. This article aims to provide a comprehensive review of recent research efforts on deep learning based recommender systems. More concretely, we provide and devise a taxonomy of deep learning based recommendation models, along with providing a comprehensive summary of the state-of-the-art. Finally, we expand on current trends and provide new perspectives pertaining to this new exciting development of the field.","Mon, 24 Jul 2017 08:23:26 UTC (1,982 KB)[v2] Thu, 27 Jul 2017 14:44:59 UTC (1,983 KB)[v3] Sat, 29 Jul 2017 14:15:51 UTC (1,991 KB)[v4] Tue, 1 Aug 2017 14:25:09 UTC (2,050 KB)[v5] Thu, 3 Aug 2017 06:11:24 UTC (2,056 KB)[v6] Tue, 4 Sep 2018 11:58:51 UTC (706 KB)"
"1365","Deep Learning in Robotics: A Review of Recent Research","Harry A. Pierson, Michael S. Gashler","Robotics (cs.RO)","Advances in deep learning over the last decade have led to a flurry of research in the application of deep artificial neural networks to robotic systems, with at least thirty papers published on the subject between 2014 and the present. This review discusses the applications, benefits, and limitations of deep learning vis-a-vis physical robotic systems, using contemporary research as exemplars. It is intended to communicate recent advances to the wider robotics community and inspire additional interest in and application of deep learning in robotics.","Sat, 22 Jul 2017 21:09:29 UTC (306 KB)"
"1366","Shallow reading with Deep Learning: Predicting popularity of online content using only its title","Wociech Stokowiec, Tomasz Trzcinski, Krzysztof Wolk, Krzysztof Marasek, Przemyslaw Rokita","Computation and Language (cs.CL)","With the ever decreasing attention span of contemporary Internet users, the title of online content (such as a news article or video) can be a major factor in determining its popularity. To take advantage of this phenomenon, we propose a new method based on a bidirectional Long Short-Term Memory (LSTM) neural network designed to predict the popularity of online content using only its title. We evaluate the proposed architecture on two distinct datasets of news articles and news videos distributed in social media that contain over 40,000 samples in total. On those datasets, our approach improves the performance over traditional shallow approaches by a margin of 15%. Additionally, we show that using pre-trained word vectors in the embedding layer improves the results of LSTM models, especially when the training set is small. To our knowledge, this is the first attempt of applying popularity prediction using only textual information from the title.","Fri, 21 Jul 2017 09:02:55 UTC (544 KB)"
"1367","Prolongation of SMAP to Spatio-temporally Seamless Coverage of Continental US Using a Deep Learning Neural Network","Kuai Fang, Chaopeng Shen, Daniel Kifer, Xiao Yang","Machine Learning (stat.ML)","The Soil Moisture Active Passive (SMAP) mission has delivered valuable sensing of surface soil moisture since 2015. However, it has a short time span and irregular revisit schedule. Utilizing a state-of-the-art time-series deep learning neural network, Long Short-Term Memory (LSTM), we created a system that predicts SMAP level-3 soil moisture data with atmospheric forcing, model-simulated moisture, and static physiographic attributes as inputs. The system removes most of the bias with model simulations and improves predicted moisture climatology, achieving small test root-mean-squared error (<0.035) and high correlation coefficient >0.87 for over 75\% of Continental United States, including the forested Southeast. As the first application of LSTM in hydrology, we show the proposed network avoids overfitting and is robust for both temporal and spatial extrapolation tests. LSTM generalizes well across regions with distinct climates and physiography. With high fidelity to SMAP, LSTM shows great potential for hindcasting, data assimilation, and weather forecasting.","Thu, 20 Jul 2017 17:06:47 UTC (2,108 KB)[v2] Wed, 16 Aug 2017 16:22:13 UTC (1,877 KB)[v3] Mon, 11 Sep 2017 18:38:40 UTC (2,294 KB)"
"1368","Machine Learning for Quantum Dynamics: Deep Learning of Excitation Energy Transfer Properties","Florian Hase, Christoph Kreisbeck, Alan Aspuru-Guzik","Chemical Physics (physics.chem-ph); Machine Learning (stat.ML)","Understanding the relationship between the structure of light-harvesting systems and their excitation energy transfer properties is of fundamental importance in many applications including the development of next generation photovoltaics. Natural light harvesting in photosynthesis shows remarkable excitation energy transfer properties, which suggests that pigment-protein complexes could serve as blueprints for the design of nature inspired devices. Mechanistic insights into energy transport dynamics can be gained by leveraging numerically involved propagation schemes such as the hierarchical equations of motion (HEOM). Solving these equations, however, is computationally costly due to the adverse scaling with the number of pigments. Therefore virtual high-throughput screening, which has become a powerful tool in material discovery, is less readily applicable for the search of novel excitonic devices. We propose the use of artificial neural networks to bypass the computational limitations of established techniques for exploring the structure-dynamics relation in excitonic systems. Once trained, our neural networks reduce computational costs by several orders of magnitudes. Our predicted transfer times and transfer efficiencies exhibit similar or even higher accuracies than frequently used approximate methods such as secular Redfield theory","Thu, 20 Jul 2017 02:00:58 UTC (4,885 KB)"
"1369","Improving Output Uncertainty Estimation and Generalization in Deep Learning via Neural Network Gaussian Processes","Tomoharu Iwata, Zoubin Ghahramani","Machine Learning (stat.ML)","We propose a simple method that combines neural networks and Gaussian processes. The proposed method can estimate the uncertainty of outputs and flexibly adjust target functions where training data exist, which are advantages of Gaussian processes. The proposed method can also achieve high generalization performance for unseen input configurations, which is an advantage of neural networks. With the proposed method, neural networks are used for the mean functions of Gaussian processes. We present a scalable stochastic inference procedure, where sparse Gaussian processes are inferred by stochastic variational inference, and the parameters of neural networks and kernels are estimated by stochastic gradient descent methods, simultaneously. We use two real-world spatio-temporal data sets to demonstrate experimentally that the proposed method achieves better uncertainty estimation and generalization performance than neural networks and Gaussian processes.","Wed, 19 Jul 2017 02:29:49 UTC (145 KB)"
"1370","A deep learning approach to diabetic blood glucose prediction","H.N. Mhaskar, S.V. Pereverzyev, M.D. van der Walt","Machine Learning (cs.LG); Numerical Analysis (math.NA)","We consider the question of 30-minute prediction of blood glucose levels measured by continuous glucose monitoring devices, using clinical data. While most studies of this nature deal with one patient at a time, we take a certain percentage of patients in the data set as training data, and test on the remainder of the patients; i.e., the machine need not re-calibrate on the new patients in the data set. We demonstrate how deep learning can outperform shallow networks in this example. One novelty is to demonstrate how a parsimonious deep representation can be constructed using domain knowledge.","Tue, 18 Jul 2017 19:21:29 UTC (211 KB)"
"1371","A Novel Deep Learning Architecture for Testis Histology Image Classification","Chia-Yu Kao, Leonard McMillan","Computer Vision and Pattern Recognition (cs.CV)","Unlike other histology analysis, classification of tubule status in testis histology is very challenging due to their high similarity of texture and shape. Traditional deep learning networks have difficulties to capture nuance details among different tubule categories. In this paper, we propose a novel deep learning architecture for feature learning, image classification, and image reconstruction. It is based on stacked auto-encoders with an additional layer, called a hyperlayer, which is created to capture features of an image at different layers in the network. This addition effectively combines features at different scales and thus provides a more complete profile for further classification. Evaluation is performed on a set of 10,542 tubule image patches. We demonstrate our approach with two experiments on two different subsets of the dataset. The results show that the features learned from our architecture achieve more than 98% accuracy and represent an improvement over traditional deep network architectures.","Tue, 18 Jul 2017 18:19:41 UTC (3,883 KB)"
"1372","TensorLog: Deep Learning Meets Probabilistic DBs","William W. Cohen, Fan Yang, Kathryn Rivard Mazaitis","Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","We present an implementation of a probabilistic first-order logic called TensorLog, in which classes of logical queries are compiled into differentiable functions in a neural-network infrastructure such as Tensorflow or Theano. This leads to a close integration of probabilistic logical reasoning with deep-learning infrastructure: in particular, it enables high-performance deep learning frameworks to be used for tuning the parameters of a probabilistic logic. Experimental results show that TensorLog scales to problems involving hundreds of thousands of knowledge-base triples and tens of thousands of examples.","Mon, 17 Jul 2017 20:37:08 UTC (176 KB)"
"1373","Unsupervised Iterative Deep Learning of Speech Features and Acoustic Tokens with Applications to Spoken Term Detection","Cheng-Tao Chung, Cheng-Yu Tsai, Chia-Hsiang Liu, Lin-Shan Lee","Computation and Language (cs.CL)","In this paper we aim to automatically discover high quality frame-level speech features and acoustic tokens directly from unlabeled speech data. A Multi-granular Acoustic Tokenizer (MAT) was proposed for automatic discovery of multiple sets of acoustic tokens from the given corpus. Each acoustic token set is specified by a set of hyperparameters describing the model configuration. These different sets of acoustic tokens carry different characteristics for the given corpus and the language behind, thus can be mutually reinforced. The multiple sets of token labels are then used as the targets of a Multi-target Deep Neural Network (MDNN) trained on frame-level acoustic features. Bottleneck features extracted from the MDNN are then used as the feedback input to the MAT and the MDNN itself in the next iteration. The multi-granular acoustic token sets and the frame-level speech features can be iteratively optimized in the iterative deep learning framework. We call this framework the Multi-granular Acoustic Tokenizing Deep Neural Network (MATDNN). The results were evaluated using the metrics and corpora defined in the Zero Resource Speech Challenge organized at Interspeech 2015, and improved performance was obtained with a set of experiments of query-by-example spoken term detection on the same corpora. Visualization for the discovered tokens against the English phonemes was also shown.","Mon, 17 Jul 2017 10:20:15 UTC (5,249 KB)"
"1374","Cosmological model discrimination with Deep Learning","Jorit Schmelzle, Aurelien Lucchi, Tomasz Kacprzak, Adam Amara, Raphael Sgier, Alexandre Refregier, Thomas Hofmann","Cosmology and Nongalactic Astrophysics (astro-ph.CO); Machine Learning (stat.ML)","We demonstrate the potential of Deep Learning methods for measurements of cosmological parameters from density fields, focusing on the extraction of non-Gaussian information. We consider weak lensing mass maps as our dataset. We aim for our method to be able to distinguish between five models, which were chosen to lie along the $ヲ_8$ - $ヘ_m$ degeneracy, and have nearly the same two-point statistics. We design and implement a Deep Convolutional Neural Network (DCNN) which learns the relation between five cosmological models and the mass maps they generate. We develop a new training strategy which ensures the good performance of the network for high levels of noise. We compare the performance of this approach to commonly used non-Gaussian statistics, namely the skewness and kurtosis of the convergence maps. We find that our implementation of DCNN outperforms the skewness and kurtosis statistics, especially for high noise levels. The network maintains the mean discrimination efficiency greater than $85\%$ even for noise levels corresponding to ground based lensing observations, while the other statistics perform worse in this setting, achieving efficiency less than $70\%$. This demonstrates the ability of CNN-based methods to efficiently break the $ヲ_8$ - $ヘ_m$ degeneracy with weak lensing mass maps alone. We discuss the potential of this method to be applied to the analysis of real weak lensing data and other datasets.","Mon, 17 Jul 2017 13:58:18 UTC (3,316 KB)[v2] Tue, 18 Jul 2017 08:52:20 UTC (3,315 KB)"
"1375","Deep Learning to Attend to Risk in ICU","Phuoc Nguyen, Truyen Tran, Svetha Venkatesh","Machine Learning (cs.LG); Machine Learning (stat.ML)","Modeling physiological time-series in ICU is of high clinical importance. However, data collected within ICU are irregular in time and often contain missing measurements. Since absence of a measure would signify its lack of importance, the missingness is indeed informative and might reflect the decision making by the clinician. Here we propose a deep learning architecture that can effectively handle these challenges for predicting ICU mortality outcomes. The model is based on Long Short-Term Memory, and has layered attention mechanisms. At the sensing layer, the model decides whether to observe and incorporate parts of the current measurements. At the reasoning layer, evidences across time steps are weighted and combined. The model is evaluated on the PhysioNet 2012 dataset showing competitive and interpretable results.","Mon, 17 Jul 2017 06:23:20 UTC (2,075 KB)"
"1376","Improved deep learning based macromolecules structure classification from electron cryo tomograms","Chengqian Che, Ruogu Lin, Xiangrui Zeng, Karim Elmaaroufi, John Galeotti, Min Xu","Quantitative Methods (q-bio.QM)","Cellular processes are governed by macromolecular complexes inside the cell. Study of the native structures of macromolecular complexes has been extremely difficult due to lack of data. With recent breakthroughs in Cellular electron cryo tomography (CECT) 3D imaging technology, it is now possible for researchers to gain accesses to fully study and understand the macromolecular structures single cells. However, systematic recovery of macromolecular structures from CECT is very difficult due to high degree of structural complexity and practical imaging limitations. Specifically, we proposed a deep learning based image classification approach for large-scale systematic macromolecular structure separation from CECT data. However, our previous work was only a very initial step towards exploration of the full potential of deep learning based macromolecule separation. In this paper, we focus on improving classification performance by proposing three newly designed individual CNN models: an extended version of (Deep Small Receptive Field) DSRF3D, donated as DSRF3D-v2, a 3D residual block based neural network, named as RB3D and a convolutional 3D(C3D) based model, CB3D. We compare them with our previously developed model (DSRF3D) on 12 datasets with different SNRs and tilt angle ranges. The experiments show that our new models achieved significantly higher classification accuracies. The accuracies are not only higher than 0.9 on normal datasets, but also demonstrate potentials to operate on datasets with high levels of noises and missing wedge effects presented.","Sun, 16 Jul 2017 14:25:31 UTC (1,032 KB)"
"1377","Listening while Speaking: Speech Chain by Deep Learning","Andros Tjandra, Sakriani Sakti, Satoshi Nakamura","Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)","Despite the close relationship between speech perception and production, research in automatic speech recognition (ASR) and text-to-speech synthesis (TTS) has progressed more or less independently without exerting much mutual influence on each other. In human communication, on the other hand, a closed-loop speech chain mechanism with auditory feedback from the speaker's mouth to her ear is crucial. In this paper, we take a step further and develop a closed-loop speech chain model based on deep learning. The sequence-to-sequence model in close-loop architecture allows us to train our model on the concatenation of both labeled and unlabeled data. While ASR transcribes the unlabeled speech features, TTS attempts to reconstruct the original speech waveform based on the text from ASR. In the opposite direction, ASR also attempts to reconstruct the original text transcription given the synthesized speech. To the best of our knowledge, this is the first deep learning model that integrates human speech perception and production behaviors. Our experimental results show that the proposed approach significantly improved the performance more than separate systems that were only trained with labeled data.","Sun, 16 Jul 2017 13:27:56 UTC (952 KB)"
"1378","Sorting and Transforming Program Repair Ingredients via Deep Learning Code Similarities","Martin White, Michele Tufano, Matias Martinez, Martin Monperrus, Denys Poshyvanyk","Software Engineering (cs.SE)","In the field of automated program repair, the redundancy assumption claims large programs contain the seeds of their own repair. However, most redundancy-based program repair techniques do not reason about the repair ingredients---the code that is reused to craft a patch. We aim to reason about the repair ingredients by using code similarities to prioritize and transform statements in a codebase for patch generation. Our approach, DeepRepair, relies on deep learning to reason about code similarities. Code fragments at well-defined levels of granularity in a codebase can be sorted according to their similarity to suspicious elements (i.e., code elements that contain suspicious statements) and statements can be transformed by mapping out-of-scope identifiers to similar identifiers in scope. We examined these new search strategies for patch generation with respect to effectiveness from the viewpoint of a software maintainer. Our comparative experiments were executed on six open-source Java projects including 374 buggy program revisions and consisted of 19,949 trials spanning 2,616 days of computation time. DeepRepair's search strategy using code similarities generally found compilable ingredients faster than the baseline, jGenProg, but this improvement neither yielded test-adequate patches in fewer attempts (on average) nor found significantly more patches than the baseline. Although the patch counts were not statistically different, there were notable differences between the nature of DeepRepair patches and baseline patches. The results demonstrate that our learning-based approach finds patches that cannot be found by existing redundancy-based repair techniques.","Sat, 15 Jul 2017 14:41:40 UTC (239 KB)"
"1379","Recognizing Abnormal Heart Sounds Using Deep Learning","Jonathan Rubin, Rui Abreu, Anurag Ganguli, Saigopal Nelaturi, Ion Matei, Kumar Sricharan","Sound (cs.SD); Computer Vision and Pattern Recognition (cs.CV)","The work presented here applies deep learning to the task of automated cardiac auscultation, i.e. recognizing abnormalities in heart sounds. We describe an automated heart sound classification algorithm that combines the use of time-frequency heat map representations with a deep convolutional neural network (CNN). Given the cost-sensitive nature of misclassification, our CNN architecture is trained using a modified loss function that directly optimizes the trade-off between sensitivity and specificity. We evaluated our algorithm at the 2016 PhysioNet Computing in Cardiology challenge where the objective was to accurately classify normal and abnormal heart sounds from single, short, potentially noisy recordings. Our entry to the challenge achieved a final specificity of 0.95, sensitivity of 0.73 and overall score of 0.84. We achieved the greatest specificity score out of all challenge entries and, using just a single CNN, our algorithm differed in overall score by only 0.02 compared to the top place finisher, which used an ensemble approach.","Fri, 14 Jul 2017 21:17:24 UTC (304 KB)[v2] Thu, 19 Oct 2017 08:27:01 UTC (304 KB)"
"1380","Deep Learning with Topological Signatures","Christoph Hofer, Roland Kwitt, Marc Niethammer, Andreas Uhl","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Algebraic Topology (math.AT)","Inferring topological and geometrical information from data can offer an alternative perspective on machine learning problems. Methods from topological data analysis, e.g., persistent homology, enable us to obtain such information, typically in the form of summary representations of topological features. However, such topological signatures often come with an unusual structure (e.g., multisets of intervals) that is highly impractical for most machine learning techniques. While many strategies have been proposed to map these topological signatures into machine learning compatible representations, they suffer from being agnostic to the target learning task. In contrast, we propose a technique that enables us to input topological signatures to deep neural networks and learn a task-optimal representation during training. Our approach is realized as a novel input layer with favorable theoretical properties. Classification experiments on 2D object shapes and social network graphs demonstrate the versatility of the approach and, in case of the latter, we even outperform the state-of-the-art by a large margin.","Thu, 13 Jul 2017 09:36:05 UTC (708 KB)[v2] Mon, 13 Nov 2017 11:38:53 UTC (719 KB)[v3] Fri, 16 Feb 2018 07:12:19 UTC (719 KB)"
"1381","DeepProf: Performance Analysis for Deep Learning Applications via Mining GPU Execution Patterns","Jiazhen Gu, Huan Liu, Yangfan Zhou, Xin Wang","Software Engineering (cs.SE)","Deep learning applications are computation-intensive and often employ GPU as the underlying computing devices. Deep learning frameworks provide powerful programming interfaces, but the gap between source codes and practical GPU operations make it difficult to analyze the performance of deep learning applications. In this paper, through examing the features of GPU traces and deep learning applications, we use the suffix tree structure to extract the repeated patten in GPU traces. Performance analysis graphs can be generated from the preprocessed GPU traces. We further present \texttt{DeepProf}, a novel tool to automatically process GPU traces and generate performance analysis reports for deep learning applications. Empirical study verifies the effectiveness of \texttt{DeepProf} in performance analysis and diagnosis. We also find out some interesting properties of Tensorflow, which can be used to guide the deep learning system setup.","Wed, 12 Jul 2017 14:59:35 UTC (230 KB)"
"1382","Learning Macromanagement in StarCraft from Replays using Deep Learning","Niels Justesen, Sebastian Risi","Artificial Intelligence (cs.AI)","The real-time strategy game StarCraft has proven to be a challenging environment for artificial intelligence techniques, and as a result, current state-of-the-art solutions consist of numerous hand-crafted modules. In this paper, we show how macromanagement decisions in StarCraft can be learned directly from game replays using deep learning. Neural networks are trained on 789,571 state-action pairs extracted from 2,005 replays of highly skilled players, achieving top-1 and top-3 error rates of 54.6% and 22.9% in predicting the next build action. By integrating the trained network into UAlbertaBot, an open source StarCraft bot, the system can significantly outperform the game's built-in Terran bot, and play competitively against UAlbertaBot with a fixed rush strategy. To our knowledge, this is the first time macromanagement tasks are learned directly from replays in StarCraft. While the best hand-crafted strategies are still the state-of-the-art, the deep network approach is able to express a wide range of different strategies and thus improving the network's performance further with deep reinforcement learning is an immediately promising avenue for future research. Ultimately this approach could lead to strong StarCraft bots that are less reliant on hard-coded strategies.","Wed, 12 Jul 2017 14:40:00 UTC (3,976 KB)"
"1383","A Deep Learning Approach for Blind Drift Calibration of Sensor Networks","Yuzhi Wang, Anqi Yang, Xiaoming Chen, Pengjun Wang, Yu Wang, Huazhong Yang","Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC)","Temporal drift of sensory data is a severe problem impacting the data quality of wireless sensor networks (WSNs). With the proliferation of large-scale and long-term WSNs, it is becoming more important to calibrate sensors when the ground truth is unavailable. This problem is called ""blind calibration"". In this paper, we propose a novel deep learning method named projection-recovery network (PRNet) to blindly calibrate sensor measurements online. The PRNet first projects the drifted data to a feature space, and uses a powerful deep convolutional neural network to recover the estimated drift-free measurements. We deploy a 24-sensor testbed and provide comprehensive empirical evidence showing that the proposed method significantly improves the sensing accuracy and drifted sensor detection. Compared with previous methods, PRNet can calibrate 2x of drifted sensors at the recovery rate of 80% under the same level of accuracy requirement. We also provide helpful insights for designing deep neural networks for sensor calibration. We hope our proposed simple and effective approach will serve as a solid baseline in blind drift calibration of sensor networks.","Fri, 16 Jun 2017 17:10:13 UTC (2,981 KB)"
"1384","Elephant Search with Deep Learning for Microarray Data Analysis","Mrutyunjaya Panda","Neural and Evolutionary Computing (cs.NE); Quantitative Methods (q-bio.QM)","Even though there is a plethora of research in Microarray gene expression data analysis, still, it poses challenges for researchers to effectively and efficiently analyze the large yet complex expression of genes. The feature (gene) selection method is of paramount importance for understanding the differences in biological and non-biological variation between samples. In order to address this problem, a novel elephant search (ES) based optimization is proposed to select best gene expressions from the large volume of microarray data. Further, a promising machine learning method is envisioned to leverage such high dimensional and complex microarray dataset for extracting hidden patterns inside to make a meaningful prediction and most accurate classification. In particular, stochastic gradient descent based Deep learning (DL) with softmax activation function is then used on the reduced features (genes) for better classification of different samples according to their gene expression levels. The experiments are carried out on nine most popular Cancer microarray gene selection datasets, obtained from UCI machine learning repository. The empirical results obtained by the proposed elephant search based deep learning (ESDL) approach are compared with most recent published article for its suitability in future Bioinformatics research.","Wed, 12 Jul 2017 09:04:04 UTC (201 KB)"
"1385","Estimating ground-level PM2.5 by fusing satellite and station observations: A geo-intelligent deep learning approach","Tongwen Li, Huanfeng Shen, Qiangqiang Yuan, Xuechen Zhang, Liangpei Zhang","Atmospheric and Oceanic Physics (physics.ao-ph)","Fusing satellite observations and station measurements to estimate ground-level PM2.5 is promising for monitoring PM2.5 pollution. A geo-intelligent approach, which incorporates geographical correlation into an intelligent deep learning architecture, is developed to estimate PM2.5. Specifically, it considers geographical distance and spatiotemporally correlated PM2.5 in a deep belief network (denoted as Geoi-DBN). Geoi-DBN can capture the essential features associated with PM2.5 from latent factors. It was trained and tested with data from China in 2015. The results show that Geoi-DBN performs significantly better than the traditional neural network. The cross-validation R increases from 0.63 to 0.94, and RMSE decreases from 29.56 to 13.68$レ$g/m3. On the basis of the derived PM2.5 distribution, it is predicted that over 80% of the Chinese population live in areas with an annual mean PM2.5 of greater than 35$レ$g/m3. This study provides a new perspective for air pollution monitoring in large geographic regions.","Wed, 12 Jul 2017 06:29:57 UTC (2,381 KB)"
"1386","Deep Learning for Sensor-based Activity Recognition: A Survey","Jindong Wang, Yiqiang Chen, Shuji Hao, Xiaohui Peng, Lisha Hu","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Sensor-based activity recognition seeks the profound high-level knowledge about human activities from multitudes of low-level sensor readings. Conventional pattern recognition approaches have made tremendous progress in the past years. However, those methods often heavily rely on heuristic hand-crafted feature extraction, which could hinder their generalization performance. Additionally, existing methods are undermined for unsupervised and incremental learning tasks. Recently, the recent advancement of deep learning makes it possible to perform automatic high-level feature extraction thus achieves promising performance in many areas. Since then, deep learning based methods have been widely adopted for the sensor-based activity recognition tasks. This paper surveys the recent advance of deep learning based sensor-based activity recognition. We summarize existing literature from three aspects: sensor modality, deep model, and application. We also present detailed insights on existing work and propose grand challenges for future research.","Wed, 12 Jul 2017 00:21:04 UTC (1,311 KB)[v2] Thu, 14 Dec 2017 03:11:15 UTC (659 KB)"
"1387","Creatism: A deep-learning photographer capable of creating professional work","Hui Fang, Meng Zhang","Computer Vision and Pattern Recognition (cs.CV)","Machine-learning excels in many areas with well-defined goals. However, a clear goal is usually not available in art forms, such as photography. The success of a photograph is measured by its aesthetic value, a very subjective concept. This adds to the challenge for a machine learning approach. We introduce Creatism, a deep-learning system for artistic content creation. In our system, we break down aesthetics into multiple aspects, each can be learned individually from a shared dataset of professional examples. Each aspect corresponds to an image operation that can be optimized efficiently. A novel editing tool, dramatic mask, is introduced as one operation that improves dramatic lighting for a photo. Our training does not require a dataset with before/after image pairs, or any additional labels to indicate different aspects in aesthetics. Using our system, we mimic the workflow of a landscape photographer, from framing for the best composition to carrying out various post-processing operations. The environment for our virtual photographer is simulated by a collection of panorama images from Google Street View. We design a ""Turing-test""-like experiment to objectively measure quality of its creations, where professional photographers rate a mixture of photographs from different sources blindly. Experiments show that a portion of our robot's creation can be confused with professional work.","Tue, 11 Jul 2017 23:18:50 UTC (8,823 KB)"
"1388","Individual Recognition in Schizophrenia using Deep Learning Methods with Random Forest and Voting Classifiers: Insights from Resting State EEG Streams","Lei Chu, Robert Qiu, Haichun Liu, Zenan Ling, Tianhong Zhang, Jijun Wang","Computer Vision and Pattern Recognition (cs.CV)","Recently, there has been a growing interest in monitoring brain activity for individual recognition system. So far these works are mainly focussing on single channel data or fragment data collected by some advanced brain monitoring modalities. In this study we propose new individual recognition schemes based on spatio-temporal resting state Electroencephalography (EEG) data. Besides, instead of using features derived from artificially-designed procedures, modified deep learning architectures which aim to automatically extract an individual's unique features are developed to conduct classification. Our designed deep learning frameworks are proved of a small but consistent advantage of replacing the $softmax$ layer with Random Forest. Additionally, a voting layer is added at the top of designed neural networks in order to tackle the classification problem arisen from EEG streams. Lastly, various experiments are implemented to evaluate the performance of the designed deep learning architectures; Results indicate that the proposed EEG-based individual recognition scheme yields a high degree of classification accuracy: $81.6\%$ for characteristics in high risk (CHR) individuals, $96.7\%$ for clinically stable first episode patients with schizophrenia (FES) and $99.2\%$ for healthy controls (HC).","Tue, 20 Jun 2017 01:23:24 UTC (1,131 KB)[v2] Wed, 17 Jan 2018 13:06:39 UTC (989 KB)"
"1389","Deep Learning-Based Communication Over the Air","Sebastian Dorner, Sebastian Cammerer, Jakob Hoydis, Stephan ten Brink","Machine Learning (stat.ML); Information Theory (cs.IT)","End-to-end learning of communications systems is a fascinating novel concept that has so far only been validated by simulations for block-based transmissions. It allows learning of transmitter and receiver implementations as deep neural networks (NNs) that are optimized for an arbitrary differentiable end-to-end performance metric, e.g., block error rate (BLER). In this paper, we demonstrate that over-the-air transmissions are possible: We build, train, and run a complete communications system solely composed of NNs using unsynchronized off-the-shelf software-defined radios (SDRs) and open-source deep learning (DL) software libraries. We extend the existing ideas towards continuous data transmission which eases their current restriction to short block lengths but also entails the issue of receiver synchronization. We overcome this problem by introducing a frame synchronization module based on another NN. A comparison of the BLER performance of the ""learned"" system with that of a practical baseline shows competitive performance close to 1 dB, even without extensive hyperparameter tuning. We identify several practical challenges of training such a system over actual channels, in particular the missing channel gradient, and propose a two-step learning procedure based on the idea of transfer learning that circumvents this issue.","Tue, 11 Jul 2017 17:47:23 UTC (510 KB)"
"1390","Deep Learning for Real Time Crime Forecasting","Bao Wang, Duo Zhang, Duanhao Zhang, P.Jeffery Brantingham, Andrea L. Bertozzi","Numerical Analysis (math.NA); Machine Learning (cs.LG); Machine Learning (stat.ML)","Accurate real time crime prediction is a fundamental issue for public safety, but remains a challenging problem for the scientific community. Crime occurrences depend on many complex factors. Compared to many predictable events, crime is sparse. At different spatio-temporal scales, crime distributions display dramatically different patterns. These distributions are of very low regularity in both space and time. In this work, we adapt the state-of-the-art deep learning spatio-temporal predictor, ST-ResNet [Zhang et al, AAAI, 2017], to collectively predict crime distribution over the Los Angeles area. Our models are two staged. First, we preprocess the raw crime data. This includes regularization in both space and time to enhance predictable signals. Second, we adapt hierarchical structures of residual convolutional units to train multi-factor crime prediction models. Experiments over a half year period in Los Angeles reveal highly accurate predictive power of our models.","Sun, 9 Jul 2017 17:36:53 UTC (358 KB)"
"1391","A deep learning architecture for temporal sleep stage classification using multivariate and multimodal time series","Stanislas Chambon, Mathieu Galtier, Pierrick Arnal, Gilles Wainrib, Alexandre Gramfort","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)","Sleep stage classification constitutes an important preliminary exam in the diagnosis of sleep disorders. It is traditionally performed by a sleep expert who assigns to each 30s of signal a sleep stage, based on the visual inspection of signals such as electroencephalograms (EEG), electrooculograms (EOG), electrocardiograms (ECG) and electromyograms (EMG). We introduce here the first deep learning approach for sleep stage classification that learns end-to-end without computing spectrograms or extracting hand-crafted features, that exploits all multivariate and multimodal Polysomnography (PSG) signals (EEG, EMG and EOG), and that can exploit the temporal context of each 30s window of data. For each modality the first layer learns linear spatial filters that exploit the array of sensors to increase the signal-to-noise ratio, and the last layer feeds the learnt representation to a softmax classifier. Our model is compared to alternative automatic approaches based on convolutional networks or decisions trees. Results obtained on 61 publicly available PSG records with up to 20 EEG channels demonstrate that our network architecture yields state-of-the-art performance. Our study reveals a number of insights on the spatio-temporal distribution of the signal of interest: a good trade-off for optimal classification performance measured with balanced accuracy is to use 6 EEG with 2 EOG (left and right) and 3 EMG chin channels. Also exploiting one minute of data before and after each data segment offers the strongest improvement when a limited number of channels is available. As sleep experts, our system exploits the multivariate and multimodal nature of PSG signals in order to deliver state-of-the-art classification performance with a small computational cost.","Wed, 5 Jul 2017 08:29:36 UTC (426 KB)[v2] Mon, 27 Nov 2017 09:37:28 UTC (453 KB)"
"1392","Generalised Dice overlap as a deep learning loss function for highly unbalanced segmentations","Carole H Sudre, Wenqi Li, Tom Vercauteren, Sebastien Ourselin, M. Jorge Cardoso","Computer Vision and Pattern Recognition (cs.CV)","Deep-learning has proved in recent years to be a powerful tool for image analysis and is now widely used to segment both 2D and 3D medical images. Deep-learning segmentation frameworks rely not only on the choice of network architecture but also on the choice of loss function. When the segmentation process targets rare observations, a severe class imbalance is likely to occur between candidate labels, thus resulting in sub-optimal performance. In order to mitigate this issue, strategies such as the weighted cross-entropy function, the sensitivity function or the Dice loss function, have been proposed. In this work, we investigate the behavior of these loss functions and their sensitivity to learning rate tuning in the presence of different rates of label imbalance across 2D and 3D segmentation tasks. We also propose to use the class re-balancing properties of the Generalized Dice overlap, a known metric for segmentation assessment, as a robust and accurate deep-learning loss function for unbalanced tasks.","Tue, 11 Jul 2017 12:07:52 UTC (1,303 KB)[v2] Wed, 12 Jul 2017 05:50:55 UTC (1,303 KB)[v3] Fri, 14 Jul 2017 16:57:58 UTC (1,426 KB)"
"1393","Revisiting Unreasonable Effectiveness of Data in Deep Learning Era","Chen Sun, Abhinav Shrivastava, Saurabh Singh, Abhinav Gupta","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)","The success of deep learning in vision can be attributed to: (a) models with high capacity; (b) increased computational power; and (c) availability of large-scale labeled data. Since 2012, there have been significant advances in representation capabilities of the models and computational capabilities of GPUs. But the size of the biggest dataset has surprisingly remained constant. What will happen if we increase the dataset size by 10x or 100x? This paper takes a step towards clearing the clouds of mystery surrounding the relationship between `enormous data' and visual deep learning. By exploiting the JFT-300M dataset which has more than 375M noisy labels for 300M images, we investigate how the performance of current vision tasks would change if this data was used for representation learning. Our paper delivers some surprising (and some expected) findings. First, we find that the performance on vision tasks increases logarithmically based on volume of training data size. Second, we show that representation learning (or pre-training) still holds a lot of promise. One can improve performance on many vision tasks by just training a better base model. Finally, as expected, we present new state-of-the-art results for different vision tasks including image classification, object detection, semantic segmentation and human pose estimation. Our sincere hope is that this inspires vision community to not undervalue the data and develop collective efforts in building larger datasets.","Mon, 10 Jul 2017 17:54:31 UTC (834 KB)[v2] Fri, 4 Aug 2017 01:33:22 UTC (834 KB)"
"1394","Solving high-dimensional partial differential equations using deep learning","Jiequn Han, Arnulf Jentzen, Weinan E","Numerical Analysis (math.NA); Machine Learning (cs.LG); Optimization and Control (math.OC); Probability (math.PR)","Developing algorithms for solving high-dimensional partial differential equations (PDEs) has been an exceedingly difficult task for a long time, due to the notoriously difficult problem known as the ""curse of dimensionality"". This paper introduces a deep learning-based approach that can handle general high-dimensional parabolic PDEs. To this end, the PDEs are reformulated using backward stochastic differential equations and the gradient of the unknown solution is approximated by neural networks, very much in the spirit of deep reinforcement learning with the gradient acting as the policy function. Numerical results on examples including the nonlinear Black-Scholes equation, the Hamilton-Jacobi-Bellman equation, and the Allen-Cahn equation suggest that the proposed algorithm is quite effective in high dimensions, in terms of both accuracy and cost. This opens up new possibilities in economics, finance, operational research, and physics, by considering all participating agents, assets, resources, or particles together at the same time, instead of making ad hoc assumptions on their inter-relationships.","Sun, 9 Jul 2017 12:05:15 UTC (352 KB)[v2] Tue, 22 May 2018 01:28:53 UTC (354 KB)[v3] Tue, 3 Jul 2018 10:08:29 UTC (354 KB)"
"1395","Deep Learning for Vanishing Point Detection Using an Inverse Gnomonic Projection","Florian Kluger, Hanno Ackermann, Michael Ying Yang, Bodo Rosenhahn","Computer Vision and Pattern Recognition (cs.CV)","We present a novel approach for vanishing point detection from uncalibrated monocular images. In contrast to state-of-the-art, we make no a priori assumptions about the observed scene. Our method is based on a convolutional neural network (CNN) which does not use natural images, but a Gaussian sphere representation arising from an inverse gnomonic projection of lines detected in an image. This allows us to rely on synthetic data for training, eliminating the need for labelled images. Our method achieves competitive performance on three horizon estimation benchmark datasets. We further highlight some additional use cases for which our vanishing point detection algorithm can be used.","Sat, 8 Jul 2017 11:41:51 UTC (1,080 KB)[v2] Thu, 16 Nov 2017 13:13:03 UTC (1,081 KB)"
"1396","An Embedded Deep Learning based Word Prediction","Seunghak Yu, Nilesh Kulkarni, Haejun Lee, Jihie Kim","Computation and Language (cs.CL)","Recent developments in deep learning with application to language modeling have led to success in tasks of text processing, summarizing and machine translation. However, deploying huge language models for mobile device such as on-device keyboards poses computation as a bottle-neck due to their puny computation capacities. In this work we propose an embedded deep learning based word prediction method that optimizes run-time memory and also provides a real time prediction environment. Our model size is 7.40MB and has average prediction time of 6.47 ms. We improve over the existing methods for word prediction in terms of key stroke savings and word prediction rate.","Thu, 6 Jul 2017 07:39:06 UTC (1,321 KB)"
"1397","RIDDLE: Race and ethnicity Imputation from Disease history with Deep LEarning","Ji-Sung Kim, Xin Gao, Andrey Rzhetsky","Quantitative Methods (q-bio.QM); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Anonymized electronic medical records are an increasingly popular source of research data. However, these datasets often lack race and ethnicity information. This creates problems for researchers modeling human disease, as race and ethnicity are powerful confounders for many health exposures and treatment outcomes; race and ethnicity are closely linked to population-specific genetic variation. We showed that deep neural networks generate more accurate estimates for missing racial and ethnic information than competing methods (e.g., logistic regression, random forest). RIDDLE yielded significantly better classification performance across all metrics that were considered: accuracy, cross-entropy loss (error), and area under the curve for receiver operating characteristic plots (all $p < 10^{-6}$). We made specific efforts to interpret the trained neural network models to identify, quantify, and visualize medical features which are predictive of race and ethnicity. We used these characterizations of informative features to perform a systematic comparison of differential disease patterns by race and ethnicity. The fact that clinical histories are informative for imputing race and ethnicity could reflect (1) a skewed distribution of blue- and white-collar professions across racial and ethnic groups, (2) uneven accessibility and subjective importance of prophylactic health, (3) possible variation in lifestyle, such as dietary habits, and (4) differences in background genetic variation which predispose to diseases.","Thu, 6 Jul 2017 03:03:57 UTC (728 KB)[v2] Fri, 27 Apr 2018 21:21:47 UTC (728 KB)"
"1398","PBODL : Parallel Bayesian Online Deep Learning for Click-Through Rate Prediction in Tencent Advertising System","Xun Liu, Wei Xue, Lei Xiao, Bo Zhang","Machine Learning (cs.LG)","We describe a parallel bayesian online deep learning framework (PBODL) for click-through rate (CTR) prediction within today's Tencent advertising system, which provides quick and accurate learning of user preferences. We first explain the framework with a deep probit regression model, which is trained with probabilistic back-propagation in the mode of assumed Gaussian density filtering. Then we extend the model family to a variety of bayesian online models with increasing feature embedding capabilities, such as Sparse-MLP, FM-MLP and FFM-MLP. Finally, we implement a parallel training system based on a stream computing infrastructure and parameter servers. Experiments with public available datasets and Tencent industrial datasets show that models within our framework perform better than several common online models, such as AdPredictor, FTRL-Proximal and MatchBox. Online A/B test within Tencent advertising system further proves that our framework could achieve CTR and CPM lift by learning more quickly and accurately.","Tue, 4 Jul 2017 02:40:41 UTC (473 KB)[v2] Sun, 9 Jul 2017 08:42:32 UTC (473 KB)"
"1399","Deep-learning-based data page classification for holographic memory","Tomoyoshi Shimobaba, Naoki Kuwata, Mizuha Homma, Takayuki Takahashi, Yuki Nagahama, Marie Sano, Satoki Hasegawa, Ryuji Hirayama, Takashi Kakue, Atsushi Shiraki, Naoki Takada, Tomoyoshi Ito","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Optics (physics.optics)","We propose a deep-learning-based classification of data pages used in holographic memory. We numerically investigated the classification performance of a conventional multi-layer perceptron (MLP) and a deep neural network, under the condition that reconstructed page data are contaminated by some noise and are randomly laterally shifted. The MLP was found to have a classification accuracy of 91.58%, whereas the deep neural network was able to classify data pages at an accuracy of 99.98%. The accuracy of the deep neural network is two orders of magnitude better than the MLP.","Sun, 2 Jul 2017 05:47:37 UTC (1,189 KB)"
"1400","Detection and Localization of Image Forgeries using Resampling Features and Deep Learning","Jason Bunk, Jawadul H. Bappy, Tajuddin Manhar Mohammed, Lakshmanan Nataraj, Arjuna Flenner, B.S. Manjunath, Shivkumar Chandrasekaran, Amit K. Roy-Chowdhury, Lawrence Peterson","Computer Vision and Pattern Recognition (cs.CV)","Resampling is an important signature of manipulated images. In this paper, we propose two methods to detect and localize image manipulations based on a combination of resampling features and deep learning. In the first method, the Radon transform of resampling features are computed on overlapping image patches. Deep learning classifiers and a Gaussian conditional random field model are then used to create a heatmap. Tampered regions are located using a Random Walker segmentation method. In the second method, resampling features computed on overlapping image patches are passed through a Long short-term memory (LSTM) based network for classification and localization. We compare the performance of detection/localization of both these methods. Our experimental results show that both techniques are effective in detecting and localizing digital image forgeries.","Mon, 3 Jul 2017 07:50:15 UTC (7,751 KB)"
"1401","Deep Convolutional Framelets: A General Deep Learning Framework for Inverse Problems","Jong Chul Ye, Yoseob Han, Eunju Cha","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Information Theory (cs.IT); Machine Learning (cs.LG)","Recently, deep learning approaches with various network architectures have achieved significant performance improvement over existing iterative reconstruction methods in various imaging problems. However, it is still unclear why these deep learning architectures work for specific inverse problems. To address these issues, here we show that the long-searched-for missing link is the convolution framelets for representing a signal by convolving local and non-local bases. The convolution framelets was originally developed to generalize the theory of low-rank Hankel matrix approaches for inverse problems, and this paper further extends the idea so that we can obtain a deep neural network using multilayer convolution framelets with perfect reconstruction (PR) under rectilinear linear unit nonlinearity (ReLU). Our analysis also shows that the popular deep network components such as residual block, redundant filter channels, and concatenated ReLU (CReLU) do indeed help to achieve the PR, while the pooling and unpooling layers should be augmented with high-pass branches to meet the PR condition. Moreover, by changing the number of filter channels and bias, we can control the shrinkage behaviors of the neural network. This discovery leads us to propose a novel theory for deep convolutional framelets neural network. Using numerical experiments with various inverse problems, we demonstrated that our deep convolution framelets network shows consistent improvement over existing deep architectures.This discovery suggests that the success of deep learning is not from a magical power of a black-box, but rather comes from the power of a novel signal representation using non-local basis combined with data-driven local basis, which is indeed a natural extension of classical signal processing theory.","Mon, 3 Jul 2017 00:16:04 UTC (2,767 KB)[v2] Thu, 20 Jul 2017 08:20:27 UTC (3,072 KB)[v3] Wed, 2 Aug 2017 13:27:07 UTC (2,710 KB)[v4] Thu, 30 Nov 2017 07:12:01 UTC (6,771 KB)[v5] Thu, 25 Jan 2018 09:37:10 UTC (7,421 KB)"
"1402","Towards Understanding Generalization of Deep Learning: Perspective of Loss Landscapes","Lei Wu, Zhanxing Zhu, Weinan E","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","It is widely observed that deep learning models with learned parameters generalize well, even with much more model parameters than the number of training samples. We systematically investigate the underlying reasons why deep neural networks often generalize well, and reveal the difference between the minima (with the same training error) that generalize well and those they don't. We show that it is the characteristics the landscape of the loss function that explains the good generalization capability. For the landscape of loss function for deep networks, the volume of basin of attraction of good minima dominates over that of poor minima, which guarantees optimization methods with random initialization to converge to good minima. We theoretically justify our findings through analyzing 2-layer neural networks; and show that the low-complexity solutions have a small norm of Hessian matrix with respect to model parameters. For deeper networks, extensive numerical evidence helps to support our arguments.","Fri, 30 Jun 2017 15:30:21 UTC (711 KB)[v2] Tue, 28 Nov 2017 02:40:04 UTC (915 KB)"
"1403","Optimization Methods for Supervised Machine Learning: From Linear Models to Deep Learning","Frank E. Curtis, Katya Scheinberg","Machine Learning (stat.ML); Machine Learning (cs.LG)","The goal of this tutorial is to introduce key models, algorithms, and open questions related to the use of optimization methods for solving problems arising in machine learning. It is written with an INFORMS audience in mind, specifically those readers who are familiar with the basics of optimization algorithms, but less familiar with machine learning. We begin by deriving a formulation of a supervised learning problem and show how it leads to various optimization problems, depending on the context and underlying assumptions. We then discuss some of the distinctive features of these optimization problems, focusing on the examples of logistic regression and the training of deep neural networks. The latter half of the tutorial focuses on optimization algorithms, first for convex logistic regression, for which we discuss the use of first-order methods, the stochastic gradient method, variance reducing stochastic methods, and second-order methods. Finally, we discuss how these approaches can be employed to the training of deep neural networks, emphasizing the difficulties that arise from the complex, nonconvex structure of these models.","Fri, 30 Jun 2017 14:09:44 UTC (134 KB)"
"1404","Deep learning bank distress from news and numerical financial data","Paola Cerchiello, Giancarlo Nicola, Samuel Ronnqvist, Peter Sarlin","Machine Learning (stat.ML); Machine Learning (cs.LG)","In this paper we focus our attention on the exploitation of the information contained in financial news to enhance the performance of a classifier of bank distress. Such information should be analyzed and inserted into the predictive model in the most efficient way and this task deals with all the issues related to text analysis and specifically analysis of news media. Among the different models proposed for such purpose, we investigate one of the possible deep learning approaches, based on a doc2vec representation of the textual data, a kind of neural network able to map the sequential and symbolic text input onto a reduced latent semantic space. Afterwards, a second supervised neural network is trained combining news data with standard financial figures to classify banks whether in distressed or tranquil states, based on a small set of known distress events. Then the final aim is not only the improvement of the predictive performance of the classifier but also to assess the importance of news data in the classification process. Does news data really bring more useful information not contained in standard financial variables? Our results seem to confirm such hypothesis.","Thu, 29 Jun 2017 08:42:44 UTC (342 KB)[v2] Tue, 16 Jan 2018 18:06:14 UTC (342 KB)[v3] Wed, 5 Sep 2018 09:08:43 UTC (363 KB)"
"1405","Chord Label Personalization through Deep Learning of Integrated Harmonic Interval-based Representations","H.V. Koops, W.B. de Haas, J. Bransen, A. Volk","Sound (cs.SD); Multimedia (cs.MM); Neural and Evolutionary Computing (cs.NE)","The increasing accuracy of automatic chord estimation systems, the availability of vast amounts of heterogeneous reference annotations, and insights from annotator subjectivity research make chord label personalization increasingly important. Nevertheless, automatic chord estimation systems are historically exclusively trained and evaluated on a single reference annotation. We introduce a first approach to automatic chord label personalization by modeling subjectivity through deep learning of a harmonic interval-based chord label representation. After integrating these representations from multiple annotators, we can accurately personalize chord labels for individual annotators from a single model and the annotators' chord label vocabulary. Furthermore, we show that chord personalization using multiple reference annotations outperforms using a single reference annotation.","Thu, 29 Jun 2017 02:38:02 UTC (9 KB)"
"1406","Deep Learning Based Large-Scale Automatic Satellite Crosswalk Classification","Rodrigo F. Berriel, Andre Teixeira Lopes, Alberto F. de Souza, Thiago Oliveira-Santos","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","High-resolution satellite imagery have been increasingly used on remote sensing classification problems. One of the main factors is the availability of this kind of data. Even though, very little effort has been placed on the zebra crossing classification problem. In this letter, crowdsourcing systems are exploited in order to enable the automatic acquisition and annotation of a large-scale satellite imagery database for crosswalks related tasks. Then, this dataset is used to train deep-learning-based models in order to accurately classify satellite images that contains or not zebra crossings. A novel dataset with more than 240,000 images from 3 continents, 9 countries and more than 20 cities was used in the experiments. Experimental results showed that freely available crowdsourcing data can be used to accurately (97.11%) train robust models to perform crosswalk classification on a global scale.","Wed, 28 Jun 2017 14:06:24 UTC (1,252 KB)[v2] Wed, 5 Jul 2017 12:58:35 UTC (1,252 KB)"
"1407","Classification of Medical Images and Illustrations in the Biomedical Literature Using Synergic Deep Learning","Jianpeng Zhang, Yong Xia, Qi Wu, Yutong Xie","Computer Vision and Pattern Recognition (cs.CV)","The Classification of medical images and illustrations in the literature aims to label a medical image according to the modality it was produced or label an illustration according to its production attributes. It is an essential and challenging research hotspot in the area of automated literature review, retrieval and mining. The significant intra-class variation and inter-class similarity caused by the diverse imaging modalities and various illustration types brings a great deal of difficulties to the problem. In this paper, we propose a synergic deep learning (SDL) model to address this issue. Specifically, a dual deep convolutional neural network with a synergic signal system is designed to mutually learn image representation. The synergic signal is used to verify whether the input image pair belongs to the same category and to give the corrective feedback if a synergic error exists. Our SDL model can be trained 'end to end'. In the test phase, the class label of an input can be predicted by averaging the likelihood probabilities obtained by two convolutional neural network components. Experimental results on the ImageCLEF2016 Subfigure Classification Challenge suggest that our proposed SDL model achieves the state-of-the art performance in this medical image classification problem and its accuracy is higher than that of the first place solution on the Challenge leader board so far.","Wed, 28 Jun 2017 01:15:06 UTC (1,007 KB)"
"1408","Super-Resolution via Deep Learning","Khizar Hayat","Computer Vision and Pattern Recognition (cs.CV)","The recent phenomenal interest in convolutional neural networks (CNNs) must have made it inevitable for the super-resolution (SR) community to explore its potential. The response has been immense and in the last three years, since the advent of the pioneering work, there appeared too many works not to warrant a comprehensive survey. This paper surveys the SR literature in the context of deep learning. We focus on the three important aspects of multimedia - namely image, video and multi-dimensions, especially depth maps. In each case, first relevant benchmarks are introduced in the form of datasets and state of the art SR methods, excluding deep learning. Next is a detailed analysis of the individual works, each including a short description of the method and a critique of the results with special reference to the benchmarking done. This is followed by minimum overall benchmarking in the form of comparison on some common dataset, while relying on the results reported in various works.","Wed, 28 Jun 2017 00:02:18 UTC (5,963 KB)"
"1409","Exploring Generalization in Deep Learning","Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, Nathan Srebro","Machine Learning (cs.LG)","With a goal of understanding what drives generalization in deep networks, we consider several recently suggested explanations, including norm-based control, sharpness and robustness. We study how these measures can ensure generalization, highlighting the importance of scale normalization, and making a connection between sharpness and PAC-Bayes theory. We then investigate how well the measures explain different observed phenomena.","Tue, 27 Jun 2017 17:20:06 UTC (1,149 KB)[v2] Thu, 6 Jul 2017 17:10:40 UTC (1,154 KB)"
"1410","Cross-Country Skiing Gears Classification using Deep Learning","Aliaa Rassem, Mohammed El-Beltagy, Mohamed Saleh","Computer Vision and Pattern Recognition (cs.CV)","Human Activity Recognition has witnessed a significant progress in the last decade. Although a great deal of work in this field goes in recognizing normal human activities, few studies focused on identifying motion in sports. Recognizing human movements in different sports has high impact on understanding the different styles of humans in the play and on improving their performance. As deep learning models proved to have good results in many classification problems, this paper will utilize deep learning to classify cross-country skiing movements, known as gears, collected using a 3D accelerometer. It will also provide a comparison between different deep learning models such as convolutional and recurrent neural networks versus standard multi-layer perceptron. Results show that deep learning is more effective and has the highest classification accuracy.","Tue, 27 Jun 2017 16:14:00 UTC (154 KB)"
"1411","Topometric Localization with Deep Learning","Gabriel L. Oliveira, Noha Radwan, Wolfram Burgard, Thomas Brox","Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","Compared to LiDAR-based localization methods, which provide high accuracy but rely on expensive sensors, visual localization approaches only require a camera and thus are more cost-effective while their accuracy and reliability typically is inferior to LiDAR-based methods. In this work, we propose a vision-based localization approach that learns from LiDAR-based localization methods by using their output as training data, thus combining a cheap, passive sensor with an accuracy that is on-par with LiDAR-based localization. The approach consists of two deep networks trained on visual odometry and topological localization, respectively, and a successive optimization to combine the predictions of these two networks. We evaluate the approach on a new challenging pedestrian-based dataset captured over the course of six months in varying weather conditions with a high degree of noise. The experiments demonstrate that the localization errors are up to 10 times smaller than with traditional vision-based localization methods.","Tue, 27 Jun 2017 11:03:31 UTC (4,030 KB)"
"1412","Proceedings of the First International Workshop on Deep Learning and Music","Dorien Herremans, Ching-Hua Chuan","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD)","Proceedings of the First International Workshop on Deep Learning and Music, joint with IJCNN, Anchorage, US, May 17-18, 2017","Tue, 27 Jun 2017 05:28:06 UTC (1 KB)"
"1413","Fast and accurate classification of echocardiograms using deep learning","Ali Madani, Ramy Arnaout, Mohammad Mofrad, Rima Arnaout","Computer Vision and Pattern Recognition (cs.CV)","Echocardiography is essential to modern cardiology. However, human interpretation limits high throughput analysis, limiting echocardiography from reaching its full clinical and research potential for precision medicine. Deep learning is a cutting-edge machine-learning technique that has been useful in analyzing medical images but has not yet been widely applied to echocardiography, partly due to the complexity of echocardiograms' multi view, multi modality format. The essential first step toward comprehensive computer assisted echocardiographic interpretation is determining whether computers can learn to recognize standard views. To this end, we anonymized 834,267 transthoracic echocardiogram (TTE) images from 267 patients (20 to 96 years, 51 percent female, 26 percent obese) seen between 2000 and 2017 and labeled them according to standard views. Images covered a range of real world clinical variation. We built a multilayer convolutional neural network and used supervised learning to simultaneously classify 15 standard views. Eighty percent of data used was randomly chosen for training and 20 percent reserved for validation and testing on never seen echocardiograms. Using multiple images from each clip, the model classified among 12 video views with 97.8 percent overall test accuracy without overfitting. Even on single low resolution images, test accuracy among 15 views was 91.7 percent versus 70.2 to 83.5 percent for board-certified echocardiographers. Confusional matrices, occlusion experiments, and saliency mapping showed that the model finds recognizable similarities among related views and classifies using clinically relevant image features. In conclusion, deep neural networks can classify essential echocardiographic views simultaneously and with high accuracy. Our results provide a foundation for more complex deep learning assisted echocardiographic interpretation.","Tue, 27 Jun 2017 03:21:47 UTC (4,646 KB)"
"1414","Inverse Ising inference by combining Ornstein-Zernike theory with deep learning","Soma Turi, Alpha A. Lee","Statistical Mechanics (cond-mat.stat-mech); Disordered Systems and Neural Networks (cond-mat.dis-nn); Data Analysis, Statistics and Probability (physics.data-an)","Inferring a generative model from data is a fundamental problem in machine learning. It is well-known that the Ising model is the maximum entropy model for binary variables which reproduces the sample mean and pairwise correlations. Learning the parameters of the Ising model from data is the challenge. We establish an analogy between the inverse Ising problem and the Ornstein-Zernike formalism in liquid state physics. Rather than analytically deriving the closure relation, we use a deep neural network to learn the closure from simulations of the Ising model. We show, using simulations as well as biochemical datasets, that the deep neural network model outperforms systematic field-theoretic expansions, is more data-efficient than the pseudolikelihood method, and can generalize well beyond the parameter regime of the training data. The neural network is able to learn from synthetic data, which can be generated with relative ease, to give accurate predictions on real world datasets.","Mon, 26 Jun 2017 16:37:26 UTC (350 KB)[v2] Sun, 17 Jun 2018 19:32:18 UTC (433 KB)"
"1415","Deep learning approach to the Higgs boson CP measurement in H to tau tau decay and associated systematics","Elisabetta Barberio, Brian Le, Elzbieta Richter-Was, Zbigniew Was, Daniele Zanzi, Jakub Zaremba","High Energy Physics - Phenomenology (hep-ph)","The H to tau tau decays form the prime channel for the measurement of the Higgs boson state and tests of the CP invariance of Higgs boson couplings. A previous study has shown the viability of deep learning techniques for the measurement. In this paper, the study is expanded. Effects due to the partial modelling of experimental effects are discussed. Furthermore, systematics due to ? decay modelling for complex cascade decays to tau^pm to a_1^pm nu_tau to rho^0 pi^pm nu_tau to 3pi^\pm nu_tau are also addressed. Various parameterisations are considered using low-energy collision data.","Sat, 24 Jun 2017 17:10:05 UTC (1,369 KB)"
"1416","Collaborative Deep Learning in Fixed Topology Networks","Zhanhong Jiang, Aditya Balu, Chinmay Hegde, Soumik Sarkar","Machine Learning (stat.ML); Machine Learning (cs.LG)","There is significant recent interest to parallelize deep learning algorithms in order to handle the enormous growth in data and model sizes. While most advances focus on model parallelization and engaging multiple computing agents via using a central parameter server, aspect of data parallelization along with decentralized computation has not been explored sufficiently. In this context, this paper presents a new consensus-based distributed SGD (CDSGD) (and its momentum variant, CDMSGD) algorithm for collaborative deep learning over fixed topology networks that enables data parallelization as well as decentralized computation. Such a framework can be extremely useful for learning agents with access to only local/private data in a communication constrained environment. We analyze the convergence properties of the proposed algorithm with strongly convex and nonconvex objective functions with fixed and diminishing step sizes using concepts of Lyapunov function construction. We demonstrate the efficacy of our algorithms in comparison with the baseline centralized SGD and the recently proposed federated averaging algorithm (that also enables data parallelism) based on benchmark datasets such as MNIST, CIFAR-10 and CIFAR-100.","Fri, 23 Jun 2017 22:30:17 UTC (2,362 KB)"
"1417","Personalized Acoustic Modeling by Weakly Supervised Multi-Task Deep Learning using Acoustic Tokens Discovered from Unlabeled Data","Cheng-Kuan Wei, Cheng-Tao Chung, Hung-Yi Lee, Lin-Shan Lee","Sound (cs.SD)","It is well known that recognizers personalized to each user are much more effective than user-independent recognizers. With the popularity of smartphones today, although it is not difficult to collect a large set of audio data for each user, it is difficult to transcribe it. However, it is now possible to automatically discover acoustic tokens from unlabeled personal data in an unsupervised way. We therefore propose a multi-task deep learning framework called a phoneme-token deep neural network (PTDNN), jointly trained from unsupervised acoustic tokens discovered from unlabeled data and very limited transcribed data for personalized acoustic modeling. We term this scenario ""weakly supervised"". The underlying intuition is that the high degree of similarity between the HMM states of acoustic token models and phoneme models may help them learn from each other in this multi-task learning framework. Initial experiments performed over a personalized audio data set recorded from Facebook posts demonstrated that very good improvements can be achieved in both frame accuracy and word accuracy over popularly-considered baselines such as fDLR, speaker code and lightly supervised adaptation. This approach complements existing speaker adaptation approaches and can be used jointly with such techniques to yield improved results.","Fri, 23 Jun 2017 12:54:43 UTC (511 KB)"
"1418","Deep Transfer Learning: A new deep learning glitch classification method for advanced LIGO","Daniel George, Hongyu Shen, E. A. Huerta","General Relativity and Quantum Cosmology (gr-qc); Instrumentation and Methods for Astrophysics (astro-ph.IM); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","The exquisite sensitivity of the advanced LIGO detectors has enabled the detection of multiple gravitational wave signals. The sophisticated design of these detectors mitigates the effect of most types of noise. However, advanced LIGO data streams are contaminated by numerous artifacts known as glitches: non-Gaussian noise transients with complex morphologies. Given their high rate of occurrence, glitches can lead to false coincident detections, obscure and even mimic gravitational wave signals. Therefore, successfully characterizing and removing glitches from advanced LIGO data is of utmost importance. Here, we present the first application of Deep Transfer Learning for glitch classification, showing that knowledge from deep learning algorithms trained for real-world object recognition can be transferred for classifying glitches in time-series based on their spectrogram images. Using the Gravity Spy dataset, containing hand-labeled, multi-duration spectrograms obtained from real LIGO data, we demonstrate that this method enables optimal use of very deep convolutional neural networks for classification given small training datasets, significantly reduces the time for training the networks, and achieves state-of-the-art accuracy above 98.8%, with perfect precision-recall on 8 out of 22 classes. Furthermore, new types of glitches can be classified accurately given few labeled examples with this technique. Once trained via transfer learning, we show that the convolutional neural networks can be truncated and used as excellent feature extractors for unsupervised clustering methods to identify new classes based on their morphology, without any labeled examples. Therefore, this provides a new framework for dynamic glitch classification for gravitational wave detectors, which are expected to encounter new types of noise as they undergo gradual improvements to attain design sensitivity.","Thu, 22 Jun 2017 18:11:13 UTC (7,190 KB)"
"1419","Deep Learning Methods for Improved Decoding of Linear Codes","Eliya Nachmani, Elad Marciano, Loren Lugosch, Warren J. Gross, David Burshtein, Yair Beery","Information Theory (cs.IT); Neural and Evolutionary Computing (cs.NE)","The problem of low complexity, close to optimal, channel decoding of linear codes with short to moderate block length is considered. It is shown that deep learning methods can be used to improve a standard belief propagation decoder, despite the large example space. Similar improvements are obtained for the min-sum algorithm. It is also shown that tying the parameters of the decoders across iterations, so as to form a recurrent neural network architecture, can be implemented with comparable results. The advantage is that significantly less parameters are required. We also introduce a recurrent neural decoder architecture based on the method of successive relaxation. Improvements over standard belief propagation are also observed on sparser Tanner graph representations of the codes. Furthermore, we demonstrate that the neural belief propagation decoder can be used to improve the performance, or alternatively reduce the computational complexity, of a close to optimal decoder of short BCH codes.","Wed, 21 Jun 2017 06:46:14 UTC (1,328 KB)[v2] Mon, 1 Jan 2018 20:13:24 UTC (1,537 KB)"
"1420","Deep Learning Autoencoder Approach for Handwritten Arabic Digits Recognition","Mohamed Loey, Ahmed El-Sawy, Hazem EL-Bakry","Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)","This paper presents a new unsupervised learning approach with stacked autoencoder (SAE) for Arabic handwritten digits categorization. Recently, Arabic handwritten digits recognition has been an important area due to its applications in several fields. This work is focusing on the recognition part of handwritten Arabic digits recognition that face several challenges, including the unlimited variation in human handwriting and the large public databases. Arabic digits contains ten numbers that were descended from the Indian digits system. Stacked autoencoder (SAE) tested and trained the MADBase database (Arabic handwritten digits images) that contain 10000 testing images and 60000 training images. We show that the use of SAE leads to significant improvements across different machine-learning classification algorithms. SAE is giving an average accuracy of 98.5%.","Wed, 21 Jun 2017 02:02:31 UTC (746 KB)"
"1421","Advanced Steel Microstructural Classification by Deep Learning Methods","Seyed Majid Azimi, Dominik Britz, Michael Engstler, Mario Fritz, Frank Mucklich","Computer Vision and Pattern Recognition (cs.CV); Materials Science (cond-mat.mtrl-sci)","The inner structure of a material is called microstructure. It stores the genesis of a material and determines all its physical and chemical properties. While microstructural characterization is widely spread and well known, the microstructural classification is mostly done manually by human experts, which gives rise to uncertainties due to subjectivity. Since the microstructure could be a combination of different phases or constituents with complex substructures its automatic classification is very challenging and only a few prior studies exist. Prior works focused on designed and engineered features by experts and classified microstructures separately from the feature extraction step. Recently, Deep Learning methods have shown strong performance in vision applications by learning the features from data together with the classification step. In this work, we propose a Deep Learning method for microstructural classification in the examples of certain microstructural constituents of low carbon steel. This novel method employs pixel-wise segmentation via Fully Convolutional Neural Networks (FCNN) accompanied by a max-voting scheme. Our system achieves 93.94% classification accuracy, drastically outperforming the state-of-the-art method of 48.89% accuracy. Beyond the strong performance of our method, this line of research offers a more robust and first of all objective way for the difficult task of steel quality appreciation.","Tue, 20 Jun 2017 14:29:42 UTC (2,037 KB)[v2] Thu, 15 Feb 2018 14:30:16 UTC (5,185 KB)"
"1422","Deep Learning in (and of) Agent-Based Models: A Prospectus","Sander van der Hoog","General Economics (econ.GN)","A very timely issue for economic agent-based models (ABMs) is their empirical estimation. This paper describes a line of research that could resolve the issue by using machine learning techniques, using multi-layer artificial neural networks (ANNs), or so called Deep Nets. The seminal contribution by Hinton et al. (2006) introduced a fast and efficient training algorithm called Deep Learning, and there have been major breakthroughs in machine learning ever since. Economics has not yet benefited from these developments, and therefore we believe that now is the right time to apply Deep Learning and multi-layered neural networks to agent-based models in economics.","Tue, 20 Jun 2017 08:08:44 UTC (23 KB)"
"1423","Short-Term Forecasting of Passenger Demand under On-Demand Ride Services: A Spatio-Temporal Deep Learning Approach","Jintao Ke, Hongyu Zheng, Hai Yang, Xiqun (Michael)Chen","Machine Learning (cs.LG)","Short-term passenger demand forecasting is of great importance to the on-demand ride service platform, which can incentivize vacant cars moving from over-supply regions to over-demand regions. The spatial dependences, temporal dependences, and exogenous dependences need to be considered simultaneously, however, which makes short-term passenger demand forecasting challenging. We propose a novel deep learning (DL) approach, named the fusion convolutional long short-term memory network (FCL-Net), to address these three dependences within one end-to-end learning architecture. The model is stacked and fused by multiple convolutional long short-term memory (LSTM) layers, standard LSTM layers, and convolutional layers. The fusion of convolutional techniques and the LSTM network enables the proposed DL approach to better capture the spatio-temporal characteristics and correlations of explanatory variables. A tailored spatially aggregated random forest is employed to rank the importance of the explanatory variables. The ranking is then used for feature selection. The proposed DL approach is applied to the short-term forecasting of passenger demand under an on-demand ride service platform in Hangzhou, China. Experimental results, validated on real-world data provided by DiDi Chuxing, show that the FCL-Net achieves better predictive performance than traditional approaches including both classical time-series prediction models and neural network based algorithms (e.g., artificial neural network and LSTM). This paper is one of the first DL studies to forecast the short-term passenger demand of an on-demand ride service platform by examining the spatio-temporal correlations.","Tue, 20 Jun 2017 06:07:20 UTC (6,775 KB)"
"1424","Using deep learning to reveal the neural code for images in primary visual cortex","William F. Kindel, Elijah D. Christensen, Joel Zylberberg","Neurons and Cognition (q-bio.NC); Computer Vision and Pattern Recognition (cs.CV)","Primary visual cortex (V1) is the first stage of cortical image processing, and a major effort in systems neuroscience is devoted to understanding how it encodes information about visual stimuli. Within V1, many neurons respond selectively to edges of a given preferred orientation: these are known as simple or complex cells, and they are well-studied. Other neurons respond to localized center-surround image features. Still others respond selectively to certain image stimuli, but the specific features that excite them are unknown. Moreover, even for the simple and complex cells-- the best-understood V1 neurons-- it is challenging to predict how they will respond to natural image stimuli. Thus, there are important gaps in our understanding of how V1 encodes images. To fill this gap, we train deep convolutional neural networks to predict the firing rates of V1 neurons in response to natural image stimuli, and find that 15% of these neurons are within 10% of their theoretical limit of predictability. For these well predicted neurons, we invert the predictor network to identify the image features (receptive fields) that cause the V1 neurons to spike. In addition to those with previously-characterized receptive fields (Gabor wavelet and center-surround), we identify neurons that respond predictably to higher-level textural image features that are not localized to any particular region of the image.","Mon, 19 Jun 2017 23:13:54 UTC (760 KB)"
"1425","meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced Overfitting","Xu Sun, Xuancheng Ren, Shuming Ma, Houfeng Wang","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)","We propose a simple yet effective technique for neural network learning. The forward propagation is computed as usual. In back propagation, only a small subset of the full gradient is computed to update the model parameters. The gradient vectors are sparsified in such a way that only the top-$k$ elements (in terms of magnitude) are kept. As a result, only $k$ rows or columns (depending on the layout) of the weight matrix are modified, leading to a linear reduction ($k$ divided by the vector dimension) in the computational cost. Surprisingly, experimental results demonstrate that we can update only 1--4\% of the weights at each back propagation pass. This does not result in a larger number of training iterations. More interestingly, the accuracy of the resulting models is actually improved rather than degraded, and a detailed analysis is given. The code is available at this https URL","Mon, 19 Jun 2017 22:36:33 UTC (153 KB)[v2] Wed, 5 Jul 2017 01:34:50 UTC (158 KB)[v3] Mon, 30 Oct 2017 09:48:41 UTC (158 KB)[v4] Tue, 31 Oct 2017 02:04:52 UTC (158 KB)"
"1426","Towards Deep Learning Models Resistant to Adversarial Attacks","Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu","Machine Learning (stat.ML); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Recent work has demonstrated that neural networks are vulnerable to adversarial examples, i.e., inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models.","Mon, 19 Jun 2017 17:53:11 UTC (788 KB)[v2] Wed, 9 Aug 2017 17:34:00 UTC (834 KB)[v3] Thu, 9 Nov 2017 01:16:40 UTC (866 KB)"
"1427","A deep learning-inspired model of the hippocampus as storage device of the brain extended dataset","Alessandro Fontana","Neurons and Cognition (q-bio.NC)","The standard model of memory consolidation foresees that memories are initially recorded in the hippocampus, while features that capture higher-level generalisations of data are created in the cortex, where they are stored for a possibly indefinite period of time. Computer scientists have sought inspiration from nature to build machines that exhibit some of the remarkable properties present in biological systems. One of the results of this effort is represented by artificial neural networks, a class of algorithms that represent the state of the art in many artificial intelligence applications. In this work, we reverse the inspiration flow and use the experience obtained from neural networks to gain insight into the design of brain architecture and the functioning of memory. Our starting observation is that neural networks learn from data and need to be exposed to each data record many times during learning: this requires the storage of the entire dataset in computer memory. Our thesis is that the same holds true for the brain and the main role of the hippocampus is to store the ""brain dataset"", from which high-level features are learned and encoded in cortical neurons.","Fri, 26 May 2017 15:21:43 UTC (1,909 KB)"
"1428","Deep learning with spatiotemporal consistency for nerve segmentation in ultrasound images","Adel Hafiane, Pierre Vieyres, Alain Delbos","Computer Vision and Pattern Recognition (cs.CV)","Ultrasound-Guided Regional Anesthesia (UGRA) has been gaining importance in the last few years, offering numerous advantages over alternative methods of nerve localization (neurostimulation or paraesthesia). However, nerve detection is one of the most tasks that anaesthetists can encounter in the UGRA procedure. Computer aided system that can detect automatically region of nerve, would help practitioner to concentrate more in anaesthetic delivery. In this paper we propose a new method based on deep learning combined with spatiotemporal information to robustly segment the nerve region. The proposed method is based on two phases, localisation and segmentation. The first phase, consists in using convolutional neural network combined with spatial and temporal consistency to detect the nerve zone. The second phase utilises active contour model to delineate the region of interest. Obtained results show the validity of the proposed approach and its robustness.","Mon, 19 Jun 2017 10:36:39 UTC (851 KB)"
"1429","SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability","Maithra Raghu, Justin Gilmer, Jason Yosinski, Jascha Sohl-Dickstein","Machine Learning (stat.ML); Machine Learning (cs.LG)","We propose a new technique, Singular Vector Canonical Correlation Analysis (SVCCA), a tool for quickly comparing two representations in a way that is both invariant to affine transform (allowing comparison between different layers and networks) and fast to compute (allowing more comparisons to be calculated than with previous methods). We deploy this tool to measure the intrinsic dimensionality of layers, showing in some cases needless over-parameterization; to probe learning dynamics throughout training, finding that networks converge to final representations from the bottom up; to show where class-specific information in networks is formed; and to suggest new training regimes that simultaneously save computation and overfit less. Code: this https URL","Mon, 19 Jun 2017 07:09:20 UTC (5,459 KB)[v2] Wed, 8 Nov 2017 08:36:27 UTC (11,976 KB)"
"1430","Addressing Item-Cold Start Problem in Recommendation Systems using Model Based Approach and Deep Learning","Ivica Obadi<U+0107>, Gjorgji Madjarov (1), Ivica Dimitrovski (1), Dejan Gjorgjevikj (1) ((1) Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Skopje, Macedonia)","Information Retrieval (cs.IR); Machine Learning (cs.LG); Machine Learning (stat.ML)","Traditional recommendation systems rely on past usage data in order to generate new recommendations. Those approaches fail to generate sensible recommendations for new users and items into the system due to missing information about their past interactions. In this paper, we propose a solution for successfully addressing item-cold start problem which uses model-based approach and recent advances in deep learning. In particular, we use latent factor model for recommendation, and predict the latent factors from item's descriptions using convolutional neural network when they cannot be obtained from usage data. Latent factors obtained by applying matrix factorization to the available usage data are used as ground truth to train the convolutional neural network. To create latent factor representations for the new items, the convolutional neural network uses their textual description. The results from the experiments reveal that the proposed approach significantly outperforms several baseline estimators.","Sun, 18 Jun 2017 21:51:10 UTC (414 KB)"
"1431","Towards the Improvement of Automated Scientific Document Categorization by Deep Learning","Thomas Krause","Information Retrieval (cs.IR); Computation and Language (cs.CL)","This master thesis describes an algorithm for automated categorization of scientific documents using deep learning techniques and compares the results to the results of existing classification algorithms. As an additional goal a reusable API is to be developed allowing the automation of classification tasks in existing software. A design will be proposed using a convolutional neural network as a classifier and integrating this into a REST based API. This is then used as the basis for an actual proof of concept implementation presented as well in this thesis. It will be shown that the deep learning classifier provides very good result in the context of multi-class document categorization and that it is feasible to integrate such classifiers into a larger ecosystem using REST based services.","Sun, 18 Jun 2017 20:29:15 UTC (3,112 KB)"
"1432","Deep learning-based numerical methods for high-dimensional parabolic partial differential equations and backward stochastic differential equations","Weinan E, Jiequn Han, Arnulf Jentzen","Numerical Analysis (math.NA); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Probability (math.PR); Machine Learning (stat.ML)","We propose a new algorithm for solving parabolic partial differential equations (PDEs) and backward stochastic differential equations (BSDEs) in high dimension, by making an analogy between the BSDE and reinforcement learning with the gradient of the solution playing the role of the policy function, and the loss function given by the error between the prescribed terminal condition and the solution of the BSDE. The policy function is then approximated by a neural network, as is done in deep reinforcement learning. Numerical results using TensorFlow illustrate the efficiency and accuracy of the proposed algorithms for several 100-dimensional nonlinear PDEs from physics and finance such as the Allen-Cahn equation, the Hamilton-Jacobi-Bellman equation, and a nonlinear pricing model for financial derivatives.","Thu, 15 Jun 2017 00:28:58 UTC (1,225 KB)"
"1433","Deep Learning Methods for Efficient Large Scale Video Labeling","Miha Skalic, Marcin Pekalski, Xingguo E. Pan","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","We present a solution to ""Google Cloud and YouTube-8M Video Understanding Challenge"" that ranked 5th place. The proposed model is an ensemble of three model families, two frame level and one video level. The training was performed on augmented dataset, with cross validation.","Wed, 14 Jun 2017 16:24:18 UTC (75 KB)"
"1434","Modeling Multimodal Clues in a Hybrid Deep Learning Framework for Video Classification","Yu-Gang Jiang, Zuxuan Wu, Jinhui Tang, Zechao Li, Xiangyang Xue, Shih-Fu Chang","Multimedia (cs.MM); Computer Vision and Pattern Recognition (cs.CV)","Videos are inherently multimodal. This paper studies the problem of how to fully exploit the abundant multimodal clues for improved video categorization. We introduce a hybrid deep learning framework that integrates useful clues from multiple modalities, including static spatial appearance information, motion patterns within a short time window, audio information as well as long-range temporal dynamics. More specifically, we utilize three Convolutional Neural Networks (CNNs) operating on appearance, motion and audio signals to extract their corresponding features. We then employ a feature fusion network to derive a unified representation with an aim to capture the relationships among features. Furthermore, to exploit the long-range temporal dynamics in videos, we apply two Long Short Term Memory networks with extracted appearance and motion features as inputs. Finally, we also propose to refine the prediction scores by leveraging contextual relationships among video semantics. The hybrid deep learning framework is able to exploit a comprehensive set of multimodal features for video classification. Through an extensive set of experiments, we demonstrate that (1) LSTM networks which model sequences in an explicitly recurrent manner are highly complementary with CNN models; (2) the feature fusion network which produces a fused representation through modeling feature relationships outperforms alternative fusion strategies; (3) the semantic context of video classes can help further refine the predictions for improved performance. Experimental results on two challenging benchmarks, the UCF-101 and the Columbia Consumer Videos (CCV), provide strong quantitative evidence that our framework achieves promising results: $93.1\%$ on the UCF-101 and $84.5\%$ on the CCV, outperforming competing methods with clear margins.","Wed, 14 Jun 2017 14:23:08 UTC (1,093 KB)"
"1435","$ロ$-net: Deep Learning for Generalized Biventricular Cardiac Mass and Function Parameters","Hinrich B Winther, Christian Hundt, Bertil Schmidt, Christoph Czerner, Johann Bauersachs, Frank Wacker, Jens Vogel-Claussen","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Background: Cardiac MRI derived biventricular mass and function parameters, such as end-systolic volume (ESV), end-diastolic volume (EDV), ejection fraction (EF), stroke volume (SV), and ventricular mass (VM) are clinically well established. Image segmentation can be challenging and time-consuming, due to the complex anatomy of the human heart. Objectives: This study introduces $ロ$-net (/nju:n$\varepsilon$t/) -- a deep learning approach allowing for fully-automated high quality segmentation of right (RV) and left ventricular (LV) endocardium and epicardium for extraction of cardiac function parameters. Methods: A set consisting of 253 manually segmented cases has been used to train a deep neural network. Subsequently, the network has been evaluated on 4 different multicenter data sets with a total of over 1000 cases. Results: For LV EF the intraclass correlation coefficient (ICC) is 98, 95, and 80 % (95 %), and for RV EF 96, and 87 % (80 %) on the respective data sets (human expert ICCs reported in parenthesis). The LV VM ICC is 95, and 94 % (84 %), and the RV VM ICC is 83, and 83 % (54 %). This study proposes a simple adjustment procedure, allowing for the adaptation to distinct segmentation philosophies. $ロ$-net exhibits state of-the-art performance in terms of dice coefficient. Conclusions: Biventricular mass and function parameters can be determined reliably in high quality by applying a deep neural network for cardiac MRI segmentation, especially in the anatomically complex right ventricle. Adaption to individual segmentation styles by applying a simple adjustment procedure is viable, allowing for the processing of novel data without time-consuming additional training.","Wed, 14 Jun 2017 10:36:30 UTC (2,797 KB)"
"1436","When Image Denoising Meets High-Level Vision Tasks: A Deep Learning Approach","Ding Liu, Bihan Wen, Xianming Liu, Zhangyang Wang, Thomas S. Huang","Computer Vision and Pattern Recognition (cs.CV)","Conventionally, image denoising and high-level vision tasks are handled separately in computer vision. In this paper, we cope with the two jointly and explore the mutual influence between them. First we propose a convolutional neural network for image denoising which achieves the state-of-the-art performance. Second we propose a deep neural network solution that cascades two modules for image denoising and various high-level tasks, respectively, and use the joint loss for updating only the denoising network via back-propagation. We demonstrate that on one hand, the proposed denoiser has the generality to overcome the performance degradation of different high-level vision tasks. On the other hand, with the guidance of high-level vision information, the denoising network can generate more visually appealing results. To the best of our knowledge, this is the first work investigating the benefit of exploiting image semantics simultaneously for image denoising and high-level vision tasks via deep learning. The code is available online this https URL.","Wed, 14 Jun 2017 00:04:56 UTC (6,099 KB)[v2] Tue, 5 Sep 2017 03:30:51 UTC (6,107 KB)[v3] Mon, 16 Apr 2018 19:33:33 UTC (10,113 KB)"
"1437","von Mises-Fisher Mixture Model-based Deep learning: Application to Face Verification","Md. Abul Hasnat, Julien Bohne, Jonathan Milgram, Stephane Gentric, Liming Chen","Computer Vision and Pattern Recognition (cs.CV)","A number of pattern recognition tasks, \textit{e.g.}, face verification, can be boiled down to classification or clustering of unit length directional feature vectors whose distance can be simply computed by their angle. In this paper, we propose the von Mises-Fisher (vMF) mixture model as the theoretical foundation for an effective deep-learning of such directional features and derive a novel vMF Mixture Loss and its corresponding vMF deep features. The proposed vMF feature learning achieves the characteristics of discriminative learning, \textit{i.e.}, compacting the instances of the same class while increasing the distance of instances from different classes. Moreover, it subsumes a number of popular loss functions as well as an effective method in deep learning, namely normalization. We conduct extensive experiments on face verification using 4 different challenging face datasets, \textit{i.e.}, LFW, YouTube faces, CACD and IJB-A. Results show the effectiveness and excellent generalization ability of the proposed approach as it achieves state-of-the-art results on the LFW, YouTube faces and CACD datasets and competitive results on the IJB-A dataset.","Tue, 13 Jun 2017 21:43:05 UTC (1,840 KB)[v2] Sun, 31 Dec 2017 22:24:58 UTC (5,596 KB)"
"1438","Temporally Efficient Deep Learning with Spikes","Peter O'Connor, Efstratios Gavves, Max Welling","Neural and Evolutionary Computing (cs.NE)","The vast majority of natural sensory data is temporally redundant. Video frames or audio samples which are sampled at nearby points in time tend to have similar values. Typically, deep learning algorithms take no advantage of this redundancy to reduce computation. This can be an obscene waste of energy. We present a variant on backpropagation for neural networks in which computation scales with the rate of change of the data - not the rate at which we process the data. We do this by having neurons communicate a combination of their state, and their temporal change in state. Intriguingly, this simple communication rule give rise to units that resemble biologically-inspired leaky integrate-and-fire neurons, and to a weight-update rule that is equivalent to a form of Spike-Timing Dependent Plasticity (STDP), a synaptic learning rule observed in the brain. We demonstrate that on MNIST and a temporal variant of MNIST, our algorithm performs about as well as a Multilayer Perceptron trained with backpropagation, despite only communicating discrete values between layers.","Tue, 13 Jun 2017 16:56:27 UTC (454 KB)"
"1439","Deep Learning-Based Food Calorie Estimation Method in Dietary Assessment","Yanchao Liang, Jianhua Li","Computer Vision and Pattern Recognition (cs.CV)","Obesity treatment requires obese patients to record all food intakes per day. Computer vision has been introduced to estimate calories from food images. In order to increase accuracy of detection and reduce the error of volume estimation in food calorie estimation, we present our calorie estimation method in this paper. To estimate calorie of food, a top view and side view is needed. Faster R-CNN is used to detect the food and calibration object. GrabCut algorithm is used to get each food's contour. Then the volume is estimated with the food and corresponding object. Finally we estimate each food's calorie. And the experiment results show our estimation method is effective.","Sat, 10 Jun 2017 09:42:28 UTC (1,050 KB)[v2] Tue, 20 Jun 2017 01:28:15 UTC (1,050 KB)[v3] Tue, 2 Jan 2018 10:47:35 UTC (1,540 KB)[v4] Sun, 18 Feb 2018 08:13:04 UTC (1,190 KB)"
"1440","Practical Gauss-Newton Optimisation for Deep Learning","Aleksandar Botev, Hippolyt Ritter, David Barber","Machine Learning (stat.ML)","We present an efficient block-diagonal ap- proximation to the Gauss-Newton matrix for feedforward neural networks. Our result- ing algorithm is competitive against state- of-the-art first order optimisation methods, with sometimes significant improvement in optimisation performance. Unlike first-order methods, for which hyperparameter tuning of the optimisation parameters is often a labo- rious process, our approach can provide good performance even when used with default set- tings. A side result of our work is that for piecewise linear transfer functions, the net- work objective function can have no differ- entiable local maxima, which may partially explain why such transfer functions facilitate effective optimisation.","Mon, 12 Jun 2017 14:39:48 UTC (70 KB)[v2] Tue, 13 Jun 2017 17:56:09 UTC (7,677 KB)"
"1441","Optimal Auctions through Deep Learning","Paul Dutting, Zhe Feng, Harikrishna Narasimhan, David C. Parkes","Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","Designing an auction that maximizes expected revenue is an intricate task. Indeed, as of today--despite major efforts and impressive progress over the past few years--only the single-item case is fully understood. In this work, we initiate the exploration of the use of tools from deep learning on this topic. The design objective is revenue optimal, dominant-strategy incentive compatible auctions. We show that multi-layer neural networks can learn almost-optimal auctions for settings for which there are analytical solutions, such as Myerson's auction for a single item, Manelli and Vincent's mechanism for a single bidder with additive preferences over two items, or Yao's auction for two additive bidders with binary support distributions and multiple items, even if no prior knowledge about the form of optimal auctions is encoded in the network and the only feedback during training is revenue and regret. We further show how characterization results, even rather implicit ones such as Rochet's characterization through induced utilities and their gradients, can be leveraged to obtain more precise fits to the optimal design. We conclude by demonstrating the potential of deep learning for deriving optimal auctions with high revenue for poorly understood problems.","Mon, 12 Jun 2017 04:03:15 UTC (1,475 KB)[v2] Mon, 19 Mar 2018 17:56:32 UTC (1,913 KB)"
"1442","Deep Learning for Precipitation Nowcasting: A Benchmark and A New Model","Xingjian Shi, Zhihan Gao, Leonard Lausen, Hao Wang, Dit-Yan Yeung, Wai-kin Wong, Wang-chun Woo","Computer Vision and Pattern Recognition (cs.CV)","With the goal of making high-resolution forecasts of regional rainfall, precipitation nowcasting has become an important and fundamental technology underlying various public services ranging from rainstorm warnings to flight safety. Recently, the Convolutional LSTM (ConvLSTM) model has been shown to outperform traditional optical flow based methods for precipitation nowcasting, suggesting that deep learning models have a huge potential for solving the problem. However, the convolutional recurrence structure in ConvLSTM-based models is location-invariant while natural motion and transformation (e.g., rotation) are location-variant in general. Furthermore, since deep-learning-based precipitation nowcasting is a newly emerging area, clear evaluation protocols have not yet been established. To address these problems, we propose both a new model and a benchmark for precipitation nowcasting. Specifically, we go beyond ConvLSTM and propose the Trajectory GRU (TrajGRU) model that can actively learn the location-variant structure for recurrent connections. Besides, we provide a benchmark that includes a real-world large-scale dataset from the Hong Kong Observatory, a new training loss, and a comprehensive evaluation protocol to facilitate future research and gauge the state of the art.","Mon, 12 Jun 2017 04:02:03 UTC (647 KB)[v2] Thu, 5 Oct 2017 06:31:47 UTC (648 KB)"
"1443","Deep EHR: A Survey of Recent Advances in Deep Learning Techniques for Electronic Health Record (EHR) Analysis","Benjamin Shickel, Patrick Tighe, Azra Bihorac, Parisa Rashidi","Machine Learning (cs.LG); Machine Learning (stat.ML)","The past decade has seen an explosion in the amount of digital information stored in electronic health records (EHR). While primarily designed for archiving patient clinical information and administrative healthcare tasks, many researchers have found secondary use of these records for various clinical informatics tasks. Over the same period, the machine learning community has seen widespread advances in deep learning techniques, which also have been successfully applied to the vast amount of EHR data. In this paper, we review these deep EHR systems, examining architectures, technical aspects, and clinical applications. We also identify shortcomings of current techniques and discuss avenues of future research for EHR-based deep learning.","Mon, 12 Jun 2017 03:03:15 UTC (2,062 KB)[v2] Sat, 24 Feb 2018 01:41:18 UTC (2,102 KB)"
"1444","Poseidon: An Efficient Communication Architecture for Distributed Deep Learning on GPU Clusters","Hao Zhang, Zeyu Zheng, Shizhen Xu, Wei Dai, Qirong Ho, Xiaodan Liang, Zhiting Hu, Jinliang Wei, Pengtao Xie, Eric P. Xing","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (stat.ML)","Deep learning models can take weeks to train on a single GPU-equipped machine, necessitating scaling out DL training to a GPU-cluster. However, current distributed DL implementations can scale poorly due to substantial parameter synchronization over the network, because the high throughput of GPUs allows more data batches to be processed per unit time than CPUs, leading to more frequent network synchronization. We present Poseidon, an efficient communication architecture for distributed DL on GPUs. Poseidon exploits the layered model structures in DL programs to overlap communication and computation, reducing bursty network communication. Moreover, Poseidon uses a hybrid communication scheme that optimizes the number of bytes required to synchronize each layer, according to layer properties and the number of machines. We show that Poseidon is applicable to different DL frameworks by plugging Poseidon into Caffe and TensorFlow. We show that Poseidon enables Caffe and TensorFlow to achieve 15.5x speed-up on 16 single-GPU machines, even with limited bandwidth (10GbE) and the challenging VGG19-22K network for image classification. Moreover, Poseidon-enabled TensorFlow achieves 31.5x speed-up with 32 single-GPU machines on Inception-V3, a 50% improvement over the open-source TensorFlow (20x speed-up).","Sun, 11 Jun 2017 01:11:06 UTC (5,135 KB)"
"1445","Toward Optimal Run Racing: Application to Deep Learning Calibration","Olivier Bousquet, Sylvain Gelly, Karol Kurach, Marc Schoenauer, Michele Sebag, Olivier Teytaud, Damien Vincent","Machine Learning (cs.LG)","This paper aims at one-shot learning of deep neural nets, where a highly parallel setting is considered to address the algorithm calibration problem - selecting the best neural architecture and learning hyper-parameter values depending on the dataset at hand. The notoriously expensive calibration problem is optimally reduced by detecting and early stopping non-optimal runs. The theoretical contribution regards the optimality guarantees within the multiple hypothesis testing framework. Experimentations on the Cifar10, PTB and Wiki benchmarks demonstrate the relevance of the approach with a principled and consistent improvement on the state of the art with no extra hyper-parameter.","Sat, 10 Jun 2017 07:55:38 UTC (974 KB)[v2] Tue, 20 Jun 2017 11:38:25 UTC (974 KB)"
"1446","Direct detection of pixel-level myocardial infarction areas via a deep-learning algorithm","Chenchu Xu, Lei Xu, Zhifan Gao, Shen zhao, Heye Zhang, Yanping Zhang, Xiuquan Du, Shu Zhao, Dhanjoo Ghista, Shuo Li","Computer Vision and Pattern Recognition (cs.CV)","Accurate detection of the myocardial infarction (MI) area is crucial for early diagnosis planning and follow-up management. In this study, we propose an end-to-end deep-learning algorithm framework (OF-RNN ) to accurately detect the MI area at the pixel level. Our OF-RNN consists of three different function layers: the heart localization layers, which can accurately and automatically crop the region-of-interest (ROI) sequences, including the left ventricle, using the whole cardiac magnetic resonance image sequences; the motion statistical layers, which are used to build a time-series architecture to capture two types of motion features (at the pixel-level) by integrating the local motion features generated by long short-term memory-recurrent neural networks and the global motion features generated by deep optical flows from the whole ROI sequence, which can effectively characterize myocardial physiologic function; and the fully connected discriminate layers, which use stacked auto-encoders to further learn these features, and they use a softmax classifier to build the correspondences from the motion features to the tissue identities (infarction or not) for each pixel. Through the seamless connection of each layer, our OF-RNN can obtain the area, position, and shape of the MI for each patient. Our proposed framework yielded an overall classification accuracy of 94.35% at the pixel level, from 114 clinical subjects. These results indicate the potential of our proposed method in aiding standardized MI assessments.","Sat, 10 Jun 2017 05:03:38 UTC (3,763 KB)"
"1447","Deep Learning for Isotropic Super-Resolution from Non-Isotropic 3D Electron Microscopy","Larissa Heinrich, John A. Bogovic, Stephan Saalfeld","Computer Vision and Pattern Recognition (cs.CV)","The most sophisticated existing methods to generate 3D isotropic super-resolution (SR) from non-isotropic electron microscopy (EM) are based on learned dictionaries. Unfortunately, none of the existing methods generate practically satisfying results. For 2D natural images, recently developed super-resolution methods that use deep learning have been shown to significantly outperform the previous state of the art. We have adapted one of the most successful architectures (FSRCNN) for 3D super-resolution, and compared its performance to a 3D U-Net architecture that has not been used previously to generate super-resolution. We trained both architectures on artificially downscaled isotropic ground truth from focused ion beam milling scanning EM (FIB-SEM) and tested the performance for various hyperparameter settings. Our results indicate that both architectures can successfully generate 3D isotropic super-resolution from non-isotropic EM, with the U-Net performing consistently better. We propose several promising directions for practical application.","Fri, 9 Jun 2017 22:17:16 UTC (149 KB)"
"1448","An Ensemble Deep Learning Based Approach for Red Lesion Detection in Fundus Images","Jose Ignacio Orlando, Elena Prokofyeva, Mariana del Fresno, Matthew B. Blaschko","Computer Vision and Pattern Recognition (cs.CV)","Diabetic retinopathy is one of the leading causes of preventable blindness in the world. Its earliest sign are red lesions, a general term that groups both microaneurysms and hemorrhages. In daily clinical practice, these lesions are manually detected by physicians using fundus photographs. However, this task is tedious and time consuming, and requires an intensive effort due to the small size of the lesions and their lack of contrast. Computer-assisted diagnosis of DR based on red lesion detection is being actively explored due to its improvement effects both in clinicians consistency and accuracy. Several methods for detecting red lesions have been proposed in the literature, most of them based on characterizing lesion candidates using hand crafted features, and classifying them into true or false positive detections. Deep learning based approaches, by contrast, are scarce in this domain due to the high expense of annotating the lesions manually. In this paper we propose a novel method for red lesion detection based on combining both deep learned and domain knowledge. Features learned by a CNN are augmented by incorporating hand crafted features. Such ensemble vector of descriptors is used afterwards to identify true lesion candidates using a Random Forest classifier. We empirically observed that combining both sources of information significantly improve results with respect to using each approach separately. Furthermore, our method reported the highest performance on a per-lesion basis on DIARETDB1 and e-ophtha, and for screening and need for referral on MESSIDOR compared to a second human expert. Results highlight the fact that integrating manually engineered approaches with deep learned features is relevant to improve results when the networks are trained from lesion-level annotated data. An open source implementation of our system is publicly available online.","Fri, 9 Jun 2017 15:47:11 UTC (6,772 KB)[v2] Thu, 12 Oct 2017 19:44:36 UTC (5,595 KB)"
"1449","Enhancing SDO/HMI images using deep learning","C.J. Diaz Baso, A. Asensio Ramos","Solar and Stellar Astrophysics (astro-ph.SR); Instrumentation and Methods for Astrophysics (astro-ph.IM); Computer Vision and Pattern Recognition (cs.CV)","The Helioseismic and Magnetic Imager (HMI) provides continuum images and magnetograms with a cadence better than one per minute. It has been continuously observing the Sun 24 hours a day for the past 7 years. The obvious trade-off between full disk observations and spatial resolution makes HMI not enough to analyze the smallest-scale events in the solar atmosphere. Our aim is to develop a new method to enhance HMI data, simultaneously deconvolving and super-resolving images and magnetograms. The resulting images will mimic observations with a diffraction-limited telescope twice the diameter of HMI. Our method, which we call Enhance, is based on two deep fully convolutional neural networks that input patches of HMI observations and output deconvolved and super-resolved data. The neural networks are trained on synthetic data obtained from simulations of the emergence of solar active regions. We have obtained deconvolved and supper-resolved HMI images. To solve this ill-defined problem with infinite solutions we have used a neural network approach to add prior information from the simulations. We test Enhance against Hinode data that has been degraded to a 28 cm diameter telescope showing very good consistency. The code is open source.","Fri, 9 Jun 2017 12:54:03 UTC (1,649 KB)[v2] Tue, 30 Jan 2018 19:45:05 UTC (3,396 KB)"
"1450","Assessing the Performance of Deep Learning Algorithms for Newsvendor Problem","Yanfei Zhang, Junbin Gao","Machine Learning (stat.ML); Machine Learning (cs.LG)","In retailer management, the Newsvendor problem has widely attracted attention as one of basic inventory models. In the traditional approach to solving this problem, it relies on the probability distribution of the demand. In theory, if the probability distribution is known, the problem can be considered as fully solved. However, in any real world scenario, it is almost impossible to even approximate or estimate a better probability distribution for the demand. In recent years, researchers start adopting machine learning approach to learn a demand prediction model by using other feature information. In this paper, we propose a supervised learning that optimizes the demand quantities for products based on feature information. We demonstrate that the original Newsvendor loss function as the training objective outperforms the recently suggested quadratic loss function. The new algorithm has been assessed on both the synthetic data and real-world data, demonstrating better performance.","Fri, 9 Jun 2017 11:21:35 UTC (41 KB)"
"1451","Deep-Learning the Landscape","Yang-Hui He","High Energy Physics - Theory (hep-th); High Energy Physics - Phenomenology (hep-ph); Algebraic Geometry (math.AG); Machine Learning (stat.ML)","We propose a paradigm to deep-learn the ever-expanding databases which have emerged in mathematical physics and particle phenomenology, as diverse as the statistics of string vacua or combinatorial and algebraic geometry. As concrete examples, we establish multi-layer neural networks as both classifiers and predictors and train them with a host of available data ranging from Calabi-Yau manifolds and vector bundles, to quiver representations for gauge theories. We find that even a relatively simple neural network can learn many significant quantities to astounding accuracy in a matter of minutes and can also predict hithertofore unencountered results. This paradigm should prove a valuable tool in various investigations in landscapes in physics as well as pure mathematics.","Thu, 8 Jun 2017 18:01:02 UTC (233 KB)[v2] Mon, 19 Jun 2017 21:28:02 UTC (475 KB)[v3] Sat, 27 Jan 2018 09:50:52 UTC (602 KB)"
"1452","Photometric redshift estimation via deep learning","Antonio D'Isanto, Kai Lars Polsterer","Instrumentation and Methods for Astrophysics (astro-ph.IM)","The need to analyze the available large synoptic multi-band surveys drives the development of new data-analysis methods. Photometric redshift estimation is one field of application where such new methods improved the results, substantially. Up to now, the vast majority of applied redshift estimation methods have utilized photometric features. We aim to develop a method to derive probabilistic photometric redshift directly from multi-band imaging data, rendering pre-classification of objects and feature extraction obsolete. A modified version of a deep convolutional network was combined with a mixture density network. The estimates are expressed as Gaussian mixture models representing the probability density functions (PDFs) in the redshift space. In addition to the traditional scores, the continuous ranked probability score (CRPS) and the probability integral transform (PIT) were applied as performance criteria. We have adopted a feature based random forest and a plain mixture density network to compare performances on experiments with data from SDSS (DR9). We show that the proposed method is able to predict redshift PDFs independently from the type of source, for example galaxies, quasars or stars. Thereby the prediction performance is better than both presented reference methods and is comparable to results from the literature. The presented method is extremely general and allows us to solve of any kind of probabilistic regression problems based on imaging data, for example estimating metallicity or star formation rate of galaxies. This kind of methodology is tremendously important for the next generation of surveys.","Thu, 8 Jun 2017 07:55:57 UTC (6,294 KB)[v2] Thu, 13 Jul 2017 12:40:27 UTC (6,418 KB)[v3] Fri, 8 Sep 2017 12:14:40 UTC (6,418 KB)"
"1453","Seamless Integration and Coordination of Cognitive Skills in Humanoid Robots: A Deep Learning Approach","Jungsik Hwang, Jun Tani","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)","This study investigates how adequate coordination among the different cognitive processes of a humanoid robot can be developed through end-to-end learning of direct perception of visuomotor stream. We propose a deep dynamic neural network model built on a dynamic vision network, a motor generation network, and a higher-level network. The proposed model was designed to process and to integrate direct perception of dynamic visuomotor patterns in a hierarchical model characterized by different spatial and temporal constraints imposed on each level. We conducted synthetic robotic experiments in which a robot learned to read human's intention through observing the gestures and then to generate the corresponding goal-directed actions. Results verify that the proposed model is able to learn the tutored skills and to generalize them to novel situations. The model showed synergic coordination of perception, action and decision making, and it integrated and coordinated a set of cognitive skills including visual perception, intention reading, attention switching, working memory, action preparation and execution in a seamless manner. Analysis reveals that coherent internal representations emerged at each level of the hierarchy. Higher-level representation reflecting actional intention developed by means of continuous integration of the lower-level visuo-proprioceptive stream.","Thu, 8 Jun 2017 01:15:00 UTC (1,791 KB)"
"1454","Are Saddles Good Enough for Deep Learning?","Adepu Ravi Sankar, Vineeth N Balasubramanian","Machine Learning (stat.ML); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Recent years have seen a growing interest in understanding deep neural networks from an optimization perspective. It is understood now that converging to low-cost local minima is sufficient for such models to become effective in practice. However, in this work, we propose a new hypothesis based on recent theoretical findings and empirical studies that deep neural network models actually converge to saddle points with high degeneracy. Our findings from this work are new, and can have a significant impact on the development of gradient descent based methods for training deep networks. We validated our hypotheses using an extensive experimental evaluation on standard datasets such as MNIST and CIFAR-10, and also showed that recent efforts that attempt to escape saddles finally converge to saddles with high degeneracy, which we define as `good saddles'. We also verified the famous Wigner's Semicircle Law in our experimental results.","Wed, 7 Jun 2017 05:44:07 UTC (121 KB)"
"1455","DeepSketch2Face: A Deep Learning Based Sketching System for 3D Face and Caricature Modeling","Xiaoguang Han, Chang Gao, Yizhou Yu","Graphics (cs.GR); Computer Vision and Pattern Recognition (cs.CV)","Face modeling has been paid much attention in the field of visual computing. There exist many scenarios, including cartoon characters, avatars for social media, 3D face caricatures as well as face-related art and design, where low-cost interactive face modeling is a popular approach especially among amateur users. In this paper, we propose a deep learning based sketching system for 3D face and caricature modeling. This system has a labor-efficient sketching interface, that allows the user to draw freehand imprecise yet expressive 2D lines representing the contours of facial features. A novel CNN based deep regression network is designed for inferring 3D face models from 2D sketches. Our network fuses both CNN and shape based features of the input sketch, and has two independent branches of fully connected layers generating independent subsets of coefficients for a bilinear face representation. Our system also supports gesture based interactions for users to further manipulate initial face models. Both user studies and numerical results indicate that our sketching system can help users create face models quickly and effectively. A significantly expanded face database with diverse identities, expressions and levels of exaggeration is constructed to promote further research and evaluation of face modeling techniques.","Wed, 7 Jun 2017 04:02:27 UTC (3,127 KB)"
"1456","Deep Learning: Generalization Requires Deep Compositional Feature Space Design","Mrinal Haloi","Machine Learning (cs.LG); Machine Learning (stat.ML)","Generalization error defines the discriminability and the representation power of a deep model. In this work, we claim that feature space design using deep compositional function plays a significant role in generalization along with explicit and implicit regularizations. Our claims are being established with several image classification experiments. We show that the information loss due to convolution and max pooling can be marginalized with the compositional design, improving generalization performance. Also, we will show that learning rate decay acts as an implicit regularizer in deep model training.","Tue, 6 Jun 2017 21:10:07 UTC (84 KB)[v2] Sat, 8 Jul 2017 22:31:36 UTC (59 KB)"
"1457","Efficient Antihydrogen Detection in Antimatter Physics by Deep Learning","Peter Sadowski, Balint Radics, Ananya, Yasunori Yamazaki, Pierre Baldi","Instrumentation and Detectors (physics.ins-det); Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)","Antihydrogen is at the forefront of antimatter research at the CERN Antiproton Decelerator. Experiments aiming to test the fundamental CPT symmetry and antigravity effects require the efficient detection of antihydrogen annihilation events, which is performed using highly granular tracking detectors installed around an antimatter trap. Improving the efficiency of the antihydrogen annihilation detection plays a central role in the final sensitivity of the experiments. We propose deep learning as a novel technique to analyze antihydrogen annihilation data, and compare its performance with a traditional track and vertex reconstruction method. We report that the deep learning approach yields significant improvement, tripling event coverage while simultaneously improving performance by over 5% in terms of Area Under Curve (AUC).","Tue, 6 Jun 2017 16:00:36 UTC (591 KB)"
"1458","Deep learning for extracting protein-protein interactions from biomedical literature","Yifan Peng, Zhiyong Lu","Computation and Language (cs.CL); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)","State-of-the-art methods for protein-protein interaction (PPI) extraction are primarily feature-based or kernel-based by leveraging lexical and syntactic information. But how to incorporate such knowledge in the recent deep learning methods remains an open question. In this paper, we propose a multichannel dependency-based convolutional neural network model (McDepCNN). It applies one channel to the embedding vector of each word in the sentence, and another channel to the embedding vector of the head of the corresponding word. Therefore, the model can use richer information obtained from different channels. Experiments on two public benchmarking datasets, AIMed and BioInfer, demonstrate that McDepCNN compares favorably to the state-of-the-art rich-feature and single-kernel based methods. In addition, McDepCNN achieves 24.4% relative improvement in F1-score over the state-of-the-art methods on cross-corpus evaluation and 12% improvement in F1-score over kernel-based methods on ""difficult"" instances. These results suggest that McDepCNN generalizes more easily over different corpora, and is capable of capturing long distance features in the sentences.","Mon, 5 Jun 2017 23:09:06 UTC (224 KB)[v2] Wed, 7 Jun 2017 00:28:21 UTC (224 KB)"
"1459","Yeah, Right, Uh-Huh: A Deep Learning Backchannel Predictor","Robin Ruede, Markus Muller, Sebastian Stuker, Alex Waibel","Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Sound (cs.SD)","Using supporting backchannel (BC) cues can make human-computer interaction more social. BCs provide a feedback from the listener to the speaker indicating to the speaker that he is still listened to. BCs can be expressed in different ways, depending on the modality of the interaction, for example as gestures or acoustic cues. In this work, we only considered acoustic cues. We are proposing an approach towards detecting BC opportunities based on acoustic input features like power and pitch. While other works in the field rely on the use of a hand-written rule set or specialized features, we made use of artificial neural networks. They are capable of deriving higher order features from input features themselves. In our setup, we first used a fully connected feed-forward network to establish an updated baseline in comparison to our previously proposed setup. We also extended this setup by the use of Long Short-Term Memory (LSTM) networks which have shown to outperform feed-forward based setups on various tasks. Our best system achieved an F1-Score of 0.37 using power and pitch features. Adding linguistic information using word2vec, the score increased to 0.39.","Fri, 2 Jun 2017 17:05:26 UTC (476 KB)"
"1460","Deep learning evaluation using deep linguistic processing","Alexander Kuhnle, Ann Copestake","Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","We discuss problems with the standard approaches to evaluation for tasks like visual question answering, and argue that artificial data can be used to address these as a complement to current practice. We demonstrate that with the help of existing 'deep' linguistic processing technology we are able to create challenging abstract datasets, which enable us to investigate the language understanding abilities of multimodal deep learning models in detail, as compared to a single performance value on a static and monolithic dataset.","Mon, 5 Jun 2017 13:53:56 UTC (71 KB)[v2] Sat, 12 May 2018 10:37:02 UTC (82 KB)"
"1461","Jet-Parton Assignment in ttH Events using Deep Learning","Martin Erdmann, Benjamin Fischer, Marcel Rieger","High Energy Physics - Experiment (hep-ex)","The direct measurement of the top quark-Higgs coupling is one of the important questions in understanding the Higgs boson. The coupling can be obtained through measurement of the top quark pair-associated Higgs boson production cross-section. Of the multiple challenges arising in this cross-section measurement, we investigate the reconstruction of the partons originating from the hard scattering process using the measured jets in simulated ttH events. The task corresponds to an assignment challenge of m objects (jets) to n other objects (partons), where m>=n. We compare several methods with emphasis on a concept based on deep learning techniques which yields the best results with more than 50% of correct jet-parton assignments.","Sun, 4 Jun 2017 17:57:44 UTC (247 KB)[v2] Fri, 8 Sep 2017 16:03:11 UTC (248 KB)"
"1462","Deep-Learning Convolutional Neural Networks for scattered shrub detection with Google Earth Imagery","Emilio Guirado, Siham Tabik, Domingo Alcaraz-Segura, Javier Cabello, Francisco Herrera","Computer Vision and Pattern Recognition (cs.CV)","There is a growing demand for accurate high-resolution land cover maps in many fields, e.g., in land-use planning and biodiversity conservation. Developing such maps has been performed using Object-Based Image Analysis (OBIA) methods, which usually reach good accuracies, but require a high human supervision and the best configuration for one image can hardly be extrapolated to a different image. Recently, the deep learning Convolutional Neural Networks (CNNs) have shown outstanding results in object recognition in the field of computer vision. However, they have not been fully explored yet in land cover mapping for detecting species of high biodiversity conservation interest. This paper analyzes the potential of CNNs-based methods for plant species detection using free high-resolution Google Earth T M images and provides an objective comparison with the state-of-the-art OBIA-methods. We consider as case study the detection of Ziziphus lotus shrubs, which are protected as a priority habitat under the European Union Habitats Directive. According to our results, compared to OBIA-based methods, the proposed CNN-based detection model, in combination with data-augmentation, transfer learning and pre-processing, achieves higher performance with less human intervention and the knowledge it acquires in the first image can be transferred to other images, which makes the detection process very fast. The provided methodology can be systematically reproduced for other species detection.","Sat, 3 Jun 2017 09:13:22 UTC (7,429 KB)"
"1463","IDK Cascades: Fast Deep Learning by Learning not to Overthink","Xin Wang, Yujia Luo, Daniel Crankshaw, Alexey Tumanov, Fisher Yu, Joseph E. Gonzalez","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Advances in deep learning have led to substantial increases in prediction accuracy but have been accompanied by increases in the cost of rendering predictions. We conjecture that fora majority of real-world inputs, the recent advances in deep learning have created models that effectively ""overthink"" on simple inputs. In this paper, we revisit the classic question of building model cascades that primarily leverage class asymmetry to reduce cost. We introduce the ""I Don't Know""(IDK) prediction cascades framework, a general framework to systematically compose a set of pre-trained models to accelerate inference without a loss in prediction accuracy. We propose two search based methods for constructing cascades as well as a new cost-aware objective within this framework. The proposed IDK cascade framework can be easily adopted in the existing model serving systems without additional model re-training. We evaluate the proposed techniques on a range of benchmarks to demonstrate the effectiveness of the proposed framework.","Sat, 3 Jun 2017 02:29:12 UTC (1,184 KB)[v2] Tue, 20 Jun 2017 21:03:43 UTC (1,184 KB)[v3] Wed, 13 Sep 2017 17:19:04 UTC (2,168 KB)[v4] Wed, 27 Jun 2018 07:11:26 UTC (2,506 KB)"
"1464","Deep Learning: A Bayesian Perspective","Nicholas Polson, Vadim Sokolov","Machine Learning (stat.ML); Machine Learning (cs.LG); Methodology (stat.ME)","Deep learning is a form of machine learning for nonlinear high dimensional pattern matching and prediction. By taking a Bayesian probabilistic perspective, we provide a number of insights into more efficient algorithms for optimisation and hyper-parameter tuning. Traditional high-dimensional data reduction techniques, such as principal component analysis (PCA), partial least squares (PLS), reduced rank regression (RRR), projection pursuit regression (PPR) are all shown to be shallow learners. Their deep learning counterparts exploit multiple deep layers of data reduction which provide predictive performance gains. Stochastic gradient descent (SGD) training optimisation and Dropout (DO) regularization provide estimation and variable selection. Bayesian regularization is central to finding weights and connections in networks to optimize the predictive bias-variance trade-off. To illustrate our methodology, we provide an analysis of international bookings on Airbnb. Finally, we conclude with directions for future research.","Thu, 1 Jun 2017 19:50:37 UTC (5,073 KB)[v2] Mon, 28 Aug 2017 00:57:42 UTC (5,309 KB)[v3] Tue, 5 Sep 2017 01:33:09 UTC (5,309 KB)[v4] Tue, 14 Nov 2017 03:36:51 UTC (5,370 KB)"
"1465","Deep Learning for Hate Speech Detection in Tweets","Pinkesh Badjatiya, Shashank Gupta, Manish Gupta, Vasudeva Varma","Computation and Language (cs.CL); Information Retrieval (cs.IR)","Hate speech detection on Twitter is critical for applications like controversial event extraction, building AI chatterbots, content recommendation, and sentiment analysis. We define this task as being able to classify a tweet as racist, sexist or neither. The complexity of the natural language constructs makes this task very challenging. We perform extensive experiments with multiple deep learning architectures to learn semantic word embeddings to handle this complexity. Our experiments on a benchmark dataset of 16K annotated tweets show that such deep learning methods outperform state-of-the-art char/word n-gram methods by ~18 F1 points.","Thu, 1 Jun 2017 07:25:22 UTC (25 KB)"
"1466","Criticality & Deep Learning II: Momentum Renormalisation Group","Dan Oprisa, Peter Toth","Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG)","Guided by critical systems found in nature we develop a novel mechanism consisting of inhomogeneous polynomial regularisation via which we can induce scale invariance in deep learning systems. Technically, we map our deep learning (DL) setup to a genuine field theory, on which we act with the Renormalisation Group (RG) in momentum space and produce the flow equations of the couplings; those are translated to constraints and consequently interpreted as ""critical regularisation"" conditions in the optimiser; the resulting equations hence prove to be sufficient conditions for - and serve as an elegant and simple mechanism to induce scale invariance in any deep learning setup.","Wed, 31 May 2017 10:28:39 UTC (168 KB)"
"1467","Spectral Norm Regularization for Improving the Generalizability of Deep Learning","Yuichi Yoshida, Takeru Miyato","Machine Learning (stat.ML); Machine Learning (cs.LG)","We investigate the generalizability of deep learning based on the sensitivity to input perturbation. We hypothesize that the high sensitivity to the perturbation of data degrades the performance on it. To reduce the sensitivity to perturbation, we propose a simple and effective regularization method, referred to as spectral norm regularization, which penalizes the high spectral norm of weight matrices in neural networks. We provide supportive evidence for the abovementioned hypothesis by experimentally confirming that the models trained using spectral norm regularization exhibit better generalizability than other baseline methods.","Wed, 31 May 2017 04:56:25 UTC (528 KB)"
"1468","Deep Learning for Environmentally Robust Speech Recognition: An Overview of Recent Developments","Zixing Zhang, Jurgen Geiger, Jouni Pohjalainen, Amr El-Desoky Mousa, Wenyu Jin, Bjorn Schuller","Sound (cs.SD); Computation and Language (cs.CL); Machine Learning (cs.LG)","Eliminating the negative effect of non-stationary environmental noise is a long-standing research topic for automatic speech recognition that stills remains an important challenge. Data-driven supervised approaches, including ones based on deep neural networks, have recently emerged as potential alternatives to traditional unsupervised approaches and with sufficient training, can alleviate the shortcomings of the unsupervised methods in various real-life acoustic environments. In this light, we review recently developed, representative deep learning approaches for tackling non-stationary additive and convolutional degradation of speech with the aim of providing guidelines for those involved in the development of environmentally robust speech recognition systems. We separately discuss single- and multi-channel techniques developed for the front-end and back-end of speech recognition systems, as well as joint front-end and back-end training frameworks.","Tue, 30 May 2017 21:31:25 UTC (55 KB)[v2] Sat, 8 Jul 2017 09:44:32 UTC (104 KB)[v3] Fri, 21 Sep 2018 09:05:57 UTC (123 KB)"
"1469","ResnetCrowd: A Residual Deep Learning Architecture for Crowd Counting, Violent Behaviour Detection and Crowd Density Level Classification","Mark Marsden, Kevin McGuinness, Suzanne Little, Noel E. O'Connor","Computer Vision and Pattern Recognition (cs.CV)","In this paper we propose ResnetCrowd, a deep residual architecture for simultaneous crowd counting, violent behaviour detection and crowd density level classification. To train and evaluate the proposed multi-objective technique, a new 100 image dataset referred to as Multi Task Crowd is constructed. This new dataset is the first computer vision dataset fully annotated for crowd counting, violent behaviour detection and density level classification. Our experiments show that a multi-task approach boosts individual task performance for all tasks and most notably for violent behaviour detection which receives a 9\% boost in ROC curve AUC (Area under the curve). The trained ResnetCrowd model is also evaluated on several additional benchmarks highlighting the superior generalisation of crowd analysis models trained for multiple objectives.","Tue, 30 May 2017 15:18:41 UTC (862 KB)"
"1470","Deep Learning is Robust to Massive Label Noise","David Rolnick, Andreas Veit, Serge Belongie, Nir Shavit","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)","Deep neural networks trained on large supervised datasets have led to impressive results in image classification and other tasks. However, well-annotated datasets can be time-consuming and expensive to collect, lending increased interest to larger but noisy datasets that are more easily obtained. In this paper, we show that deep neural networks are capable of generalizing from training data for which true labels are massively outnumbered by incorrect labels. We demonstrate remarkably high test performance after training on corrupted data from MNIST, CIFAR, and ImageNet. For example, on MNIST we obtain test accuracy above 90 percent even after each clean training example has been diluted with 100 randomly-labeled examples. Such behavior holds across multiple patterns of label noise, even when erroneous labels are biased towards confusing classes. We show that training in this regime requires a significant but manageable increase in dataset size that is related to the factor by which correct labels have been diluted. Finally, we provide an analysis of our results that shows how increasing noise decreases the effective batch size.","Tue, 30 May 2017 15:10:51 UTC (102 KB)[v2] Wed, 31 May 2017 02:02:56 UTC (102 KB)[v3] Mon, 26 Feb 2018 16:51:57 UTC (597 KB)"
"1471","Collaborative Deep Learning for Speech Enhancement: A Run-Time Model Selection Method Using Autoencoders","Minje Kim","Sound (cs.SD); Machine Learning (cs.LG)","We show that a Modular Neural Network (MNN) can combine various speech enhancement modules, each of which is a Deep Neural Network (DNN) specialized on a particular enhancement job. Differently from an ordinary ensemble technique that averages variations in models, the propose MNN selects the best module for the unseen test signal to produce a greedy ensemble. We see this as Collaborative Deep Learning (CDL), because it can reuse various already-trained DNN models without any further refining. In the proposed MNN selecting the best module during run time is challenging. To this end, we employ a speech AutoEncoder (AE) as an arbitrator, whose input and output are trained to be as similar as possible if its input is clean speech. Therefore, the AE can gauge the quality of the module-specific denoised result by seeing its AE reconstruction error, e.g. low error means that the module output is similar to clean speech. We propose an MNN structure with various modules that are specialized on dealing with a specific noise type, gender, and input Signal-to-Noise Ratio (SNR) value, and empirically prove that it almost always works better than an arbitrarily chosen DNN module and sometimes as good as an oracle result.","Mon, 29 May 2017 20:30:24 UTC (287 KB)"
"1472","Deep Learning for Ontology Reasoning","Patrick Hohenecker, Thomas Lukasiewicz","Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","In this work, we present a novel approach to ontology reasoning that is based on deep learning rather than logic-based formal reasoning. To this end, we introduce a new model for statistical relational learning that is built upon deep recursive neural networks, and give experimental evidence that it can easily compete with, or even outperform, existing logic-based reasoners on the task of ontology reasoning. More precisely, we compared our implemented system with one of the best logic-based ontology reasoners at present, RDFox, on a number of large standard benchmark datasets, and found that our system attained high reasoning quality, while being up to two orders of magnitude faster.","Mon, 29 May 2017 18:17:52 UTC (19 KB)"
"1473","Who's to say what's funny? A computer using Language Models and Deep Learning, That's Who!","Xinru Yan, Ted Pedersen","Computation and Language (cs.CL)","Humor is a defining characteristic of human beings. Our goal is to develop methods that automatically detect humorous statements and rank them on a continuous scale. In this paper we report on results using a Language Model approach, and outline our plans for using methods from Deep Learning.","Mon, 29 May 2017 16:20:21 UTC (12 KB)"
"1474","Deep Learning for Patient-Specific Kidney Graft Survival Analysis","Margaux Luck, Tristan Sylvain, Heloise Cardinal, Andrea Lodi, Yoshua Bengio","Machine Learning (cs.LG); Machine Learning (stat.ML)","An accurate model of patient-specific kidney graft survival distributions can help to improve shared-decision making in the treatment and care of patients. In this paper, we propose a deep learning method that directly models the survival function instead of estimating the hazard function to predict survival times for graft patients based on the principle of multi-task learning. By learning to jointly predict the time of the event, and its rank in the cox partial log likelihood framework, our deep learning approach outperforms, in terms of survival time prediction quality and concordance index, other common methods for survival analysis, including the Cox Proportional Hazards model and a network trained on the cox partial log-likelihood.","Mon, 29 May 2017 15:17:14 UTC (319 KB)"
"1475","Fast learning rate of deep learning via a kernel perspective","Taiji Suzuki","Statistics Theory (math.ST); Machine Learning (cs.LG); Machine Learning (stat.ML)","We develop a new theoretical framework to analyze the generalization error of deep learning, and derive a new fast learning rate for two representative algorithms: empirical risk minimization and Bayesian deep learning. The series of theoretical analyses of deep learning has revealed its high expressive power and universal approximation capability. Although these analyses are highly nonparametric, existing generalization error analyses have been developed mainly in a fixed dimensional parametric model. To compensate this gap, we develop an infinite dimensional model that is based on an integral form as performed in the analysis of the universal approximation capability. This allows us to define a reproducing kernel Hilbert space corresponding to each layer. Our point of view is to deal with the ordinary finite dimensional deep neural network as a finite approximation of the infinite dimensional one. The approximation error is evaluated by the degree of freedom of the reproducing kernel Hilbert space in each layer. To estimate a good finite dimensional model, we consider both of empirical risk minimization and Bayesian deep learning. We derive its generalization error bound and it is shown that there appears bias-variance trade-off in terms of the number of parameters of the finite dimensional approximation. We show that the optimal width of the internal layers can be determined through the degree of freedom and the convergence rate can be faster than $O(1/\sqrt{n})$ rate which has been shown in the existing studies.","Mon, 29 May 2017 13:47:44 UTC (508 KB)"
"1476","Deep Learning for User Comment Moderation","John Pavlopoulos, Prodromos Malakasiotis, Ion Androutsopoulos","Computation and Language (cs.CL); Machine Learning (cs.LG)","Experimenting with a new dataset of 1.6M user comments from a Greek news portal and existing datasets of English Wikipedia comments, we show that an RNN outperforms the previous state of the art in moderation. A deep, classification-specific attention mechanism improves further the overall performance of the RNN. We also compare against a CNN and a word-list baseline, considering both fully automatic and semi-automatic moderation.","Sun, 28 May 2017 21:12:56 UTC (1,433 KB)[v2] Mon, 17 Jul 2017 15:25:56 UTC (1,433 KB)"
"1477","Deep Learning for Spatio-Temporal Modeling: Dynamic Traffic Flows and High Frequency Trading","Matthew F. Dixon, Nicholas G. Polson, Vadim O. Sokolov","Machine Learning (stat.ML)","Deep learning applies hierarchical layers of hidden variables to construct nonlinear high dimensional predictors. Our goal is to develop and train deep learning architectures for spatio-temporal modeling. Training a deep architecture is achieved by stochastic gradient descent (SGD) and drop-out (DO) for parameter regularization with a goal of minimizing out-of-sample predictive mean squared error. To illustrate our methodology, we predict the sharp discontinuities in traffic flow data, and secondly, we develop a classification rule to predict short-term futures market prices as a function of the order book depth. Finally, we conclude with directions for future research.","Sat, 27 May 2017 18:17:58 UTC (2,365 KB)[v2] Mon, 7 May 2018 16:51:59 UTC (1,280 KB)"
"1478","Deep Learning for Lung Cancer Detection: Tackling the Kaggle Data Science Bowl 2017 Challenge","Kingsley Kuan, Mathieu Ravaut, Gaurav Manek, Huiling Chen, Jie Lin, Babar Nazir, Cen Chen, Tse Chiang Howe, Zeng Zeng, Vijay Chandrasekhar","Computer Vision and Pattern Recognition (cs.CV)","We present a deep learning framework for computer-aided lung cancer diagnosis. Our multi-stage framework detects nodules in 3D lung CAT scans, determines if each nodule is malignant, and finally assigns a cancer probability based on these results. We discuss the challenges and advantages of our framework. In the Kaggle Data Science Bowl 2017, our framework ranked 41st out of 1972 teams.","Fri, 26 May 2017 05:36:29 UTC (152 KB)"
"1479","DeepSecure: Scalable Provably-Secure Deep Learning","Bita Darvish Rouhani, M. Sadegh Riazi, Farinaz Koushanfar","Cryptography and Security (cs.CR)","This paper proposes DeepSecure, a novel framework that enables scalable execution of the state-of-the-art Deep Learning (DL) models in a privacy-preserving setting. DeepSecure targets scenarios in which neither of the involved parties including the cloud servers that hold the DL model parameters or the delegating clients who own the data is willing to reveal their information. Our framework is the first to empower accurate and scalable DL analysis of data generated by distributed clients without sacrificing the security to maintain efficiency. The secure DL computation in DeepSecure is performed using Yao's Garbled Circuit (GC) protocol. We devise GC-optimized realization of various components used in DL. Our optimized implementation achieves more than 58-fold higher throughput per sample compared with the best-known prior solution. In addition to our optimized GC realization, we introduce a set of novel low-overhead pre-processing techniques which further reduce the GC overall runtime in the context of deep learning. Extensive evaluations of various DL applications demonstrate up to two orders-of-magnitude additional runtime improvement achieved as a result of our pre-processing methodology. This paper also provides mechanisms to securely delegate GC computations to a third party in constrained embedded settings.","Wed, 24 May 2017 20:44:38 UTC (1,531 KB)"
"1480","Dynamic Occupancy Grid Prediction for Urban Autonomous Driving: A Deep Learning Approach with Fully Automatic Labeling","Stefan Hoermann, Martin Bach, Klaus Dietmayer","Robotics (cs.RO)","Long-term situation prediction plays a crucial role in the development of intelligent vehicles. A major challenge still to overcome is the prediction of complex downtown scenarios with multiple road users, e.g., pedestrians, bikes, and motor vehicles, interacting with each other. This contribution tackles this challenge by combining a Bayesian filtering technique for environment representation, and machine learning as long-term predictor. More specifically, a dynamic occupancy grid map is utilized as input to a deep convolutional neural network. This yields the advantage of using spatially distributed velocity estimates from a single time step for prediction, rather than a raw data sequence, alleviating common problems dealing with input time series of multiple sensors. Furthermore, convolutional neural networks have the inherent characteristic of using context information, enabling the implicit modeling of road user interaction. Pixel-wise balancing is applied in the loss function counteracting the extreme imbalance between static and dynamic cells. One of the major advantages is the unsupervised learning character due to fully automatic label generation. The presented algorithm is trained and evaluated on multiple hours of recorded sensor data and compared to Monte-Carlo simulation.","Wed, 24 May 2017 14:09:00 UTC (7,592 KB)[v2] Tue, 7 Nov 2017 09:53:25 UTC (4,344 KB)"
"1481","Bayesian Compression for Deep Learning","Christos Louizos, Karen Ullrich, Max Welling","Machine Learning (stat.ML); Machine Learning (cs.LG)","Compression and computational efficiency in deep learning have become a problem of great significance. In this work, we argue that the most principled and effective way to attack this problem is by adopting a Bayesian point of view, where through sparsity inducing priors we prune large parts of the network. We introduce two novelties in this paper: 1) we use hierarchical priors to prune nodes instead of individual weights, and 2) we use the posterior uncertainties to determine the optimal fixed point precision to encode the weights. Both factors significantly contribute to achieving the state of the art in terms of compression rates, while still staying competitive with methods designed to optimize for speed or energy efficiency.","Wed, 24 May 2017 09:07:01 UTC (598 KB)[v2] Mon, 29 May 2017 04:59:44 UTC (599 KB)[v3] Thu, 10 Aug 2017 04:03:01 UTC (599 KB)[v4] Mon, 6 Nov 2017 12:46:40 UTC (1,137 KB)"
"1482","Deep Learning Improves Template Matching by Normalized Cross Correlation","Davit Buniatyan, Thomas Macrina, Dodam Ih, Jonathan Zung, H. Sebastian Seung","Computer Vision and Pattern Recognition (cs.CV)","Template matching by normalized cross correlation (NCC) is widely used for finding image correspondences. We improve the robustness of this algorithm by preprocessing images with ""siamese"" convolutional networks trained to maximize the contrast between NCC values of true and false matches. The improvement is quantified using patches of brain images from serial section electron microscopy. Relative to a parameter-tuned bandpass filter, siamese convolutional networks significantly reduce false matches. Furthermore, all false matches can be eliminated by removing a tiny fraction of all matches based on NCC values. The improved accuracy of our method could be essential for connectomics, because emerging petascale datasets may require billions of template matches to assemble 2D images of serial sections into a 3D image stack. Our method is also expected to generalize to many other computer vision applications that use NCC template matching to find image correspondences.","Wed, 24 May 2017 03:24:25 UTC (7,179 KB)"
"1483","Input Fast-Forwarding for Better Deep Learning","Ahmed Ibrahim, A. Lynn Abbott, Mohamed E. Hussein","Computer Vision and Pattern Recognition (cs.CV)","This paper introduces a new architectural framework, known as input fast-forwarding, that can enhance the performance of deep networks. The main idea is to incorporate a parallel path that sends representations of input values forward to deeper network layers. This scheme is substantially different from ""deep supervision"" in which the loss layer is re-introduced to earlier layers. The parallel path provided by fast-forwarding enhances the training process in two ways. First, it enables the individual layers to combine higher-level information (from the standard processing path) with lower-level information (from the fast-forward path). Second, this new architecture reduces the problem of vanishing gradients substantially because the fast-forwarding path provides a shorter route for gradient backpropagation. In order to evaluate the utility of the proposed technique, a Fast-Forward Network (FFNet), with 20 convolutional layers along with parallel fast-forward paths, has been created and tested. The paper presents empirical results that demonstrate improved learning capacity of FFNet due to fast-forwarding, as compared to GoogLeNet (with deep supervision) and CaffeNet, which are 4x and 18x larger in size, respectively. All of the source code and deep learning models described in this paper will be made available to the entire research community","Tue, 23 May 2017 18:57:08 UTC (90 KB)"
"1484","Thinking Fast and Slow with Deep Learning and Tree Search","Thomas Anthony, Zheng Tian, David Barber","Artificial Intelligence (cs.AI)","Sequential decision making problems, such as structured prediction, robotic control, and game playing, require a combination of planning policies and generalisation of those plans. In this paper, we present Expert Iteration (ExIt), a novel reinforcement learning algorithm which decomposes the problem into separate planning and generalisation tasks. Planning new policies is performed by tree search, while a deep neural network generalises those plans. Subsequently, tree search is improved by using the neural network policy to guide search, increasing the strength of new plans. In contrast, standard deep Reinforcement Learning algorithms rely on a neural network not only to generalise plans, but to discover them too. We show that ExIt outperforms REINFORCE for training a neural network to play the board game Hex, and our final tree search agent, trained tabula rasa, defeats MoHex 1.0, the most recent Olympiad Champion player to be publicly released.","Tue, 23 May 2017 17:48:51 UTC (650 KB)[v2] Sat, 4 Nov 2017 17:37:18 UTC (1,008 KB)[v3] Fri, 10 Nov 2017 10:01:16 UTC (1,008 KB)[v4] Sun, 3 Dec 2017 10:56:00 UTC (1,008 KB)"
"1485","Detection Algorithms for Communication Systems Using Deep Learning","Nariman Farsad, Andrea Goldsmith","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)","The design and analysis of communication systems typically rely on the development of mathematical models that describe the underlying communication channel, which dictates the relationship between the transmitted and the received signals. However, in some systems, such as molecular communication systems where chemical signals are used for transfer of information, it is not possible to accurately model this relationship. In these scenarios, because of the lack of mathematical channel models, a completely new approach to design and analysis is required. In this work, we focus on one important aspect of communication systems, the detection algorithms, and demonstrate that by borrowing tools from deep learning, it is possible to train detectors that perform well, without any knowledge of the underlying channel models. We evaluate these algorithms using experimental data that is collected by a chemical communication platform, where the channel model is unknown and difficult to model analytically. We show that deep learning algorithms perform significantly better than a simple detector that was used in previous works, which also did not assume any knowledge of the channel.","Mon, 22 May 2017 23:47:47 UTC (3,586 KB)[v2] Mon, 31 Jul 2017 02:43:27 UTC (3,586 KB)"
"1486","TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep Learning","Wei Wen, Cong Xu, Feng Yan, Chunpeng Wu, Yandan Wang, Yiran Chen, Hai Li","Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC); Neural and Evolutionary Computing (cs.NE)","High network communication cost for synchronizing gradients and parameters is the well-known bottleneck of distributed training. In this work, we propose TernGrad that uses ternary gradients to accelerate distributed deep learning in data parallelism. Our approach requires only three numerical levels {-1,0,1}, which can aggressively reduce the communication time. We mathematically prove the convergence of TernGrad under the assumption of a bound on gradients. Guided by the bound, we propose layer-wise ternarizing and gradient clipping to improve its convergence. Our experiments show that applying TernGrad on AlexNet does not incur any accuracy loss and can even improve accuracy. The accuracy loss of GoogLeNet induced by TernGrad is less than 2% on average. Finally, a performance model is proposed to study the scalability of TernGrad. Experiments show significant speed gains for various deep neural networks. Our source code is available.","Mon, 22 May 2017 17:42:15 UTC (690 KB)[v2] Wed, 24 May 2017 06:41:05 UTC (693 KB)[v3] Mon, 4 Sep 2017 23:49:08 UTC (693 KB)[v4] Mon, 18 Sep 2017 16:21:51 UTC (727 KB)[v5] Tue, 31 Oct 2017 16:36:41 UTC (694 KB)[v6] Fri, 29 Dec 2017 02:51:48 UTC (694 KB)"
"1487","CrossNets: Cross-Information Flow in Deep Learning Architectures","Chirag Agarwal, Joe Klobusicky, Mehdi Sharifzhadeh, Dan Schonfeld","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","We propose a novel neural network structure called CrossNets, which considers architectures on directed acyclic graphs. This structure builds on previous generalization of sequential feed-forward models, such as ResNets, by allowing for all forward cross-connections between both adjacent and non-adjacent layers. The addition of cross-connections within the network increases the information flow across the whole network, leading to better training and testing performances. The superior performance of the network is tested against both image classification and compression tasks using various datasets, such as MNIST, FER, CIFAR-10, CIFAR-100, and SVHN. We conclude with a proof of convergence for CrossNets to a local minimum for error, where weights for connections are chosen through backpropagation with momentum.","Sun, 21 May 2017 06:50:49 UTC (1,726 KB)[v2] Sun, 15 Jul 2018 23:57:53 UTC (3,356 KB)"
"1488","Simultaneous Multiple Surface Segmentation Using Deep Learning","Abhay Shah, Michael Abramoff, Xiaodong Wu","Computer Vision and Pattern Recognition (cs.CV)","The task of automatically segmenting 3-D surfaces representing boundaries of objects is important for quantitative analysis of volumetric images, and plays a vital role in biomedical image analysis. Recently, graph-based methods with a global optimization property have been developed and optimized for various medical imaging applications. Despite their widespread use, these require human experts to design transformations, image features, surface smoothness priors, and re-design for a different tissue, organ or imaging modality. Here, we propose a Deep Learning based approach for segmentation of the surfaces in volumetric medical images, by learning the essential features and transformations from training data, without any human expert intervention. We employ a regional approach to learn the local surface profiles. The proposed approach was evaluated on simultaneous intraretinal layer segmentation of optical coherence tomography (OCT) images of normal retinas and retinas affected by age related macular degeneration (AMD). The proposed approach was validated on 40 retina OCT volumes including 20 normal and 20 AMD subjects. The experiments showed statistically significant improvement in accuracy for our approach compared to state-of-the-art graph based optimal surface segmentation with convex priors (G-OSC). A single Convolution Neural Network (CNN) was used to learn the surfaces for both normal and diseased images. The mean unsigned surface positioning errors obtained by G-OSC method 2.31 voxels (95% CI 2.02-2.60 voxels) was improved to $1.27$ voxels (95% CI 1.14-1.40 voxels) using our new approach. On average, our approach takes 94.34 s, requiring 95.35 MB memory, which is much faster than the 2837.46 s and 6.87 GB memory required by the G-OSC method on the same computer system.","Fri, 19 May 2017 18:43:07 UTC (2,151 KB)"
"1489","Deep Learning as a Tool to Predict Flow Patterns in Two-Phase Flow","Mohammadmehdi Ezzatabadipour, Parth Singh, Melvin D. Robinson, Pablo Guillen-Rondon, Carlos Torres","Machine Learning (cs.LG)","In order to better model complex real-world data such as multiphase flow, one approach is to develop pattern recognition techniques and robust features that capture the relevant information. In this paper, we use deep learning methods, and in particular employ the multilayer perceptron, to build an algorithm that can predict flow pattern in twophase flow from fluid properties and pipe conditions. The preliminary results show excellent performance when compared with classical methods of flow pattern prediction.","Fri, 19 May 2017 03:11:30 UTC (13 KB)"
"1490","The Landscape of Deep Learning Algorithms","Pan Zhou, Jiashi Feng","Machine Learning (stat.ML); Machine Learning (cs.LG); Optimization and Control (math.OC)","This paper studies the landscape of empirical risk of deep neural networks by theoretically analyzing its convergence behavior to the population risk as well as its stationary points and properties. For an $l$-layer linear neural network, we prove its empirical risk uniformly converges to its population risk at the rate of $\mathcal{O}(r^{2l}\sqrt{d\log(l)}/\sqrt{n})$ with training sample size of $n$, the total weight dimension of $d$ and the magnitude bound $r$ of weight of each layer. We then derive the stability and generalization bounds for the empirical risk based on this result. Besides, we establish the uniform convergence of gradient of the empirical risk to its population counterpart. We prove the one-to-one correspondence of the non-degenerate stationary points between the empirical and population risks with convergence guarantees, which describes the landscape of deep neural networks. In addition, we analyze these properties for deep nonlinear neural networks with sigmoid activation functions. We prove similar results for convergence behavior of their empirical risks as well as the gradients and analyze properties of their non-degenerate stationary points. To our best knowledge, this work is the first one theoretically characterizing landscapes of deep learning algorithms. Besides, our results provide the sample complexity of training a good deep neural network. We also provide theoretical understanding on how the neural network depth $l$, the layer width, the network size $d$ and parameter magnitude determine the neural network landscapes.","Fri, 19 May 2017 15:07:07 UTC (900 KB)[v2] Sat, 5 Aug 2017 12:30:25 UTC (915 KB)"
"1491","ADMM-Net: A Deep Learning Approach for Compressive Sensing MRI","Yan Yang, Jian Sun, Huibin Li, Zongben Xu","Computer Vision and Pattern Recognition (cs.CV)","Compressive sensing (CS) is an effective approach for fast Magnetic Resonance Imaging (MRI). It aims at reconstructing MR images from a small number of under-sampled data in k-space, and accelerating the data acquisition in MRI. To improve the current MRI system in reconstruction accuracy and speed, in this paper, we propose two novel deep architectures, dubbed ADMM-Nets in basic and generalized versions. ADMM-Nets are defined over data flow graphs, which are derived from the iterative procedures in Alternating Direction Method of Multipliers (ADMM) algorithm for optimizing a general CS-based MRI model. They take the sampled k-space data as inputs and output reconstructed MR images. Moreover, we extend our network to cope with complex-valued MR images. In the training phase, all parameters of the nets, e.g., transforms, shrinkage functions, etc., are discriminatively trained end-to-end. In the testing phase, they have computational overhead similar to ADMM algorithm but use optimized parameters learned from the data for CS-based reconstruction task. We investigate different configurations in network structures and conduct extensive experiments on MR image reconstruction under different sampling rates. Due to the combination of the advantages in model-based approach and deep learning approach, the ADMM-Nets achieve state-of-the-art reconstruction accuracies with fast computational speed.","Fri, 19 May 2017 06:33:18 UTC (7,451 KB)"
"1492","DeepXplore: Automated Whitebox Testing of Deep Learning Systems","Kexin Pei, Yinzhi Cao, Junfeng Yang, Suman Jana","Machine Learning (cs.LG); Cryptography and Security (cs.CR); Software Engineering (cs.SE)","Deep learning (DL) systems are increasingly deployed in safety- and security-critical domains including self-driving cars and malware detection, where the correctness and predictability of a system's behavior for corner case inputs are of great importance. Existing DL testing depends heavily on manually labeled data and therefore often fails to expose erroneous behaviors for rare inputs. We design, implement, and evaluate DeepXplore, the first whitebox framework for systematically testing real-world DL systems. First, we introduce neuron coverage for systematically measuring the parts of a DL system exercised by test inputs. Next, we leverage multiple DL systems with similar functionality as cross-referencing oracles to avoid manual checking. Finally, we demonstrate how finding inputs for DL systems that both trigger many differential behaviors and achieve high neuron coverage can be represented as a joint optimization problem and solved efficiently using gradient-based search techniques. DeepXplore efficiently finds thousands of incorrect corner case behaviors (e.g., self-driving cars crashing into guard rails and malware masquerading as benign software) in state-of-the-art DL models with thousands of neurons trained on five popular datasets including ImageNet and Udacity self-driving challenge data. For all tested DL models, on average, DeepXplore generated one test input demonstrating incorrect behavior within one second while running only on a commodity laptop. We further show that the test inputs generated by DeepXplore can also be used to retrain the corresponding DL model to improve the model's accuracy by up to 3%.","Thu, 18 May 2017 15:09:39 UTC (7,849 KB)[v2] Sun, 4 Jun 2017 23:40:43 UTC (4,771 KB)[v3] Mon, 10 Jul 2017 17:05:40 UTC (4,771 KB)[v4] Sun, 24 Sep 2017 15:55:11 UTC (5,526 KB)"
"1493","Deep Learning Classification in Asteroseismology","Marc Hon, Dennis Stello, Jie Yu","Solar and Stellar Astrophysics (astro-ph.SR); Instrumentation and Methods for Astrophysics (astro-ph.IM)","In the power spectra of oscillating red giants, there are visually distinct features defining stars ascending the red giant branch from those that have commenced helium core burning. We train a one-dimensional convolutional neural network by supervised learning to automatically learn these visual features from images of folded oscillation spectra. By training and testing on \textit{Kepler} red giants, we achieve an accuracy of up to 99\% in separating helium-burning red giants from those ascending the red giant branch. The convolutional neural network additionally shows capability in accurately predicting the evolutionary states of 5379 previously unclassified \textit{Kepler} red giants, by which we now have greatly increased the number of classified stars.","Thu, 18 May 2017 03:17:34 UTC (2,969 KB)[v2] Fri, 19 May 2017 05:25:17 UTC (2,969 KB)[v3] Sat, 17 Jun 2017 01:47:13 UTC (3,258 KB)"
"1494","Optimizing and Visualizing Deep Learning for Benign/Malignant Classification in Breast Tumors","Darvin Yi, Rebecca Lynn Sawyer, David Cohn III, Jared Dunnmon, Carson Lam, Xuerong Xiao, Daniel Rubin","Computer Vision and Pattern Recognition (cs.CV)","Breast cancer has the highest incidence and second highest mortality rate for women in the US. Our study aims to utilize deep learning for benign/malignant classification of mammogram tumors using a subset of cases from the Digital Database of Screening Mammography (DDSM). Though it was a small dataset from the view of Deep Learning (about 1000 patients), we show that currently state of the art architectures of deep learning can find a robust signal, even when trained from scratch. Using convolutional neural networks (CNNs), we are able to achieve an accuracy of 85% and an ROC AUC of 0.91, while leading hand-crafted feature based methods are only able to achieve an accuracy of 71%. We investigate an amalgamation of architectures to show that our best result is reached with an ensemble of the lightweight GoogLe Nets tasked with interpreting both the coronal caudal view and the mediolateral oblique view, simply averaging the probability scores of both views to make the final prediction. In addition, we have created a novel method to visualize what features the neural network detects for the benign/malignant classification, and have correlated those features with well known radiological features, such as spiculation. Our algorithm significantly improves existing classification methods for mammography lesions and identifies features that correlate with established clinical markers.","Wed, 17 May 2017 22:35:28 UTC (5,392 KB)"
"1495","Practical Processing of Mobile Sensor Data for Continual Deep Learning Predictions","Kleomenis Katevas, Ilias Leontiadis, Martin Pielot, Joan Serra","Machine Learning (cs.LG); Human-Computer Interaction (cs.HC)","We present a practical approach for processing mobile sensor time series data for continual deep learning predictions. The approach comprises data cleaning, normalization, capping, time-based compression, and finally classification with a recurrent neural network. We demonstrate the effectiveness of the approach in a case study with 279 participants. On the basis of sparse sensor events, the network continually predicts whether the participants would attend to a notification within 10 minutes. Compared to a random baseline, the classifier achieves a 40% performance increase (AUC of 0.702) on a withheld test set. This approach allows to forgo resource-intensive, domain-specific, error-prone feature engineering, which may drastically increase the applicability of machine learning to mobile phone sensor data.","Wed, 17 May 2017 15:55:53 UTC (448 KB)"
"1496","Subregular Complexity and Deep Learning","Enes Avcu, Chihiro Shibata, Jeffrey Heinz","Computation and Language (cs.CL)","This paper argues that the judicial use of formal language theory and grammatical inference are invaluable tools in understanding how deep neural networks can and cannot represent and learn long-term dependencies in temporal sequences. Learning experiments were conducted with two types of Recurrent Neural Networks (RNNs) on six formal languages drawn from the Strictly Local (SL) and Strictly Piecewise (SP) classes. The networks were Simple RNNs (s-RNNs) and Long Short-Term Memory RNNs (LSTMs) of varying sizes. The SL and SP classes are among the simplest in a mathematically well-understood hierarchy of subregular classes. They encode local and long-term dependencies, respectively. The grammatical inference algorithm Regular Positive and Negative Inference (RPNI) provided a baseline. According to earlier research, the LSTM architecture should be capable of learning long-term dependencies and should outperform s-RNNs. The results of these experiments challenge this narrative. First, the LSTMs' performance was generally worse in the SP experiments than in the SL ones. Second, the s-RNNs out-performed the LSTMs on the most complex SP experiment and performed comparably to them on the others.","Tue, 16 May 2017 22:13:45 UTC (4,057 KB)[v2] Mon, 3 Jul 2017 02:18:14 UTC (4,057 KB)[v3] Sat, 14 Oct 2017 18:24:08 UTC (76 KB)"
"1497","Holography as deep learning","Wen-Cong Gan, Fu-Wen Shu","General Relativity and Quantum Cosmology (gr-qc); High Energy Physics - Theory (hep-th); Quantum Physics (quant-ph)","Quantum many-body problem with exponentially large degrees of freedom can be reduced to a tractable computational form by neural network method \cite{CT}. The power of deep neural network (DNN) based on deep learning is clarified by mapping it to renormalization group (RG), which may shed lights on holographic principle by identifying a sequence of RG transformations to the AdS geometry. In this essay, we show that any network which reflects RG process has intrinsic hyperbolic geometry, and discuss the structure of entanglement encoded in the graph of DNN. We find the entanglement structure of deep neural network is of Ryu-Takayanagi form. Based on these facts, we argue that the emergence of holographic gravitational theory is related to deep learning process of the quantum field theory.","Tue, 16 May 2017 14:57:22 UTC (82 KB)[v2] Sat, 27 May 2017 12:02:57 UTC (431 KB)"
"1498","Research on Bi-mode Biometrics Based on Deep Learning","Hao Jiang","Computer Vision and Pattern Recognition (cs.CV)","In view of the fact that biological characteristics have excellent independent distinguishing characteristics,biometric identification technology involves almost all the relevant areas of human distinction. Fingerprints, iris, face, voice-print and other biological features have been widely used in the public security departments to detect detection, mobile equipment unlock, target tracking and other fields. With the use of electronic devices more and more widely and the frequency is getting higher and higher. Only the Biometrics identification technology with excellent recognition rate can guarantee the long-term development of these fields.","Tue, 16 May 2017 09:55:05 UTC (4,276 KB)"
"1499","A Deep Learning Based 6 Degree-of-Freedom Localization Method for Endoscopic Capsule Robots","Mehmet Turan, Yasin Almalioglu, Ender Konukoglu, Metin Sitti","Computer Vision and Pattern Recognition (cs.CV)","We present a robust deep learning based 6 degrees-of-freedom (DoF) localization system for endoscopic capsule robots. Our system mainly focuses on localization of endoscopic capsule robots inside the GI tract using only visual information captured by a mono camera integrated to the robot. The proposed system is a 23-layer deep convolutional neural network (CNN) that is capable to estimate the pose of the robot in real time using a standard CPU. The dataset for the evaluation of the system was recorded inside a surgical human stomach model with realistic surface texture, softness, and surface liquid properties so that the pre-trained CNN architecture can be transferred confidently into a real endoscopic scenario. An average error of 7:1% and 3:4% for translation and rotation has been obtained, respectively. The results accomplished from the experiments demonstrate that a CNN pre-trained with raw 2D endoscopic images performs accurately inside the GI tract and is robust to various challenges posed by reflection distortions, lens imperfections, vignetting, noise, motion blur, low resolution, and lack of unique landmarks to track.","Mon, 15 May 2017 20:33:37 UTC (2,621 KB)"
"1500","DeepRT: deep learning for peptide retention time prediction in proteomics","Chunwei Ma, Zhiyong Zhu, Jun Ye, Jiarui Yang, Jianguo Pei, Shaohang Xu, Ruo Zhou, Chang Yu, Fan Mo, Bo Wen, Siqi Liu","Quantitative Methods (q-bio.QM)","Accurate predictions of peptide retention times (RT) in liquid chromatography have many applications in mass spectrometry-based proteomics. Herein, we present DeepRT, a deep learning based software for peptide retention time prediction. DeepRT automatically learns features directly from the peptide sequences using the deep convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) model, which eliminates the need to use hand-crafted features or rules. After the feature learning, principal component analysis (PCA) was used for dimensionality reduction, then three conventional machine learning methods were utilized to perform modeling. Two published datasets were used to evaluate the performance of DeepRT and we demonstrate that DeepRT greatly outperforms previous state-of-the-art approaches ELUDE and GPTime.","Mon, 15 May 2017 10:13:36 UTC (257 KB)"
"1501","Mosquito Detection with Neural Networks: The Buzz of Deep Learning","Ivan Kiskin, Bernardo Perez Orozco, Theo Windebank, Davide Zilli, Marianne Sinka, Kathy Willis, Stephen Roberts","Machine Learning (stat.ML); Sound (cs.SD); Applications (stat.AP)","Many real-world time-series analysis problems are characterised by scarce data. Solutions typically rely on hand-crafted features extracted from the time or frequency domain allied with classification or regression engines which condition on this (often low-dimensional) feature vector. The huge advances enjoyed by many application domains in recent years have been fuelled by the use of deep learning architectures trained on large data sets. This paper presents an application of deep learning for acoustic event detection in a challenging, data-scarce, real-world problem. Our candidate challenge is to accurately detect the presence of a mosquito from its acoustic signature. We develop convolutional neural networks (CNNs) operating on wavelet transformations of audio recordings. Furthermore, we interrogate the network's predictive power by visualising statistics of network-excitatory samples. These visualisations offer a deep insight into the relative informativeness of components in the detection problem. We include comparisons with conventional classifiers, conditioned on both hand-tuned and generic features, to stress the strength of automatic deep feature learning. Detection is achieved with performance metrics significantly surpassing those of existing algorithmic methods, as well as marginally exceeding those attained by individual human experts.","Mon, 15 May 2017 12:19:15 UTC (3,886 KB)"
"1502","Revisiting IM2GPS in the Deep Learning Era","Nam Vo, Nathan Jacobs, James Hays","Computer Vision and Pattern Recognition (cs.CV)","Image geolocalization, inferring the geographic location of an image, is a challenging computer vision problem with many potential applications. The recent state-of-the-art approach to this problem is a deep image classification approach in which the world is spatially divided into cells and a deep network is trained to predict the correct cell for a given image. We propose to combine this approach with the original Im2GPS approach in which a query image is matched against a database of geotagged images and the location is inferred from the retrieved set. We estimate the geographic location of a query image by applying kernel density estimation to the locations of its nearest neighbors in the reference database. Interestingly, we find that the best features for our retrieval task are derived from networks trained with classification loss even though we do not use a classification approach at test time. Training with classification loss outperforms several deep feature learning methods (e.g. Siamese networks with contrastive of triplet loss) more typical for retrieval applications. Our simple approach achieves state-of-the-art geolocalization accuracy while also requiring significantly less training data.","Sat, 13 May 2017 14:43:02 UTC (3,559 KB)"
"1503","Deep Learning Microscopy","Yair Rivenson, Zoltan Gorocs, Harun Gunaydin, Yibo Zhang, Hongda Wang, Aydogan Ozcan","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Optics (physics.optics)","We demonstrate that a deep neural network can significantly improve optical microscopy, enhancing its spatial resolution over a large field-of-view and depth-of-field. After its training, the only input to this network is an image acquired using a regular optical microscope, without any changes to its design. We blindly tested this deep learning approach using various tissue samples that are imaged with low-resolution and wide-field systems, where the network rapidly outputs an image with remarkably better resolution, matching the performance of higher numerical aperture lenses, also significantly surpassing their limited field-of-view and depth-of-field. These results are transformative for various fields that use microscopy tools, including e.g., life sciences, where optical microscopy is considered as one of the most widely used and deployed techniques. Beyond such applications, our presented approach is broadly applicable to other imaging modalities, also spanning different parts of the electromagnetic spectrum, and can be used to design computational imagers that get better and better as they continue to image specimen and establish new transformations among different modes of imaging.","Fri, 12 May 2017 18:22:54 UTC (3,937 KB)"
"1504","Concussion classification via deep learning using whole-brain white matter fiber strains","Yunliang Cai, Shaoju Wu, Wei Zhao, Zhigang Li, Songbai Ji","Quantitative Methods (q-bio.QM)","Developing an accurate and reliable injury predictor is central to the biomechanical studies of traumatic brain injury. State-of-the-art efforts continue to rely on empirical, scalar metrics based on kinematics or model-estimated tissue responses explicitly pre-defined in a specific brain region of interest. They could suffer from loss of information. A single training dataset has also been used to evaluate performance but without cross-validation. In this study, we developed a deep learning approach for concussion classification using implicit features of the entire voxel-wise white matter fiber strains. Using reconstructed American National Football League (NFL) injury cases, leave-one-out cross-validation was employed to objectively compare injury prediction performances against two baseline machine learning classifiers (support vector machine (SVM) and random forest (RF)) and four scalar metrics via univariate logistic regression (Brain Injury Criterion (BrIC), cumulative strain damage measure of the whole brain (CSDM-WB) and the corpus callosum (CSDM-CC), and peak fiber strain in the CC). Feature-based deep learning and machine learning classifiers consistently outperformed all scalar injury metrics across all performance categories in cross-validation (e.g., average accuracy of 0.844 vs. 0.746, and average area under the receiver operating curve (AUC) of 0.873 vs. 0.769, respectively, based on the testing dataset). Nevertheless, deep learning achieved the best cross-validation accuracy, sensitivity, and AUC (e.g., accuracy of 0.862 vs. 0.828 and 0.842 for SVM and RF, respectively). These findings demonstrate the superior performances of deep learning in concussion prediction, and suggest its promise for future applications in biomechanical investigations of traumatic brain injury.","Fri, 12 May 2017 14:40:59 UTC (1,120 KB)[v2] Mon, 15 Jan 2018 18:09:48 UTC (2,502 KB)"
"1505","Phase recovery and holographic image reconstruction using deep learning in neural networks","Yair Rivenson, Yibo Zhang, Harun Gunaydin, Da Teng, Aydogan Ozcan","Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR); Machine Learning (cs.LG); Applied Physics (physics.app-ph); Optics (physics.optics)","Phase recovery from intensity-only measurements forms the heart of coherent imaging techniques and holography. Here we demonstrate that a neural network can learn to perform phase recovery and holographic image reconstruction after appropriate training. This deep learning-based approach provides an entirely new framework to conduct holographic imaging by rapidly eliminating twin-image and self-interference related spatial artifacts. Compared to existing approaches, this neural network based method is significantly faster to compute, and reconstructs improved phase and amplitude images of the objects using only one hologram, i.e., requires less number of measurements in addition to being computationally faster. We validated this method by reconstructing phase and amplitude images of various samples, including blood and Pap smears, and tissue sections. These results are broadly applicable to any phase recovery problem, and highlight that through machine learning challenging problems in imaging science can be overcome, providing new avenues to design powerful computational imaging systems.","Wed, 10 May 2017 03:26:30 UTC (2,272 KB)"
"1506","Why & When Deep Learning Works: Looking Inside Deep Learnings","Ronny Ronen","Machine Learning (cs.LG)","The Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI) has been heavily supporting Machine Learning and Deep Learning research from its foundation in 2012. We have asked six leading ICRI-CI Deep Learning researchers to address the challenge of ""Why & When Deep Learning works"", with the goal of looking inside Deep Learning, providing insights on how deep networks function, and uncovering key observations on their expressiveness, limitations, and potential. The output of this challenge resulted in five papers that address different facets of deep learning. These different facets include a high-level understating of why and when deep networks work (and do not work), the impact of geometry on the expressiveness of deep networks, and making deep networks interpretable.","Wed, 10 May 2017 18:52:26 UTC (254 KB)"
"1507","Net2Vec: Deep Learning for the Network","Roberto Gonzalez, Filipe Manco, Alberto Garcia-Duran, Jose Mendes, Felipe Huici, Saverio Niccolini, Mathias Niepert","Networking and Internet Architecture (cs.NI); Machine Learning (cs.LG)","We present Net2Vec, a flexible high-performance platform that allows the execution of deep learning algorithms in the communication network. Net2Vec is able to capture data from the network at more than 60Gbps, transform it into meaningful tuples and apply predictions over the tuples in real time. This platform can be used for different purposes ranging from traffic classification to network performance analysis. Finally, we showcase the use of Net2Vec by implementing and testing a solution able to profile network users at line rate using traces coming from a real network. We show that the use of deep learning for this case outperforms the baseline method both in terms of accuracy and performance.","Wed, 10 May 2017 13:28:19 UTC (1,773 KB)"
"1508","A Survey of Deep Learning Methods for Relation Extraction","Shantanu Kumar","Computation and Language (cs.CL)","Relation Extraction is an important sub-task of Information Extraction which has the potential of employing deep learning (DL) models with the creation of large datasets using distant supervision. In this review, we compare the contributions and pitfalls of the various DL models that have been used for the task, to help guide the path ahead.","Wed, 10 May 2017 08:05:44 UTC (544 KB)"
"1509","OMNIRank: Risk Quantification for P2P Platforms with Deep Learning","Honglun Zhang, Haiyang Wang, Xiaming Chen, Yongkun Wang, Yaohui Jin","Computers and Society (cs.CY); Machine Learning (cs.LG)","P2P lending presents as an innovative and flexible alternative for conventional lending institutions like banks, where lenders and borrowers directly make transactions and benefit each other without complicated verifications. However, due to lack of specialized laws, delegated monitoring and effective managements, P2P platforms may spawn potential risks, such as withdraw failures, investigation involvements and even runaway bosses, which cause great losses to lenders and are especially serious and notorious in China. Although there are abundant public information and data available on the Internet related to P2P platforms, challenges of multi-sourcing and heterogeneity matter. In this paper, we promote a novel deep learning model, OMNIRank, which comprehends multi-dimensional features of P2P platforms for risk quantification and produces scores for ranking. We first construct a large-scale flexible crawling framework and obtain great amounts of multi-source heterogeneous data of domestic P2P platforms since 2007 from the Internet. Purifications like duplication and noise removal, null handing, format unification and fusion are applied to improve data qualities. Then we extract deep features of P2P platforms via text comprehension, topic modeling, knowledge graph and sentiment analysis, which are delivered as inputs to OMNIRank, a deep learning model for risk quantification of P2P platforms. Finally, according to rankings generated by OMNIRank, we conduct flourish data visualizations and interactions, providing lenders with comprehensive information supports, decision suggestions and safety guarantees.","Thu, 27 Apr 2017 03:15:38 UTC (4,882 KB)"
"1510","DeepMetabolism: A Deep Learning System to Predict Phenotype from Genome Sequencing","Weihua Guo, You Xu, Xueyang Feng","Genomics (q-bio.GN); Quantitative Methods (q-bio.QM)","Life science is entering a new era of petabyte-level sequencing data. Converting such big data to biological insights represents a huge challenge for computational analysis. To this end, we developed DeepMetabolism, a biology-guided deep learning system to predict cell phenotypes from transcriptomics data. By integrating unsupervised pre-training with supervised training, DeepMetabolism is able to predict phenotypes with high accuracy (PCC>0.92), high speed (<30 min for >100 GB data using a single GPU), and high robustness (tolerate up to 75% noise). We envision DeepMetabolism to bridge the gap between genotype and phenotype and to serve as a springboard for applications in synthetic biology and precision medicine.","Mon, 8 May 2017 21:26:07 UTC (5,548 KB)"
"1511","Geometry of Optimization and Implicit Regularization in Deep Learning","Behnam Neyshabur, Ryota Tomioka, Ruslan Salakhutdinov, Nathan Srebro","Machine Learning (cs.LG)","We argue that the optimization plays a crucial role in generalization of deep learning models through implicit regularization. We do this by demonstrating that generalization ability is not controlled by network size but rather by some other implicit control. We then demonstrate how changing the empirical optimization procedure can improve generalization, even if actual optimization quality is not affected. We do so by studying the geometry of the parameter space of deep networks, and devising an optimization algorithm attuned to this geometry.","Mon, 8 May 2017 20:12:08 UTC (359 KB)"
"1512","Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression","Nilaksh Das, Madhuri Shanbhogue, Shang-Tse Chen, Fred Hohman, Li Chen, Michael E. Kounavis, Duen Horng Chau","Computer Vision and Pattern Recognition (cs.CV); Cryptography and Security (cs.CR)","Deep neural networks (DNNs) have achieved great success in solving a variety of machine learning (ML) problems, especially in the domain of image recognition. However, recent research showed that DNNs can be highly vulnerable to adversarially generated instances, which look seemingly normal to human observers, but completely confuse DNNs. These adversarial samples are crafted by adding small perturbations to normal, benign images. Such perturbations, while imperceptible to the human eye, are picked up by DNNs and cause them to misclassify the manipulated instances with high confidence. In this work, we explore and demonstrate how systematic JPEG compression can work as an effective pre-processing step in the classification pipeline to counter adversarial attacks and dramatically reduce their effects (e.g., Fast Gradient Sign Method, DeepFool). An important component of JPEG compression is its ability to remove high frequency signal components, inside square blocks of an image. Such an operation is equivalent to selective blurring of the image, helping remove additive perturbations. Further, we propose an ensemble-based technique that can be constructed quickly from a given well-performing DNN, and empirically show how such an ensemble that leverages JPEG compression can protect a model from multiple types of adversarial attacks, without requiring knowledge about the model.","Mon, 8 May 2017 14:55:32 UTC (1,875 KB)"
"1513","Handwritten Bangla Digit Recognition Using Deep Learning","Md Zahangir Alom, Paheding Sidike, Tarek M. Taha, Vijayan K. Asari","Computer Vision and Pattern Recognition (cs.CV)","In spite of the advances in pattern recognition technology, Handwritten Bangla Character Recognition (HBCR) (such as alpha-numeric and special characters) remains largely unsolved due to the presence of many perplexing characters and excessive cursive in Bangla handwriting. Even the best existing recognizers do not lead to satisfactory performance for practical applications. To improve the performance of Handwritten Bangla Digit Recognition (HBDR), we herein present a new approach based on deep neural networks which have recently shown excellent performance in many pattern recognition and machine learning applications, but has not been throughly attempted for HBDR. We introduce Bangla digit recognition techniques based on Deep Belief Network (DBN), Convolutional Neural Networks (CNN), CNN with dropout, CNN with dropout and Gaussian filters, and CNN with dropout and Gabor filters. These networks have the advantage of extracting and using feature information, improving the recognition of two dimensional shapes with a high degree of invariance to translation, scaling and other pattern distortions. We systematically evaluated the performance of our method on publicly available Bangla numeral image database named CMATERdb 3.1.1. From experiments, we achieved 98.78% recognition rate using the proposed method: CNN with Gabor features and dropout, which outperforms the state-of-the-art algorithms for HDBR.","Sun, 7 May 2017 18:49:27 UTC (4,530 KB)"
"1514","A Study and Comparison of Human and Deep Learning Recognition Performance Under Visual Distortions","Samuel Dodge, Lina Karam","Computer Vision and Pattern Recognition (cs.CV)","Deep neural networks (DNNs) achieve excellent performance on standard classification tasks. However, under image quality distortions such as blur and noise, classification accuracy becomes poor. In this work, we compare the performance of DNNs with human subjects on distorted images. We show that, although DNNs perform better than or on par with humans on good quality images, DNN performance is still much lower than human performance on distorted images. We additionally find that there is little correlation in errors between DNNs and human subjects. This could be an indication that the internal representation of images are different between DNNs and the human visual system. These comparisons with human performance could be used to guide future development of more robust DNNs.","Sat, 6 May 2017 16:16:11 UTC (8,159 KB)"
"1515","SLDR-DL: A Framework for SLD-Resolution with Deep Learning","Cheng-Hao Cai","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic in Computer Science (cs.LO)","This paper introduces an SLD-resolution technique based on deep learning. This technique enables neural networks to learn from old and successful resolution processes and to use learnt experiences to guide new resolution processes. An implementation of this technique is named SLDR-DL. It includes a Prolog library of deep feedforward neural networks and some essential functions of resolution. In the SLDR-DL framework, users can define logical rules in the form of definite clauses and teach neural networks to use the rules in reasoning processes.","Fri, 5 May 2017 13:32:54 UTC (659 KB)"
"1516","A Deep Learning Perspective on the Origin of Facial Expressions","Ran Breuer, Ron Kimmel","Computer Vision and Pattern Recognition (cs.CV)","Facial expressions play a significant role in human communication and behavior. Psychologists have long studied the relationship between facial expressions and emotions. Paul Ekman et al., devised the Facial Action Coding System (FACS) to taxonomize human facial expressions and model their behavior. The ability to recognize facial expressions automatically, enables novel applications in fields like human-computer interaction, social gaming, and psychological research. There has been a tremendously active research in this field, with several recent papers utilizing convolutional neural networks (CNN) for feature extraction and inference. In this paper, we employ CNN understanding methods to study the relation between the features these computational networks are using, the FACS and Action Units (AU). We verify our findings on the Extended Cohn-Kanade (CK+), NovaEmotions and FER2013 datasets. We apply these models to various tasks and tests using transfer learning, including cross-dataset validation and cross-task performance. Finally, we exploit the nature of the FER based CNN models for the detection of micro-expressions and achieve state-of-the-art accuracy using a simple long-short-term-memory (LSTM) recurrent neural network (RNN).","Thu, 4 May 2017 13:59:07 UTC (4,742 KB)[v2] Wed, 10 May 2017 13:05:00 UTC (4,742 KB)"
"1517","XES Tensorflow - Process Prediction using the Tensorflow Deep-Learning Framework","Joerg Evermann, Jana-Rebecca Rehse, Peter Fettke","Machine Learning (cs.LG)","Predicting the next activity of a running process is an important aspect of process management. Recently, artificial neural networks, so called deep-learning approaches, have been proposed to address this challenge. This demo paper describes a software application that applies the Tensorflow deep-learning framework to process prediction. The software application reads industry-standard XES files for training and presents the user with an easy-to-use graphical user interface for both training and prediction. The system provides several improvements over earlier work. This demo paper focuses on the software implementation and describes the architecture and user interface.","Wed, 3 May 2017 16:48:51 UTC (385 KB)"
"1518","Amobee at SemEval-2017 Task 4: Deep Learning System for Sentiment Detection on Twitter","Alon Rozental, Daniel Fleischer","Computation and Language (cs.CL); Machine Learning (stat.ML)","This paper describes the Amobee sentiment analysis system, adapted to compete in SemEval 2017 task 4. The system consists of two parts: a supervised training of RNN models based on a Twitter sentiment treebank, and the use of feedforward NN, Naive Bayes and logistic regression classifiers to produce predictions for the different sub-tasks. The algorithm reached the 3rd place on the 5-label classification task (sub-task C).","Wed, 3 May 2017 08:50:56 UTC (312 KB)"
"1519","Deep Learning for Tumor Classification in Imaging Mass Spectrometry","Jens Behrmann, Christian Etmann, Tobias Boskamp, Rita Casadonte, Jorg Kriegsmann, Peter Maass","Machine Learning (stat.ML); Machine Learning (cs.LG)","Motivation: Tumor classification using Imaging Mass Spectrometry (IMS) data has a high potential for future applications in pathology. Due to the complexity and size of the data, automated feature extraction and classification steps are required to fully process the data. Deep learning offers an approach to learn feature extraction and classification combined in a single model. Commonly these steps are handled separately in IMS data analysis, hence deep learning offers an alternative strategy worthwhile to explore. Results: Methodologically, we propose an adapted architecture based on deep convolutional networks to handle the characteristics of mass spectrometry data, as well as a strategy to interpret the learned model in the spectral domain based on a sensitivity analysis. The proposed methods are evaluated on two challenging tumor classification tasks and compared to a baseline approach. Competitiveness of the proposed methods are shown on both tasks by studying the performance via cross-validation. Moreover, the learned models are analyzed by the proposed sensitivity analysis revealing biologically plausible effects as well as confounding factors of the considered task. Thus, this study may serve as a starting point for further development of deep learning approaches in IMS classification tasks.","Tue, 2 May 2017 15:15:19 UTC (1,615 KB)[v2] Mon, 15 May 2017 14:34:05 UTC (1,615 KB)[v3] Fri, 20 Oct 2017 10:03:22 UTC (1,615 KB)"
"1520","Deep Learning in the Automotive Industry: Applications and Tools","Andre Luckow, Matthew Cook, Nathan Ashcraft, Edwin Weill, Emil Djerekarov, Bennie Vorster","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC)","Deep Learning refers to a set of machine learning techniques that utilize neural networks with many hidden layers for tasks, such as image classification, speech recognition, language understanding. Deep learning has been proven to be very effective in these domains and is pervasively used by many Internet services. In this paper, we describe different automotive uses cases for deep learning in particular in the domain of computer vision. We surveys the current state-of-the-art in libraries, tools and infrastructures (e.\,g.\ GPUs and clouds) for implementing, training and deploying deep neural networks. We particularly focus on convolutional neural networks and computer vision use cases, such as the visual inspection process in manufacturing plants and the analysis of social media data. To train neural networks, curated and labeled datasets are essential. In particular, both the availability and scope of such datasets is typically very limited. A main contribution of this paper is the creation of an automotive dataset, that allows us to learn and automatically recognize different vehicle properties. We describe an end-to-end deep learning application utilizing a mobile app for data collection and process support, and an Amazon-based cloud backend for storage and training. For training we evaluate the use of cloud and on-premises infrastructures (including multiple GPUs) in conjunction with different neural network architectures and frameworks. We assess both the training times as well as the accuracy of the classifier. Finally, we demonstrate the effectiveness of the trained classifier in a real world setting during manufacturing process.","Sun, 30 Apr 2017 17:17:44 UTC (96 KB)"
"1521","DeepCCI: End-to-end Deep Learning for Chemical-Chemical Interaction Prediction","Sunyoung Kwon, Sungroh Yoon","Machine Learning (cs.LG)","Chemical-chemical interaction (CCI) plays a key role in predicting candidate drugs, toxicity, therapeutic effects, and biological functions. In various types of chemical analyses, computational approaches are often required due to the amount of data that needs to be handled. The recent remarkable growth and outstanding performance of deep learning have attracted considerable research attention. However,even in state-of-the-art drug analysis methods, deep learning continues to be used only as a classifier, although deep learning is capable of not only simple classification but also automated feature extraction. In this paper, we propose the first end-to-end learning method for CCI, named DeepCCI. Hidden features are derived from a simplified molecular input line entry system (SMILES), which is a string notation representing the chemical structure, instead of learning from crafted features. To discover hidden representations for the SMILES strings, we use convolutional neural networks (CNNs). To guarantee the commutative property for homogeneous interaction, we apply model sharing and hidden representation merging techniques. The performance of DeepCCI was compared with a plain deep classifier and conventional machine learning methods. The proposed DeepCCI showed the best performance in all seven evaluation metrics used. In addition, the commutative property was experimentally validated. The automatically extracted features through end-to-end SMILES learning alleviates the significant efforts required for manual feature engineering. It is expected to improve prediction performance, in drug analyses.","Thu, 27 Apr 2017 05:03:08 UTC (1,106 KB)[v2] Tue, 27 Jun 2017 04:28:17 UTC (1,275 KB)[v3] Thu, 14 Dec 2017 08:19:08 UTC (1,446 KB)"
"1522","Spectral Ergodicity in Deep Learning Architectures via Surrogate Random Matrices","Mehmet Suzen, Cornelius Weber, Joan J. Cerda","Machine Learning (stat.ML); Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG)","In this work a novel method to quantify spectral ergodicity for random matrices is presented. The new methodology combines approaches rooted in the metrics of Thirumalai-Mountain (TM) and Kullbach-Leibler (KL) divergence. The method is applied to a general study of deep and recurrent neural networks via the analysis of random matrix ensembles mimicking typical weight matrices of those systems. In particular, we examine circular random matrix ensembles: circular unitary ensemble (CUE), circular orthogonal ensemble (COE), and circular symplectic ensemble (CSE). Eigenvalue spectra and spectral ergodicity are computed for those ensembles as a function of network size. It is observed that as the matrix size increases the level of spectral ergodicity of the ensemble rises, i.e., the eigenvalue spectra obtained for a single realisation at random from the ensemble is closer to the spectra obtained averaging over the whole ensemble. Based on previous results we conjecture that success of deep learning architectures is strongly bound to the concept of spectral ergodicity. The method to compute spectral ergodicity proposed in this work could be used to optimise the size and architecture of deep as well as recurrent neural networks.","Tue, 25 Apr 2017 17:26:08 UTC (45 KB)[v2] Thu, 18 May 2017 21:47:38 UTC (46 KB)[v3] Tue, 11 Jul 2017 09:57:03 UTC (70 KB)"
"1523","A Review on Deep Learning Techniques Applied to Semantic Segmentation","Alberto Garcia-Garcia, Sergio Orts-Escolano, Sergiu Oprea, Victor Villena-Martinez, Jose Garcia-Rodriguez","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)","Image semantic segmentation is more and more being of interest for computer vision and machine learning researchers. Many applications on the rise need accurate and efficient segmentation mechanisms: autonomous driving, indoor navigation, and even virtual or augmented reality systems to name a few. This demand coincides with the rise of deep learning approaches in almost every field or application target related to computer vision, including semantic segmentation or scene understanding. This paper provides a review on deep learning methods for semantic segmentation applied to various application areas. Firstly, we describe the terminology of this field as well as mandatory background concepts. Next, the main datasets and challenges are exposed to help researchers decide which are the ones that best suit their needs and their targets. Then, existing methods are reviewed, highlighting their contributions and their significance in the field. Finally, quantitative results are given for the described methods and the datasets in which they were evaluated, following up with a discussion of the results. At last, we point out a set of promising future works and draw our own conclusions about the state of the art of semantic segmentation using deep learning techniques.","Sat, 22 Apr 2017 23:37:43 UTC (8,639 KB)"
"1524","Deep Learning for Medical Image Processing: Overview, Challenges and Future","Muhammad Imran Razzak, Saeeda Naz, Ahmad Zaib","Computer Vision and Pattern Recognition (cs.CV)","Healthcare sector is totally different from other industry. It is on high priority sector and people expect highest level of care and services regardless of cost. It did not achieve social expectation even though it consume huge percentage of budget. Mostly the interpretations of medical data is being done by medical expert. In terms of image interpretation by human expert, it is quite limited due to its subjectivity, the complexity of the image, extensive variations exist across different interpreters, and fatigue. After the success of deep learning in other real world application, it is also providing exciting solutions with good accuracy for medical imaging and is seen as a key method for future applications in health secotr. In this chapter, we discussed state of the art deep learning architecture and its optimization used for medical image segmentation and classification. In the last section, we have discussed the challenges deep learning based methods for medical imaging and open research issue.","Sat, 22 Apr 2017 17:49:04 UTC (1,007 KB)"
"1525","Deep Learning based Isolated Arabic Scene Character Recognition","Saad Bin Ahmed, Saeeda Naz, Muhammad Imran Razzak, Rubiyah Yousaf","Computer Vision and Pattern Recognition (cs.CV)","The technological advancement and sophistication in cameras and gadgets prompt researchers to have focus on image analysis and text understanding. The deep learning techniques demonstrated well to assess the potential for classifying text from natural scene images as reported in recent years. There are variety of deep learning approaches that prospects the detection and recognition of text, effectively from images. In this work, we presented Arabic scene text recognition using Convolutional Neural Networks (ConvNets) as a deep learning classifier. As the scene text data is slanted and skewed, thus to deal with maximum variations, we employ five orientations with respect to single occurrence of a character. The training is formulated by keeping filter size 3 x 3 and 5 x 5 with stride value as 1 and 2. During text classification phase, we trained network with distinct learning rates. Our approach reported encouraging results on recognition of Arabic characters from segmented Arabic scene images.","Sat, 22 Apr 2017 17:09:02 UTC (3,244 KB)"
"1526","Using Mise-En-Scene Visual Features based on MPEG-7 and Deep Learning for Movie Recommendation","Yashar Deldjoo, Massimo Quadrana, Mehdi Elahi, Paolo Cremonesi","Information Retrieval (cs.IR); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)","Item features play an important role in movie recommender systems, where recommendations can be generated by using explicit or implicit preferences of users on traditional features (attributes) such as tag, genre, and cast. Typically, movie features are human-generated, either editorially (e.g., genre and cast) or by leveraging the wisdom of the crowd (e.g., tag), and as such, they are prone to noise and are expensive to collect. Moreover, these features are often rare or absent for new items, making it difficult or even impossible to provide good quality recommendations. In this paper, we show that user's preferences on movies can be better described in terms of the mise-en-scene features, i.e., the visual aspects of a movie that characterize design, aesthetics and style (e.g., colors, textures). We use both MPEG-7 visual descriptors and Deep Learning hidden layers as example of mise-en-scene features that can visually describe movies. Interestingly, mise-en-scene features can be computed automatically from video files or even from trailers, offering more flexibility in handling new items, avoiding the need for costly and error-prone human-based tagging, and providing good scalability. We have conducted a set of experiments on a large catalogue of 4K movies. Results show that recommendations based on mise-en-scene features consistently provide the best performance with respect to richer sets of more traditional features, such as genre and tag.","Thu, 20 Apr 2017 12:33:48 UTC (1,248 KB)"
"1527","Predicting Cognitive Decline with Deep Learning of Brain Metabolism and Amyloid Imaging","Hongyoon Choi, Kyong Hwan Jin","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)","For effective treatment of Alzheimer disease (AD), it is important to identify subjects who are most likely to exhibit rapid cognitive decline. Herein, we developed a novel framework based on a deep convolutional neural network which can predict future cognitive decline in mild cognitive impairment (MCI) patients using flurodeoxyglucose and florbetapir positron emission tomography (PET). The architecture of the network only relies on baseline PET studies of AD and normal subjects as the training dataset. Feature extraction and complicated image preprocessing including nonlinear warping are unnecessary for our approach. Accuracy of prediction (84.2%) for conversion to AD in MCI patients outperformed conventional feature-based quantification approaches. ROC analyses revealed that performance of CNN-based approach was significantly higher than that of the conventional quantification methods (p < 0.05). Output scores of the network were strongly correlated with the longitudinal change in cognitive measurements. These results show the feasibility of deep learning as a tool for predicting disease outcome using brain images.","Thu, 20 Apr 2017 07:33:18 UTC (1,198 KB)"
"1528","A Deep Learning Framework using Passive WiFi Sensing for Respiration Monitoring","U. M. Khan, Z. Kabir, S. A. Hassan, S. H. Ahmed","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","This paper presents an end-to-end deep learning framework using passive WiFi sensing to classify and estimate human respiration activity. A passive radar test-bed is used with two channels where the first channel provides the reference WiFi signal, whereas the other channel provides a surveillance signal that contains reflections from the human target. Adaptive filtering is performed to make the surveillance signal source-data invariant by eliminating the echoes of the direct transmitted signal. We propose a novel convolutional neural network to classify the complex time series data and determine if it corresponds to a breathing activity, followed by a random forest estimator to determine breathing rate. We collect an extensive dataset to train the learning models and develop reference benchmarks for the future studies in the field. Based on the results, we conclude that deep learning techniques coupled with passive radars offer great potential for end-to-end human activity recognition.","Wed, 19 Apr 2017 12:35:17 UTC (1,433 KB)"
"1529","A Study of Deep Learning Robustness Against Computation Failures","Jean-Charles Vialatte, Francois Leduc-Primeau","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG)","For many types of integrated circuits, accepting larger failure rates in computations can be used to improve energy efficiency. We study the performance of faulty implementations of certain deep neural networks based on pessimistic and optimistic models of the effect of hardware faults. After identifying the impact of hyperparameters such as the number of layers on robustness, we study the ability of the network to compensate for computational failures through an increase of the network size. We show that some networks can achieve equivalent performance under faulty implementations, and quantify the required increase in computational complexity.","Tue, 18 Apr 2017 15:33:10 UTC (439 KB)"
"1530","Deep Learning Based Regression and Multi-class Models for Acute Oral Toxicity Prediction with Automatic Chemical Feature Extraction","Youjun Xu, Jianfeng Pei, Luhua Lai","Machine Learning (stat.ML); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)","For quantitative structure-property relationship (QSPR) studies in chemoinformatics, it is important to get interpretable relationship between chemical properties and chemical features. However, the predictive power and interpretability of QSPR models are usually two different objectives that are difficult to achieve simultaneously. A deep learning architecture using molecular graph encoding convolutional neural networks (MGE-CNN) provided a universal strategy to construct interpretable QSPR models with high predictive power. Instead of using application-specific preset molecular descriptors or fingerprints, the models can be resolved using raw and pertinent features without manual intervention or selection. In this study, we developed acute oral toxicity (AOT) models of compounds using the MGE-CNN architecture as a case study. Three types of high-level predictive models: regression model (deepAOT-R), multi-classification model (deepAOT-C) and multi-task model (deepAOT-CR) for AOT evaluation were constructed. These models highly outperformed previously reported models. For the two external datasets containing 1673 (test set I) and 375 (test set II) compounds, the R2 and mean absolute error (MAE) of deepAOT-R on the test set I were 0.864 and 0.195, and the prediction accuracy of deepAOT-C was 95.5% and 96.3% on the test set I and II, respectively. The two external prediction accuracy of deepAOT-CR is 95.0% and 94.1%, while the R2 and MAE are 0.861 and 0.204 for test set I, respectively.","Sun, 16 Apr 2017 04:17:32 UTC (1,977 KB)[v2] Wed, 26 Apr 2017 02:10:10 UTC (1,976 KB)[v3] Thu, 4 May 2017 09:52:38 UTC (1,978 KB)"
"1531","Deep Learning for Photoacoustic Tomography from Sparse Data","Stephan Antholzer, Markus Haltmeier, Johannes Schwab","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","The development of fast and accurate image reconstruction algorithms is a central aspect of computed tomography. In this paper, we investigate this issue for the sparse data problem in photoacoustic tomography (PAT). We develop a direct and highly efficient reconstruction algorithm based on deep learning. In our approach image reconstruction is performed with a deep convolutional neural network (CNN), whose weights are adjusted prior to the actual image reconstruction based on a set of training data. The proposed reconstruction approach can be interpreted as a network that uses the PAT filtered backprojection algorithm for the first layer, followed by the U-net architecture for the remaining layers. Actual image reconstruction with deep learning consists in one evaluation of the trained CNN, which does not require time consuming solution of the forward and adjoint problems. At the same time, our numerical results demonstrate that the proposed deep learning approach reconstructs images with a quality comparable to state of the art iterative approaches for PAT from sparse data.","Sat, 15 Apr 2017 05:33:32 UTC (508 KB)[v2] Fri, 18 Aug 2017 06:22:48 UTC (557 KB)[v3] Thu, 30 Aug 2018 13:45:40 UTC (584 KB)"
"1532","3D Deep Learning for Biological Function Prediction from Physical Fields","Vladimir Golkov, Marcin J. Skwark, Atanas Mirchev, Georgi Dikov, Alexander R. Geanes, Jeffrey Mendenhall, Jens Meiler, Daniel Cremers","Biomolecules (q-bio.BM); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)","Predicting the biological function of molecules, be it proteins or drug-like compounds, from their atomic structure is an important and long-standing problem. Function is dictated by structure, since it is by spatial interactions that molecules interact with each other, both in terms of steric complementarity, as well as intermolecular forces. Thus, the electron density field and electrostatic potential field of a molecule contain the ""raw fingerprint"" of how this molecule can fit to binding partners. In this paper, we show that deep learning can predict biological function of molecules directly from their raw 3D approximated electron density and electrostatic potential fields. Protein function based on EC numbers is predicted from the approximated electron density field. In another experiment, the activity of small molecules is predicted with quality comparable to state-of-the-art descriptor-based methods. We propose several alternative computational models for the GPU with different memory and runtime requirements for different sizes of molecules and of databases. We also propose application-specific multi-channel data representations. With future improvements of training datasets and neural network settings in combination with complementary information sources (sequence, genomic context, expression level), deep learning can be expected to show its generalization power and revolutionize the field of molecular function prediction.","Thu, 13 Apr 2017 09:11:23 UTC (695 KB)"
"1533","Shape-independent Hardness Estimation Using Deep Learning and a GelSight Tactile Sensor","Wenzhen Yuan, Chenzhuo Zhu, Andrew Owens, Mandayam A. Srinivasan, Edward H. Adelson","Robotics (cs.RO)","Hardness is among the most important attributes of an object that humans learn about through touch. However, approaches for robots to estimate hardness are limited, due to the lack of information provided by current tactile sensors. In this work, we address these limitations by introducing a novel method for hardness estimation, based on the GelSight tactile sensor, and the method does not require accurate control of contact conditions or the shape of objects. A GelSight has a soft contact interface, and provides high resolution tactile images of contact geometry, as well as contact force and slip conditions. In this paper, we try to use the sensor to measure hardness of objects with multiple shapes, under a loosely controlled contact condition. The contact is made manually or by a robot hand, while the force and trajectory are unknown and uneven. We analyze the data using a deep constitutional (and recurrent) neural network. Experiments show that the neural net model can estimate the hardness of objects with different shapes and hardness ranging from 8 to 87 in Shore 00 scale.","Thu, 13 Apr 2017 00:12:48 UTC (7,074 KB)"
"1534","Feature Tracking Cardiac Magnetic Resonance via Deep Learning and Spline Optimization","Davis M. Vigneault, Weidi Xie, David A. Bluemke, J. Alison Noble","Computer Vision and Pattern Recognition (cs.CV)","Feature tracking Cardiac Magnetic Resonance (CMR) has recently emerged as an area of interest for quantification of regional cardiac function from balanced, steady state free precession (SSFP) cine sequences. However, currently available techniques lack full automation, limiting reproducibility. We propose a fully automated technique whereby a CMR image sequence is first segmented with a deep, fully convolutional neural network (CNN) architecture, and quadratic basis splines are fitted simultaneously across all cardiac frames using least squares optimization. Experiments are performed using data from 42 patients with hypertrophic cardiomyopathy (HCM) and 21 healthy control subjects. In terms of segmentation, we compared state-of-the-art CNN frameworks, U-Net and dilated convolution architectures, with and without temporal context, using cross validation with three folds. Performance relative to expert manual segmentation was similar across all networks: pixel accuracy was ~97%, intersection-over-union (IoU) across all classes was ~87%, and IoU across foreground classes only was ~85%. Endocardial left ventricular circumferential strain calculated from the proposed pipeline was significantly different in control and disease subjects (-25.3% vs -29.1%, p = 0.006), in agreement with the current clinical literature.","Wed, 12 Apr 2017 08:43:35 UTC (6,707 KB)"
"1535","Deep Learning for Multi-Task Medical Image Segmentation in Multiple Modalities","Pim Moeskops, Jelmer M. Wolterink, Bas H.M. van der Velden, Kenneth G.A. Gilhuijs, Tim Leiner, Max A. Viergever, Ivana I<U+0161>gum","Computer Vision and Pattern Recognition (cs.CV)","Automatic segmentation of medical images is an important task for many clinical applications. In practice, a wide range of anatomical structures are visualised using different imaging modalities. In this paper, we investigate whether a single convolutional neural network (CNN) can be trained to perform different segmentation tasks. A single CNN is trained to segment six tissues in MR brain images, the pectoral muscle in MR breast images, and the coronary arteries in cardiac CTA. The CNN therefore learns to identify the imaging modality, the visualised anatomical structures, and the tissue classes. For each of the three tasks (brain MRI, breast MRI and cardiac CTA), this combined training procedure resulted in a segmentation performance equivalent to that of a CNN trained specifically for that task, demonstrating the high capacity of CNN architectures. Hence, a single system could be used in clinical practice to automatically perform diverse segmentation tasks without task-specific training.","Tue, 11 Apr 2017 15:52:34 UTC (2,499 KB)"
"1536","On Feature Reduction using Deep Learning for Trend Prediction in Finance","Luigi Troiano, Elena Mejuto, Pravesh Kriplani","Trading and Market Microstructure (q-fin.TR); Machine Learning (cs.LG)","One of the major advantages in using Deep Learning for Finance is to embed a large collection of information into investment decisions. A way to do that is by means of compression, that lead us to consider a smaller feature space. Several studies are proving that non-linear feature reduction performed by Deep Learning tools is effective in price trend prediction. The focus has been put mainly on Restricted Boltzmann Machines (RBM) and on output obtained by them. Few attention has been payed to Auto-Encoders (AE) as an alternative means to perform a feature reduction. In this paper we investigate the application of both RBM and AE in more general terms, attempting to outline how architectural and input space characteristics can affect the quality of prediction.","Tue, 11 Apr 2017 09:08:50 UTC (252 KB)"
"1537","Pyramid Vector Quantization for Deep Learning","Vincenzo Liguori","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","This paper explores the use of Pyramid Vector Quantization (PVQ) to reduce the computational cost for a variety of neural networks (NNs) while, at the same time, compressing the weights that describe them. This is based on the fact that the dot product between an N dimensional vector of real numbers and an N dimensional PVQ vector can be calculated with only additions and subtractions and one multiplication. This is advantageous since tensor products, commonly used in NNs, can be re-conduced to a dot product or a set of dot products. Finally, it is stressed that any NN architecture that is based on an operation that can be re-conduced to a dot product can benefit from the techniques described here.","Mon, 10 Apr 2017 01:17:43 UTC (238 KB)"
"1538","Automatic Image Filtering on Social Networks Using Deep Learning and Perceptual Hashing During Crises","Dat Tien Nguyen, Firoj Alam, Ferda Ofli, Muhammad Imran","Computers and Society (cs.CY); Computer Vision and Pattern Recognition (cs.CV); Social and Information Networks (cs.SI)","The extensive use of social media platforms, especially during disasters, creates unique opportunities for humanitarian organizations to gain situational awareness and launch relief operations accordingly. In addition to the textual content, people post overwhelming amounts of imagery data on social networks within minutes of a disaster hit. Studies point to the importance of this online imagery content for emergency response. Despite recent advances in the computer vision field, automatic processing of the crisis-related social media imagery data remains a challenging task. It is because a majority of which consists of redundant and irrelevant content. In this paper, we present an image processing pipeline that comprises de-duplication and relevancy filtering mechanisms to collect and filter social media image content in real-time during a crisis event. Results obtained from extensive experiments on real-world crisis datasets demonstrate the significance of the proposed pipeline for optimal utilization of both human and machine computing resources.","Sun, 9 Apr 2017 13:34:27 UTC (4,736 KB)"
"1539","Coupled Deep Learning for Heterogeneous Face Recognition","Xiang Wu, Lingxiao Song, Ran He, Tieniu Tan","Computer Vision and Pattern Recognition (cs.CV)","Heterogeneous face matching is a challenge issue in face recognition due to large domain difference as well as insufficient pairwise images in different modalities during training. This paper proposes a coupled deep learning (CDL) approach for the heterogeneous face matching. CDL seeks a shared feature space in which the heterogeneous face matching problem can be approximately treated as a homogeneous face matching problem. The objective function of CDL mainly includes two parts. The first part contains a trace norm and a block-diagonal prior as relevance constraints, which not only make unpaired images from multiple modalities be clustered and correlated, but also regularize the parameters to alleviate overfitting. An approximate variational formulation is introduced to deal with the difficulties of optimizing low-rank constraint directly. The second part contains a cross modal ranking among triplet domain specific images to maximize the margin for different identities and increase data for a small amount of training samples. Besides, an alternating minimization method is employed to iteratively update the parameters of CDL. Experimental results show that CDL achieves better performance on the challenging CASIA NIR-VIS 2.0 face recognition database, the IIIT-D Sketch database, the CUHK Face Sketch (CUFS), and the CUHK Face Sketch FERET (CUFSF), which significantly outperforms state-of-the-art heterogeneous face recognition methods.","Sat, 8 Apr 2017 07:10:45 UTC (329 KB)[v2] Thu, 16 Nov 2017 08:48:23 UTC (224 KB)"
"1540","Best Practices for Applying Deep Learning to Novel Applications","Leslie N. Smith","Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)","This report is targeted to groups who are subject matter experts in their application but deep learning novices. It contains practical advice for those interested in testing the use of deep neural networks on applications that are novel for deep learning. We suggest making your project more manageable by dividing it into phases. For each phase this report contains numerous recommendations and insights to assist novice practitioners.","Wed, 5 Apr 2017 17:59:07 UTC (419 KB)"
"1541","Deep Learning and Quantum Entanglement: Fundamental Connections with Implications to Network Design","Yoav Levine, David Yakira, Nadav Cohen, Amnon Shashua","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Quantum Physics (quant-ph)","Deep convolutional networks have witnessed unprecedented success in various machine learning applications. Formal understanding on what makes these networks so successful is gradually unfolding, but for the most part there are still significant mysteries to unravel. The inductive bias, which reflects prior knowledge embedded in the network architecture, is one of them. In this work, we establish a fundamental connection between the fields of quantum physics and deep learning. We use this connection for asserting novel theoretical observations regarding the role that the number of channels in each layer of the convolutional network fulfills in the overall inductive bias. Specifically, we show an equivalence between the function realized by a deep convolutional arithmetic circuit (ConvAC) and a quantum many-body wave function, which relies on their common underlying tensorial structure. This facilitates the use of quantum entanglement measures as well-defined quantifiers of a deep network's expressive ability to model intricate correlation structures of its inputs. Most importantly, the construction of a deep ConvAC in terms of a Tensor Network is made available. This description enables us to carry a graph-theoretic analysis of a convolutional network, with which we demonstrate a direct control over the inductive bias of the deep network via its channel numbers, that are related to the min-cut in the underlying graph. This result is relevant to any practitioner designing a network for a specific task. We theoretically analyze ConvACs, and empirically validate our findings on more common ConvNets which involve ReLU activations and max pooling. Beyond the results described above, the description of a deep convolutional network in well-defined graph-theoretic tools and the formal connection to quantum entanglement, are two interdisciplinary bridges that are brought forth by this work.","Wed, 5 Apr 2017 17:53:13 UTC (2,477 KB)[v2] Mon, 10 Apr 2017 14:29:34 UTC (2,479 KB)"
"1542","On Generalization and Regularization in Deep Learning","Pirmin Lemberger","Machine Learning (stat.ML); Machine Learning (cs.LG); Statistics Theory (math.ST)","Why do large neural network generalize so well on complex tasks such as image classification or speech recognition? What exactly is the role regularization for them? These are arguably among the most important open questions in machine learning today. In a recent and thought provoking paper [C. Zhang et al.] several authors performed a number of numerical experiments that hint at the need for novel theoretical concepts to account for this phenomenon. The paper stirred quit a lot of excitement among the machine learning community but at the same time it created some confusion as discussions on OpenReview.net testifies. The aim of this pedagogical paper is to make this debate accessible to a wider audience of data scientists without advanced theoretical knowledge in statistical learning. The focus here is on explicit mathematical definitions and on a discussion of relevant concepts, not on proofs for which we provide references.","Wed, 5 Apr 2017 08:48:01 UTC (111 KB)[v2] Thu, 6 Apr 2017 19:58:27 UTC (111 KB)"
"1543","Geometric Loss Functions for Camera Pose Regression with Deep Learning","Alex Kendall, Roberto Cipolla","Computer Vision and Pattern Recognition (cs.CV)","Deep learning has shown to be effective for robust and real-time monocular image relocalisation. In particular, PoseNet is a deep convolutional neural network which learns to regress the 6-DOF camera pose from a single image. It learns to localize using high level features and is robust to difficult lighting, motion blur and unknown camera intrinsics, where point based SIFT registration fails. However, it was trained using a naive loss function, with hyper-parameters which require expensive tuning. In this paper, we give the problem a more fundamental theoretical treatment. We explore a number of novel loss functions for learning camera pose which are based on geometry and scene reprojection error. Additionally we show how to automatically learn an optimal weighting to simultaneously regress position and orientation. By leveraging geometry, we demonstrate that our technique significantly improves PoseNet's performance across datasets ranging from indoor rooms to a small city.","Sun, 2 Apr 2017 23:58:22 UTC (7,928 KB)[v2] Tue, 23 May 2017 13:45:48 UTC (7,928 KB)"
"1544","Quicksilver: Fast Predictive Image Registration - a Deep Learning Approach","Xiao Yang, Roland Kwitt, Martin Styner, Marc Niethammer","Computer Vision and Pattern Recognition (cs.CV)","This paper introduces Quicksilver, a fast deformable image registration method. Quicksilver registration for image-pairs works by patch-wise prediction of a deformation model based directly on image appearance. A deep encoder-decoder network is used as the prediction model. While the prediction strategy is general, we focus on predictions for the Large Deformation Diffeomorphic Metric Mapping (LDDMM) model. Specifically, we predict the momentum-parameterization of LDDMM, which facilitates a patch-wise prediction strategy while maintaining the theoretical properties of LDDMM, such as guaranteed diffeomorphic mappings for sufficiently strong regularization. We also provide a probabilistic version of our prediction network which can be sampled during the testing time to calculate uncertainties in the predicted deformations. Finally, we introduce a new correction network which greatly increases the prediction accuracy of an already existing prediction network. We show experimental results for uni-modal atlas-to-image as well as uni- / multi- modal image-to-image registrations. These experiments demonstrate that our method accurately predicts registrations obtained by numerical optimization, is very fast, achieves state-of-the-art registration results on four standard validation datasets, and can jointly learn an image similarity measure. Quicksilver is freely available as an open-source software.","Fri, 31 Mar 2017 14:13:55 UTC (6,513 KB)[v2] Tue, 23 May 2017 20:38:02 UTC (4,632 KB)[v3] Tue, 11 Jul 2017 14:11:02 UTC (4,633 KB)[v4] Wed, 19 Jul 2017 18:40:48 UTC (4,633 KB)"
"1545","A deep learning classification scheme based on augmented-enhanced features to segment organs at risk on the optic region in brain cancer patients","Jose Dolz, Nicolas Reyns, Nacim Betrouni, Dris Kharroubi, Mathilde Quidet, Laurent Massoptier, Maximilien Vermandel","Computer Vision and Pattern Recognition (cs.CV)","Radiation therapy has emerged as one of the preferred techniques to treat brain cancer patients. During treatment, a very high dose of radiation is delivered to a very narrow area. Prescribed radiation therapy for brain cancer requires precisely defining the target treatment area, as well as delineating vital brain structures which must be spared from radiotoxicity. Nevertheless, delineation task is usually still manually performed, which is inefficient and operator-dependent. Several attempts of automatizing this process have reported. however, marginal results when analyzing organs in the optic region. In this work we present a deep learning classification scheme based on augmented-enhanced features to automatically segment organs at risk (OARs) in the optic region -optic nerves, optic chiasm, pituitary gland and pituitary stalk-. Fifteen MR images with various types of brain tumors were retrospectively collected to undergo manual and automatic segmentation. Mean Dice Similarity coefficients around 0.80 were reported. Incorporation of proposed features yielded to improvements on the segmentation. Compared with support vector machines, our method achieved better performance with less variation on the results, as well as a considerably reduction on the classification time. Performance of the proposed approach was also evaluated with respect to manual contours. In this case, results obtained from the automatic contours mostly lie on the variability of the observers, showing no significant differences with respect to them. These results suggest therefore that the proposed system is more accurate than other presented approaches, up to date, to segment these structures. The speed, reproducibility, and robustness of the process make the proposed deep learning-based classification system a valuable tool for assisting in the delineation task of small OARs in brain cancer.","Thu, 30 Mar 2017 14:09:53 UTC (381 KB)[v2] Wed, 5 Apr 2017 12:34:07 UTC (381 KB)"
"1546","Theory II: Landscape of the Empirical Risk in Deep Learning","Qianli Liao, Tomaso Poggio","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)","Previous theoretical work on deep learning and neural network optimization tend to focus on avoiding saddle points and local minima. However, the practical observation is that, at least in the case of the most successful Deep Convolutional Neural Networks (DCNNs), practitioners can always increase the network size to fit the training data (an extreme example would be [1]). The most successful DCNNs such as VGG and ResNets are best used with a degree of ""overparametrization"". In this work, we characterize with a mix of theory and experiments, the landscape of the empirical risk of overparametrized DCNNs. We first prove in the regression framework the existence of a large number of degenerate global minimizers with zero empirical error (modulo inconsistent equations). The argument that relies on the use of Bezout theorem is rigorous when the RELUs are replaced by a polynomial nonlinearity (which empirically works as well). As described in our Theory III [2] paper, the same minimizers are degenerate and thus very likely to be found by SGD that will furthermore select with higher probability the most robust zero-minimizer. We further experimentally explored and visualized the landscape of empirical risk of a DCNN on CIFAR-10 during the entire training process and especially the global minima. Finally, based on our theoretical and experimental results, we propose an intuitive model of the landscape of DCNN's empirical loss surface, which might not be as complicated as people commonly believe.","Tue, 28 Mar 2017 22:47:04 UTC (4,386 KB)[v2] Thu, 22 Jun 2017 09:33:35 UTC (5,314 KB)"
"1547","Feature Analysis and Selection for Training an End-to-End Autonomous Vehicle Controller Using the Deep Learning Approach","Shun Yang, Wenshuo Wang, Chang Liu, Kevin Deng, J. Karl Hedrick","Computer Vision and Pattern Recognition (cs.CV); Systems and Control (cs.SY)","Deep learning-based approaches have been widely used for training controllers for autonomous vehicles due to their powerful ability to approximate nonlinear functions or policies. However, the training process usually requires large labeled data sets and takes a lot of time. In this paper, we analyze the influences of features on the performance of controllers trained using the convolutional neural networks (CNNs), which gives a guideline of feature selection to reduce computation cost. We collect a large set of data using The Open Racing Car Simulator (TORCS) and classify the image features into three categories (sky-related, roadside-related, and road-related features).We then design two experimental frameworks to investigate the importance of each single feature for training a CNN controller.The first framework uses the training data with all three features included to train a controller, which is then tested with data that has one feature removed to evaluate the feature's effects. The second framework is trained with the data that has one feature excluded, while all three features are included in the test data. Different driving scenarios are selected to test and analyze the trained controllers using the two experimental frameworks. The experiment results show that (1) the road-related features are indispensable for training the controller, (2) the roadside-related features are useful to improve the generalizability of the controller to scenarios with complicated roadside information, and (3) the sky-related features have limited contribution to train an end-to-end autonomous vehicle controller.","Tue, 28 Mar 2017 18:52:38 UTC (5,058 KB)"
"1548","Dex-Net 2.0: Deep Learning to Plan Robust Grasps with Synthetic Point Clouds and Analytic Grasp Metrics","Jeffrey Mahler, Jacky Liang, Sherdil Niyaz, Michael Laskey, Richard Doan, Xinyu Liu, Juan Aparicio Ojea, Ken Goldberg","Robotics (cs.RO)","To reduce data collection time for deep learning of robust robotic grasp plans, we explore training from a synthetic dataset of 6.7 million point clouds, grasps, and analytic grasp metrics generated from thousands of 3D models from Dex-Net 1.0 in randomized poses on a table. We use the resulting dataset, Dex-Net 2.0, to train a Grasp Quality Convolutional Neural Network (GQ-CNN) model that rapidly predicts the probability of success of grasps from depth images, where grasps are specified as the planar position, angle, and depth of a gripper relative to an RGB-D sensor. Experiments with over 1,000 trials on an ABB YuMi comparing grasp planning methods on singulated objects suggest that a GQ-CNN trained with only synthetic data from Dex-Net 2.0 can be used to plan grasps in 0.8sec with a success rate of 93% on eight known objects with adversarial geometry and is 3x faster than registering point clouds to a precomputed dataset of objects and indexing grasps. The Dex-Net 2.0 grasp planner also has the highest success rate on a dataset of 10 novel rigid objects and achieves 99% precision (one false positive out of 69 grasps classified as robust) on a dataset of 40 novel household objects, some of which are articulated or deformable. Code, datasets, videos, and supplementary material are available at this http URL .","Mon, 27 Mar 2017 21:16:30 UTC (6,409 KB)[v2] Tue, 27 Jun 2017 08:25:55 UTC (8,593 KB)[v3] Tue, 8 Aug 2017 21:46:24 UTC (8,593 KB)"
"1549","Multimodal deep learning approach for joint EEG-EMG data compression and classification","Ahmed Ben Said, Amr Mohamed, Tarek Elfouly, Khaled Harras, Z. Jane Wang","Machine Learning (cs.LG)","In this paper, we present a joint compression and classification approach of EEG and EMG signals using a deep learning approach. Specifically, we build our system based on the deep autoencoder architecture which is designed not only to extract discriminant features in the multimodal data representation but also to reconstruct the data from the latent representation using encoder-decoder layers. Since autoencoder can be seen as a compression approach, we extend it to handle multimodal data at the encoder layer, reconstructed and retrieved at the decoder layer. We show through experimental results, that exploiting both multimodal data intercorellation and intracorellation 1) Significantly reduces signal distortion particularly for high compression levels 2) Achieves better accuracy in classifying EEG and EMG signals recorded and labeled according to the sentiments of the volunteer.","Mon, 27 Mar 2017 08:37:35 UTC (586 KB)"
"1550","Multi-View Deep Learning for Consistent Semantic Mapping with RGB-D Cameras","Lingni Ma, Jorg Stuckler, Christian Kerl, Daniel Cremers","Computer Vision and Pattern Recognition (cs.CV)","Visual scene understanding is an important capability that enables robots to purposefully act in their environment. In this paper, we propose a novel approach to object-class segmentation from multiple RGB-D views using deep learning. We train a deep neural network to predict object-class semantics that is consistent from several view points in a semi-supervised way. At test time, the semantics predictions of our network can be fused more consistently in semantic keyframe maps than predictions of a network trained on individual views. We base our network architecture on a recent single-view deep learning approach to RGB and depth fusion for semantic object-class segmentation and enhance it with multi-scale loss minimization. We obtain the camera trajectory using RGB-D SLAM and warp the predictions of RGB-D images into ground-truth annotated frames in order to enforce multi-view consistency during training. At test time, predictions from multiple views are fused into keyframes. We propose and analyze several methods for enforcing multi-view consistency during training and testing. We evaluate the benefit of multi-view consistency training and demonstrate that pooling of deep features and fusion over multiple views outperforms single-view baselines on the NYUDv2 benchmark for semantic segmentation. Our end-to-end trained network achieves state-of-the-art performance on the NYUDv2 dataset in single-view segmentation as well as multi-view semantic fusion.","Sun, 26 Mar 2017 20:28:02 UTC (4,027 KB)[v2] Mon, 4 Dec 2017 19:01:11 UTC (4,393 KB)"
"1551","Comparing Rule-Based and Deep Learning Models for Patient Phenotyping","Sebastian Gehrmann, Franck Dernoncourt, Yeran Li, Eric T. Carlson, Joy T. Wu, Jonathan Welt, John Foote Jr., Edward T. Moseley, David W. Grant, Patrick D. Tyler, Leo Anthony Celi","Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","Objective: We investigate whether deep learning techniques for natural language processing (NLP) can be used efficiently for patient phenotyping. Patient phenotyping is a classification task for determining whether a patient has a medical condition, and is a crucial part of secondary analysis of healthcare data. We assess the performance of deep learning algorithms and compare them with classical NLP approaches. Materials and Methods: We compare convolutional neural networks (CNNs), n-gram models, and approaches based on cTAKES that extract pre-defined medical concepts from clinical notes and use them to predict patient phenotypes. The performance is tested on 10 different phenotyping tasks using 1,610 discharge summaries extracted from the MIMIC-III database. Results: CNNs outperform other phenotyping algorithms in all 10 tasks. The average F1-score of our model is 76 (PPV of 83, and sensitivity of 71) with our model having an F1-score up to 37 points higher than alternative approaches. We additionally assess the interpretability of our model by presenting a method that extracts the most salient phrases for a particular prediction. Conclusion: We show that NLP methods based on deep learning improve the performance of patient phenotyping. Our CNN-based algorithm automatically learns the phrases associated with each patient phenotype. As such, it reduces the annotation complexity for clinical domain experts, who are normally required to develop task-specific annotation rules and identify relevant phrases. Our method performs well in terms of both performance and interpretability, which indicates that deep learning is an effective approach to patient phenotyping based on clinicians' notes.","Sat, 25 Mar 2017 15:37:09 UTC (716 KB)"
"1552","A Hybrid Deep Learning Approach for Texture Analysis","Hussein Adly, Mohamed Moustafa","Computer Vision and Pattern Recognition (cs.CV)","Texture classification is a problem that has various applications such as remote sensing and forest species recognition. Solutions tend to be custom fit to the dataset used but fails to generalize. The Convolutional Neural Network (CNN) in combination with Support Vector Machine (SVM) form a robust selection between powerful invariant feature extractor and accurate classifier. The fusion of experts provides stability in classification rates among different datasets.","Fri, 24 Mar 2017 11:39:26 UTC (621 KB)"
"1553","Failures of Gradient-Based Deep Learning","Shai Shalev-Shwartz, Ohad Shamir, Shaked Shammah","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","In recent years, Deep Learning has become the go-to solution for a broad range of applications, often outperforming state-of-the-art. However, it is important, for both theoreticians and practitioners, to gain a deeper understanding of the difficulties and limitations associated with common approaches and algorithms. We describe four types of simple problems, for which the gradient-based algorithms commonly used in deep learning either fail or suffer from significant difficulties. We illustrate the failures through practical experiments, and provide theoretical insights explaining their source, and how they might be remedied.","Thu, 23 Mar 2017 07:16:37 UTC (316 KB)[v2] Wed, 26 Apr 2017 05:23:26 UTC (406 KB)"
"1554","Knowledge Transfer for Melanoma Screening with Deep Learning","Afonso Menegola, Michel Fornaciali, Ramon Pires, Flavia Vasques Bittencourt, Sandra Avila, Eduardo Valle","Computer Vision and Pattern Recognition (cs.CV)","Knowledge transfer impacts the performance of deep learning -- the state of the art for image classification tasks, including automated melanoma screening. Deep learning's greed for large amounts of training data poses a challenge for medical tasks, which we can alleviate by recycling knowledge from models trained on different tasks, in a scheme called transfer learning. Although much of the best art on automated melanoma screening employs some form of transfer learning, a systematic evaluation was missing. Here we investigate the presence of transfer, from which task the transfer is sourced, and the application of fine tuning (i.e., retraining of the deep learning model after transfer). We also test the impact of picking deeper (and more expensive) models. Our results favor deeper models, pre-trained over ImageNet, with fine-tuning, reaching an AUC of 80.7% and 84.5% for the two skin-lesion datasets evaluated.","Wed, 22 Mar 2017 00:51:14 UTC (1,350 KB)"
"1555","Deep Learning for Explicitly Modeling Optimization Landscapes","Shumeet Baluja","Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","In all but the most trivial optimization problems, the structure of the solutions exhibit complex interdependencies between the input parameters. Decades of research with stochastic search techniques has shown the benefit of explicitly modeling the interactions between sets of parameters and the overall quality of the solutions discovered. We demonstrate a novel method, based on learning deep networks, to model the global landscapes of optimization problems. To represent the search space concisely and accurately, the deep networks must encode information about the underlying parameter interactions and their contributions to the quality of the solution. Once the networks are trained, the networks are probed to reveal parameter combinations with high expected performance with respect to the optimization task. These estimates are used to initialize fast, randomized, local search algorithms, which in turn expose more information about the search space that is subsequently used to refine the models. We demonstrate the technique on multiple optimization problems that have arisen in a variety of real-world domains, including: packing, graphics, job scheduling, layout and compression. The problems include combinatoric search spaces, discontinuous and highly non-linear spaces, and span binary, higher-cardinality discrete, as well as continuous parameters. Strengths, limitations, and extensions of the approach are extensively discussed and demonstrated.","Tue, 21 Mar 2017 19:12:35 UTC (526 KB)"
"1556","A Comparison of deep learning methods for environmental sound","Juncheng Li, Wei Dai, Florian Metze, Shuhui Qu, Samarjit Das","Sound (cs.SD); Machine Learning (cs.LG)","Environmental sound detection is a challenging application of machine learning because of the noisy nature of the signal, and the small amount of (labeled) data that is typically available. This work thus presents a comparison of several state-of-the-art Deep Learning models on the IEEE challenge on Detection and Classification of Acoustic Scenes and Events (DCASE) 2016 challenge task and data, classifying sounds into one of fifteen common indoor and outdoor acoustic scenes, such as bus, cafe, car, city center, forest path, library, train, etc. In total, 13 hours of stereo audio recordings are available, making this one of the largest datasets available. We perform experiments on six sets of features, including standard Mel-frequency cepstral coefficients (MFCC), Binaural MFCC, log Mel-spectrum and two different large- scale temporal pooling features extracted using OpenSMILE. On these features, we apply five models: Gaussian Mixture Model (GMM), Deep Neural Network (DNN), Recurrent Neural Network (RNN), Convolutional Deep Neural Net- work (CNN) and i-vector. Using the late-fusion approach, we improve the performance of the baseline 72.5% by 15.6% in 4-fold Cross Validation (CV) avg. accuracy and 11% in test accuracy, which matches the best result of the DCASE 2016 challenge. With large feature sets, deep neural network models out- perform traditional methods and achieve the best performance among all the studied methods. Consistent with other work, the best performing single model is the non-temporal DNN model, which we take as evidence that sounds in the DCASE challenge do not exhibit strong temporal dynamics.","Mon, 20 Mar 2017 18:11:47 UTC (250 KB)"
"1557","QMDP-Net: Deep Learning for Planning under Partial Observability","Peter Karkus, David Hsu, Wee Sun Lee","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","This paper introduces the QMDP-net, a neural network architecture for planning under partial observability. The QMDP-net combines the strengths of model-free learning and model-based planning. It is a recurrent policy network, but it represents a policy for a parameterized set of tasks by connecting a model with a planning algorithm that solves the model, thus embedding the solution structure of planning in a network learning architecture. The QMDP-net is fully differentiable and allows for end-to-end training. We train a QMDP-net on different tasks so that it can generalize to new ones in the parameterized task set and ""transfer"" to other similar tasks beyond the set. In preliminary experiments, QMDP-net showed strong performance on several robotic tasks in simulation. Interestingly, while QMDP-net encodes the QMDP algorithm, it sometimes outperforms the QMDP algorithm in the experiments, as a result of end-to-end learning.","Mon, 20 Mar 2017 11:44:00 UTC (803 KB)[v2] Tue, 27 Jun 2017 12:59:39 UTC (1,919 KB)[v3] Fri, 3 Nov 2017 03:31:43 UTC (1,924 KB)"
"1558","Algorithms for Semantic Segmentation of Multispectral Remote Sensing Imagery using Deep Learning","Ronald Kemker, Carl Salvaggio, Christopher Kanan","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)","Deep convolutional neural networks (DCNNs) have been used to achieve state-of-the-art performance on many computer vision tasks (e.g., object recognition, object detection, semantic segmentation) thanks to a large repository of annotated image data. Large labeled datasets for other sensor modalities, e.g., multispectral imagery (MSI), are not available due to the large cost and manpower required. In this paper, we adapt state-of-the-art DCNN frameworks in computer vision for semantic segmentation for MSI imagery. To overcome label scarcity for MSI data, we substitute real MSI for generated synthetic MSI in order to initialize a DCNN framework. We evaluate our network initialization scheme on the new RIT-18 dataset that we present in this paper. This dataset contains very-high resolution MSI collected by an unmanned aircraft system. The models initialized with synthetic imagery were less prone to over-fitting and provide a state-of-the-art baseline for future work.","Sun, 19 Mar 2017 15:21:32 UTC (3,445 KB)[v2] Thu, 21 Sep 2017 13:45:12 UTC (5,442 KB)[v3] Tue, 1 May 2018 20:59:31 UTC (8,931 KB)"
"1559","Semi-Supervised Deep Learning for Fully Convolutional Networks","Christoph Baur, Shadi Albarqouni, Nassir Navab","Computer Vision and Pattern Recognition (cs.CV)","Deep learning usually requires large amounts of labeled training data, but annotating data is costly and tedious. The framework of semi-supervised learning provides the means to use both labeled data and arbitrary amounts of unlabeled data for training. Recently, semi-supervised deep learning has been intensively studied for standard CNN architectures. However, Fully Convolutional Networks (FCNs) set the state-of-the-art for many image segmentation tasks. To the best of our knowledge, there is no existing semi-supervised learning method for such FCNs yet. We lift the concept of auxiliary manifold embedding for semi-supervised learning to FCNs with the help of Random Feature Embedding. In our experiments on the challenging task of MS Lesion Segmentation, we leverage the proposed framework for the purpose of domain adaptation and report substantial improvements over the baseline model.","Fri, 17 Mar 2017 13:14:36 UTC (472 KB)[v2] Tue, 25 Jul 2017 12:02:55 UTC (472 KB)"
"1560","Automatically identifying, counting, and describing wild animals in camera-trap images with deep learning","Mohammed Sadegh Norouzzadeh, Anh Nguyen, Margaret Kosmala, Ali Swanson, Meredith Palmer, Craig Packer, Jeff Clune","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Having accurate, detailed, and up-to-date information about the location and behavior of animals in the wild would revolutionize our ability to study and conserve ecosystems. We investigate the ability to automatically, accurately, and inexpensively collect such data, which could transform many fields of biology, ecology, and zoology into ""big data"" sciences. Motion sensor ""camera traps"" enable collecting wildlife pictures inexpensively, unobtrusively, and frequently. However, extracting information from these pictures remains an expensive, time-consuming, manual task. We demonstrate that such information can be automatically extracted by deep learning, a cutting-edge type of artificial intelligence. We train deep convolutional neural networks to identify, count, and describe the behaviors of 48 species in the 3.2-million-image Snapshot Serengeti dataset. Our deep neural networks automatically identify animals with over 93.8% accuracy, and we expect that number to improve rapidly in years to come. More importantly, if our system classifies only images it is confident about, our system can automate animal identification for 99.3% of the data while still performing at the same 96.6% accuracy as that of crowdsourced teams of human volunteers, saving more than 8.4 years (at 40 hours per week) of human labeling effort (i.e. over 17,000 hours) on this 3.2-million-image dataset. Those efficiency gains immediately highlight the importance of using deep neural networks to automate data extraction from camera-trap images. Our results suggest that this technology could enable the inexpensive, unobtrusive, high-volume, and even real-time collection of a wealth of information about vast numbers of animals in the wild.","Thu, 16 Mar 2017 21:35:15 UTC (7,094 KB)[v2] Wed, 22 Mar 2017 00:45:55 UTC (7,094 KB)[v3] Thu, 30 Mar 2017 22:24:19 UTC (7,094 KB)[v4] Wed, 5 Apr 2017 04:26:20 UTC (7,092 KB)[v5] Wed, 15 Nov 2017 19:29:24 UTC (6,511 KB)"
"1561","A Study of Complex Deep Learning Networks on High Performance, Neuromorphic, and Quantum Computers","Thomas E. Potok, Catherine Schuman, Steven R. Young, Robert M. Patton, Federico Spedalieri, Jeremy Liu, Ke-Thia Yao, Garrett Rose, Gangotree Chakma","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG)","Current Deep Learning approaches have been very successful using convolutional neural networks (CNN) trained on large graphical processing units (GPU)-based computers. Three limitations of this approach are: 1) they are based on a simple layered network topology, i.e., highly connected layers, without intra-layer connections; 2) the networks are manually configured to achieve optimal results, and 3) the implementation of neuron model is expensive in both cost and power. In this paper, we evaluate deep learning models using three different computing architectures to address these problems: quantum computing to train complex topologies, high performance computing (HPC) to automatically determine network topology, and neuromorphic computing for a low-power hardware implementation. We use the MNIST dataset for our experiment, due to input size limitations of current quantum computers. Our results show the feasibility of using the three architectures in tandem to address the above deep learning limitations. We show a quantum computer can find high quality values of intra-layer connections weights, in a tractable time as the complexity of the network increases; a high performance computer can find optimal layer-based topologies; and a neuromorphic computer can represent the complex topology and weights derived from the other architectures in low power memristive hardware.","Wed, 15 Mar 2017 19:37:08 UTC (2,378 KB)[v2] Thu, 13 Jul 2017 18:47:59 UTC (2,378 KB)"
"1562","DeepVel: deep learning for the estimation of horizontal velocities at the solar surface","A. Asensio Ramos (1,2), I. S. Requerey (1,2), N. Vitas (1,2) ((1) Instituto de Astrofisica de Canarias, (2) Universidad de La Laguna)","Solar and Stellar Astrophysics (astro-ph.SR); Computer Vision and Pattern Recognition (cs.CV)","Many phenomena taking place in the solar photosphere are controlled by plasma motions. Although the line-of-sight component of the velocity can be estimated using the Doppler effect, we do not have direct spectroscopic access to the components that are perpendicular to the line-of-sight. These components are typically estimated using methods based on local correlation tracking. We have designed DeepVel, an end-to-end deep neural network that produces an estimation of the velocity at every single pixel and at every time step and at three different heights in the atmosphere from just two consecutive continuum images. We confront DeepVel with local correlation tracking, pointing out that they give very similar results in the time- and spatially-averaged cases. We use the network to study the evolution in height of the horizontal velocity field in fragmenting granules, supporting the buoyancy-braking mechanism for the formation of integranular lanes in these granules. We also show that DeepVel can capture very small vortices, so that we can potentially expand the scaling cascade of vortices to very small sizes and durations.","Wed, 15 Mar 2017 12:49:07 UTC (4,235 KB)[v2] Mon, 24 Apr 2017 16:03:35 UTC (3,727 KB)"
"1563","Deep learning with convolutional neural networks for EEG decoding and visualization","Robin Tibor Schirrmeister, Jost Tobias Springenberg, Lukas Dominique Josef Fiederer, Martin Glasstetter, Katharina Eggensperger, Michael Tangermann, Frank Hutter, Wolfram Burgard, Tonio Ball","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","PLEASE READ AND CITE THE REVISED VERSION at Human Brain Mapping: this http URL Code available here: this https URL","Wed, 15 Mar 2017 09:52:58 UTC (8,271 KB)[v2] Mon, 10 Jul 2017 11:06:38 UTC (8,271 KB)[v3] Mon, 7 Aug 2017 16:16:08 UTC (8,271 KB)[v4] Tue, 8 Aug 2017 08:48:58 UTC (8,271 KB)[v5] Fri, 8 Jun 2018 16:13:56 UTC (8,271 KB)"
"1564","What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?","Alex Kendall, Yarin Gal","Computer Vision and Pattern Recognition (cs.CV)","There are two major types of uncertainty one can model. Aleatoric uncertainty captures noise inherent in the observations. On the other hand, epistemic uncertainty accounts for uncertainty in the model -- uncertainty which can be explained away given enough data. Traditionally it has been difficult to model epistemic uncertainty in computer vision, but with new Bayesian deep learning tools this is now possible. We study the benefits of modeling epistemic vs. aleatoric uncertainty in Bayesian deep learning models for vision tasks. For this we present a Bayesian deep learning framework combining input-dependent aleatoric uncertainty together with epistemic uncertainty. We study models under the framework with per-pixel semantic segmentation and depth regression tasks. Further, our explicit uncertainty formulation leads to new loss functions for these tasks, which can be interpreted as learned attenuation. This makes the loss more robust to noisy data, also giving new state-of-the-art results on segmentation and depth regression benchmarks.","Wed, 15 Mar 2017 07:27:12 UTC (7,220 KB)[v2] Thu, 5 Oct 2017 13:04:51 UTC (8,214 KB)"
"1565","Comparison of the Deep-Learning-Based Automated Segmentation Methods for the Head Sectioned Images of the Virtual Korean Human Project","Mohammad Eshghi, Holger R. Roth, Masahiro Oda, Min Suk Chung, Kensaku Mori","Computer Vision and Pattern Recognition (cs.CV)","This paper presents an end-to-end pixelwise fully automated segmentation of the head sectioned images of the Visible Korean Human (VKH) project based on Deep Convolutional Neural Networks (DCNNs). By converting classification networks into Fully Convolutional Networks (FCNs), a coarse prediction map, with smaller size than the original input image, can be created for segmentation purposes. To refine this map and to obtain a dense pixel-wise output, standard FCNs use deconvolution layers to upsample the coarse map. However, upsampling based on deconvolution increases the number of network parameters and causes loss of detail because of interpolation. On the other hand, dilated convolution is a new technique introduced recently that attempts to capture multi-scale contextual information without increasing the network parameters while keeping the resolution of the prediction maps high. We used both a standard FCN and a dilated convolution based FCN for semantic segmentation of the head sectioned images of the VKH dataset. Quantitative results showed approximately 20% improvement in the segmentation accuracy when using FCNs with dilated convolutions.","Wed, 15 Mar 2017 06:49:01 UTC (5,396 KB)"
"1566","A fully end-to-end deep learning approach for real-time simultaneous 3D reconstruction and material recognition","Cheng Zhao, Li Sun, Rustam Stolkin","Computer Vision and Pattern Recognition (cs.CV)","This paper addresses the problem of simultaneous 3D reconstruction and material recognition and segmentation. Enabling robots to recognise different materials (concrete, metal etc.) in a scene is important for many tasks, e.g. robotic interventions in nuclear decommissioning. Previous work on 3D semantic reconstruction has predominantly focused on recognition of everyday domestic objects (tables, chairs etc.), whereas previous work on material recognition has largely been confined to single 2D images without any 3D reconstruction. Meanwhile, most 3D semantic reconstruction methods rely on computationally expensive post-processing, using Fully-Connected Conditional Random Fields (CRFs), to achieve consistent segmentations. In contrast, we propose a deep learning method which performs 3D reconstruction while simultaneously recognising different types of materials and labelling them at the pixel level. Unlike previous methods, we propose a fully end-to-end approach, which does not require hand-crafted features or CRF post-processing. Instead, we use only learned features, and the CRF segmentation constraints are incorporated inside the fully end-to-end learned system. We present the results of experiments, in which we trained our system to perform real-time 3D semantic reconstruction for 23 different materials in a real-world application. The run-time performance of the system can be boosted to around 10Hz, using a conventional GPU, which is enough to achieve real-time semantic reconstruction using a 30fps RGB-D camera. To the best of our knowledge, this work is the first real-time end-to-end system for simultaneous 3D reconstruction and material recognition.","Tue, 14 Mar 2017 20:23:48 UTC (4,924 KB)"
"1567","Deep Learning for Skin Lesion Classification","P. Mirunalini, Aravindan Chandrabose, Vignesh Gokul, S. M. Jaisakthi","Computer Vision and Pattern Recognition (cs.CV)","Melanoma, a malignant form of skin cancer is very threatening to life. Diagnosis of melanoma at an earlier stage is highly needed as it has a very high cure rate. Benign and malignant forms of skin cancer can be detected by analyzing the lesions present on the surface of the skin using dermoscopic images. In this work, an automated skin lesion detection system has been developed which learns the representation of the image using Google's pretrained CNN model known as Inception-v3 \cite{cnn}. After obtaining the representation vector for our input dermoscopic images we have trained two layer feed forward neural network to classify the images as malignant or benign. The system also classifies the images based on the cause of the cancer either due to melanocytic or non-melanocytic cells using a different neural network. These classification tasks are part of the challenge organized by International Skin Imaging Collaboration (ISIC) 2017. Our system learns to classify the images based on the model built using the training images given in the challenge and the experimental results were evaluated using validation and test sets. Our system has achieved an overall accuracy of 65.8\% for the validation set.","Mon, 13 Mar 2017 12:56:00 UTC (115 KB)"
"1568","Prostate Cancer Diagnosis using Deep Learning with 3D Multiparametric MRI","Saifeng Liu, Huaixiu Zheng, Yesu Feng, Wei Li","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","A novel deep learning architecture (XmasNet) based on convolutional neural networks was developed for the classification of prostate cancer lesions, using the 3D multiparametric MRI data provided by the PROSTATEx challenge. End-to-end training was performed for XmasNet, with data augmentation done through 3D rotation and slicing, in order to incorporate the 3D information of the lesion. XmasNet outperformed traditional machine learning models based on engineered features, for both train and test data. For the test data, XmasNet outperformed 69 methods from 33 participating groups and achieved the second highest AUC (0.84) in the PROSTATEx challenge. This study shows the great potential of deep learning for cancer imaging.","Sun, 12 Mar 2017 07:19:55 UTC (427 KB)"
"1569","Deep Learning in Customer Churn Prediction: Unsupervised Feature Learning on Abstract Company Independent Feature Vectors","Philip Spanoudes, Thomson Nguyen","Machine Learning (cs.LG); Machine Learning (stat.ML)","As companies increase their efforts in retaining customers, being able to predict accurately ahead of time, whether a customer will churn in the foreseeable future is an extremely powerful tool for any marketing team. The paper describes in depth the application of Deep Learning in the problem of churn prediction. Using abstract feature vectors, that can generated on any subscription based company's user event logs, the paper proves that through the use of the intrinsic property of Deep Neural Networks (learning secondary features in an unsupervised manner), the complete pipeline can be applied to any subscription based company with extremely good churn predictive performance. Furthermore the research documented in the paper was performed for Framed Data (a company that sells churn prediction as a service for other companies) in conjunction with the Data Science Institute at Lancaster University, UK. This paper is the intellectual property of Framed Data.","Fri, 10 Mar 2017 23:26:33 UTC (3,495 KB)"
"1570","Deep Learning applied to NLP","Marc Moreno Lopez, Jugal Kalita","Computation and Language (cs.CL)","Convolutional Neural Network (CNNs) are typically associated with Computer Vision. CNNs are responsible for major breakthroughs in Image Classification and are the core of most Computer Vision systems today. More recently CNNs have been applied to problems in Natural Language Processing and gotten some interesting results. In this paper, we will try to explain the basics of CNNs, its different variations and how they have been applied to NLP.","Thu, 9 Mar 2017 01:04:07 UTC (1,361 KB)"
"1571","A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile Analytics","Seyed Ali Osia, Ali Shahin Shamsabadi, Ali Taheri, Kleomenis Katevas, Sina Sajadmanesh, Hamid R. Rabiee, Nicholas D. Lane, Hamed Haddadi","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)","Deep Neural Networks are increasingly being used in a variety of machine learning applications applied to user data on the cloud. However, this approach introduces a number of privacy and efficiency challenges, as the cloud operator can perform secondary inferences on the available data. Recently, advances in edge processing have paved the way for more efficient, and private, data processing at the source for simple tasks and lighter models, though they remain a challenge for larger, and more complicated models. In this paper, we present a hybrid approach for breaking down large, complex deep models for cooperative, privacy-preserving analytics. We do this by breaking down the popular deep architectures and fine-tune them in a suitable way. We then evaluate the privacy benefits of this approach based on the information exposed to the cloud service. We also assess the local inference cost of different layers on a modern handset for mobile applications. Our evaluations show that by using certain kind of fine-tuning and embedding techniques and at a small processing cost, we can greatly reduce the level of information available to unintended tasks applied to the data features on the cloud, and hence achieving the desired tradeoff between privacy and performance.","Wed, 8 Mar 2017 18:21:03 UTC (699 KB)[v2] Thu, 23 Mar 2017 11:14:55 UTC (699 KB)[v3] Mon, 3 Apr 2017 11:43:10 UTC (699 KB)[v4] Tue, 4 Apr 2017 05:28:20 UTC (699 KB)[v5] Wed, 18 Apr 2018 05:44:35 UTC (2,189 KB)"
"1572","CMU DeepLens: Deep Learning For Automatic Image-based Galaxy-Galaxy Strong Lens Finding","Francois Lanusse, Quanbin Ma, Nan Li, Thomas E. Collett, Chun-Liang Li, Siamak Ravanbakhsh, Rachel Mandelbaum, Barnabas Poczos","Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Astrophysics of Galaxies (astro-ph.GA)","Galaxy-scale strong gravitational lensing is not only a valuable probe of the dark matter distribution of massive galaxies, but can also provide valuable cosmological constraints, either by studying the population of strong lenses or by measuring time delays in lensed quasars. Due to the rarity of galaxy-scale strongly lensed systems, fast and reliable automated lens finding methods will be essential in the era of large surveys such as LSST, Euclid, and WFIRST. To tackle this challenge, we introduce CMU DeepLens, a new fully automated galaxy-galaxy lens finding method based on Deep Learning. This supervised machine learning approach does not require any tuning after the training step which only requires realistic image simulations of strongly lensed systems. We train and validate our model on a set of 20,000 LSST-like mock observations including a range of lensed systems of various sizes and signal-to-noise ratios (S/N). We find on our simulated data set that for a rejection rate of non-lenses of 99%, a completeness of 90% can be achieved for lenses with Einstein radii larger than 1.4"" and S/N larger than 20 on individual $g$-band LSST exposures. Finally, we emphasize the importance of realistically complex simulations for training such machine learning methods by demonstrating that the performance of models of significantly different complexities cannot be distinguished on simpler simulations. We make our code publicly available at this https URL .","Wed, 8 Mar 2017 00:05:36 UTC (524 KB)"
"1573","Deep Learning for Automated Quality Assessment of Color Fundus Images in Diabetic Retinopathy Screening","Sajib Kumar Saha, Basura Fernando, Jorge Cuadros, Di Xiao, Yogesan Kanagasingam","Computer Vision and Pattern Recognition (cs.CV)","Purpose To develop a computer based method for the automated assessment of image quality in the context of diabetic retinopathy (DR) to guide the photographer. Methods A deep learning framework was trained to grade the images automatically. A large representative set of 7000 color fundus images were used for the experiment which were obtained from the EyePACS that were made available by the California Healthcare Foundation. Three retinal image analysis experts were employed to categorize these images into Accept and Reject classes based on the precise definition of image quality in the context of DR. A deep learning framework was trained using 3428 images. Results A total of 3572 images were used for the evaluation of the proposed method. The method shows an accuracy of 100% to successfully categorise Accept and Reject images. Conclusion Image quality is an essential prerequisite for the grading of DR. In this paper we have proposed a deep learning based automated image quality assessment method in the context of DR. The method can be easily incorporated with the fundus image capturing system and thus can guide the photographer whether a recapture is necessary or not.","Tue, 7 Mar 2017 18:28:50 UTC (983 KB)"
"1574","Object classification in images of Neoclassical furniture using Deep Learning","Bernhard Bermeitinger, Andre Freitas, Simon Donig, Siegfried Handschuh","Computer Vision and Pattern Recognition (cs.CV)","This short paper outlines research results on object classification in images of Neoclassical furniture. The motivation was to provide an object recognition framework which is able to support the alignment of furniture images with a symbolic level model. A data-driven bottom-up research routine in the Neoclassica research framework is the main use-case. It strives to deliver tools for analyzing the spread of aesthetic forms which are considered as a cultural transfer process.","Tue, 7 Mar 2017 15:48:55 UTC (172 KB)"
"1575","Deep Learning based Large Scale Visual Recommendation and Search for E-Commerce","Devashish Shankar, Sujay Narumanchi, H A Ananya, Pramod Kompalli, Krishnendu Chaudhury","Computer Vision and Pattern Recognition (cs.CV)","In this paper, we present a unified end-to-end approach to build a large scale Visual Search and Recommendation system for e-commerce. Previous works have targeted these problems in isolation. We believe a more effective and elegant solution could be obtained by tackling them together. We propose a unified Deep Convolutional Neural Network architecture, called VisNet, to learn embeddings to capture the notion of visual similarity, across several semantic granularities. We demonstrate the superiority of our approach for the task of image retrieval, by comparing against the state-of-the-art on the Exact Street2Shop dataset. We then share the design decisions and trade-offs made while deploying the model to power Visual Recommendations across a catalog of 50M products, supporting 2K queries a second at Flipkart, India's largest e-commerce company. The deployment of our solution has yielded a significant business impact, as measured by the conversion-rate.","Tue, 7 Mar 2017 11:58:36 UTC (8,753 KB)"
"1576","Using Deep Learning Method for Classification: A Proposed Algorithm for the ISIC 2017 Skin Lesion Classification Challenge","Wenhao Zhang, Liangcai Gao, Runtao Liu","Computer Vision and Pattern Recognition (cs.CV)","Skin cancer, the most common human malignancy, is primarily diagnosed visually by physicians [1]. Classification with an automated method like CNN [2, 3] shows potential for challenging tasks [1]. By now, the deep convolutional neural networks are on par with human dermatologist [1]. This abstract is dedicated on developing a Deep Learning method for ISIC [5] 2017 Skin Lesion Detection Competition hosted at [6] to classify the dermatology pictures, which is aimed at improving the diagnostic accuracy rate and general level of the human health. The challenge falls into three sub-challenges, including Lesion Segmentation, Lesion Dermoscopic Feature Extraction and Lesion Classification. This project only participates in the Lesion Classification part. This algorithm is comprised of three steps: (1) original images preprocessing, (2) modelling the processed images using CNN [2, 3] in Caffe [4] framework, (3) predicting the test images and calculating the scores that represent the likelihood of corresponding classification. The models are built on the source images are using the Caffe [4] framework. The scores in prediction step are obtained by two different models from the source images.","Tue, 7 Mar 2017 02:26:21 UTC (293 KB)[v2] Fri, 10 Mar 2017 08:17:47 UTC (294 KB)"
"1577","On the Expressive Power of Overlapping Architectures of Deep Learning","Or Sharir, Amnon Shashua","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","Expressive efficiency refers to the relation between two architectures A and B, whereby any function realized by B could be replicated by A, but there exists functions realized by A, which cannot be replicated by B unless its size grows significantly larger. For example, it is known that deep networks are exponentially efficient with respect to shallow networks, in the sense that a shallow network must grow exponentially large in order to approximate the functions represented by a deep network of polynomial size. In this work, we extend the study of expressive efficiency to the attribute of network connectivity and in particular to the effect of ""overlaps"" in the convolutional process, i.e., when the stride of the convolution is smaller than its filter size (receptive field). To theoretically analyze this aspect of network's design, we focus on a well-established surrogate for ConvNets called Convolutional Arithmetic Circuits (ConvACs), and then demonstrate empirically that our results hold for standard ConvNets as well. Specifically, our analysis shows that having overlapping local receptive fields, and more broadly denser connectivity, results in an exponential increase in the expressive capacity of neural networks. Moreover, while denser connectivity can increase the expressive capacity, we show that the most common types of modern architectures already exhibit exponential increase in expressivity, without relying on fully-connected layers.","Mon, 6 Mar 2017 19:07:12 UTC (776 KB)[v2] Tue, 21 Mar 2017 09:05:54 UTC (776 KB)[v3] Fri, 27 Oct 2017 14:02:11 UTC (856 KB)[v4] Sat, 24 Feb 2018 14:47:00 UTC (873 KB)"
"1578","Uncertain Photometric Redshifts with Deep Learning Methods","Antonio D'Isanto","Instrumentation and Methods for Astrophysics (astro-ph.IM)","The need for accurate photometric redshifts estimation is a topic that has fundamental importance in Astronomy, due to the necessity of efficiently obtaining redshift information without the need of spectroscopic analysis. We propose a method for determining accurate multimodal photo-z probability density functions (PDFs) using Mixture Density Networks (MDN) and Deep Convolutional Networks (DCN). A comparison with a Random Forest (RF) is performed.","Mon, 6 Mar 2017 17:07:13 UTC (700 KB)"
"1579","Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results","Antti Tarvainen, Harri Valpola","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG); Machine Learning (stat.ML)","The recently proposed Temporal Ensembling has achieved state-of-the-art results in several semi-supervised learning benchmarks. It maintains an exponential moving average of label predictions on each training example, and penalizes predictions that are inconsistent with this target. However, because the targets change only once per epoch, Temporal Ensembling becomes unwieldy when learning large datasets. To overcome this problem, we propose Mean Teacher, a method that averages model weights instead of label predictions. As an additional benefit, Mean Teacher improves test accuracy and enables training with fewer labels than Temporal Ensembling. Without changing the network architecture, Mean Teacher achieves an error rate of 4.35% on SVHN with 250 labels, outperforming Temporal Ensembling trained with 1000 labels. We also show that a good network architecture is crucial to performance. Combining Mean Teacher and Residual Networks, we improve the state of the art on CIFAR-10 with 4000 labels from 10.55% to 6.28%, and on ImageNet 2012 with 10% of the labels from 35.24% to 9.11%.","Mon, 6 Mar 2017 09:34:56 UTC (177 KB)[v2] Mon, 12 Jun 2017 07:41:30 UTC (659 KB)[v3] Thu, 30 Nov 2017 11:14:43 UTC (522 KB)[v4] Mon, 18 Dec 2017 09:13:01 UTC (522 KB)[v5] Mon, 8 Jan 2018 08:10:09 UTC (522 KB)[v6] Mon, 16 Apr 2018 10:39:11 UTC (522 KB)"
"1580","Automatic Classification of Cancerous Tissue in Laserendomicroscopy Images of the Oral Cavity using Deep Learning","Marc Aubreville, Christian Knipfer, Nicolai Oetter, Christian Jaremenko, Erik Rodner, Joachim Denzler, Christopher Bohr, Helmut Neumann, Florian Stelzle, Andreas Maier","Computer Vision and Pattern Recognition (cs.CV)","Oral Squamous Cell Carcinoma (OSCC) is a common type of cancer of the oral epithelium. Despite their high impact on mortality, sufficient screening methods for early diagnosis of OSCC often lack accuracy and thus OSCCs are mostly diagnosed at a late stage. Early detection and accurate outline estimation of OSCCs would lead to a better curative outcome and an reduction in recurrence rates after surgical treatment. Confocal Laser Endomicroscopy (CLE) records sub-surface micro-anatomical images for in vivo cell structure analysis. Recent CLE studies showed great prospects for a reliable, real-time ultrastructural imaging of OSCC in situ. We present and evaluate a novel automatic approach for a highly accurate OSCC diagnosis using deep learning technologies on CLE images. The method is compared against textural feature-based machine learning approaches that represent the current state of the art. For this work, CLE image sequences (7894 images) from patients diagnosed with OSCC were obtained from 4 specific locations in the oral cavity, including the OSCC lesion. The present approach is found to outperform the state of the art in CLE image recognition with an area under the curve (AUC) of 0.96 and a mean accuracy of 88.3% (sensitivity 86.6%, specificity 90%).","Sun, 5 Mar 2017 16:48:01 UTC (4,892 KB)[v2] Fri, 10 Mar 2017 10:58:24 UTC (2,148 KB)"
"1581","Deep-Learning for Classification of Colorectal Polyps on Whole-Slide Images","Bruno Korbar, Andrea M. Olofson, Allen P. Miraflor, Katherine M. Nicka, Matthew A. Suriawinata, Lorenzo Torresani, Arief A. Suriawinata, Saeed Hassanpour","Computer Vision and Pattern Recognition (cs.CV)","Histopathological characterization of colorectal polyps is an important principle for determining the risk of colorectal cancer and future rates of surveillance for patients. This characterization is time-intensive, requires years of specialized training, and suffers from significant inter-observer and intra-observer variability. In this work, we built an automatic image-understanding method that can accurately classify different types of colorectal polyps in whole-slide histology images to help pathologists with histopathological characterization and diagnosis of colorectal polyps. The proposed image-understanding method is based on deep-learning techniques, which rely on numerous levels of abstraction for data representation and have shown state-of-the-art results for various image analysis tasks. Our image-understanding method covers all five polyp types (hyperplastic polyp, sessile serrated polyp, traditional serrated adenoma, tubular adenoma, and tubulovillous/villous adenoma) that are included in the US multi-society task force guidelines for colorectal cancer risk assessment and surveillance, and encompasses the most common occurrences of colorectal polyps. Our evaluation on 239 independent test samples shows our proposed method can identify the types of colorectal polyps in whole-slide images with a high efficacy (accuracy: 93.0%, precision: 89.7%, recall: 88.3%, F1 score: 88.8%). The presented method in this paper can reduce the cognitive burden on pathologists and improve their accuracy and efficiency in histopathological characterization of colorectal polyps, and in subsequent risk assessment and follow-up recommendations.","Sun, 5 Mar 2017 03:17:35 UTC (4,977 KB)[v2] Wed, 12 Apr 2017 22:26:56 UTC (4,977 KB)"
"1582","Deep Learning with Domain Adaptation for Accelerated Projection-Reconstruction MR","Yo Seob Han, Jaejun Yoo, Jong Chul Ye","Computer Vision and Pattern Recognition (cs.CV)","Purpose: The radial k-space trajectory is a well-established sampling trajectory used in conjunction with magnetic resonance imaging. However, the radial k-space trajectory requires a large number of radial lines for high-resolution reconstruction. Increasing the number of radial lines causes longer acquisition time, making it more difficult for routine clinical use. On the other hand, if we reduce the number of radial lines, streaking artifact patterns are unavoidable. To solve this problem, we propose a novel deep learning approach with domain adaptation to restore high-resolution MR images from under-sampled k-space data. Methods: The proposed deep network removes the streaking artifacts from the artifact corrupted images. To address the situation given the limited available data, we propose a domain adaptation scheme that employs a pre-trained network using a large number of x-ray computed tomography (CT) or synthesized radial MR datasets, which is then fine-tuned with only a few radial MR datasets. Results: The proposed method outperforms existing compressed sensing algorithms, such as the total variation and PR-FOCUSS methods. In addition, the calculation time is several orders of magnitude faster than the total variation and PR-FOCUSS methods.Moreover, we found that pre-training using CT or MR data from similar organ data is more important than pre-training using data from the same modality for different organ. Conclusion: We demonstrate the possibility of a domain-adaptation when only a limited amount of MR data is available. The proposed method surpasses the existing compressed sensing algorithms in terms of the image quality and computation time.","Fri, 3 Mar 2017 12:49:36 UTC (3,269 KB)[v2] Tue, 9 Jan 2018 04:28:28 UTC (4,805 KB)"
"1583","A Novel Multi-task Deep Learning Model for Skin Lesion Segmentation and Classification","Xulei Yang, Zeng Zeng, Si Yong Yeo, Colin Tan, Hong Liang Tey, Yi Su","Computer Vision and Pattern Recognition (cs.CV)","In this study, a multi-task deep neural network is proposed for skin lesion analysis. The proposed multi-task learning model solves different tasks (e.g., lesion segmentation and two independent binary lesion classifications) at the same time by exploiting commonalities and differences across tasks. This results in improved learning efficiency and potential prediction accuracy for the task-specific models, when compared to training the individual models separately. The proposed multi-task deep learning model is trained and evaluated on the dermoscopic image sets from the International Skin Imaging Collaboration (ISIC) 2017 Challenge - Skin Lesion Analysis towards Melanoma Detection, which consists of 2000 training samples and 150 evaluation samples. The experimental results show that the proposed multi-task deep learning model achieves promising performances on skin lesion segmentation and classification. The average value of Jaccard index for lesion segmentation is 0.724, while the average values of area under the receiver operating characteristic curve (AUC) on two individual lesion classifications are 0.880 and 0.972, respectively.","Fri, 3 Mar 2017 03:22:16 UTC (181 KB)"
"1584","Autonomous Skill-centric Testing using Deep Learning","Simon Hangl, Sebastian Stabinger, Justus Piater","Robotics (cs.RO)","Software testing is an important tool to ensure software quality. This is a hard task in robotics due to dynamic environments and the expensive development and time-consuming execution of test cases. Most testing approaches use model-based and / or simulation-based testing to overcome these problems. We propose model-free skill-centric testing in which a robot autonomously executes skills in the real world and compares it to previous experiences. The skills are selected by maximising the expected information gain on the distribution of erroneous software functions. We use deep learning to model the sensor data observed during previous successful skill executions and to detect irregularities. Sensor data is connected to function call profiles such that certain misbehaviour can be related to specific functions. We evaluate our approach in simulation and in experiments with a KUKA LWR 4+ robot by purposefully introducing bugs to the software. We demonstrate that these bugs can be detected with high accuracy and without the need for the implementation of specific tests or task-specific models.","Thu, 2 Mar 2017 15:41:48 UTC (5,292 KB)[v2] Tue, 21 Mar 2017 15:07:04 UTC (4,320 KB)[v3] Sun, 13 Aug 2017 11:40:32 UTC (4,245 KB)"
"1585","A Robust Adaptive Stochastic Gradient Method for Deep Learning","Caglar Gulcehre, Jose Sotelo, Marcin Moczulski, Yoshua Bengio","Machine Learning (cs.LG)","Stochastic gradient algorithms are the main focus of large-scale optimization problems and led to important successes in the recent advancement of the deep learning algorithms. The convergence of SGD depends on the careful choice of learning rate and the amount of the noise in stochastic estimates of the gradients. In this paper, we propose an adaptive learning rate algorithm, which utilizes stochastic curvature information of the loss function for automatically tuning the learning rates. The information about the element-wise curvature of the loss function is estimated from the local statistics of the stochastic first order gradients. We further propose a new variance reduction technique to speed up the convergence. In our experiments with deep neural networks, we obtained better performance compared to the popular stochastic gradient algorithms.","Thu, 2 Mar 2017 14:03:48 UTC (655 KB)"
"1586","Skin Lesion Analysis Towards Melanoma Detection Using Deep Learning Network","Yuexiang Li, Linlin Shen","Computer Vision and Pattern Recognition (cs.CV)","Skin lesion is a severe disease in world-wide extent. Early detection of melanoma in dermoscopy images significantly increases the survival rate. However, the accurate recognition of melanoma is extremely challenging due to the following reasons, e.g. low contrast between lesions and skin, visual similarity between melanoma and non-melanoma lesions, etc. Hence, reliable automatic detection of skin tumors is very useful to increase the accuracy and efficiency of pathologists. International Skin Imaging Collaboration (ISIC) is a challenge focusing on the automatic analysis of skin lesion. In this paper, we proposed two deep learning methods to address all the three tasks announced in ISIC 2017, i.e. lesion segmentation (task 1), lesion dermoscopic feature extraction (task 2) and lesion classification (task 3). A deep learning framework consisting of two fully-convolutional residual networks (FCRN) is proposed to simultaneously produce the segmentation result and the coarse classification result. A lesion index calculation unit (LICU) is developed to refine the coarse classification results by calculating the distance heat-map. A straight-forward CNN is proposed for the dermoscopic feature extraction task. To our best knowledges, we are not aware of any previous work proposed for this task. The proposed deep learning frameworks were evaluated on the ISIC 2017 testing set. Experimental results show the promising accuracies of our frameworks, i.e. 0.718 for task 1, 0.833 for task 2 and 0.823 for task 3 were achieved.","Thu, 2 Mar 2017 01:24:04 UTC (246 KB)[v2] Wed, 22 Nov 2017 12:13:09 UTC (1,093 KB)"
"1587","Easy over Hard: A Case Study on Deep Learning","Wei Fu, Tim Menzies","Software Engineering (cs.SE); Machine Learning (cs.LG)","While deep learning is an exciting new technique, the benefits of this method need to be assessed with respect to its computational cost. This is particularly important for deep learning since these learners need hours (to weeks) to train the model. Such long training time limits the ability of (a)~a researcher to test the stability of their conclusion via repeated runs with different random seeds; and (b)~other researchers to repeat, improve, or even refute that original work. For example, recently, deep learning was used to find which questions in the Stack Overflow programmer discussion forum can be linked together. That deep learning system took 14 hours to execute. We show here that applying a very simple optimizer called DE to fine tune SVM, it can achieve similar (and sometimes better) results. The DE approach terminated in 10 minutes; i.e. 84 times faster hours than deep learning method. We offer these results as a cautionary tale to the software analytics community and suggest that not every new innovation should be applied without critical analysis. If researchers deploy some new and expensive process, that work should be baselined against some simpler and faster alternatives.","Wed, 1 Mar 2017 04:38:35 UTC (3,918 KB)[v2] Sat, 24 Jun 2017 16:43:01 UTC (666 KB)"
"1588","On architectural choices in deep learning: From network structure to gradient convergence and parameter estimation","Vamsi K Ithapu, Sathya N Ravi, Vikas Singh","Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)","We study mechanisms to characterize how the asymptotic convergence of backpropagation in deep architectures, in general, is related to the network structure, and how it may be influenced by other design choices including activation type, denoising and dropout rate. We seek to analyze whether network architecture and input data statistics may guide the choices of learning parameters and vice versa. Given the broad applicability of deep architectures, this issue is interesting both from theoretical and a practical standpoint. Using properties of general nonconvex objectives (with first-order information), we first build the association between structural, distributional and learnability aspects of the network vis-a-vis their interaction with parameter convergence rates. We identify a nice relationship between feature denoising and dropout, and construct families of networks that achieve the same level of convergence. We then derive a workflow that provides systematic guidance regarding the choice of network sizes and learning parameters often mediated4 by input statistics. Our technical results are corroborated by an extensive set of evaluations, presented in this paper as well as independent empirical observations reported by other groups. We also perform experiments showing the practical implications of our framework for choosing the best fully-connected design for a given problem.","Tue, 28 Feb 2017 07:05:27 UTC (1,577 KB)"
"1589","Lensless computational imaging through deep learning","Ayan Sinha, Justin Lee, Shuai Li, George Barbastathis","Computer Vision and Pattern Recognition (cs.CV); Optics (physics.optics)","Deep learning has been proven to yield reliably generalizable answers to numerous classification and decision tasks. Here, we demonstrate for the first time, to our knowledge, that deep neural networks (DNNs) can be trained to solve inverse problems in computational imaging. We experimentally demonstrate a lens-less imaging system where a DNN was trained to recover a phase object given a raw intensity image recorded some distance away.","Wed, 22 Feb 2017 20:55:26 UTC (1,016 KB)[v2] Mon, 26 Jun 2017 05:49:50 UTC (17,472 KB)"
"1590","Criticality & Deep Learning I: Generally Weighted Nets","Dan Oprisa, Peter Toth","Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","Motivated by the idea that criticality and universality of phase transitions might play a crucial role in achieving and sustaining learning and intelligent behaviour in biological and artificial networks, we analyse a theoretical and a pragmatic experimental set up for critical phenomena in deep learning. On the theoretical side, we use results from statistical physics to carry out critical point calculations in feed-forward/fully connected networks, while on the experimental side we set out to find traces of criticality in deep neural networks. This is our first step in a series of upcoming investigations to map out the relationship between criticality and learning in deep networks.","Sun, 26 Feb 2017 14:43:38 UTC (78 KB)[v2] Wed, 31 May 2017 09:38:30 UTC (78 KB)"
"1591","Spatially Aware Melanoma Segmentation Using Hybrid Deep Learning Techniques","M. Attia, M. Hossny, S. Nahavandi, A. Yazdabadi","Computer Vision and Pattern Recognition (cs.CV)","In this paper, we proposed using a hybrid method that utilises deep convolutional and recurrent neural networks for accurate delineation of skin lesion of images supplied with ISBI 2017 lesion segmentation challenge. The proposed method was trained using 1800 images and tested on 150 images from ISBI 2017 challenge.","Sun, 26 Feb 2017 00:56:25 UTC (1,520 KB)"
"1592","Deep Learning for Design and Retrieval of Nano-photonic Structures","Itzik Malkiel, Achiya Nagler, Michael Mrejen, Uri Arieli, Lior Wolf, Haim Suchowski","Optics (physics.optics)","Our visual perception of our surroundings is ultimately limited by the diffraction limit, which stipulates that optical information smaller than roughly half the illumination wavelength is not retrievable. Over the past decades, many breakthroughs have led to unprecedented imaging capabilities beyond the diffraction-limit, with applications in biology and nanotechnology. In this context, nano-photonics has revolutionized the field of optics in recent years by enabling the manipulation of light-matter interaction with subwavelength structures. However, despite the many advances in this field, its impact and penetration in our daily life has been hindered by a convoluted and iterative process, cycling through modeling, nanofabrication and nano-characterization. The fundamental reason is the fact that not only the prediction of the optical response is very time consuming and requires solving Maxwell's equations with dedicated numerical packages. But, more significantly, the inverse problem, i.e. designing a nanostructure with an on-demand optical response, is currently a prohibitive task even with the most advanced numerical tools due to the high non-linearity of the problem. Here, we harness the power of Deep Learning, a new path in modern machine learning, and show its ability to predict the geometry of nanostructures based solely on their far-field response. This approach also addresses in a direct way the currently inaccessible inverse problem breaking the ground for on-demand design of optical response with applications such as sensing, imaging and also for plasmon's mediated cancer thermotherapy.","Sat, 25 Feb 2017 21:20:22 UTC (1,665 KB)[v2] Tue, 28 Feb 2017 09:40:45 UTC (1,665 KB)[v3] Wed, 1 Mar 2017 15:15:18 UTC (1,666 KB)"
"1593","On the Origin of Deep Learning","Haohan Wang, Bhiksha Raj","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","This paper is a review of the evolutionary history of deep learning models. It covers from the genesis of neural networks when associationism modeling of the brain is studied, to the models that dominate the last decade of research in deep learning like convolutional neural networks, deep belief networks, and recurrent neural networks. In addition to a review of these models, this paper primarily focuses on the precedents of the models above, examining how the initial ideas are assembled to construct the early models and how these preliminary models are developed into their current forms. Many of these evolutionary paths last more than half a century and have a diversity of directions. For example, CNN is built on prior knowledge of biological vision system; DBN is evolved from a trade-off of modeling power and computation complexity of graphical models and many nowadays models are neural counterparts of ancient linear models. This paper reviews these evolutionary paths and offers a concise thought flow of how these models are developed, and aims to provide a thorough background for deep learning. More importantly, along with the path, this paper summarizes the gist behind these milestones and proposes many directions to guide the future research of deep learning.","Fri, 24 Feb 2017 23:30:08 UTC (4,829 KB)[v2] Wed, 1 Mar 2017 08:30:41 UTC (4,822 KB)[v3] Thu, 2 Mar 2017 01:41:09 UTC (4,822 KB)[v4] Fri, 3 Mar 2017 03:03:32 UTC (4,822 KB)"
"1594","Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning","Briland Hitaj, Giuseppe Ateniese, Fernando Perez-Cruz","Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep Learning has recently become hugely popular in machine learning, providing significant improvements in classification accuracy in the presence of highly-structured and large databases. Researchers have also considered privacy implications of deep learning. Models are typically trained in a centralized manner with all the data being processed by the same training algorithm. If the data is a collection of users' private data, including habits, personal pictures, geographical positions, interests, and more, the centralized server will have access to sensitive information that could potentially be mishandled. To tackle this problem, collaborative deep learning models have recently been proposed where parties locally train their deep learning structures and only share a subset of the parameters in the attempt to keep their respective training sets private. Parameters can also be obfuscated via differential privacy (DP) to make information extraction even more challenging, as proposed by Shokri and Shmatikov at CCS'15. Unfortunately, we show that any privacy-preserving collaborative deep learning is susceptible to a powerful attack that we devise in this paper. In particular, we show that a distributed, federated, or decentralized deep learning approach is fundamentally broken and does not protect the training sets of honest participants. The attack we developed exploits the real-time nature of the learning process that allows the adversary to train a Generative Adversarial Network (GAN) that generates prototypical samples of the targeted training set that was meant to be private (the samples generated by the GAN are intended to come from the same distribution as the training data). Interestingly, we show that record-level DP applied to the shared parameters of the model, as suggested in previous work, is ineffective (i.e., record-level DP is not designed to address our attack).","Fri, 24 Feb 2017 05:00:37 UTC (1,646 KB)[v2] Tue, 23 May 2017 20:21:27 UTC (2,081 KB)[v3] Thu, 14 Sep 2017 16:38:23 UTC (1,691 KB)"
"1595","Data-Driven Fuzzy Modeling Using Deep Learning","Erick de la Rosa, Wen Yu","Systems and Control (cs.SY)","Fuzzy modeling has many advantages over the non-fuzzy methods, such as robustness against uncertainties and less sensitivity to the varying dynamics of nonlinear systems. Data-driven fuzzy modeling needs to extract fuzzy rules from the input/output data, and train the fuzzy parameters. This paper takes advantages from deep learning, probability theory, fuzzy modeling, and extreme learning machines. We use the restricted Boltzmann machine (RBM) and probability theory to overcome some common problems in data based modeling methods. The RBM is modified such that it can be trained with continuous values. A probability based clustering method is proposed to partition the hidden features from the RBM, and extract fuzzy rules with probability measurement. An extreme learning machine and an optimization method are applied to train the consequent part of the fuzzy rules and the probability parameters. The proposed method is validated with two benchmark problems.","Thu, 23 Feb 2017 02:45:54 UTC (1,751 KB)"
"1596","Proactive Resource Management in LTE-U Systems: A Deep Learning Perspective","Ursula Challita, Li Dong, Walid Saad","Information Theory (cs.IT); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)","LTE in unlicensed spectrum (LTE-U) is a promising approach to overcome the wireless spectrum scarcity. However, to reap the benefits of LTE-U, a fair coexistence mechanism with other incumbent WiFi deployments is required. In this paper, a novel deep learning approach is proposed for modeling the resource allocation problem of LTE-U small base stations (SBSs). The proposed approach enables multiple SBSs to proactively perform dynamic channel selection, carrier aggregation, and fractional spectrum access while guaranteeing fairness with existing WiFi networks and other LTE-U operators. Adopting a proactive coexistence mechanism enables future delay-intolerant LTE-U data demands to be served within a given prediction window ahead of their actual arrival time thus avoiding the underutilization of the unlicensed spectrum during off-peak hours while maximizing the total served LTE-U traffic load. To this end, a noncooperative game model is formulated in which SBSs are modeled as Homo Egualis agents that aim at predicting a sequence of future actions and thus achieving long-term equal weighted fairness with WLAN and other LTE-U operators over a given time horizon. The proposed deep learning algorithm is then shown to reach a mixed-strategy Nash equilibrium (NE), when it converges. Simulation results using real data traces show that the proposed scheme can yield up to 28% and 11% gains over a conventional reactive approach and a proportional fair coexistence mechanism, respectively. The results also show that the proposed framework prevents WiFi performance degradation for a densely deployed LTE-U network.","Wed, 22 Feb 2017 22:34:57 UTC (1,003 KB)"
"1597","Scaling Deep Learning-based Decoding of Polar Codes via Partitioning","Sebastian Cammerer, Tobias Gruber, Jakob Hoydis, Stephan ten Brink","Information Theory (cs.IT)","The training complexity of deep learning-based channel decoders scales exponentially with the codebook size and therefore with the number of information bits. Thus, neural network decoding (NND) is currently only feasible for very short block lengths. In this work, we show that the conventional iterative decoding algorithm for polar codes can be enhanced when sub-blocks of the decoder are replaced by neural network (NN) based components. Thus, we partition the encoding graph into smaller sub-blocks and train them individually, closely approaching maximum a posteriori (MAP) performance per sub-block. These blocks are then connected via the remaining conventional belief propagation decoding stage(s). The resulting decoding algorithm is non-iterative and inherently enables a high-level of parallelization, while showing a competitive bit error rate (BER) performance. We examine the degradation through partitioning and compare the resulting decoder to state-of-the-art polar decoders such as successive cancellation list and belief propagation decoding.","Wed, 22 Feb 2017 17:20:13 UTC (291 KB)"
"1598","Using Deep Learning and Google Street View to Estimate the Demographic Makeup of the US","Timnit Gebru, Jonathan Krause, Yilun Wang, Duyun Chen, Jia Deng, Erez Lieberman Aiden, Li Fei-Fei","Computer Vision and Pattern Recognition (cs.CV)","The United States spends more than $1B each year on initiatives such as the American Community Survey (ACS), a labor-intensive door-to-door study that measures statistics relating to race, gender, education, occupation, unemployment, and other demographic factors. Although a comprehensive source of data, the lag between demographic changes and their appearance in the ACS can exceed half a decade. As digital imagery becomes ubiquitous and machine vision techniques improve, automated data analysis may provide a cheaper and faster alternative. Here, we present a method that determines socioeconomic trends from 50 million images of street scenes, gathered in 200 American cities by Google Street View cars. Using deep learning-based computer vision techniques, we determined the make, model, and year of all motor vehicles encountered in particular neighborhoods. Data from this census of motor vehicles, which enumerated 22M automobiles in total (8% of all automobiles in the US), was used to accurately estimate income, race, education, and voting patterns, with single-precinct resolution. (The average US precinct contains approximately 1000 people.) The resulting associations are surprisingly simple and powerful. For instance, if the number of sedans encountered during a 15-minute drive through a city is higher than the number of pickup trucks, the city is likely to vote for a Democrat during the next Presidential election (88% chance); otherwise, it is likely to vote Republican (82%). Our results suggest that automated systems for monitoring demographic trends may effectively complement labor-intensive approaches, with the potential to detect trends with fine spatial resolution, in close to real time.","Wed, 22 Feb 2017 06:20:13 UTC (6,378 KB)[v2] Thu, 2 Mar 2017 05:11:11 UTC (6,379 KB)"
"1599","Deep learning-based assessment of tumor-associated stroma for diagnosing breast cancer in histopathology images","Babak Ehteshami Bejnordi, Jimmy Linz, Ben Glass, Maeve Mullooly, Gretchen L Gierach, Mark E Sherman, Nico Karssemeijer, Jeroen van der Laak, Andrew H Beck","Computer Vision and Pattern Recognition (cs.CV)","Diagnosis of breast carcinomas has so far been limited to the morphological interpretation of epithelial cells and the assessment of epithelial tissue architecture. Consequently, most of the automated systems have focused on characterizing the epithelial regions of the breast to detect cancer. In this paper, we propose a system for classification of hematoxylin and eosin (H&E) stained breast specimens based on convolutional neural networks that primarily targets the assessment of tumor-associated stroma to diagnose breast cancer patients. We evaluate the performance of our proposed system using a large cohort containing 646 breast tissue biopsies. Our evaluations show that the proposed system achieves an area under ROC of 0.92, demonstrating the discriminative power of previously neglected tumor-associated stroma as a diagnostic biomarker.","Sun, 19 Feb 2017 21:59:43 UTC (1,082 KB)"
"1600","A Survey on Deep Learning in Medical Image Analysis","Geert Litjens, Thijs Kooi, Babak Ehteshami Bejnordi, Arnaud Arindra Adiyoso Setio, Francesco Ciompi, Mohsen Ghafoorian, Jeroen A.W.M. van der Laak, Bram van Ginneken, Clara I. Sanchez","Computer Vision and Pattern Recognition (cs.CV)","Deep learning algorithms, in particular convolutional networks, have rapidly become a methodology of choice for analyzing medical images. This paper reviews the major deep learning concepts pertinent to medical image analysis and summarizes over 300 contributions to the field, most of which appeared in the last year. We survey the use of deep learning for image classification, object detection, segmentation, registration, and other tasks and provide concise overviews of studies per application area. Open challenges and directions for future research are discussed.","Sun, 19 Feb 2017 13:02:28 UTC (4,745 KB)[v2] Sun, 4 Jun 2017 10:21:55 UTC (4,756 KB)"
"1601","Cloud-based Deep Learning of Big EEG Data for Epileptic Seizure Prediction","Mohammad-Parsa Hosseini, Hamid Soltanian-Zadeh, Kost Elisevich, Dario Pompili","Machine Learning (cs.LG); Machine Learning (stat.ML)","Developing a Brain-Computer Interface~(BCI) for seizure prediction can help epileptic patients have a better quality of life. However, there are many difficulties and challenges in developing such a system as a real-life support for patients. Because of the nonstationary nature of EEG signals, normal and seizure patterns vary across different patients. Thus, finding a group of manually extracted features for the prediction task is not practical. Moreover, when using implanted electrodes for brain recording massive amounts of data are produced. This big data calls for the need for safe storage and high computational resources for real-time processing. To address these challenges, a cloud-based BCI system for the analysis of this big EEG data is presented. First, a dimensionality-reduction technique is developed to increase classification accuracy as well as to decrease the communication bandwidth and computation time. Second, following a deep-learning approach, a stacked autoencoder is trained in two steps for unsupervised feature extraction and classification. Third, a cloud-computing solution is proposed for real-time analysis of big EEG data. The results on a benchmark clinical dataset illustrate the superiority of the proposed patient-specific BCI as an alternative method and its expected usefulness in real-life support of epilepsy patients.","Fri, 17 Feb 2017 00:00:38 UTC (150 KB)"
"1602","Automatic Handgun Detection Alarm in Videos Using Deep Learning","Roberto Olmos, Siham Tabik, Francisco Herrera","Computer Vision and Pattern Recognition (cs.CV)","Current surveillance and control systems still require human supervision and intervention. This work presents a novel automatic handgun detection system in videos appropriate for both, surveillance and control purposes. We reformulate this detection problem into the problem of minimizing false positives and solve it by building the key training data-set guided by the results of a deep Convolutional Neural Networks (CNN) classifier, then assessing the best classification model under two approaches, the sliding window approach and region proposal approach. The most promising results are obtained by Faster R-CNN based model trained on our new database. The best detector show a high potential even in low quality youtube videos and provides satisfactory results as automatic alarm system. Among 30 scenes, it successfully activates the alarm after five successive true positives in less than 0.2 seconds, in 27 scenes. We also define a new metric, Alarm Activation per Interval (AApI), to assess the performance of a detection model as an automatic detection system in videos.","Thu, 16 Feb 2017 20:30:33 UTC (3,007 KB)"
"1603","Understanding Deep Learning Performance through an Examination of Test Set Difficulty: A Psychometric Case Study","John P. Lalor, Hao Wu, Tsendsuren Munkhdalai, Hong Yu","Computation and Language (cs.CL)","Interpreting the performance of deep learning models beyond test set accuracy is challenging. Characteristics of individual data points are often not considered during evaluation, and each data point is treated equally. We examine the impact of a test set question's difficulty to determine if there is a relationship between difficulty and performance. We model difficulty using well-studied psychometric methods on human response patterns. Experiments on Natural Language Inference (NLI) and Sentiment Analysis (SA) show that the likelihood of answering a question correctly is impacted by the question's difficulty. As DNNs are trained with more data, easy examples are learned more quickly than hard examples.","Wed, 15 Feb 2017 23:04:09 UTC (76 KB)[v2] Thu, 29 Jun 2017 00:23:16 UTC (194 KB)[v3] Fri, 7 Sep 2018 18:20:46 UTC (2,434 KB)"
"1604","Distributed deep learning on edge-devices: feasibility via adaptive compression","Corentin Hardy, Erwan Le Merrer, Bruno Sericola","Machine Learning (cs.LG)","A large portion of data mining and analytic services use modern machine learning techniques, such as deep learning. The state-of-the-art results by deep learning come at the price of an intensive use of computing resources. The leading frameworks (e.g., TensorFlow) are executed on GPUs or on high-end servers in datacenters. On the other end, there is a proliferation of personal devices with possibly free CPU cycles; this can enable services to run in users' homes, embedding machine learning operations. In this paper, we ask the following question: Is distributed deep learning computation on WAN connected devices feasible, in spite of the traffic caused by learning tasks? We show that such a setup rises some important challenges, most notably the ingress traffic that the servers hosting the up-to-date model have to sustain. In order to reduce this stress, we propose adaComp, a novel algorithm for compressing worker updates to the model on the server. Applicable to stochastic gradient descent based approaches, it combines efficient gradient selection and learning rate modulation. We then experiment and measure the impact of compression, device heterogeneity and reliability on the accuracy of learned models, with an emulator platform that embeds TensorFlow into Linux containers. We report a reduction of the total amount of data sent by workers to the server by two order of magnitude (e.g., 191-fold reduction for a convolutional network on the MNIST dataset), when compared to a standard asynchronous stochastic gradient descent, while preserving model accuracy.","Wed, 15 Feb 2017 16:57:24 UTC (1,431 KB)[v2] Mon, 6 Nov 2017 12:54:36 UTC (503 KB)"
"1605","Handwritten Arabic Numeral Recognition using Deep Learning Neural Networks","Akm Ashiquzzaman, Abdul Kawsar Tushar","Computer Vision and Pattern Recognition (cs.CV)","Handwritten character recognition is an active area of research with applications in numerous fields. Past and recent works in this field have concentrated on various languages. Arabic is one language where the scope of research is still widespread, with it being one of the most popular languages in the world and being syntactically different from other major languages. Das et al. \cite{DBLP:journals/corr/abs-1003-1891} has pioneered the research for handwritten digit recognition in Arabic. In this paper, we propose a novel algorithm based on deep learning neural networks using appropriate activation function and regularization layer, which shows significantly improved accuracy compared to the existing Arabic numeral recognition methods. The proposed model gives 97.4 percent accuracy, which is the recorded highest accuracy of the dataset used in the experiment. We also propose a modification of the method described in \cite{DBLP:journals/corr/abs-1003-1891}, where our method scores identical accuracy as that of \cite{DBLP:journals/corr/abs-1003-1891}, with the value of 93.8 percent.","Wed, 15 Feb 2017 16:06:15 UTC (318 KB)"
"1606","A deep learning model integrating FCNNs and CRFs for brain tumor segmentation","Xiaomei Zhao, Yihong Wu, Guidong Song, Zhenye Li, Yazhuo Zhang, Yong Fan","Computer Vision and Pattern Recognition (cs.CV)","Accurate and reliable brain tumor segmentation is a critical component in cancer diagnosis, treatment planning, and treatment outcome evaluation. Build upon successful deep learning techniques, a novel brain tumor segmentation method is developed by integrating fully convolutional neural networks (FCNNs) and Conditional Random Fields (CRFs) in a unified framework to obtain segmentation results with appearance and spatial consistency. We train a deep learning based segmentation model using 2D image patches and image slices in following steps: 1) training FCNNs using image patches; 2) training CRFs as Recurrent Neural Networks (CRF-RNN) using image slices with parameters of FCNNs fixed; and 3) fine-tuning the FCNNs and the CRF-RNN using image slices. Particularly, we train 3 segmentation models using 2D image patches and slices obtained in axial, coronal and sagittal views respectively, and combine them to segment brain tumors using a voting based fusion strategy. Our method could segment brain images slice-by-slice, much faster than those based on image patches. We have evaluated our method based on imaging data provided by the Multimodal Brain Tumor Image Segmentation Challenge (BRATS) 2013, BRATS 2015 and BRATS 2016. The experimental results have demonstrated that our method could build a segmentation model with Flair, T1c, and T2 scans and achieve competitive performance as those built with Flair, T1, T1c, and T2 scans.","Wed, 15 Feb 2017 10:06:13 UTC (1,426 KB)[v2] Wed, 1 Mar 2017 00:56:42 UTC (1,325 KB)[v3] Fri, 10 Nov 2017 02:49:49 UTC (904 KB)"
"1607","Transfer Deep Learning for Low-Resource Chinese Word Segmentation with a Novel Neural Network","Jingjing Xu, Xu Sun","Computation and Language (cs.CL)","Recent studies have shown effectiveness in using neural networks for Chinese word segmentation. However, these models rely on large-scale data and are less effective for low-resource datasets because of insufficient training data. We propose a transfer learning method to improve low-resource word segmentation by leveraging high-resource corpora. First, we train a teacher model on high-resource corpora and then use the learned knowledge to initialize a student model. Second, a weighted data similarity method is proposed to train the student model on low-resource data. Experiment results show that our work significantly improves the performance on low-resource datasets: 2.3% and 1.5% F-score on PKU and CTB datasets. Furthermore, this paper achieves state-of-the-art results: 96.1%, and 96.2% F-score on PKU and CTB datasets.","Wed, 15 Feb 2017 07:37:55 UTC (287 KB)[v2] Thu, 16 Feb 2017 06:16:09 UTC (287 KB)[v3] Sun, 7 May 2017 12:53:13 UTC (227 KB)[v4] Wed, 17 May 2017 01:52:45 UTC (227 KB)[v5] Thu, 14 Sep 2017 11:10:13 UTC (790 KB)"
"1608","Small Boxes Big Data: A Deep Learning Approach to Optimize Variable Sized Bin Packing","Feng Mao, Edgar Blanco, Mingang Fu, Rohit Jain, Anurag Gupta, Sebastien Mancel, Rong Yuan, Stephen Guo, Sai Kumar, Yayang Tian","Machine Learning (cs.LG); Machine Learning (stat.ML)","Bin Packing problems have been widely studied because of their broad applications in different domains. Known as a set of NP-hard problems, they have different vari- ations and many heuristics have been proposed for obtaining approximate solutions. Specifically, for the 1D variable sized bin packing problem, the two key sets of optimization heuristics are the bin assignment and the bin allocation. Usually the performance of a single static optimization heuristic can not beat that of a dynamic one which is tailored for each bin packing instance. Building such an adaptive system requires modeling the relationship between bin features and packing perform profiles. The primary drawbacks of traditional AI machine learnings for this task are the natural limitations of feature engineering, such as the curse of dimensionality and feature selection quality. We introduce a deep learning approach to overcome the drawbacks by applying a large training data set, auto feature selection and fast, accurate labeling. We show in this paper how to build such a system by both theoretical formulation and engineering practices. Our prediction system achieves up to 89% training accuracy and 72% validation accuracy to select the best heuristic that can generate a better quality bin packing solution.","Tue, 14 Feb 2017 22:59:32 UTC (560 KB)"
"1609","On the Relevance of Auditory-Based Gabor Features for Deep Learning in Automatic Speech Recognition","Angel Mario Castro Martinez, Sri Harish Mallidi, Bernd T. Meyer","Computation and Language (cs.CL)","Previous studies support the idea of merging auditory-based Gabor features with deep learning architectures to achieve robust automatic speech recognition, however, the cause behind the gain of such combination is still unknown. We believe these representations provide the deep learning decoder with more discriminable cues. Our aim with this paper is to validate this hypothesis by performing experiments with three different recognition tasks (Aurora 4, CHiME 2 and CHiME 3) and assess the discriminability of the information encoded by Gabor filterbank features. Additionally, to identify the contribution of low, medium and high temporal modulation frequencies subsets of the Gabor filterbank were used as features (dubbed LTM, MTM and HTM respectively). With temporal modulation frequencies between 16 and 25 Hz, HTM consistently outperformed the remaining ones in every condition, highlighting the robustness of these representations against channel distortions, low signal-to-noise ratios and acoustically challenging real-life scenarios with relative improvements from 11 to 56% against a Mel-filterbank-DNN baseline. To explain the results, a measure of similarity between phoneme classes from DNN activations is proposed and linked to their acoustic properties. We find this measure to be consistent with the observed error rates and highlight specific differences on phoneme level to pinpoint the benefit of the proposed features.","Tue, 14 Feb 2017 18:46:47 UTC (730 KB)"
"1610","Semi-Supervised Deep Learning for Monocular Depth Map Prediction","Yevhen Kuznietsov, Jorg Stuckler, Bastian Leibe","Computer Vision and Pattern Recognition (cs.CV)","Supervised deep learning often suffers from the lack of sufficient training data. Specifically in the context of monocular depth map prediction, it is barely possible to determine dense ground truth depth images in realistic dynamic outdoor environments. When using LiDAR sensors, for instance, noise is present in the distance measurements, the calibration between sensors cannot be perfect, and the measurements are typically much sparser than the camera images. In this paper, we propose a novel approach to depth map prediction from monocular images that learns in a semi-supervised way. While we use sparse ground-truth depth for supervised learning, we also enforce our deep network to produce photoconsistent dense depth maps in a stereo setup using a direct image alignment loss. In experiments we demonstrate superior performance in depth map prediction from single images compared to the state-of-the-art methods.","Thu, 9 Feb 2017 05:08:22 UTC (5,104 KB)[v2] Fri, 17 Feb 2017 16:57:12 UTC (5,105 KB)[v3] Tue, 9 May 2017 21:58:52 UTC (12,232 KB)"
"1611","Deep Learning with Dynamic Computation Graphs","Moshe Looks, Marcello Herreshoff, DeLesley Hutchins, Peter Norvig","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG); Machine Learning (stat.ML)","Neural networks that compute over graph structures are a natural fit for problems in a variety of domains, including natural language (parse trees) and cheminformatics (molecular graphs). However, since the computation graph has a different shape and size for every input, such networks do not directly support batched training or inference. They are also difficult to implement in popular deep learning libraries, which are based on static data-flow graphs. We introduce a technique called dynamic batching, which not only batches together operations between different input graphs of dissimilar shape, but also between different nodes within a single input graph. The technique allows us to create static graphs, using popular libraries, that emulate dynamic computation graphs of arbitrary shape and size. We further present a high-level library of compositional blocks that simplifies the creation of dynamic graph models. Using the library, we demonstrate concise and batch-wise parallel implementations for a variety of models from the literature.","Tue, 7 Feb 2017 19:59:43 UTC (28 KB)[v2] Wed, 22 Feb 2017 04:43:02 UTC (28 KB)"
"1612","An Integrated Simulator and Dataset that Combines Grasping and Vision for Deep Learning","Matthew Veres, Medhat Moussa, Graham W. Taylor","Robotics (cs.RO); Machine Learning (stat.ML)","Deep learning is an established framework for learning hierarchical data representations. While compute power is in abundance, one of the main challenges in applying this framework to robotic grasping has been obtaining the amount of data needed to learn these representations, and structuring the data to the task at hand. Among contemporary approaches in the literature, we highlight key properties that have encouraged the use of deep learning techniques, and in this paper, detail our experience in developing a simulator for collecting cylindrical precision grasps of a multi-fingered dexterous robotic hand.","Tue, 7 Feb 2017 17:16:15 UTC (1,061 KB)[v2] Mon, 17 Apr 2017 22:22:46 UTC (1,101 KB)"
"1613","Development of JavaScript-based deep learning platform and application to distributed training","Masatoshi Hidaka, Ken Miura, Tatsuya Harada","Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC)","Deep learning is increasingly attracting attention for processing big data. Existing frameworks for deep learning must be set up to specialized computer systems. Gaining sufficient computing resources therefore entails high costs of deployment and maintenance. In this work, we implement a matrix library and deep learning framework that uses JavaScript. It can run on web browsers operating on ordinary personal computers and smartphones. Using JavaScript, deep learning can be accomplished in widely diverse environments without the necessity for software installation. Using GPGPU from WebCL framework, our framework can train large scale convolutional neural networks such as VGGNet and ResNet. In the experiments, we demonstrate their practicality by training VGGNet in a distributed manner using web browsers as the client.","Tue, 7 Feb 2017 02:02:08 UTC (823 KB)[v2] Thu, 16 Feb 2017 03:30:49 UTC (823 KB)[v3] Mon, 27 Mar 2017 09:28:06 UTC (823 KB)"
"1614","Deep Learning Models of the Retinal Response to Natural Scenes","Lane T. McIntosh, Niru Maheswaranathan, Aran Nayebi, Surya Ganguli, Stephen A. Baccus","Neurons and Cognition (q-bio.NC); Machine Learning (stat.ML)","A central challenge in neuroscience is to understand neural computations and circuit mechanisms that underlie the encoding of ethologically relevant, natural stimuli. In multilayered neural circuits, nonlinear processes such as synaptic transmission and spiking dynamics present a significant obstacle to the creation of accurate computational models of responses to natural stimuli. Here we demonstrate that deep convolutional neural networks (CNNs) capture retinal responses to natural scenes nearly to within the variability of a cell's response, and are markedly more accurate than linear-nonlinear (LN) models and Generalized Linear Models (GLMs). Moreover, we find two additional surprising properties of CNNs: they are less susceptible to overfitting than their LN counterparts when trained on small amounts of data, and generalize better when tested on stimuli drawn from a different distribution (e.g. between natural scenes and white noise). Examination of trained CNNs reveals several properties. First, a richer set of feature maps is necessary for predicting the responses to natural scenes compared to white noise. Second, temporally precise responses to slowly varying inputs originate from feedforward inhibition, similar to known retinal mechanisms. Third, the injection of latent noise sources in intermediate layers enables our model to capture the sub-Poisson spiking variability observed in retinal ganglion cells. Fourth, augmenting our CNNs with recurrent lateral connections enables them to capture contrast adaptation as an emergent property of accurately describing retinal responses to natural scenes. These methods can be readily generalized to other sensory modalities and stimulus ensembles. Overall, this work demonstrates that CNNs not only accurately capture sensory circuit responses to natural scenes, but also yield information about the circuit's internal structure and function.","Mon, 6 Feb 2017 23:48:19 UTC (2,126 KB)"
"1615","Search Intelligence: Deep Learning For Dominant Category Prediction","Zeeshan Khawar Malik, Mo Kobrosli, Peter Maas","Information Retrieval (cs.IR); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep Neural Networks, and specifically fully-connected convolutional neural networks are achieving remarkable results across a wide variety of domains. They have been trained to achieve state-of-the-art performance when applied to problems such as speech recognition, image classification, natural language processing and bioinformatics. Most of these deep learning models when applied to classification employ the softmax activation function for prediction and aim to minimize cross-entropy loss. In this paper, we have proposed a supervised model for dominant category prediction to improve search recall across all eBay classifieds platforms. The dominant category label for each query in the last 90 days is first calculated by summing the total number of collaborative clicks among all categories. The category having the highest number of collaborative clicks for the given query will be considered its dominant category. Second, each query is transformed to a numeric vector by mapping each unique word in the query document to a unique integer value; all padded to equal length based on the maximum document length within the pre-defined vocabulary size. A fully-connected deep convolutional neural network (CNN) is then applied for classification. The proposed model achieves very high classification accuracy compared to other state-of-the-art machine learning techniques.","Mon, 6 Feb 2017 17:27:12 UTC (123 KB)"
"1616","Deep learning and the Schrodinger equation","Kyle Mills, Michael Spanner, Isaac Tamblyn","Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)","We have trained a deep (convolutional) neural network to predict the ground-state energy of an electron in four classes of confining two-dimensional electrostatic potentials. On randomly generated potentials, for which there is no analytic form for either the potential or the ground-state energy, the neural network model was able to predict the ground-state energy to within chemical accuracy, with a median absolute error of 1.49 mHa. We also investigate the performance of the model in predicting other quantities such as the kinetic energy and the first excited-state energy of random potentials.","Sun, 5 Feb 2017 02:58:58 UTC (2,173 KB)[v2] Thu, 8 Jun 2017 20:39:27 UTC (2,358 KB)[v3] Fri, 3 Nov 2017 13:10:51 UTC (4,080 KB)"
"1617","Deep Learning with Low Precision by Half-wave Gaussian Quantization","Zhaowei Cai, Xiaodong He, Jian Sun, Nuno Vasconcelos","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","The problem of quantizing the activations of a deep neural network is considered. An examination of the popular binary quantization approach shows that this consists of approximating a classical non-linearity, the hyperbolic tangent, by two functions: a piecewise constant sign function, which is used in feedforward network computations, and a piecewise linear hard tanh function, used in the backpropagation step during network learning. The problem of approximating the ReLU non-linearity, widely used in the recent deep learning literature, is then considered. An half-wave Gaussian quantizer (HWGQ) is proposed for forward approximation and shown to have efficient implementation, by exploiting the statistics of of network activations and batch normalization operations commonly used in the literature. To overcome the problem of gradient mismatch, due to the use of different forward and backward approximations, several piece-wise backward approximators are then investigated. The implementation of the resulting quantized network, denoted as HWGQ-Net, is shown to achieve much closer performance to full precision networks, such as AlexNet, ResNet, GoogLeNet and VGG-Net, than previously available low-precision networks, with 1-bit binary weights and 2-bit quantized activations.","Fri, 3 Feb 2017 10:11:40 UTC (454 KB)"
"1618","An Introduction to Deep Learning for the Physical Layer","Timothy J. O'Shea, Jakob Hoydis","Information Theory (cs.IT); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)","We present and discuss several novel applications of deep learning for the physical layer. By interpreting a communications system as an autoencoder, we develop a fundamental new way to think about communications system design as an end-to-end reconstruction task that seeks to jointly optimize transmitter and receiver components in a single process. We show how this idea can be extended to networks of multiple transmitters and receivers and present the concept of radio transformer networks as a means to incorporate expert domain knowledge in the machine learning model. Lastly, we demonstrate the application of convolutional neural networks on raw IQ samples for modulation classification which achieves competitive accuracy with respect to traditional schemes relying on expert features. The paper is concluded with a discussion of open challenges and areas for future investigation.","Thu, 2 Feb 2017 21:30:08 UTC (350 KB)[v2] Tue, 11 Jul 2017 21:57:19 UTC (1,544 KB)"
"1619","Symbolic, Distributed and Distributional Representations for Natural Language Processing in the Era of Deep Learning: a Survey","Lorenzo Ferrone, Fabio Massimo Zanzotto","Computation and Language (cs.CL)","Natural language and symbols are intimately correlated. Recent advances in machine learning (ML) and in natural language processing (NLP) seem to contradict the above intuition: symbols are fading away, erased by vectors or tensors called distributed and distributional representations. However, there is a strict link between distributed/distributional representations and symbols, being the first an approximation of the second. A clearer understanding of the strict link between distributed/distributional representations and symbols will certainly lead to radically new deep learning networks. In this paper we make a survey that aims to draw the link between symbolic representations and distributed/distributional representations. This is the right time to revitalize the area of interpreting how symbols are represented inside neural networks.","Thu, 2 Feb 2017 17:53:29 UTC (129 KB)"
"1620","HashNet: Deep Learning to Hash by Continuation","Zhangjie Cao, Mingsheng Long, Jianmin Wang, Philip S. Yu","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)","Learning to hash has been widely applied to approximate nearest neighbor search for large-scale multimedia retrieval, due to its computation efficiency and retrieval quality. Deep learning to hash, which improves retrieval quality by end-to-end representation learning and hash encoding, has received increasing attention recently. Subject to the ill-posed gradient difficulty in the optimization with sign activations, existing deep learning to hash methods need to first learn continuous representations and then generate binary hash codes in a separated binarization step, which suffer from substantial loss of retrieval quality. This work presents HashNet, a novel deep architecture for deep learning to hash by continuation method with convergence guarantees, which learns exactly binary hash codes from imbalanced similarity data. The key idea is to attack the ill-posed gradient problem in optimizing deep networks with non-smooth binary activations by continuation method, in which we begin from learning an easier network with smoothed activation function and let it evolve during the training, until it eventually goes back to being the original, difficult to optimize, deep network with the sign activation function. Comprehensive empirical evidence shows that HashNet can generate exactly binary hash codes and yield state-of-the-art multimedia retrieval performance on standard benchmarks.","Thu, 2 Feb 2017 17:29:24 UTC (2,794 KB)[v2] Sun, 23 Apr 2017 22:14:09 UTC (3,001 KB)[v3] Thu, 20 Jul 2017 14:59:45 UTC (1,900 KB)[v4] Sat, 29 Jul 2017 17:55:50 UTC (1,900 KB)"
"1621","Deep Learning the Indus Script","Satish Palaniappan, Ronojoy Adhikari","Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Machine Learning (cs.LG)","Standardized corpora of undeciphered scripts, a necessary starting point for computational epigraphy, requires laborious human effort for their preparation from raw archaeological records. Automating this process through machine learning algorithms can be of significant aid to epigraphical research. Here, we take the first steps in this direction and present a deep learning pipeline that takes as input images of the undeciphered Indus script, as found in archaeological artifacts, and returns as output a string of graphemes, suitable for inclusion in a standard corpus. The image is first decomposed into regions using Selective Search and these regions are classified as containing textual and/or graphical information using a convolutional neural network. Regions classified as potentially containing text are hierarchically merged and trimmed to remove non-textual information. The remaining textual part of the image is segmented using standard image processing techniques to isolate individual graphemes. This set is finally passed to a second convolutional neural network to classify the graphemes, based on a standard corpus. The classifier can identify the presence or absence of the most frequent Indus grapheme, the ""jar"" sign, with an accuracy of 92%. Our results demonstrate the great potential of deep learning approaches in computational epigraphy and, more generally, in the digital humanities.","Thu, 2 Feb 2017 01:56:22 UTC (9,254 KB)"
"1622","Mixed Low-precision Deep Learning Inference using Dynamic Fixed Point","Naveen Mellempudi, Abhisek Kundu, Dipankar Das, Dheevatsa Mudigere, Bharat Kaul","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","We propose a cluster-based quantization method to convert pre-trained full precision weights into ternary weights with minimal impact on the accuracy. In addition, we also constrain the activations to 8-bits thus enabling sub 8-bit full integer inference pipeline. Our method uses smaller clusters of N filters with a common scaling factor to minimize the quantization loss, while also maximizing the number of ternary operations. We show that with a cluster size of N=4 on Resnet-101, can achieve 71.8% TOP-1 accuracy, within 6% of the best full precision results while replacing ~85% of all multiplications with 8-bit accumulations. Using the same method with 4-bit weights achieves 76.3% TOP-1 accuracy which within 2% of the full precision result. We also study the impact of the size of the cluster on both performance and accuracy, larger cluster sizes N=64 can replace ~98% of the multiplications with ternary operations but introduces significant drop in accuracy which necessitates fine tuning the parameters with retraining the network at lower precision. To address this we have also trained low-precision Resnet-50 with 8-bit activations and ternary weights by pre-initializing the network with full precision weights and achieve 68.9% TOP-1 accuracy within 4 additional epochs. Our final quantized model can run on a full 8-bit compute pipeline, with a potential 16x improvement in performance compared to baseline full-precision models.","Tue, 31 Jan 2017 10:28:37 UTC (70 KB)[v2] Wed, 1 Feb 2017 04:09:31 UTC (70 KB)"
"1623","SenseGen: A Deep Learning Architecture for Synthetic Sensor Data Generation","Moustafa Alzantot, Supriyo Chakraborty, Mani B. Srivastava","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)","Our ability to synthesize sensory data that preserves specific statistical properties of the real data has had tremendous implications on data privacy and big data analytics. The synthetic data can be used as a substitute for selective real data segments,that are sensitive to the user, thus protecting privacy and resulting in improved analytics.However, increasingly adversarial roles taken by data recipients such as mobile apps, or other cloud-based analytics services, mandate that the synthetic data, in addition to preserving statistical properties, should also be difficult to distinguish from the real data. Typically, visual inspection has been used as a test to distinguish between datasets. But more recently, sophisticated classifier models (discriminators), corresponding to a set of events, have also been employed to distinguish between synthesized and real data. The model operates on both datasets and the respective event outputs are compared for consistency. In this paper, we take a step towards generating sensory data that can pass a deep learning based discriminator model test, and make two specific contributions: first, we present a deep learning based architecture for synthesizing sensory data. This architecture comprises of a generator model, which is a stack of multiple Long-Short-Term-Memory (LSTM) networks and a Mixture Density Network. second, we use another LSTM network based discriminator model for distinguishing between the true and the synthesized data. Using a dataset of accelerometer traces, collected using smartphones of users doing their daily activities, we show that the deep learning based discriminator model can only distinguish between the real and synthesized traces with an accuracy in the neighborhood of 50%.","Tue, 31 Jan 2017 01:59:58 UTC (483 KB)"
"1624","Deep-learning Top Taggers or The End of QCD?","Gregor Kasieczka, Tilman Plehn, Michael Russell, Torben Schell","High Energy Physics - Phenomenology (hep-ph)","Machine learning based on convolutional neural networks can be used to study jet images from the LHC. Top tagging in fat jets offers a well-defined framework to establish our DeepTop approach and compare its performance to QCD-based top taggers. We first optimize a network architecture to identify top quarks in Monte Carlo simulations of the Standard Model production channel. Using standard fat jets we then compare its performance to a multivariate QCD-based top tagger. We find that both approaches lead to comparable performance, establishing convolutional networks as a promising new approach for multivariate hypothesis-based top tagging.","Mon, 30 Jan 2017 19:10:27 UTC (2,272 KB)[v2] Tue, 16 May 2017 10:08:49 UTC (2,382 KB)"
"1625","Deep learning based subdivision approach for large scale macromolecules structure recovery from electron cryo tomograms","Min Xu, Xiaoqi Chai, Hariank Muthakana, Xiaodan Liang, Ge Yang, Tzviya Zeev-Ben-Mordehai, Eric Xing","Quantitative Methods (q-bio.QM)","Motivation: Cellular Electron CryoTomography (CECT) enables 3D visualization of cellular organization at near-native state and in sub-molecular resolution, making it a powerful tool for analyzing structures of macromolecular complexes and their spatial organizations inside single cells. However, high degree of structural complexity together with practical imaging limitations make the systematic de novo discovery of structures within cells challenging. It would likely require averaging and classifying millions of subtomograms potentially containing hundreds of highly heterogeneous structural classes. Although it is no longer difficult to acquire CECT data containing such amount of subtomograms due to advances in data acquisition automation, existing computational approaches have very limited scalability or discrimination ability, making them incapable of processing such amount of data. Results: To complement existing approaches, in this paper we propose a new approach for subdividing subtomograms into smaller but relatively homogeneous subsets. The structures in these subsets can then be separately recovered using existing computation intensive methods. Our approach is based on supervised structural feature extraction using deep learning, in combination with unsupervised clustering and reference-free classification. Our experiments show that, compared to existing unsupervised rotation invariant feature and pose-normalization based approaches, our new approach achieves significant improvements in both discrimination ability and scalability. More importantly, our new approach is able to discover new structural classes and recover structures that do not exist in training data.","Sun, 29 Jan 2017 17:26:36 UTC (1,620 KB)"
"1626","Face Detection using Deep Learning: An Improved Faster RCNN Approach","Xudong Sun, Pengcheng Wu, Steven C.H. Hoi","Computer Vision and Pattern Recognition (cs.CV)","In this report, we present a new face detection scheme using deep learning and achieve the state-of-the-art detection performance on the well-known FDDB face detetion benchmark evaluation. In particular, we improve the state-of-the-art faster RCNN framework by combining a number of strategies, including feature concatenation, hard negative mining, multi-scale training, model pretraining, and proper calibration of key parameters. As a consequence, the proposed scheme obtained the state-of-the-art face detection performance, making it the best model in terms of ROC curves among all the published methods on the FDDB benchmark.","Sat, 28 Jan 2017 13:33:24 UTC (1,891 KB)"
"1627","On Deep Learning-Based Channel Decoding","Tobias Gruber, Sebastian Cammerer, Jakob Hoydis, Stephan ten Brink","Information Theory (cs.IT)","We revisit the idea of using deep neural networks for one-shot decoding of random and structured codes, such as polar codes. Although it is possible to achieve maximum a posteriori (MAP) bit error rate (BER) performance for both code families and for short codeword lengths, we observe that (i) structured codes are easier to learn and (ii) the neural network is able to generalize to codewords that it has never seen during training for structured, but not for random codes. These results provide some evidence that neural networks can learn a form of decoding algorithm, rather than only a simple classifier. We introduce the metric normalized validation error (NVE) in order to further investigate the potential and limitations of deep learning-based decoding with respect to performance and complexity.","Thu, 26 Jan 2017 15:24:57 UTC (295 KB)"
"1628","FPGA Architecture for Deep Learning and its application to Planetary Robotics","Pranay Gankidi, Jekan Thangavelautham","Machine Learning (cs.LG); Instrumentation and Methods for Astrophysics (astro-ph.IM); Robotics (cs.RO)","Autonomous control systems onboard planetary rovers and spacecraft benefit from having cognitive capabilities like learning so that they can adapt to unexpected situations in-situ. Q-learning is a form of reinforcement learning and it has been efficient in solving certain class of learning problems. However, embedded systems onboard planetary rovers and spacecraft rarely implement learning algorithms due to the constraints faced in the field, like processing power, chip size, convergence rate and costs due to the need for radiation hardening. These challenges present a compelling need for a portable, low-power, area efficient hardware accelerator to make learning algorithms practical onboard space hardware. This paper presents a FPGA implementation of Q-learning with Artificial Neural Networks (ANN). This method matches the massive parallelism inherent in neural network software with the fine-grain parallelism of an FPGA hardware thereby dramatically reducing processing time. Mars Science Laboratory currently uses Xilinx-Space-grade Virtex FPGA devices for image processing, pyrotechnic operation control and obstacle avoidance. We simulate and program our architecture on a Xilinx Virtex 7 FPGA. The architectural implementation for a single neuron Q-learning and a more complex Multilayer Perception (MLP) Q-learning accelerator has been demonstrated. The results show up to a 43-fold speed up by Virtex 7 FPGAs compared to a conventional Intel i5 2.3 GHz CPU. Finally, we simulate the proposed architecture using the Symphony simulator and compiler from Xilinx, and evaluate the performance and power consumption.","Thu, 26 Jan 2017 01:52:11 UTC (657 KB)"
"1629","Neurostream: Scalable and Energy Efficient Deep Learning with Smart Memory Cubes","Erfan Azarkhish, Davide Rossi, Igor Loi, Luca Benini","Hardware Architecture (cs.AR); Emerging Technologies (cs.ET)","High-performance computing systems are moving towards 2.5D and 3D memory hierarchies, based on High Bandwidth Memory (HBM) and Hybrid Memory Cube (HMC) to mitigate the main memory bottlenecks. This trend is also creating new opportunities to revisit near-memory computation. In this paper, we propose a flexible processor-in-memory (PIM) solution for scalable and energy-efficient execution of deep convolutional networks (ConvNets), one of the fastest-growing workloads for servers and high-end embedded systems. Our codesign approach consists of a network of Smart Memory Cubes (modular extensions to the standard HMC) each augmented with a many-core PIM platform called NeuroCluster. NeuroClusters have a modular design based on NeuroStream coprocessors (for Convolution-intensive computations) and general-purpose RISCV cores. In addition, a DRAM-friendly tiling mechanism and a scalable computation paradigm are presented to efficiently harness this computational capability with a very low programming effort. NeuroCluster occupies only 8% of the total logic-base (LoB) die area in a standard HMC and achieves an average performance of 240 GFLOPS for complete execution of full-featured state-of-the-art (SoA) ConvNets within a power budget of 2.5W. Overall 11 W is consumed in a single SMC device, with 22.5 GFLOPS/W energy-efficiency which is 3.5X better than the best GPU implementations in similar technologies. The minor increase in system-level power and the negligible area increase make our PIM system a cost-effective and energy efficient solution, easily scalable to 955 GFLOPS with a small network of just four SMCs.","Mon, 23 Jan 2017 14:44:47 UTC (4,662 KB)[v2] Wed, 7 Jun 2017 15:43:01 UTC (4,431 KB)[v3] Sun, 24 Sep 2017 17:47:10 UTC (4,784 KB)"
"1630","Deep learning for studies of galaxy morphology","D. Tuccillo, M. Huertas-Company, E. Decenciere, S. Velasco-Forero","Instrumentation and Methods for Astrophysics (astro-ph.IM); Astrophysics of Galaxies (astro-ph.GA)","Establishing accurate morphological measurements of galaxies in a reasonable amount of time for future big-data surveys such as EUCLID, the Large Synoptic Survey Telescope or the Wide Field Infrared Survey Telescope is a challenge. Because of its high level of abstraction with little human intervention, deep learning appears to be a promising approach. Deep learning is a rapidly growing discipline that models high-level patterns in data as complex multilayered networks. In this work we test the ability of deep convolutional networks to provide parametric properties of Hubble Space Telescope like galaxies (half-light radii, Sersic indices, total flux etc..). We simulate a set of galaxies including point spread function and realistic noise from the CANDELS survey and try to recover the main galaxy parameters using deep-learning. We com- pare the results with the ones obtained with the commonly used profile fitting based software GALFIT. This way showing that with our method we obtain results at least equally good as the ones obtained with GALFIT but, once trained, with a factor 5 hundred time faster.","Fri, 20 Jan 2017 20:20:23 UTC (614 KB)"
"1631","Deep Learning Features at Scale for Visual Place Recognition","Zetao Chen, Adam Jacobson, Niko Sunderhauf, Ben Upcroft, Lingqiao Liu, Chunhua Shen, Ian Reid, Michael Milford","Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","The success of deep learning techniques in the computer vision domain has triggered a range of initial investigations into their utility for visual place recognition, all using generic features from networks that were trained for other types of recognition tasks. In this paper, we train, at large scale, two CNN architectures for the specific place recognition task and employ a multi-scale feature encoding method to generate condition- and viewpoint-invariant features. To enable this training to occur, we have developed a massive Specific PlacEs Dataset (SPED) with hundreds of examples of place appearance change at thousands of different places, as opposed to the semantic place type datasets currently available. This new dataset enables us to set up a training regime that interprets place recognition as a classification problem. We comprehensively evaluate our trained networks on several challenging benchmark place recognition datasets and demonstrate that they achieve an average 10% increase in performance over other place recognition algorithms and pre-trained CNNs. By analyzing the network responses and their differences from pre-trained networks, we provide insights into what a network learns when training for place recognition, and what these results signify for future research in this area.","Wed, 18 Jan 2017 16:28:03 UTC (811 KB)"
"1632","Fusing Deep Learned and Hand-Crafted Features of Appearance, Shape, and Dynamics for Automatic Pain Estimation","Joy Egede, Michel Valstar, Brais Martinez","Computer Vision and Pattern Recognition (cs.CV)","Automatic continuous time, continuous value assessment of a patient's pain from face video is highly sought after by the medical profession. Despite the recent advances in deep learning that attain impressive results in many domains, pain estimation risks not being able to benefit from this due to the difficulty in obtaining data sets of considerable size. In this work we propose a combination of hand-crafted and deep-learned features that makes the most of deep learning techniques in small sample settings. Encoding shape, appearance, and dynamics, our method significantly outperforms the current state of the art, attaining a RMSE error of less than 1 point on a 16-level pain scale, whilst simultaneously scoring a 67.3% Pearson correlation coefficient between our predicted pain level time series and the ground truth.","Tue, 17 Jan 2017 06:05:48 UTC (165 KB)"
"1633","Deep Learning for Computational Chemistry","Garrett B. Goh, Nathan O. Hodas, Abhinav Vishnu","Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)","The rise and fall of artificial neural networks is well documented in the scientific literature of both computer science and computational chemistry. Yet almost two decades later, we are now seeing a resurgence of interest in deep learning, a machine learning algorithm based on multilayer neural networks. Within the last few years, we have seen the transformative impact of deep learning in many domains, particularly in speech recognition and computer vision, to the extent that the majority of expert practitioners in those field are now regularly eschewing prior established models in favor of deep learning models. In this review, we provide an introductory overview into the theory of deep neural networks and their unique properties that distinguish them from traditional machine learning algorithms used in cheminformatics. By providing an overview of the variety of emerging applications of deep neural networks, we highlight its ubiquity and broad applicability to a wide range of challenges in the field, including QSAR, virtual screening, protein structure prediction, quantum chemistry, materials design and property prediction. In reviewing the performance of deep neural networks, we observed a consistent outperformance against non-neural networks state-of-the-art models across disparate research topics, and deep neural network based models often exceeded the ""glass ceiling"" expectations of their respective tasks. Coupled with the maturity of GPU-accelerated computing for training deep neural networks and the exponential growth of chemical data on which to train these networks on, we anticipate that deep learning algorithms will be a valuable tool for computational chemistry.","Tue, 17 Jan 2017 01:15:14 UTC (1,271 KB)"
"1634","Classification of MRI data using Deep Learning and Gaussian Process-based Model Selection","Hadrien Bertrand, Matthieu Perrot, Roberto Ardon, Isabelle Bloch","Machine Learning (cs.LG); Machine Learning (stat.ML)","The classification of MRI images according to the anatomical field of view is a necessary task to solve when faced with the increasing quantity of medical images. In parallel, advances in deep learning makes it a suitable tool for computer vision problems. Using a common architecture (such as AlexNet) provides quite good results, but not sufficient for clinical use. Improving the model is not an easy task, due to the large number of hyper-parameters governing both the architecture and the training of the network, and to the limited understanding of their relevance. Since an exhaustive search is not tractable, we propose to optimize the network first by random search, and then by an adaptive search based on Gaussian Processes and Probability of Improvement. Applying this method on a large and varied MRI dataset, we show a substantial improvement between the baseline network and the final one (up to 20\% for the most difficult classes).","Mon, 16 Jan 2017 17:02:31 UTC (1,533 KB)"
"1635","An OpenCL(TM) Deep Learning Accelerator on Arria 10","Utku Aydonat, Shane O'Connell, Davor Capalija, Andrew C. Ling, Gordon R. Chiu","Distributed, Parallel, and Cluster Computing (cs.DC); Hardware Architecture (cs.AR); Computer Vision and Pattern Recognition (cs.CV)","Convolutional neural nets (CNNs) have become a practical means to perform vision tasks, particularly in the area of image classification. FPGAs are well known to be able to perform convolutions efficiently, however, most recent efforts to run CNNs on FPGAs have shown limited advantages over other devices such as GPUs. Previous approaches on FPGAs have often been memory bound due to the limited external memory bandwidth on the FPGA device. We show a novel architecture written in OpenCL(TM), which we refer to as a Deep Learning Accelerator (DLA), that maximizes data reuse and minimizes external memory bandwidth. Furthermore, we show how we can use the Winograd transform to significantly boost the performance of the FPGA. As a result, when running our DLA on Intel's Arria 10 device we can achieve a performance of 1020 img/s, or 23 img/s/W when running the AlexNet CNN benchmark. This comes to 1382 GFLOPs and is 10x faster with 8.4x more GFLOPS and 5.8x better efficiency than the state-of-the-art on FPGAs. Additionally, 23 img/s/W is competitive against the best publicly known implementation of AlexNet on nVidia's TitanX GPU.","Fri, 13 Jan 2017 00:31:15 UTC (891 KB)"
"1636","Deep Learning for Logo Recognition","Simone Bianco, Marco Buzzelli, Davide Mazzini, Raimondo Schettini","Computer Vision and Pattern Recognition (cs.CV)","In this paper we propose a method for logo recognition using deep learning. Our recognition pipeline is composed of a logo region proposal followed by a Convolutional Neural Network (CNN) specifically trained for logo classification, even if they are not precisely localized. Experiments are carried out on the FlickrLogos-32 database, and we evaluate the effect on recognition performance of synthetic versus real data augmentation, and image pre-processing. Moreover, we systematically investigate the benefits of different training choices such as class-balancing, sample-weighting and explicit modeling the background class (i.e. no-logo regions). Experimental results confirm the feasibility of the proposed method, that outperforms the methods in the state of the art.","Tue, 10 Jan 2017 14:51:39 UTC (2,185 KB)[v2] Wed, 3 May 2017 07:30:48 UTC (2,162 KB)"
"1637","DeepDSL: A Compilation-based Domain-Specific Language for Deep Learning","Tian Zhao, Xiaobing Huang, Yu Cao","Programming Languages (cs.PL); Machine Learning (cs.LG)","In recent years, Deep Learning (DL) has found great success in domains such as multimedia understanding. However, the complex nature of multimedia data makes it difficult to develop DL-based software. The state-of-the art tools, such as Caffe, TensorFlow, Torch7, and CNTK, while are successful in their applicable domains, are programming libraries with fixed user interface, internal representation, and execution environment. This makes it difficult to implement portable and customized DL applications. In this paper, we present DeepDSL, a domain specific language (DSL) embedded in Scala, that compiles deep networks written in DeepDSL to Java source code. Deep DSL provides (1) intuitive constructs to support compact encoding of deep networks; (2) symbolic gradient derivation of the networks; (3) static analysis for memory consumption and error detection; and (4) DSL-level optimization to improve memory and runtime efficiency. DeepDSL programs are compiled into compact, efficient, customizable, and portable Java source code, which operates the CUDA and CUDNN interfaces running on Nvidia GPU via a Java Native Interface (JNI) library. We evaluated DeepDSL with a number of popular DL networks. Our experiments show that the compiled programs have very competitive runtime performance and memory efficiency compared to the existing libraries.","Mon, 9 Jan 2017 18:02:13 UTC (80 KB)"
"1638","Deep Learning for Time-Series Analysis","John Cristian Borges Gamboa","Machine Learning (cs.LG)","In many real-world application, e.g., speech recognition or sleep stage classification, data are captured over the course of time, constituting a Time-Series. Time-Series often contain temporal dependencies that cause two otherwise identical points of time to belong to different classes or predict different behavior. This characteristic generally increases the difficulty of analysing them. Existing techniques often depended on hand-crafted features that were expensive to create and required expert knowledge of the field. With the advent of Deep Learning new models of unsupervised learning of features for Time-series analysis and forecast have been developed. Such new developments are the topic of this paper: a review of the main Deep Learning techniques is presented, and some applications on Time-Series analysis are summaried. The results make it clear that Deep Learning has a lot to contribute to the field.","Sat, 7 Jan 2017 21:44:04 UTC (63 KB)"
"1639","DeepFace: Face Generation using Deep Learning","Hardie Cate, Fahim Dalvi, Zeshan Hussain","Computer Vision and Pattern Recognition (cs.CV)","We use CNNs to build a system that both classifies images of faces based on a variety of different facial attributes and generates new faces given a set of desired facial characteristics. After introducing the problem and providing context in the first section, we discuss recent work related to image generation in Section 2. In Section 3, we describe the methods used to fine-tune our CNN and generate new images using a novel approach inspired by a Gaussian mixture model. In Section 4, we discuss our working dataset and describe our preprocessing steps and handling of facial attributes. Finally, in Sections 5, 6 and 7, we explain our experiments and results and conclude in the following section. Our classification system has 82\% test accuracy. Furthermore, our generation pipeline successfully creates well-formed faces.","Sat, 7 Jan 2017 20:22:05 UTC (4,494 KB)"
"1640","Transforming Sensor Data to the Image Domain for Deep Learning - an Application to Footstep Detection","Monit Shah Singh, Vinaychandran Pondenkandath, Bo Zhou, Paul Lukowicz, Marcus Liwicki","Computer Vision and Pattern Recognition (cs.CV)","Convolutional Neural Networks (CNNs) have become the state-of-the-art in various computer vision tasks, but they are still premature for most sensor data, especially in pervasive and wearable computing. A major reason for this is the limited amount of annotated training data. In this paper, we propose the idea of leveraging the discriminative power of pre-trained deep CNNs on 2-dimensional sensor data by transforming the sensor modality to the visual domain. By three proposed strategies, 2D sensor output is converted into pressure distribution imageries. Then we utilize a pre-trained CNN for transfer learning on the converted imagery data. We evaluate our method on a gait dataset of floor surface pressure mapping. We obtain a classification accuracy of 87.66%, which outperforms the conventional machine learning methods by over 10%.","Wed, 4 Jan 2017 17:12:43 UTC (3,226 KB)[v2] Wed, 17 May 2017 01:10:23 UTC (3,117 KB)[v3] Fri, 14 Jul 2017 18:07:03 UTC (6,227 KB)"
"1641","Two-Bit Networks for Deep Learning on Resource-Constrained Embedded Devices","Wenjia Meng, Zonghua Gu, Ming Zhang, Zhaohui Wu","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)","With the rapid proliferation of Internet of Things and intelligent edge devices, there is an increasing need for implementing machine learning algorithms, including deep learning, on resource-constrained mobile embedded devices with limited memory and computation power. Typical large Convolutional Neural Networks (CNNs) need large amounts of memory and computational power, and cannot be deployed on embedded devices efficiently. We present Two-Bit Networks (TBNs) for model compression of CNNs with edge weights constrained to (-2, -1, 1, 2), which can be encoded with two bits. Our approach can reduce the memory usage and improve computational efficiency significantly while achieving good performance in terms of classification accuracy, thus representing a reasonable tradeoff between model size and performance.","Mon, 2 Jan 2017 04:28:16 UTC (978 KB)[v2] Wed, 4 Jan 2017 13:54:51 UTC (980 KB)"
"1642","Deep learning for plasma tomography using the bolometer system at JET","Francisco A. Matos, Diogo R. Ferreira, Pedro J. Carvalho, JET Contributors","Machine Learning (stat.ML); Plasma Physics (physics.plasm-ph)","Deep learning is having a profound impact in many fields, especially those that involve some form of image processing. Deep neural networks excel in turning an input image into a set of high-level features. On the other hand, tomography deals with the inverse problem of recreating an image from a number of projections. In plasma diagnostics, tomography aims at reconstructing the cross-section of the plasma from radiation measurements. This reconstruction can be computed with neural networks. However, previous attempts have focused on learning a parametric model of the plasma profile. In this work, we use a deep neural network to produce a full, pixel-by-pixel reconstruction of the plasma profile. For this purpose, we use the overview bolometer system at JET, and we introduce an up-convolutional network that has been trained and tested on a large set of sample tomograms. We show that this network is able to reproduce existing reconstructions with a high level of accuracy, as measured by several metrics.","Mon, 2 Jan 2017 06:29:00 UTC (1,321 KB)"
"1643","Deep Learning Logo Detection with Data Expansion by Synthesising Context","Hang Su, Xiatian Zhu, Shaogang Gong","Computer Vision and Pattern Recognition (cs.CV)","Logo detection in unconstrained images is challenging, particularly when only very sparse labelled training images are accessible due to high labelling costs. In this work, we describe a model training image synthesising method capable of improving significantly logo detection performance when only a handful of (e.g., 10) labelled training images captured in realistic context are available, avoiding extensive manual labelling costs. Specifically, we design a novel algorithm for generating Synthetic Context Logo (SCL) training images to increase model robustness against unknown background clutters, resulting in superior logo detection performance. For benchmarking model performance, we introduce a new logo detection dataset TopLogo-10 collected from top 10 most popular clothing/wearable brandname logos captured in rich visual context. Extensive comparisons show the advantages of our proposed SCL model over the state-of-the-art alternatives for logo detection using two real-world logo benchmark datasets: FlickrLogo-32 and our new TopLogo-10.","Thu, 29 Dec 2016 21:48:22 UTC (5,501 KB)[v2] Wed, 4 Jan 2017 12:30:56 UTC (5,502 KB)[v3] Fri, 16 Mar 2018 10:04:15 UTC (5,502 KB)"
"1644","Deep Learning and Hierarchal Generative Models","Elchanan Mossel","Machine Learning (cs.LG)","It is argued that deep learning is efficient for data that is generated from hierarchal generative models. Examples of such generative models include wavelet scattering networks, functions of compositional structure, and deep rendering models. Unfortunately so far, for all such models, it is either not rigorously known that they can be learned efficiently, or it is not known that ""deep algorithms"" are required in order to learn them. We propose a simple family of ""generative hierarchal models"" which can be efficiently learned and where ""deep"" algorithm are necessary for learning. Our definition of ""deep"" algorithms is based on the empirical observation that deep nets necessarily use correlations between features. More formally, we show that in a semi-supervised setting, given access to low-order moments of the labeled data and all of the unlabeled data, it is information theoretically impossible to perform classification while at the same time there is an efficient algorithm, that given all labelled and unlabeled data, perfectly labels all unlabelled data with high probability. For the proof, we use and strengthen the fact that Belief Propagation does not admit a good approximation in terms of linear functions.","Thu, 29 Dec 2016 07:26:26 UTC (16 KB)[v2] Mon, 31 Jul 2017 20:54:32 UTC (18 KB)[v3] Sun, 29 Oct 2017 16:27:27 UTC (19 KB)[v4] Tue, 4 Sep 2018 23:18:35 UTC (20 KB)"
"1645","A Deep Learning Approach To Multiple Kernel Fusion","Huan Song, Jayaraman J. Thiagarajan, Prasanna Sattigeri, Karthikeyan Natesan Ramamurthy, Andreas Spanias","Machine Learning (stat.ML); Machine Learning (cs.LG)","Kernel fusion is a popular and effective approach for combining multiple features that characterize different aspects of data. Traditional approaches for Multiple Kernel Learning (MKL) attempt to learn the parameters for combining the kernels through sophisticated optimization procedures. In this paper, we propose an alternative approach that creates dense embeddings for data using the kernel similarities and adopts a deep neural network architecture for fusing the embeddings. In order to improve the effectiveness of this network, we introduce the kernel dropout regularization strategy coupled with the use of an expanded set of composition kernels. Experiment results on a real-world activity recognition dataset show that the proposed architecture is effective in fusing kernels and achieves state-of-the-art performance.","Wed, 28 Dec 2016 23:43:27 UTC (175 KB)"
"1646","Text Summarization using Deep Learning and Ridge Regression","Karthik Bangalore Mani","Computation and Language (cs.CL)","We develop models and extract relevant features for automatic text summarization and investigate the performance of different models on the DUC 2001 dataset. Two different models were developed, one being a ridge regressor and the other one was a multi-layer perceptron. The hyperparameters were varied and their performance were noted. We segregated the summarization task into 2 main steps, the first being sentence ranking and the second step being sentence selection. In the first step, given a document, we sort the sentences based on their Importance, and in the second step, in order to obtain non-redundant sentences, we weed out the sentences that are have high similarity with the previously selected sentences.","Mon, 26 Dec 2016 07:17:30 UTC (471 KB)[v2] Tue, 13 Jun 2017 06:37:24 UTC (471 KB)[v3] Wed, 14 Jun 2017 00:23:45 UTC (506 KB)[v4] Thu, 15 Jun 2017 02:42:47 UTC (520 KB)"
"1647","Deep Learning and Its Applications to Machine Health Monitoring: A Survey","Rui Zhao, Ruqiang Yan, Zhenghua Chen, Kezhi Mao, Peng Wang, Robert X. Gao","Machine Learning (cs.LG); Machine Learning (stat.ML)","Since 2006, deep learning (DL) has become a rapidly growing research direction, redefining state-of-the-art performances in a wide range of areas such as object recognition, image segmentation, speech recognition and machine translation. In modern manufacturing systems, data-driven machine health monitoring is gaining in popularity due to the widespread deployment of low-cost sensors and their connection to the Internet. Meanwhile, deep learning provides useful tools for processing and analyzing these big machinery data. The main purpose of this paper is to review and summarize the emerging research work of deep learning on machine health monitoring. After the brief introduction of deep learning techniques, the applications of deep learning in machine health monitoring systems are reviewed mainly from the following aspects: Auto-encoder (AE) and its variants, Restricted Boltzmann Machines and its variants including Deep Belief Network (DBN) and Deep Boltzmann Machines (DBM), Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN). Finally, some new trends of DL-based machine health monitoring methods are discussed.","Fri, 16 Dec 2016 04:56:30 UTC (2,445 KB)"
"1648","A deep learning approach for predicting the quality of online health expert question-answering services","Ze Hu, Zhan Zhang, Qing Chen, Haiqin Yang, Decheng Zuo","Information Retrieval (cs.IR); Computation and Language (cs.CL)","Currently, a growing number of health consumers are asking health-related questions online, at any time and from anywhere, which effectively lowers the cost of health care. The most common approach is using online health expert question-answering (HQA) services, as health consumers are more willing to trust answers from professional physicians. However, these answers can be of varying quality depending on circumstance. In addition, as the available HQA services grow, how to predict the answer quality of HQA services via machine learning becomes increasingly important and challenging. In an HQA service, answers are normally short texts, which are severely affected by the data sparsity problem. Furthermore, HQA services lack community features such as best answer and user votes. Therefore, the wisdom of the crowd is not available to rate answer quality. To address these problems, in this paper, the prediction of HQA answer quality is defined as a classification task. First, based on the characteristics of HQA services and feedback from medical experts, a standard for HQA service answer quality evaluation is defined. Next, based on the characteristics of HQA services, several novel non-textual features are proposed, including surface linguistic features and social features. Finally, a deep belief network (DBN)-based HQA answer quality prediction framework is proposed to predict the quality of answers by learning the high-level hidden semantic representation from the physicians' answers. Our results prove that the proposed framework overcomes the problem of overly sparse textual features in short text answers and effectively identifies high-quality answers.","Wed, 21 Dec 2016 10:09:30 UTC (1,863 KB)"
"1649","Detecting Unexpected Obstacles for Self-Driving Cars: Fusing Deep Learning and Geometric Modeling","Sebastian Ramos, Stefan Gehrig, Peter Pinggera, Uwe Franke, Carsten Rother","Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","The detection of small road hazards, such as lost cargo, is a vital capability for self-driving cars. We tackle this challenging and rarely addressed problem with a vision system that leverages appearance, contextual as well as geometric cues. To utilize the appearance and contextual cues, we propose a new deep learning-based obstacle detection framework. Here a variant of a fully convolutional network is used to predict a pixel-wise semantic labeling of (i) free-space, (ii) on-road unexpected obstacles, and (iii) background. The geometric cues are exploited using a state-of-the-art detection approach that predicts obstacles from stereo input images via model-based statistical hypothesis tests. We present a principled Bayesian framework to fuse the semantic and stereo-based detection results. The mid-level Stixel representation is used to describe obstacles in a flexible, compact and robust manner. We evaluate our new obstacle detection system on the Lost and Found dataset, which includes very challenging scenes with obstacles of only 5 cm height. Overall, we report a major improvement over the state-of-the-art, with relative performance gains of up to 50%. In particular, we achieve a detection rate of over 90% for distances of up to 50 m. Our system operates at 22 Hz on our self-driving platform.","Tue, 20 Dec 2016 09:55:00 UTC (4,573 KB)"
"1650","Deep Learning on Lie Groups for Skeleton-based Action Recognition","Zhiwu Huang, Chengde Wan, Thomas Probst, Luc Van Gool","Computer Vision and Pattern Recognition (cs.CV)","In recent years, skeleton-based action recognition has become a popular 3D classification problem. State-of-the-art methods typically first represent each motion sequence as a high-dimensional trajectory on a Lie group with an additional dynamic time warping, and then shallowly learn favorable Lie group features. In this paper we incorporate the Lie group structure into a deep network architecture to learn more appropriate Lie group features for 3D action recognition. Within the network structure, we design rotation mapping layers to transform the input Lie group features into desirable ones, which are aligned better in the temporal domain. To reduce the high feature dimensionality, the architecture is equipped with rotation pooling layers for the elements on the Lie group. Furthermore, we propose a logarithm mapping layer to map the resulting manifold data into a tangent space that facilitates the application of regular output layers for the final classification. Evaluations of the proposed network for standard 3D human action recognition datasets clearly demonstrate its superiority over existing shallow Lie group feature learning methods as well as most conventional deep learning methods.","Sun, 18 Dec 2016 09:08:29 UTC (421 KB)[v2] Tue, 11 Apr 2017 08:47:00 UTC (392 KB)"
"1651","Neuromorphic Deep Learning Machines","Emre Neftci, Charles Augustine, Somnath Paul, Georgios Detorakis","Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI)","An ongoing challenge in neuromorphic computing is to devise general and computationally efficient models of inference and learning which are compatible with the spatial and temporal constraints of the brain. One increasingly popular and successful approach is to take inspiration from inference and learning algorithms used in deep neural networks. However, the workhorse of deep learning, the gradient descent Back Propagation (BP) rule, often relies on the immediate availability of network-wide information stored with high-precision memory, and precise operations that are difficult to realize in neuromorphic hardware. Remarkably, recent work showed that exact backpropagated weights are not essential for learning deep representations. Random BP replaces feedback weights with random ones and encourages the network to adjust its feed-forward weights to learn pseudo-inverses of the (random) feedback weights. Building on these results, we demonstrate an event-driven random BP (eRBP) rule that uses an error-modulated synaptic plasticity for learning deep representations in neuromorphic computing hardware. The rule requires only one addition and two comparisons for each synaptic weight using a two-compartment leaky Integrate & Fire (I&F) neuron, making it very suitable for implementation in digital or mixed-signal neuromorphic hardware. Our results show that using eRBP, deep representations are rapidly learned, achieving nearly identical classification accuracies compared to artificial neural network simulations on GPUs, while being robust to neural and synaptic state quantizations during learning.","Fri, 16 Dec 2016 19:06:35 UTC (245 KB)[v2] Sat, 21 Jan 2017 07:45:32 UTC (1,774 KB)"
"1652","Towards a Deep Learning Framework for Unconstrained Face Detection","Yutong Zheng, Chenchen Zhu, Khoa Luu, Chandrasekhar Bhagavatula, T. Hoang Ngan Le, Marios Savvides","Computer Vision and Pattern Recognition (cs.CV)","Robust face detection is one of the most important pre-processing steps to support facial expression analysis, facial landmarking, face recognition, pose estimation, building of 3D facial models, etc. Although this topic has been intensely studied for decades, it is still challenging due to numerous variants of face images in real-world scenarios. In this paper, we present a novel approach named Multiple Scale Faster Region-based Convolutional Neural Network (MS-FRCNN) to robustly detect human facial regions from images collected under various challenging conditions, e.g. large occlusions, extremely low resolutions, facial expressions, strong illumination variations, etc. The proposed approach is benchmarked on two challenging face detection databases, i.e. the Wider Face database and the Face Detection Dataset and Benchmark (FDDB), and compared against recent other face detection methods, e.g. Two-stage CNN, Multi-scale Cascade CNN, Faceness, Aggregate Chanel Features, HeadHunter, Multi-view Face Detection, Cascade CNN, etc. The experimental results show that our proposed approach consistently achieves highly competitive results with the state-of-the-art performance against other recent face detection methods.","Fri, 16 Dec 2016 00:34:06 UTC (548 KB)[v2] Mon, 2 Jan 2017 18:06:49 UTC (650 KB)"
"1653","Music Generation with Deep Learning","Vasanth Kalingeri, Srikanth Grandhe","Sound (cs.SD)","The use of deep learning to solve problems in literary arts has been a recent trend that has gained a lot of attention and automated generation of music has been an active area. This project deals with the generation of music using raw audio files in the frequency domain relying on various LSTM architectures. Fully connected and convolutional layers are used along with LSTM's to capture rich features in the frequency domain and increase the quality of music generated. The work is focused on unconstrained music generation and uses no information about musical structure(notes or chords) to aid learning.The music generated from various architectures are compared using blind fold tests. Using the raw audio to train models is the direction to tapping the enormous amount of mp3 files that exist over the internet without requiring the manual effort to make structured MIDI files. Moreover, not all audio files can be represented with MIDI files making the study of these models an interesting prospect to the future of such models.","Thu, 15 Dec 2016 05:06:40 UTC (572 KB)"
"1654","Deep Learning the Quantum Phase Transitions in Random Electron Systems: Applications to Three Dimensions","Tomi Ohtsuki, Tomoki Ohtsuki","Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech)","Three-dimensional random electron systems undergo quantum phase transitions and show rich phase diagrams. Examples of the phases are the band gap insulator, Anderson insulator, strong and weak topological insulators, Weyl semimetal, and diffusive metal. As in the previous paper on two-dimensional quantum phase transitions [J. Phys. Soc. Jpn. vol. 85, 123706 (2016)], we use an image recognition algorithm based on a multilayered convolutional neural network to identify which phase the eigenfunction belongs to. The Anderson model for localization-delocalization transition, the Wilson--Dirac model for topological insulators, and the layered Chern insulator model for Weyl semimetal are studied. The situation where the standard transfer matrix approach is not applicable is also treated by this method.","Thu, 15 Dec 2016 02:36:30 UTC (191 KB)[v2] Tue, 7 Feb 2017 06:37:24 UTC (328 KB)[v3] Wed, 15 Mar 2017 02:24:03 UTC (328 KB)"
"1655","Deep learning is effective for the classification of OCT images of normal versus Age-related Macular Degeneration","Cecilia S. Lee, Doug M. Baughman, Aaron Y. Lee","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Objective: The advent of Electronic Medical Records (EMR) with large electronic imaging databases along with advances in deep neural networks with machine learning has provided a unique opportunity to achieve milestones in automated image analysis. Optical coherence tomography (OCT) is the most commonly obtained imaging modality in ophthalmology and represents a dense and rich dataset when combined with labels derived from the EMR. We sought to determine if deep learning could be utilized to distinguish normal OCT images from images from patients with Age-related Macular Degeneration (AMD). Methods: Automated extraction of an OCT imaging database was performed and linked to clinical endpoints from the EMR. OCT macula scans were obtained by Heidelberg Spectralis, and each OCT scan was linked to EMR clinical endpoints extracted from EPIC. The central 11 images were selected from each OCT scan of two cohorts of patients: normal and AMD. Cross-validation was performed using a random subset of patients. Area under receiver operator curves (auROC) were constructed at an independent image level, macular OCT level, and patient level. Results: Of an extraction of 2.6 million OCT images linked to clinical datapoints from the EMR, 52,690 normal and 48,312 AMD macular OCT images were selected. A deep neural network was trained to categorize images as either normal or AMD. At the image level, we achieved an auROC of 92.78% with an accuracy of 87.63%. At the macula level, we achieved an auROC of 93.83% with an accuracy of 88.98%. At a patient level, we achieved an auROC of 97.45% with an accuracy of 93.45%. Peak sensitivity and specificity with optimal cutoffs were 92.64% and 93.69% respectively. Conclusions: Deep learning techniques are effective for classifying OCT images. These findings have important implications in utilizing OCT in automated screening and computer aided diagnosis tools.","Thu, 15 Dec 2016 00:23:43 UTC (2,663 KB)"
"1656","Predicting Process Behaviour using Deep Learning","Joerg Evermann, Jana-Rebecca Rehse, Peter Fettke","Machine Learning (cs.LG); Machine Learning (stat.ML)","Predicting business process behaviour is an important aspect of business process management. Motivated by research in natural language processing, this paper describes an application of deep learning with recurrent neural networks to the problem of predicting the next event in a business process. This is both a novel method in process prediction, which has largely relied on explicit process models, and also a novel application of deep learning methods. The approach is evaluated on two real datasets and our results surpass the state-of-the-art in prediction precision.","Wed, 14 Dec 2016 12:33:28 UTC (213 KB)[v2] Wed, 22 Mar 2017 17:22:08 UTC (210 KB)"
"1657","An equation-of-state-meter of QCD transition from deep learning","Long-Gang Pang, Kai Zhou, Nan Su, Hannah Petersen, Horst Stocker, Xin-Nian Wang","High Energy Physics - Phenomenology (hep-ph); Machine Learning (cs.LG); High Energy Physics - Theory (hep-th); Nuclear Theory (nucl-th); Machine Learning (stat.ML)","Supervised learning with a deep convolutional neural network is used to identify the QCD equation of state (EoS) employed in relativistic hydrodynamic simulations of heavy-ion collisions from the simulated final-state particle spectra $ヱ(p_T,フ)$. High-level correlations of $ヱ(p_T,フ)$ learned by the neural network act as an effective ""EoS-meter"" in detecting the nature of the QCD transition. The EoS-meter is model independent and insensitive to other simulation inputs, especially the initial conditions. Thus it provides a powerful direct-connection of heavy-ion collision observables with the bulk properties of QCD.","Tue, 13 Dec 2016 16:19:00 UTC (714 KB)[v2] Mon, 20 Mar 2017 23:53:50 UTC (746 KB)[v3] Wed, 2 Aug 2017 01:50:06 UTC (547 KB)"
"1658","Neurogenesis Deep Learning","Timothy J. Draelos, Nadine E. Miner, Christopher C. Lamb, Jonathan A. Cox, Craig M. Vineyard, Kristofor D. Carlson, William M. Severa, Conrad D. James, James B. Aimone","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG); Machine Learning (stat.ML)","Neural machine learning methods, such as deep neural networks (DNN), have achieved remarkable success in a number of complex data processing tasks. These methods have arguably had their strongest impact on tasks such as image and audio processing - data processing domains in which humans have long held clear advantages over conventional algorithms. In contrast to biological neural systems, which are capable of learning continuously, deep artificial networks have a limited ability for incorporating new information in an already trained network. As a result, methods for continuous learning are potentially highly impactful in enabling the application of deep networks to dynamic data sets. Here, inspired by the process of adult neurogenesis in the hippocampus, we explore the potential for adding new neurons to deep layers of artificial neural networks in order to facilitate their acquisition of novel information while preserving previously trained data representations. Our results on the MNIST handwritten digit dataset and the NIST SD 19 dataset, which includes lower and upper case letters and digits, demonstrate that neurogenesis is well suited for addressing the stability-plasticity dilemma that has long challenged adaptive machine learning algorithms.","Mon, 12 Dec 2016 16:25:23 UTC (1,502 KB)[v2] Tue, 28 Mar 2017 16:45:11 UTC (2,817 KB)"
"1659","Towards deep learning with spiking neurons in energy based models with contrastive Hebbian plasticity","Thomas Mesnard, Wulfram Gerstner, Johanni Brea","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Neurons and Cognition (q-bio.NC)","In machine learning, error back-propagation in multi-layer neural networks (deep learning) has been impressively successful in supervised and reinforcement learning tasks. As a model for learning in the brain, however, deep learning has long been regarded as implausible, since it relies in its basic form on a non-local plasticity rule. To overcome this problem, energy-based models with local contrastive Hebbian learning were proposed and tested on a classification task with networks of rate neurons. We extended this work by implementing and testing such a model with networks of leaky integrate-and-fire neurons. Preliminary results indicate that it is possible to learn a non-linear regression task with hidden layers, spiking neurons and a local synaptic plasticity rule.","Fri, 9 Dec 2016 23:17:11 UTC (5,283 KB)"
"1660","Learning in the Machine: Random Backpropagation and the Deep Learning Channel","Pierre Baldi, Peter Sadowski, Zhiqin Lu","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)","Random backpropagation (RBP) is a variant of the backpropagation algorithm for training neural networks, where the transpose of the forward matrices are replaced by fixed random matrices in the calculation of the weight updates. It is remarkable both because of its effectiveness, in spite of using random matrices to communicate error information, and because it completely removes the taxing requirement of maintaining symmetric weights in a physical neural system. To better understand random backpropagation, we first connect it to the notions of local learning and learning channels. Through this connection, we derive several alternatives to RBP, including skipped RBP (SRPB), adaptive RBP (ARBP), sparse RBP, and their combinations (e.g. ASRBP) and analyze their computational complexity. We then study their behavior through simulations using the MNIST and CIFAR-10 bechnmark datasets. These simulations show that most of these variants work robustly, almost as well as backpropagation, and that multiplication by the derivatives of the activation functions is important. As a follow-up, we study also the low-end of the number of bits required to communicate error information over the learning channel. We then provide partial intuitive explanations for some of the remarkable properties of RBP and its variations. Finally, we prove several mathematical results, including the convergence to fixed points of linear chains of arbitrary length, the convergence to fixed points of linear autoencoders with decorrelated data, the long-term existence of solutions for linear systems with a single hidden layer and convergence in special cases, and the convergence to fixed points of non-linear chains, when the derivative of the activation functions is included.","Thu, 8 Dec 2016 17:15:45 UTC (1,846 KB)[v2] Fri, 22 Dec 2017 17:29:20 UTC (931 KB)"
"1661","From Motion Blur to Motion Flow: a Deep Learning Solution for Removing Heterogeneous Motion Blur","Dong Gong, Jie Yang, Lingqiao Liu, Yanning Zhang, Ian Reid, Chunhua Shen, Anton van den Hengel, Qinfeng Shi","Computer Vision and Pattern Recognition (cs.CV)","Removing pixel-wise heterogeneous motion blur is challenging due to the ill-posed nature of the problem. The predominant solution is to estimate the blur kernel by adding a prior, but the extensive literature on the subject indicates the difficulty in identifying a prior which is suitably informative, and general. Rather than imposing a prior based on theory, we propose instead to learn one from the data. Learning a prior over the latent image would require modeling all possible image content. The critical observation underpinning our approach is thus that learning the motion flow instead allows the model to focus on the cause of the blur, irrespective of the image content. This is a much easier learning task, but it also avoids the iterative process through which latent image priors are typically applied. Our approach directly estimates the motion flow from the blurred image through a fully-convolutional deep neural network (FCN) and recovers the unblurred image from the estimated motion flow. Our FCN is the first universal end-to-end mapping from the blurred image to the dense motion flow. To train the FCN, we simulate motion flows to generate synthetic blurred-image-motion-flow pairs thus avoiding the need for human labeling. Extensive experiments on challenging realistic blurred images demonstrate that the proposed method outperforms the state-of-the-art.","Thu, 8 Dec 2016 10:05:57 UTC (8,377 KB)"
"1662","Predicting brain age with deep learning from raw imaging data results in a reliable and heritable biomarker","James H Cole, Rudra PK Poudel, Dimosthenis Tsagkrasoulis, Matthan WA Caan, Claire Steves, Tim D Spector, Giovanni Montana","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)","Machine learning analysis of neuroimaging data can accurately predict chronological age in healthy people and deviations from healthy brain ageing have been associated with cognitive impairment and disease. Here we sought to further establish the credentials of ""brain-predicted age"" as a biomarker of individual differences in the brain ageing process, using a predictive modelling approach based on deep learning, and specifically convolutional neural networks (CNN), and applied to both pre-processed and raw T1-weighted MRI data. Firstly, we aimed to demonstrate the accuracy of CNN brain-predicted age using a large dataset of healthy adults (N = 2001). Next, we sought to establish the heritability of brain-predicted age using a sample of monozygotic and dizygotic female twins (N = 62). Thirdly, we examined the test-retest and multi-centre reliability of brain-predicted age using two samples (within-scanner N = 20; between-scanner N = 11). CNN brain-predicted ages were generated and compared to a Gaussian Process Regression (GPR) approach, on all datasets. Input data were grey matter (GM) or white matter (WM) volumetric maps generated by Statistical Parametric Mapping (SPM) or raw data. Brain-predicted age represents an accurate, highly reliable and genetically-valid phenotype, that has potential to be used as a biomarker of brain ageing. Moreover, age predictions can be accurately generated on raw T1-MRI data, substantially reducing computation time for novel data, bringing the process closer to giving real-time information on brain health in clinical settings.","Thu, 8 Dec 2016 09:26:08 UTC (876 KB)"
"1663","A Probabilistic Framework for Deep Learning","Ankit B. Patel, Tan Nguyen, Richard G. Baraniuk","Machine Learning (stat.ML); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","We develop a probabilistic framework for deep learning based on the Deep Rendering Mixture Model (DRMM), a new generative probabilistic model that explicitly capture variations in data due to latent task nuisance variables. We demonstrate that max-sum inference in the DRMM yields an algorithm that exactly reproduces the operations in deep convolutional neural networks (DCNs), providing a first principles derivation. Our framework provides new insights into the successes and shortcomings of DCNs as well as a principled route to their improvement. DRMM training via the Expectation-Maximization (EM) algorithm is a powerful alternative to DCN back-propagation, and initial training results are promising. Classification based on the DRMM and other variants outperforms DCNs in supervised digit classification, training 2-3x faster while achieving similar accuracy. Moreover, the DRMM is applicable to semi-supervised and unsupervised learning tasks, achieving results that are state-of-the-art in several categories on the MNIST benchmark and comparable to state of the art on the CIFAR10 benchmark.","Tue, 6 Dec 2016 18:15:40 UTC (5,731 KB)"
"1664","Deep learning in color: towards automated quark/gluon jet discrimination","Patrick T. Komiske, Eric M. Metodiev, Matthew D. Schwartz","High Energy Physics - Phenomenology (hep-ph); Machine Learning (stat.ML)","Artificial intelligence offers the potential to automate challenging data-processing tasks in collider physics. To establish its prospects, we explore to what extent deep learning with convolutional neural networks can discriminate quark and gluon jets better than observables designed by physicists. Our approach builds upon the paradigm that a jet can be treated as an image, with intensity given by the local calorimeter deposits. We supplement this construction by adding color to the images, with red, green and blue intensities given by the transverse momentum in charged particles, transverse momentum in neutral particles, and pixel-level charged particle counts. Overall, the deep networks match or outperform traditional jet variables. We also find that, while various simulations produce different quark and gluon jets, the neural networks are surprisingly insensitive to these differences, similar to traditional observables. This suggests that the networks can extract robust physical information from imperfect simulations.","Mon, 5 Dec 2016 21:18:00 UTC (529 KB)[v2] Fri, 3 Feb 2017 01:13:44 UTC (1,367 KB)[v3] Tue, 4 Sep 2018 20:40:14 UTC (1,372 KB)"
"1665","On the instability and degeneracy of deep learning models","Andee Kaplan, Daniel Nordman, Stephen Vardeman","Statistics Theory (math.ST)","A probability model exhibits instability if small changes in a data outcome result in large, and often unanticipated, changes in probability. This instability is a property of the probability model, rather than the fitted parameter vector. For correlated data structures found in several application areas, there is increasing interest in predicting/identifying such sensitivity in model probability structure. We consider the problem of quantifying instability for general probability models defined on sequences of observations, where each sequence of length N has a finite number of possible values. A sequence of probability models results, indexed by N, that accommodates data of expanding dimension. Model instability is formally shown to occur when a certain log-probability ratio under such models grows faster than N. In this case, a one component change in the data sequence can shift probability by orders of magnitude. Also, as instability becomes more extreme, the resulting probability models are shown to tend to degeneracy, placing all their probability on potentially small portions of the sample space. These results on instability apply to large classes of models commonly used in random graphs, network analysis, and machine learning contexts.","Sun, 4 Dec 2016 18:17:24 UTC (10 KB)[v2] Tue, 7 Nov 2017 13:47:31 UTC (44 KB)"
"1666","Deep Learning of Robotic Tasks without a Simulator using Strong and Weak Human Supervision","Bar Hilleli, Ran El-Yaniv","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)","We propose a scheme for training a computerized agent to perform complex human tasks such as highway steering. The scheme is designed to follow a natural learning process whereby a human instructor teaches a computerized trainee. The learning process consists of five elements: (i) unsupervised feature learning; (ii) supervised imitation learning; (iii) supervised reward induction; (iv) supervised safety module construction; and (v) reinforcement learning. We implemented the last four elements of the scheme using deep convolutional networks and applied it to successfully create a computerized agent capable of autonomous highway steering over the well-known racing game Assetto Corsa. We demonstrate that the use of the last four elements is essential to effectively carry out the steering task using vision alone, without access to a driving simulator internals, and operating in wall-clock time. This is made possible also through the introduction of a safety network, a novel way for preventing the agent from performing catastrophic mistakes during the reinforcement learning stage.","Sun, 4 Dec 2016 08:28:38 UTC (955 KB)[v2] Tue, 14 Mar 2017 17:08:16 UTC (2,095 KB)[v3] Sun, 26 Mar 2017 08:43:23 UTC (2,095 KB)"
"1667","Joint Visual Denoising and Classification using Deep Learning","Gang Chen, Yawei Li, Sargur N. Srihari","Computer Vision and Pattern Recognition (cs.CV)","Visual restoration and recognition are traditionally addressed in pipeline fashion, i.e. denoising followed by classification. Instead, observing correlations between the two tasks, for example clearer image will lead to better categorization and vice visa, we propose a joint framework for visual restoration and recognition for handwritten images, inspired by advances in deep autoencoder and multi-modality learning. Our model is a 3-pathway deep architecture with a hidden-layer representation which is shared by multi-inputs and outputs, and each branch can be composed of a multi-layer deep model. Thus, visual restoration and classification can be unified using shared representation via non-linear mapping, and model parameters can be learnt via backpropagation. Using MNIST and USPS data corrupted with structured noise, the proposed framework performs at least 20\% better in classification than separate pipelines, as well as clearer recovered images. The noise model and the reproducible source code is available at {\url{this https URL}}.","Sun, 4 Dec 2016 05:51:55 UTC (1,098 KB)"
"1668","Skin Cancer Detection and Tracking using Data Synthesis and Deep Learning","Yunzhu Li, Andre Esteva, Brett Kuprel, Rob Novoa, Justin Ko, Sebastian Thrun","Computer Vision and Pattern Recognition (cs.CV)","Dense object detection and temporal tracking are needed across applications domains ranging from people-tracking to analysis of satellite imagery over time. The detection and tracking of malignant skin cancers and benign moles poses a particularly challenging problem due to the general uniformity of large skin patches, the fact that skin lesions vary little in their appearance, and the relatively small amount of data available. Here we introduce a novel data synthesis technique that merges images of individual skin lesions with full-body images and heavily augments them to generate significant amounts of data. We build a convolutional neural network (CNN) based system, trained on this synthetic data, and demonstrate superior performance to traditional detection and tracking techniques. Additionally, we compare our system to humans trained with simple criteria. Our system is intended for potential clinical use to augment the capabilities of healthcare providers. While domain-specific, we believe the methods invoked in this work will be useful in applying CNNs across domains that suffer from limited data availability.","Sun, 4 Dec 2016 05:47:47 UTC (7,871 KB)"
"1669","Short-term traffic flow forecasting with spatial-temporal correlation in a hybrid deep learning framework","Yuankai Wu, Huachun Tan","Computer Vision and Pattern Recognition (cs.CV)","Deep learning approaches have reached a celebrity status in artificial intelligence field, its success have mostly relied on Convolutional Networks (CNN) and Recurrent Networks. By exploiting fundamental spatial properties of images and videos, the CNN always achieves dominant performance on visual tasks. And the Recurrent Networks (RNN) especially long short-term memory methods (LSTM) can successfully characterize the temporal correlation, thus exhibits superior capability for time series tasks. Traffic flow data have plentiful characteristics on both time and space domain. However, applications of CNN and LSTM approaches on traffic flow are limited. In this paper, we propose a novel deep architecture combined CNN and LSTM to forecast future traffic flow (CLTFP). An 1-dimension CNN is exploited to capture spatial features of traffic flow, and two LSTMs are utilized to mine the short-term variability and periodicities of traffic flow. Given those meaningful features, the feature-level fusion is performed to achieve short-term forecasting. The proposed CLTFP is compared with other popular forecasting methods on an open datasets. Experimental results indicate that the CLTFP has considerable advantages in traffic flow forecasting. in additional, the proposed CLTFP is analyzed from the view of Granger Causality, and several interesting properties of CLTFP are discovered and discussed .","Sat, 3 Dec 2016 21:30:26 UTC (3,515 KB)"
"1670","Deep Learning with Energy-efficient Binary Gradient Cameras","Suren Jayasuriya, Orazio Gallo, Jinwei Gu, Jan Kautz","Computer Vision and Pattern Recognition (cs.CV)","Power consumption is a critical factor for the deployment of embedded computer vision systems. We explore the use of computational cameras that directly output binary gradient images to reduce the portion of the power consumption allocated to image sensing. We survey the accuracy of binary gradient cameras on a number of computer vision tasks using deep learning. These include object recognition, head pose regression, face detection, and gesture recognition. We show that, for certain applications, accuracy can be on par or even better than what can be achieved on traditional images. We are also the first to recover intensity information from binary spatial gradient images--useful for applications with a human observer in the loop, such as surveillance. Our results, which we validate with a prototype binary gradient camera, point to the potential of gradient-based computer vision systems.","Sat, 3 Dec 2016 17:04:52 UTC (7,297 KB)"
"1671","PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation","Charles R. Qi, Hao Su, Kaichun Mo, Leonidas J. Guibas","Computer Vision and Pattern Recognition (cs.CV)","Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds and well respects the permutation invariance of points in the input. Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption.","Fri, 2 Dec 2016 08:40:40 UTC (7,585 KB)[v2] Mon, 10 Apr 2017 22:25:25 UTC (7,515 KB)"
"1672","3D Bounding Box Estimation Using Deep Learning and Geometry","Arsalan Mousavian, Dragomir Anguelov, John Flynn, Jana Kosecka","Computer Vision and Pattern Recognition (cs.CV)","We present a method for 3D object detection and pose estimation from a single image. In contrast to current techniques that only regress the 3D orientation of an object, our method first regresses relatively stable 3D object properties using a deep convolutional neural network and then combines these estimates with geometric constraints provided by a 2D object bounding box to produce a complete 3D bounding box. The first network output estimates the 3D object orientation using a novel hybrid discrete-continuous loss, which significantly outperforms the L2 loss. The second output regresses the 3D object dimensions, which have relatively little variance compared to alternatives and can often be predicted for many object types. These estimates, combined with the geometric constraints on translation imposed by the 2D bounding box, enable us to recover a stable and accurate 3D object pose. We evaluate our method on the challenging KITTI object detection benchmark both on the official metric of 3D orientation estimation and also on the accuracy of the obtained 3D bounding boxes. Although conceptually simple, our method outperforms more complex and computationally expensive approaches that leverage semantic segmentation, instance level segmentation and flat ground priors and sub-category detection. Our discrete-continuous loss also produces state of the art results for 3D viewpoint estimation on the Pascal 3D+ dataset.","Thu, 1 Dec 2016 22:16:48 UTC (9,156 KB)[v2] Mon, 10 Apr 2017 19:05:46 UTC (7,806 KB)"
"1673","The observer-assisted method for adjusting hyper-parameters in deep learning algorithms","Maciej Wielgosz","Machine Learning (cs.LG); Artificial Intelligence (cs.AI)","This paper presents a concept of a novel method for adjusting hyper-parameters in Deep Learning (DL) algorithms. An external agent-observer monitors a performance of a selected Deep Learning algorithm. The observer learns to model the DL algorithm using a series of random experiments. Consequently, it may be used for predicting a response of the DL algorithm in terms of a selected quality measurement to a set of hyper-parameters. This allows to construct an ensemble composed of a series of evaluators which constitute an observer-assisted architecture. The architecture may be used to gradually iterate towards to the best achievable quality score in tiny steps governed by a unit of progress. The algorithm is stopped when the maximum number of steps is reached or no further progress is made.","Wed, 30 Nov 2016 19:37:48 UTC (112 KB)"
"1674","Active Deep Learning for Classification of Hyperspectral Images","Peng Liu, Hui Zhang, Kie B. Eom","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","Active deep learning classification of hyperspectral images is considered in this paper. Deep learning has achieved success in many applications, but good-quality labeled samples are needed to construct a deep learning network. It is expensive getting good labeled samples in hyperspectral images for remote sensing applications. An active learning algorithm based on a weighted incremental dictionary learning is proposed for such applications. The proposed algorithm selects training samples that maximize two selection criteria, namely representative and uncertainty. This algorithm trains a deep network efficiently by actively selecting training samples at each iteration. The proposed algorithm is applied for the classification of hyperspectral images, and compared with other classification algorithms employing active learning. It is shown that the proposed algorithm is efficient and effective in classifying hyperspectral images.","Wed, 30 Nov 2016 07:34:46 UTC (1,336 KB)"
"1675","Attend in groups: a weakly-supervised deep learning framework for learning from web data","Bohan Zhuang, Lingqiao Liu, Yao Li, Chunhua Shen, Ian Reid","Computer Vision and Pattern Recognition (cs.CV)","Large-scale datasets have driven the rapid development of deep neural networks for visual recognition. However, annotating a massive dataset is expensive and time-consuming. Web images and their labels are, in comparison, much easier to obtain, but direct training on such automatically harvested images can lead to unsatisfactory performance, because the noisy labels of Web images adversely affect the learned recognition models. To address this drawback we propose an end-to-end weakly-supervised deep learning framework which is robust to the label noise in Web images. The proposed framework relies on two unified strategies -- random grouping and attention -- to effectively reduce the negative impact of noisy web image annotations. Specifically, random grouping stacks multiple images into a single training instance and thus increases the labeling accuracy at the instance level. Attention, on the other hand, suppresses the noisy signals from both incorrectly labeled images and less discriminative image regions. By conducting intensive experiments on two challenging datasets, including a newly collected fine-grained dataset with Web images of different car models, the superior performance of the proposed methods over competitive baselines is clearly demonstrated.","Wed, 30 Nov 2016 01:23:43 UTC (3,419 KB)"
"1676","Gossip training for deep learning","Michael Blot, David Picard, Matthieu Cord, Nicolas Thome","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","We address the issue of speeding up the training of convolutional networks. Here we study a distributed method adapted to stochastic gradient descent (SGD). The parallel optimization setup uses several threads, each applying individual gradient descents on a local variable. We propose a new way to share information between different threads inspired by gossip algorithms and showing good consensus convergence properties. Our method called GoSGD has the advantage to be fully asynchronous and decentralized. We compared our method to the recent EASGD in \cite{elastic} on CIFAR-10 show encouraging results.","Tue, 29 Nov 2016 17:01:31 UTC (315 KB)"
"1677","Learning Filter Banks Using Deep Learning For Acoustic Signals","Shuhui Qu, Juncheng Li, Wei Dai, Samarjit Das","Sound (cs.SD); Artificial Intelligence (cs.AI)","Designing appropriate features for acoustic event recognition tasks is an active field of research. Expressive features should both improve the performance of the tasks and also be interpret-able. Currently, heuristically designed features based on the domain knowledge requires tremendous effort in hand-crafting, while features extracted through deep network are difficult for human to interpret. In this work, we explore the experience guided learning method for designing acoustic features. This is a novel hybrid approach combining both domain knowledge and purely data driven feature designing. Based on the procedure of log Mel-filter banks, we design a filter bank learning layer. We concatenate this layer with a convolutional neural network (CNN) model. After training the network, the weight of the filter bank learning layer is extracted to facilitate the design of acoustic features. We smooth the trained weight of the learning layer and re-initialize it in filter bank learning layer as audio feature extractor. For the environmental sound recognition task based on the Urban- sound8K dataset, the experience guided learning leads to a 2% accuracy improvement compared with the fixed feature extractors (the log Mel-filter bank). The shape of the new filter banks are visualized and explained to prove the effectiveness of the feature design process.","Tue, 29 Nov 2016 08:46:26 UTC (2,117 KB)"
"1678","Voronoi-based compact image descriptors: Efficient Region-of-Interest retrieval with VLAD and deep-learning-based descriptors","Aaron Chadha, Yiannis Andreopoulos","Computer Vision and Pattern Recognition (cs.CV)","We investigate the problem of image retrieval based on visual queries when the latter comprise arbitrary regions-of-interest (ROI) rather than entire images. Our proposal is a compact image descriptor that combines the state-of-the-art in content-based descriptor extraction with a multi-level, Voronoi-based spatial partitioning of each dataset image. The proposed multi-level Voronoi-based encoding uses a spatial hierarchical K-means over interest-point locations, and computes a content-based descriptor over each cell. In order to reduce the matching complexity with minimal or no sacrifice in retrieval performance: (i) we utilize the tree structure of the spatial hierarchical K-means to perform a top-to-bottom pruning for local similarity maxima; (ii) we propose a new image similarity score that combines relevant information from all partition levels into a single measure for similarity; (iii) we combine our proposal with a novel and efficient approach for optimal bit allocation within quantized descriptor representations. By deriving both a Voronoi-based VLAD descriptor (termed as Fast-VVLAD) and a Voronoi-based deep convolutional neural network (CNN) descriptor (termed as Fast-VDCNN), we demonstrate that our Voronoi-based framework is agnostic to the descriptor basis, and can easily be slotted into existing frameworks. Via a range of ROI queries in two standard datasets, it is shown that the Voronoi-based descriptors achieve comparable or higher mean Average Precision against conventional grid-based spatial search, while offering more than two-fold reduction in complexity. Finally, beyond ROI queries, we show that Voronoi partitioning improves the geometric invariance of compact CNN descriptors, thereby resulting in competitive performance to the current state-of-the-art on whole image retrieval.","Sun, 27 Nov 2016 20:35:48 UTC (3,645 KB)[v2] Mon, 20 Mar 2017 18:37:56 UTC (1,633 KB)"
"1679","Did Evolution get it right? An evaluation of Near-Infrared imaging in semantic scene segmentation using deep learning","J. Rafid Siddiqui","Computer Vision and Pattern Recognition (cs.CV)","Animals have evolved to restrict their sensing capabilities to certain region of electromagnetic spectrum. This is surprisingly a very narrow band on a vast scale which makes one think if there is a systematic bias underlying such selective filtration. The situation becomes even more intriguing when we find a sharp cutoff point at Near-infrared point whereby almost all animal vision systems seem to have a lower bound. This brings us to an interesting question: did evolution ""intentionally"" performed such a restriction in order to evolve higher visual cognition? In this work this question is addressed by experimenting with Near-infrared images for their potential applicability in higher visual processing such as semantic segmentation. A modified version of Fully Convolutional Networks are trained on NIR images and RGB images respectively and compared for their respective effectiveness in the wake of semantic segmentation. The results from the experiments show that visible part of the spectrum alone is sufficient for the robust semantic segmentation of the indoor as well as outdoor scenes.","Sun, 27 Nov 2016 09:59:10 UTC (9,683 KB)"
"1680","Geometric deep learning on graphs and manifolds using mixture model CNNs","Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodola, Jan Svoboda, Michael M. Bronstein","Computer Vision and Pattern Recognition (cs.CV)","Deep learning has achieved a remarkable performance breakthrough in several fields, most notably in speech recognition, natural language processing, and computer vision. In particular, convolutional neural network (CNN) architectures currently produce state-of-the-art performance on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has so far focused on dealing with 1D, 2D, or 3D Euclidean-structured data such as acoustic signals, images, or videos. Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics. In this paper, we propose a unified framework allowing to generalize CNN architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features. We show that various non-Euclidean CNN methods previously proposed in the literature can be considered as particular instances of our framework. We test the proposed method on standard tasks from the realms of image-, graph- and 3D shape analysis and show that it consistently outperforms previous approaches.","Fri, 25 Nov 2016 10:05:03 UTC (6,191 KB)[v2] Mon, 28 Nov 2016 10:06:39 UTC (6,189 KB)[v3] Tue, 6 Dec 2016 21:38:12 UTC (6,191 KB)"
"1681","An Overview on Data Representation Learning: From Traditional Feature Learning to Recent Deep Learning","Guoqiang Zhong, Li-Na Wang, Junyu Dong","Machine Learning (cs.LG); Machine Learning (stat.ML)","Since about 100 years ago, to learn the intrinsic structure of data, many representation learning approaches have been proposed, including both linear ones and nonlinear ones, supervised ones and unsupervised ones. Particularly, deep architectures are widely applied for representation learning in recent years, and have delivered top results in many tasks, such as image classification, object detection and speech recognition. In this paper, we review the development of data representation learning methods. Specifically, we investigate both traditional feature learning algorithms and state-of-the-art deep learning models. The history of data representation learning is introduced, while available resources (e.g. online course, tutorial and book information) and toolboxes are provided. Finally, we conclude this paper with remarks and some interesting research directions on data representation learning.","Fri, 25 Nov 2016 00:53:37 UTC (34 KB)"
"1682","Geometric deep learning: going beyond Euclidean data","Michael M. Bronstein, Joan Bruna, Yann LeCun, Arthur Szlam, Pierre Vandergheynst","Computer Vision and Pattern Recognition (cs.CV)","Many scientific fields study data with an underlying structure that is a non-Euclidean space. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions), and are natural targets for machine learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure, and in cases where the invariances of these structures are built into networks used to model them. Geometric deep learning is an umbrella term for emerging techniques attempting to generalize (structured) deep neural models to non-Euclidean domains such as graphs and manifolds. The purpose of this paper is to overview different examples of geometric deep learning problems and present available solutions, key difficulties, applications, and future research directions in this nascent field.","Thu, 24 Nov 2016 08:45:01 UTC (4,130 KB)[v2] Wed, 3 May 2017 12:37:19 UTC (5,413 KB)"
"1683","User Personalized Satisfaction Prediction via Multiple Instance Deep Learning","Zheqian Chen, Ben Gao, Huimin Zhang, Zhou Zhao, Deng Cai","Information Retrieval (cs.IR); Computation and Language (cs.CL)","Community based question answering services have arisen as a popular knowledge sharing pattern for netizens. With abundant interactions among users, individuals are capable of obtaining satisfactory information. However, it is not effective for users to attain answers within minutes. Users have to check the progress over time until the satisfying answers submitted. We address this problem as a user personalized satisfaction prediction task. Existing methods usually exploit manual feature selection. It is not desirable as it requires careful design and is labor intensive. In this paper, we settle this issue by developing a new multiple instance deep learning framework. Specifically, in our settings, each question follows a weakly supervised learning multiple instance learning assumption, where its obtained answers can be regarded as instance sets and we define the question resolved with at least one satisfactory answer. We thus design an efficient framework exploiting multiple instance learning property with deep learning to model the question answer pairs. Extensive experiments on large scale datasets from Stack Exchange demonstrate the feasibility of our proposed framework in predicting askers personalized satisfaction. Our framework can be extended to numerous applications such as UI satisfaction Prediction, multi armed bandit problem, expert finding and so on.","Thu, 24 Nov 2016 08:43:03 UTC (3,289 KB)"
"1684","Relaxed Earth Mover's Distances for Chain- and Tree-connected Spaces and their use as a Loss Function in Deep Learning","Manuel Martinez, Monica Haurilet, Ziad Al-Halah, Makarand Tapaswi, Rainer Stiefelhagen","Computer Vision and Pattern Recognition (cs.CV)","The Earth Mover's Distance (EMD) computes the optimal cost of transforming one distribution into another, given a known transport metric between them. In deep learning, the EMD loss allows us to embed information during training about the output space structure like hierarchical or semantic relations. This helps in achieving better output smoothness and generalization. However EMD is computationally expensive.Moreover, solving EMD optimization problems usually require complex techniques like lasso. These properties limit the applicability of EMD-based approaches in large scale machine learning. We address in this work the difficulties facing incorporation of EMD-based loss in deep learning frameworks. Additionally, we provide insight and novel solutions on how to integrate such loss function in training deep neural networks. Specifically, we make three main contributions: (i) we provide an in-depth analysis of the fastest state-of-the-art EMD algorithm (Sinkhorn Distance) and discuss its limitations in deep learning scenarios. (ii) we derive fast and numerically stable closed-form solutions for the EMD gradient in output spaces with chain- and tree- connectivity; and (iii) we propose a relaxed form of the EMD gradient with equivalent computational complexity but faster convergence rate. We support our claims with experiments on real datasets. In a restricted data setting on the ImageNet dataset, we train a model to classify 1000 categories using 50K images, and demonstrate that our relaxed EMD loss achieves better Top-1 accuracy than the cross entropy loss. Overall, we show that our relaxed EMD loss criterion is a powerful asset for deep learning in the small data regime.","Tue, 22 Nov 2016 22:54:05 UTC (1,557 KB)"
"1685","Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond","Levent Sagun, Leon Bottou, Yann LeCun","Machine Learning (cs.LG)","We look at the eigenvalues of the Hessian of a loss function before and after training. The eigenvalue distribution is seen to be composed of two parts, the bulk which is concentrated around zero, and the edges which are scattered away from zero. We present empirical evidence for the bulk indicating how over-parametrized the system is, and for the edges that depend on the input data.","Tue, 22 Nov 2016 19:24:49 UTC (4,520 KB)[v2] Thu, 5 Oct 2017 13:28:50 UTC (2,514 KB)"
"1686","Deep Learning Approximation for Stochastic Control Problems","Jiequn Han, Weinan E","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC); Machine Learning (stat.ML)","Many real world stochastic control problems suffer from the ""curse of dimensionality"". To overcome this difficulty, we develop a deep learning approach that directly solves high-dimensional stochastic control problems based on Monte-Carlo sampling. We approximate the time-dependent controls as feedforward neural networks and stack these networks together through model dynamics. The objective function for the control problem plays the role of the loss function for the deep neural network. We test this approach using examples from the areas of optimal trading and energy storage. Our results suggest that the algorithm presented here achieves satisfactory accuracy and at the same time, can handle rather high dimensional problems.","Wed, 2 Nov 2016 02:47:26 UTC (136 KB)"
"1687","A Deep Learning Based DDoS Detection System in Software-Defined Networking (SDN)","Quamar Niyaz, Weiqing Sun, Ahmad Y Javaid","Networking and Internet Architecture (cs.NI)","Distributed Denial of Service (DDoS) is one of the most prevalent attacks that an organizational network infrastructure comes across nowadays. We propose a deep learning based multi-vector DDoS detection system in a software-defined network (SDN) environment. SDN provides flexibility to program network devices for different objectives and eliminates the need for third-party vendor-specific hardware. We implement our system as a network application on top of an SDN controller. We use deep learning for feature reduction of a large set of features derived from network traffic headers. We evaluate our system based on different performance metrics by applying it on traffic traces collected from different scenarios. We observe high accuracy with a low false-positive for attack detection in our proposed system.","Tue, 22 Nov 2016 16:36:27 UTC (663 KB)"
"1688","A Deep Learning Approach for Joint Video Frame and Reward Prediction in Atari Games","Felix Leibfried, Nate Kushman, Katja Hofmann","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","Reinforcement learning is concerned with identifying reward-maximizing behaviour policies in environments that are initially unknown. State-of-the-art reinforcement learning approaches, such as deep Q-networks, are model-free and learn to act effectively across a wide range of environments such as Atari games, but require huge amounts of data. Model-based techniques are more data-efficient, but need to acquire explicit knowledge about the environment. In this paper, we take a step towards using model-based techniques in environments with a high-dimensional visual state space by demonstrating that it is possible to learn system dynamics and the reward structure jointly. Our contribution is to extend a recently developed deep neural network for video frame prediction in Atari games to enable reward prediction as well. To this end, we phrase a joint optimization problem for minimizing both video frame and reward reconstruction loss, and adapt network parameters accordingly. Empirical evaluations on five Atari games demonstrate accurate cumulative reward prediction of up to 200 frames. We consider these results as opening up important directions for model-based reinforcement learning in complex, initially unknown environments.","Mon, 21 Nov 2016 22:06:23 UTC (3,945 KB)[v2] Thu, 17 Aug 2017 09:00:01 UTC (4,192 KB)"
"1689","A Metaprogramming and Autotuning Framework for Deploying Deep Learning Applications","Matthew W. Moskewicz, Ali Jannesari, Kurt Keutzer","Neural and Evolutionary Computing (cs.NE); Distributed, Parallel, and Cluster Computing (cs.DC); Mathematical Software (cs.MS)","In recent years, deep neural networks (DNNs), have yielded strong results on a wide range of applications. Graphics Processing Units (GPUs) have been one key enabling factor leading to the current popularity of DNNs. However, despite increasing hardware flexibility and software programming toolchain maturity, high efficiency GPU programming remains difficult: it suffers from high complexity, low productivity, and low portability. GPU vendors such as NVIDIA have spent enormous effort to write special-purpose DNN libraries. However, on other hardware targets, especially mobile GPUs, such vendor libraries are not generally available. Thus, the development of portable, open, high-performance, energy-efficient GPU code for DNN operations would enable broader deployment of DNN-based algorithms. Toward this end, this work presents a framework to enable productive, high-efficiency GPU programming for DNN computations across hardware platforms and programming models. In particular, the framework provides specific support for metaprogramming, autotuning, and DNN-tailored data types. Using our framework, we explore implementing DNN operations on three different hardware targets: NVIDIA, AMD, and Qualcomm GPUs. On NVIDIA GPUs, we show both portability between OpenCL and CUDA as well competitive performance compared to the vendor library. On Qualcomm GPUs, we show that our framework enables productive development of target-specific optimizations, and achieves reasonable absolute performance. Finally, On AMD GPUs, we show initial results that indicate our framework can yield reasonable performance on a new platform with minimal effort.","Mon, 21 Nov 2016 18:49:23 UTC (1,439 KB)"
"1690","Predicting 1p19q Chromosomal Deletion of Low-Grade Gliomas from MR Images using Deep Learning","Zeynettin Akkus, Issa Ali, Jiri Sedlar, Timothy L. Kline, Jay P. Agrawal, Ian F. Parney, Caterina Giannini, Bradley J. Erickson","Computer Vision and Pattern Recognition (cs.CV)","Objective: Several studies have associated codeletion of chromosome arms 1p/19q in low-grade gliomas (LGG) with positive response to treatment and longer progression free survival. Therefore, predicting 1p/19q status is crucial for effective treatment planning of LGG. In this study, we predict the 1p/19q status from MR images using convolutional neural networks (CNN), which could be a noninvasive alternative to surgical biopsy and histopathological analysis. Method: Our method consists of three main steps: image registration, tumor segmentation, and classification of 1p/19q status using CNN. We included a total of 159 LGG with 3 image slices each who had biopsy-proven 1p/19q status (57 nondeleted and 102 codeleted) and preoperative postcontrast-T1 (T1C) and T2 images. We divided our data into training, validation, and test sets. The training data was balanced for equal class probability and then augmented with iterations of random translational shift, rotation, and horizontal and vertical flips to increase the size of the training set. We shuffled and augmented the training data to counter overfitting in each epoch. Finally, we evaluated several configurations of a multi-scale CNN architecture until training and validation accuracies became consistent. Results: The results of the best performing configuration on the unseen test set were 93.3% (sensitivity), 82.22% (specificity), and 87.7% (accuracy). Conclusion: Multi-scale CNN with their self-learning capability provides promising results for predicting 1p/19q status noninvasively based on T1C and T2 images. Significance: Predicting 1p/19q status noninvasively from MR images would allow selecting effective treatment strategies for LGG patients without the need for surgical biopsy.","Mon, 21 Nov 2016 18:43:20 UTC (3,437 KB)"
"1691","Deep Learning for the Classification of Lung Nodules","He Yang, Hengyong Yu, Ge Wang","Quantitative Methods (q-bio.QM); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Deep learning, as a promising new area of machine learning, has attracted a rapidly increasing attention in the field of medical imaging. Compared to the conventional machine learning methods, deep learning requires no hand-tuned feature extractor, and has shown a superior performance in many visual object recognition applications. In this study, we develop a deep convolutional neural network (CNN) and apply it to thoracic CT images for the classification of lung nodules. We present the CNN architecture and classification accuracy for the original images of lung nodules. In order to understand the features of lung nodules, we further construct new datasets, based on the combination of artificial geometric nodules and some transformations of the original images, as well as a stochastic nodule shape model. It is found that simplistic geometric nodules cannot capture the important features of lung nodules.","Mon, 21 Nov 2016 05:12:44 UTC (1,448 KB)[v2] Sat, 26 Nov 2016 21:43:48 UTC (1,448 KB)"
"1692","ModelHub: Towards Unified Data and Lifecycle Management for Deep Learning","Hui Miao, Ang Li, Larry S. Davis, Amol Deshpande","Databases (cs.DB); Computer Vision and Pattern Recognition (cs.CV)","Deep learning has improved state-of-the-art results in many important fields, and has been the subject of much research in recent years, leading to the development of several systems for facilitating deep learning. Current systems, however, mainly focus on model building and training phases, while the issues of data management, model sharing, and lifecycle management are largely ignored. Deep learning modeling lifecycle generates a rich set of data artifacts, such as learned parameters and training logs, and comprises of several frequently conducted tasks, e.g., to understand the model behaviors and to try out new models. Dealing with such artifacts and tasks is cumbersome and largely left to the users. This paper describes our vision and implementation of a data and lifecycle management system for deep learning. First, we generalize model exploration and model enumeration queries from commonly conducted tasks by deep learning modelers, and propose a high-level domain specific language (DSL), inspired by SQL, to raise the abstraction level and accelerate the modeling process. To manage the data artifacts, especially the large amount of checkpointed float parameters, we design a novel model versioning system (dlv), and a read-optimized parameter archival storage system (PAS) that minimizes storage footprint and accelerates query workloads without losing accuracy. PAS archives versioned models using deltas in a multi-resolution fashion by separately storing the less significant bits, and features a novel progressive query (inference) evaluation algorithm. Third, we show that archiving versioned models using deltas poses a new dataset versioning problem and we develop efficient algorithms for solving it. We conduct extensive experiments over several real datasets from computer vision domain to show the efficiency of the proposed techniques.","Fri, 18 Nov 2016 20:59:25 UTC (324 KB)"
"1693","GaDei: On Scale-up Training As A Service For Deep Learning","Wei Zhang, Minwei Feng, Yunhui Zheng, Yufei Ren, Yandong Wang, Ji Liu, Peng Liu, Bing Xiang, Li Zhang, Bowen Zhou, Fei Wang","Machine Learning (stat.ML); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","Deep learning (DL) training-as-a-service (TaaS) is an important emerging industrial workload. The unique challenge of TaaS is that it must satisfy a wide range of customers who have no experience and resources to tune DL hyper-parameters, and meticulous tuning for each user's dataset is prohibitively expensive. Therefore, TaaS hyper-parameters must be fixed with values that are applicable to all users. IBM Watson Natural Language Classifier (NLC) service, the most popular IBM cognitive service used by thousands of enterprise-level clients around the globe, is a typical TaaS service. By evaluating the NLC workloads, we show that only the conservative hyper-parameter setup (e.g., small mini-batch size and small learning rate) can guarantee acceptable model accuracy for a wide range of customers. We further justify theoretically why such a setup guarantees better model convergence in general. Unfortunately, the small mini-batch size causes a high volume of communication traffic in a parameter-server based system. We characterize the high communication bandwidth requirement of TaaS using representative industrial deep learning workloads and demonstrate that none of the state-of-the-art scale-up or scale-out solutions can satisfy such a requirement. We then present GaDei, an optimized shared-memory based scale-up parameter server design. We prove that the designed protocol is deadlock-free and it processes each gradient exactly once. Our implementation is evaluated on both commercial benchmarks and public benchmarks to demonstrate that it significantly outperforms the state-of-the-art parameter-server based implementation while maintaining the required accuracy and our implementation reaches near the best possible runtime performance, constrained only by the hardware limitation. Furthermore, to the best of our knowledge, GaDei is the only scale-up DL system that provides fault-tolerance.","Fri, 18 Nov 2016 20:06:27 UTC (1,657 KB)[v2] Tue, 3 Oct 2017 20:30:19 UTC (1,832 KB)"
"1694","DeepVO: A Deep Learning approach for Monocular Visual Odometry","Vikram Mohanty, Shubh Agrawal, Shaswat Datta, Arna Ghosh, Vishnu Dutt Sharma, Debashish Chakravarty","Computer Vision and Pattern Recognition (cs.CV)","Deep Learning based techniques have been adopted with precision to solve a lot of standard computer vision problems, some of which are image classification, object detection and segmentation. Despite the widespread success of these approaches, they have not yet been exploited largely for solving the standard perception related problems encountered in autonomous navigation such as Visual Odometry (VO), Structure from Motion (SfM) and Simultaneous Localization and Mapping (SLAM). This paper analyzes the problem of Monocular Visual Odometry using a Deep Learning-based framework, instead of the regular 'feature detection and tracking' pipeline approaches. Several experiments were performed to understand the influence of a known/unknown environment, a conventional trackable feature and pre-trained activations tuned for object classification on the network's ability to accurately estimate the motion trajectory of the camera (or the vehicle). Based on these observations, we propose a Convolutional Neural Network architecture, best suited for estimating the object's pose under known environment conditions, and displays promising results when it comes to inferring the actual scale using just a single camera in real-time.","Fri, 18 Nov 2016 13:41:22 UTC (692 KB)"
"1695","Solving Cold-Start Problem in Large-scale Recommendation Engines: A Deep Learning Approach","Jianbo Yuan, Walid Shalaby, Mohammed Korayem, David Lin, Khalifeh AlJadda, Jiebo Luo","Information Retrieval (cs.IR); Machine Learning (cs.LG)","Collaborative Filtering (CF) is widely used in large-scale recommendation engines because of its efficiency, accuracy and scalability. However, in practice, the fact that recommendation engines based on CF require interactions between users and items before making recommendations, make it inappropriate for new items which haven't been exposed to the end users to interact with. This is known as the cold-start problem. In this paper we introduce a novel approach which employs deep learning to tackle this problem in any CF based recommendation engine. One of the most important features of the proposed technique is the fact that it can be applied on top of any existing CF based recommendation engine without changing the CF core. We successfully applied this technique to overcome the item cold-start problem in Careerbuilder's CF based recommendation engine. Our experiments show that the proposed technique is very efficient to resolve the cold-start problem while maintaining high accuracy of the CF recommendations.","Wed, 16 Nov 2016 22:03:04 UTC (488 KB)"
"1696","The ZipML Framework for Training Models with End-to-End Low Precision: The Cans, the Cannots, and a Little Bit of Deep Learning","Hantian Zhang, Jerry Li, Kaan Kara, Dan Alistarh, Ji Liu, Ce Zhang","Machine Learning (cs.LG); Machine Learning (stat.ML)","Recently there has been significant interest in training machine-learning models at low precision: by reducing precision, one can reduce computation and communication by one order of magnitude. We examine training at reduced precision, both from a theoretical and practical perspective, and ask: is it possible to train models at end-to-end low precision with provable guarantees? Can this lead to consistent order-of-magnitude speedups? We present a framework called ZipML to answer these questions. For linear models, the answer is yes. We develop a simple framework based on one simple but novel strategy called double sampling. Our framework is able to execute training at low precision with no bias, guaranteeing convergence, whereas naive quantization would introduce significant bias. We validate our framework across a range of applications, and show that it enables an FPGA prototype that is up to 6.5x faster than an implementation using full 32-bit precision. We further develop a variance-optimal stochastic quantization strategy and show that it can make a significant difference in a variety of settings. When applied to linear models together with double sampling, we save up to another 1.7x in data movement compared with uniform quantization. When training deep networks with quantized models, we achieve higher accuracy than the state-of-the-art XNOR-Net. Finally, we extend our framework through approximation to non-linear models, such as SVM. We show that, although using low-precision data induces bias, we can appropriately bound and control the bias. We find in practice 8-bit precision is often sufficient to converge to the correct solution. Interestingly, however, in practice we notice that our framework does not always outperform the naive rounding approach. We discuss this negative result in detail.","Wed, 16 Nov 2016 18:45:09 UTC (5,493 KB)[v2] Wed, 8 Mar 2017 23:33:12 UTC (3,637 KB)[v3] Mon, 19 Jun 2017 14:36:00 UTC (4,003 KB)"
"1697","Cost-Sensitive Deep Learning with Layer-Wise Cost Estimation","Yu-An Chung, Hsuan-Tien Lin","Computer Vision and Pattern Recognition (cs.CV)","While deep neural networks have succeeded in several visual applications, such as object recognition, detection, and localization, by reaching very high classification accuracies, it is important to note that many real-world applications demand vary- ing costs for different types of misclassification errors, thus requiring cost-sensitive classification algorithms. Current models of deep neural networks for cost-sensitive classification are restricted to some specific network structures and limited depth. In this paper, we propose a novel framework that can be applied to deep neural networks with any structure to facilitate their learning of meaningful representations for cost-sensitive classification problems. Furthermore, the framework allows end- to-end training of deeper networks directly. The framework is designed by augmenting auxiliary neurons to the output of each hidden layer for layer-wise cost estimation, and including the total estimation loss within the optimization objective. Experimental results on public benchmark visual data sets with two cost information settings demonstrate that the proposed frame- work outperforms state-of-the-art cost-sensitive deep learning models.","Wed, 16 Nov 2016 03:31:25 UTC (765 KB)"
"1698","How to scale distributed deep learning?","Peter H. Jin, Qiaochu Yuan, Forrest Iandola, Kurt Keutzer","Machine Learning (cs.LG)","Training time on large datasets for deep neural networks is the principal workflow bottleneck in a number of important applications of deep learning, such as object classification and detection in automatic driver assistance systems (ADAS). To minimize training time, the training of a deep neural network must be scaled beyond a single machine to as many machines as possible by distributing the optimization method used for training. While a number of approaches have been proposed for distributed stochastic gradient descent (SGD), at the current time synchronous approaches to distributed SGD appear to be showing the greatest performance at large scale. Synchronous scaling of SGD suffers from the need to synchronize all processors on each gradient step and is not resilient in the face of failing or lagging processors. In asynchronous approaches using parameter servers, training is slowed by contention to the parameter server. In this paper we compare the convergence of synchronous and asynchronous SGD for training a modern ResNet network architecture on the ImageNet classification problem. We also propose an asynchronous method, gossiping SGD, that aims to retain the positive features of both systems by replacing the all-reduce collective operation of synchronous training with a gossip aggregation algorithm. We find, perhaps counterintuitively, that asynchronous SGD, including both elastic averaging and gossiping, converges faster at fewer nodes (up to about 32 nodes), whereas synchronous SGD scales better to more nodes (up to about 100 nodes).","Mon, 14 Nov 2016 20:59:54 UTC (670 KB)"
"1699","Deep Learning with Sets and Point Clouds","Siamak Ravanbakhsh, Jeff Schneider, Barnabas Poczos","Machine Learning (stat.ML); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","We introduce a simple permutation equivariant layer for deep learning with set structure.This type of layer, obtained by parameter-sharing, has a simple implementation and linear-time complexity in the size of each set. We use deep permutation-invariant networks to perform point-could classification and MNIST-digit summation, where in both cases the output is invariant to permutations of the input. In a semi-supervised setting, where the goal is make predictions for each instance within a set, we demonstrate the usefulness of this type of layer in set-outlier detection as well as semi-supervised learning with clustering side-information.","Mon, 14 Nov 2016 17:55:34 UTC (8,911 KB)[v2] Sat, 26 Nov 2016 22:01:55 UTC (8,911 KB)[v3] Fri, 24 Feb 2017 01:54:59 UTC (8,758 KB)"
"1700","Post Training in Deep Learning with Last Kernel","Thomas Moreau, Julien Audiffren","Machine Learning (stat.ML); Machine Learning (cs.LG)","One of the main challenges of deep learning methods is the choice of an appropriate training strategy. In particular, additional steps, such as unsupervised pre-training, have been shown to greatly improve the performances of deep structures. In this article, we propose an extra training step, called post-training, which only optimizes the last layer of the network. We show that this procedure can be analyzed in the context of kernel theory, with the first layers computing an embedding of the data and the last layer a statistical model to solve the task based on this embedding. This step makes sure that the embedding, or representation, of the data is used in the best possible way for the considered task. This idea is then tested on multiple architectures with various data sets, showing that it consistently provides a boost in performance.","Mon, 14 Nov 2016 17:54:28 UTC (282 KB)[v2] Tue, 31 Oct 2017 09:25:13 UTC (71 KB)"
"1701","Identity Matters in Deep Learning","Moritz Hardt, Tengyu Ma","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","An emerging design principle in deep learning is that each layer of a deep artificial neural network should be able to easily express the identity transformation. This idea not only motivated various normalization techniques, such as \emph{batch normalization}, but was also key to the immense success of \emph{residual networks}. In this work, we put the principle of \emph{identity parameterization} on a more solid theoretical footing alongside further empirical progress. We first give a strikingly simple proof that arbitrarily deep linear residual networks have no spurious local optima. The same result for linear feed-forward networks in their standard parameterization is substantially more delicate. Second, we show that residual networks with ReLu activations have universal finite-sample expressivity in the sense that the network can represent any function of its sample provided that the model has more parameters than the sample size. Directly inspired by our theory, we experiment with a radically simple residual architecture consisting of only residual convolutional layers and ReLu activations, but no batch normalization, dropout, or max pool. Our model improves significantly on previous all-convolutional networks on the CIFAR10, CIFAR100, and ImageNet classification benchmarks.","Mon, 14 Nov 2016 02:44:18 UTC (394 KB)[v2] Sun, 11 Dec 2016 11:39:00 UTC (421 KB)[v3] Fri, 20 Jul 2018 04:38:23 UTC (410 KB)"
"1702","Tricks from Deep Learning","Atlm Gune<U+015F> Baydin, Barak A. Pearlmutter, Jeffrey Mark Siskind","Machine Learning (cs.LG); Machine Learning (stat.ML)","The deep learning community has devised a diverse set of methods to make gradient optimization, using large datasets, of large and highly complex models with deeply cascaded nonlinearities, practical. Taken as a whole, these methods constitute a breakthrough, allowing computational structures which are quite wide, very deep, and with an enormous number and variety of free parameters to be effectively optimized. The result now dominates much of practical machine learning, with applications in machine translation, computer vision, and speech recognition. Many of these methods, viewed through the lens of algorithmic differentiation (AD), can be seen as either addressing issues with the gradient itself, or finding ways of achieving increased efficiency using tricks that are AD-related, but not provided by current AD systems. The goal of this paper is to explain not just those methods of most relevance to AD, but also the technical constraints and mindset which led to their discovery. After explaining this context, we present a ""laundry list"" of methods developed by the deep learning community. Two of these are discussed in further mathematical detail: a way to dramatically reduce the size of the tape when performing reverse-mode AD on a (theoretically) time-reversible process like an ODE integrator; and a new mathematical insight that allows for the implementation of a stochastic Newton's method.","Thu, 10 Nov 2016 17:57:19 UTC (12 KB)"
"1703","UTCNN: a Deep Learning Model of Stance Classificationon on Social Media Text","Wei-Fan Chen, Lun-Wei Ku","Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","Most neural network models for document classification on social media focus on text infor-mation to the neglect of other information on these platforms. In this paper, we classify post stance on social media channels and develop UTCNN, a neural network model that incorporates user tastes, topic tastes, and user comments on posts. UTCNN not only works on social media texts, but also analyzes texts in forums and message boards. Experiments performed on Chinese Facebook data and English online debate forum data show that UTCNN achieves a 0.755 macro-average f-score for supportive, neutral, and unsupportive stance classes on Facebook data, which is significantly better than models in which either user, topic, or comment information is withheld. This model design greatly mitigates the lack of data for the minor class without the use of oversampling. In addition, UTCNN yields a 0.842 accuracy on English online debate forum data, which also significantly outperforms results from previous work as well as other deep learning models, showing that UTCNN performs well regardless of language or platform.","Fri, 11 Nov 2016 07:05:49 UTC (69 KB)"
"1704","Understanding deep learning requires rethinking generalization","Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals","Machine Learning (cs.LG)","Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.","Thu, 10 Nov 2016 22:02:36 UTC (296 KB)[v2] Sun, 26 Feb 2017 19:36:40 UTC (308 KB)"
"1705","X-ray Scattering Image Classification Using Deep Learning","Boyu Wang, Kevin Yager, Dantong Yu, Minh Hoai","Computer Vision and Pattern Recognition (cs.CV)","Visual inspection of x-ray scattering images is a powerful technique for probing the physical structure of materials at the molecular scale. In this paper, we explore the use of deep learning to develop methods for automatically analyzing x-ray scattering images. In particular, we apply Convolutional Neural Networks and Convolutional Autoencoders for x-ray scattering image classification. To acquire enough training data for deep learning, we use simulation software to generate synthetic x-ray scattering images. Experiments show that deep learning methods outperform previously published methods by 10\% on synthetic and real datasets.","Thu, 10 Nov 2016 14:32:24 UTC (14,036 KB)"
"1706","Large-scale JPEG steganalysis using hybrid deep-learning framework","Jishen Zeng, Shunquan Tan, Bin Li, Jiwu Huang","Multimedia (cs.MM)","Adoption of deep learning in image steganalysis is still in its initial stage. In this paper we propose a generic hybrid deep-learning framework for JPEG steganalysis incorporating the domain knowledge behind rich steganalytic models. Our proposed framework involves two main stages. The first stage is hand-crafted, corresponding to the convolution phase and the quantization & truncation phase of the rich models. The second stage is a compound deep neural network containing multiple deep subnets in which the model parameters are learned in the training procedure. We provided experimental evidences and theoretical reflections to argue that the introduction of threshold quantizers, though disable the gradient-descent-based learning of the bottom convolution phase, is indeed cost-effective. We have conducted extensive experiments on a large-scale dataset extracted from ImageNet. The primary dataset used in our experiments contains 500,000 cover images, while our largest dataset contains five million cover images. Our experiments show that the integration of quantization and truncation into deep-learning steganalyzers do boost the detection performance by a clear margin. Furthermore, we demonstrate that our framework is insensitive to JPEG blocking artifact alterations, and the learned model can be easily transferred to a different attacking target and even a different dataset. These properties are of critical importance in practical applications.","Thu, 10 Nov 2016 09:33:12 UTC (473 KB)[v2] Thu, 26 Jan 2017 11:50:08 UTC (491 KB)[v3] Sat, 25 Nov 2017 01:50:14 UTC (1,016 KB)"
"1707","Low-effort place recognition with WiFi fingerprints using deep learning","Micha Nowicki, Jan Wietrzykowski","Robotics (cs.RO); Neural and Evolutionary Computing (cs.NE)","Using WiFi signals for indoor localization is the main localization modality of the existing personal indoor localization systems operating on mobile devices. WiFi fingerprinting is also used for mobile robots, as WiFi signals are usually available indoors and can provide rough initial position estimate or can be used together with other positioning systems. Currently, the best solutions rely on filtering, manual data analysis, and time-consuming parameter tuning to achieve reliable and accurate localization. In this work, we propose to use deep neural networks to significantly lower the work-force burden of the localization system design, while still achieving satisfactory results. Assuming the state-of-the-art hierarchical approach, we employ the DNN system for building/floor classification. We show that stacked autoencoders allow to efficiently reduce the feature space in order to achieve robust and precise classification. The proposed architecture is verified on the publicly available UJIIndoorLoc dataset and the results are compared with other solutions.","Mon, 7 Nov 2016 13:47:25 UTC (239 KB)[v2] Fri, 28 Apr 2017 06:32:25 UTC (238 KB)"
"1708","DeepSense: A Unified Deep Learning Framework for Time-Series Mobile Sensing Data Processing","Shuochao Yao, Shaohan Hu, Yiran Zhao, Aston Zhang, Tarek Abdelzaher","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Networking and Internet Architecture (cs.NI)","Mobile sensing applications usually require time-series inputs from sensors. Some applications, such as tracking, can use sensed acceleration and rate of rotation to calculate displacement based on physical system models. Other applications, such as activity recognition, extract manually designed features from sensor inputs for classification. Such applications face two challenges. On one hand, on-device sensor measurements are noisy. For many mobile applications, it is hard to find a distribution that exactly describes the noise in practice. Unfortunately, calculating target quantities based on physical system and noise models is only as accurate as the noise assumptions. Similarly, in classification applications, although manually designed features have proven to be effective, it is not always straightforward to find the most robust features to accommodate diverse sensor noise patterns and user behaviors. To this end, we propose DeepSense, a deep learning framework that directly addresses the aforementioned noise and feature customization challenges in a unified manner. DeepSense integrates convolutional and recurrent neural networks to exploit local interactions among similar mobile sensors, merge local interactions of different sensory modalities into global interactions, and extract temporal relationships to model signal dynamics. DeepSense thus provides a general signal estimation and classification framework that accommodates a wide range of applications. We demonstrate the effectiveness of DeepSense using three representative and challenging tasks: car tracking with motion sensors, heterogeneous human activity recognition, and user identification with biometric motion analysis. DeepSense significantly outperforms the state-of-the-art methods for all three tasks. In addition, DeepSense is feasible to implement on smartphones due to its moderate energy consumption and low latency","Mon, 7 Nov 2016 09:10:06 UTC (8,430 KB)[v2] Sun, 2 Jul 2017 22:02:21 UTC (8,432 KB)"
"1709","Domain Adaptation For Formant Estimation Using Deep Learning","Yehoshua Dissen, Joseph Keshet, Jacob Goldberger, Cynthia Clopper","Computation and Language (cs.CL); Sound (cs.SD)","In this paper we present a domain adaptation technique for formant estimation using a deep network. We first train a deep learning network on a small read speech dataset. We then freeze the parameters of the trained network and use several different datasets to train an adaptation layer that makes the obtained network universal in the sense that it works well for a variety of speakers and speech domains with very different characteristics. We evaluated our adapted network on three datasets, each of which has different speaker characteristics and speech styles. The performance of our method compares favorably with alternative methods for formant estimation.","Sun, 6 Nov 2016 14:00:14 UTC (146 KB)"
"1710","A Differentiable Physics Engine for Deep Learning in Robotics","Jonas Degrave, Michiel Hermans, Joni Dambre, Francis wyffels","Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI); Robotics (cs.RO)","An important field in robotics is the optimization of controllers. Currently, robots are often treated as a black box in this optimization process, which is the reason why derivative-free optimization methods such as evolutionary algorithms or reinforcement learning are omnipresent. When gradient-based methods are used, models are kept small or rely on finite difference approximations for the Jacobian. This method quickly grows expensive with increasing numbers of parameters, such as found in deep learning. We propose the implementation of a modern physics engine, which can differentiate control parameters. This engine is implemented for both CPU and GPU. Firstly, this paper shows how such an engine speeds up the optimization process, even for small problems. Furthermore, it explains why this is an alternative approach to deep Q-learning, for using deep learning in robotics. Finally, we argue that this is a big step for deep learning in robotics, as it opens up new possibilities to optimize robots, both in hardware and software.","Sat, 5 Nov 2016 13:34:58 UTC (2,591 KB)[v2] Sat, 24 Nov 2018 14:41:48 UTC (5,724 KB)"
"1711","Semi-supervised deep learning by metric embedding","Elad Hoffer, Nir Ailon","Machine Learning (cs.LG)","Deep networks are successfully used as classification models yielding state-of-the-art results when trained on a large number of labeled samples. These models, however, are usually much less suited for semi-supervised problems because of their tendency to overfit easily when trained on small amounts of data. In this work we will explore a new training objective that is targeting a semi-supervised regime with only a small subset of labeled data. This criterion is based on a deep metric embedding over distance relations within the set of labeled samples, together with constraints over the embeddings of the unlabeled set. The final learned representations are discriminative in euclidean space, and hence can be used with subsequent nearest-neighbor classification using the labeled samples.","Fri, 4 Nov 2016 16:39:20 UTC (102 KB)"
"1712","Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics","Jay M. Wong","Robotics (cs.RO); Artificial Intelligence (cs.AI)","Despite outstanding success in vision amongst other domains, many of the recent deep learning approaches have evident drawbacks for robots. This manuscript surveys recent work in the literature that pertain to applying deep learning systems to the robotics domain, either as means of estimation or as a tool to resolve motor commands directly from raw percepts. These recent advances are only a piece to the puzzle. We suggest that deep learning as a tool alone is insufficient in building a unified framework to acquire general intelligence. For this reason, we complement our survey with insights from cognitive development and refer to ideas from classical control theory, producing an integrated direction for a lifelong learning architecture.","Tue, 1 Nov 2016 12:47:50 UTC (656 KB)"
"1713","Towards Deep Learning in Hindi NER: An approach to tackle the Labelled Data Scarcity","Vinayak Athavale, Shreenivas Bharadwaj, Monik Pamecha, Ameya Prabhu, Manish Shrivastava","Computation and Language (cs.CL); Machine Learning (cs.LG)","In this paper we describe an end to end Neural Model for Named Entity Recognition NER) which is based on Bi-Directional RNN-LSTM. Almost all NER systems for Hindi use Language Specific features and handcrafted rules with gazetteers. Our model is language independent and uses no domain specific features or any handcrafted rules. Our models rely on semantic information in the form of word vectors which are learnt by an unsupervised learning algorithm on an unannotated corpus. Our model attained state of the art performance in both English and Hindi without the use of any morphological analysis or without using gazetteers of any sort.","Mon, 31 Oct 2016 01:31:52 UTC (198 KB)[v2] Wed, 16 Nov 2016 17:15:14 UTC (178 KB)"
"1714","Towards automatic pulmonary nodule management in lung cancer screening with deep learning","Francesco Ciompi, Kaman Chung, Sarah J. van Riel, Arnaud Arindra Adiyoso Setio, Paul K. Gerke, Colin Jacobs, Ernst Th. Scholten, Cornelia Schaefer-Prokop, Mathilde M. W. Wille, Alfonso Marchiano, Ugo Pastorino, Mathias Prokop, Bram van Ginneken","Computer Vision and Pattern Recognition (cs.CV)","The introduction of lung cancer screening programs will produce an unprecedented amount of chest CT scans in the near future, which radiologists will have to read in order to decide on a patient follow-up strategy. According to the current guidelines, the workup of screen-detected nodules strongly relies on nodule size and nodule type. In this paper, we present a deep learning system based on multi-stream multi-scale convolutional networks, which automatically classifies all nodule types relevant for nodule workup. The system processes raw CT data containing a nodule without the need for any additional information such as nodule segmentation or nodule size and learns a representation of 3D data by analyzing an arbitrary number of 2D views of a given nodule. The deep learning system was trained with data from the Italian MILD screening trial and validated on an independent set of data from the Danish DLCST screening trial. We analyze the advantage of processing nodules at multiple scales with a multi-stream convolutional network architecture, and we show that the proposed deep learning system achieves performance at classifying nodule type that surpasses the one of classical machine learning approaches and is within the inter-observer variability among four experienced human observers.","Fri, 28 Oct 2016 10:25:11 UTC (5,975 KB)[v2] Tue, 23 May 2017 12:53:49 UTC (5,978 KB)"
"1715","Predicting First Impressions with Deep Learning","Mel McCurrie, Fernando Beletti, Lucas Parzianello, Allen Westendorp, Samuel Anthony, Walter Scheirer","Computer Vision and Pattern Recognition (cs.CV)","Describable visual facial attributes are now commonplace in human biometrics and affective computing, with existing algorithms even reaching a sufficient point of maturity for placement into commercial products. These algorithms model objective facets of facial appearance, such as hair and eye color, expression, and aspects of the geometry of the face. A natural extension, which has not been studied to any great extent thus far, is the ability to model subjective attributes that are assigned to a face based purely on visual judgements. For instance, with just a glance, our first impression of a face may lead us to believe that a person is smart, worthy of our trust, and perhaps even our admiration - regardless of the underlying truth behind such attributes. Psychologists believe that these judgements are based on a variety of factors such as emotional states, personality traits, and other physiognomic cues. But work in this direction leads to an interesting question: how do we create models for problems where there is no ground truth, only measurable behavior? In this paper, we introduce a new convolutional neural network-based regression framework that allows us to train predictive models of crowd behavior for social attribute assignment. Over images from the AFLW face database, these models demonstrate strong correlations with human crowd ratings.","Tue, 25 Oct 2016 23:36:57 UTC (3,201 KB)[v2] Wed, 10 May 2017 22:46:28 UTC (3,839 KB)"
"1716","A data augmentation methodology for training machine/deep learning gait recognition algorithms","Christoforos C. Charalambous, Anil A. Bharath","Computer Vision and Pattern Recognition (cs.CV)","There are several confounding factors that can reduce the accuracy of gait recognition systems. These factors can reduce the distinctiveness, or alter the features used to characterise gait, they include variations in clothing, lighting, pose and environment, such as the walking surface. Full invariance to all confounding factors is challenging in the absence of high-quality labelled training data. We introduce a simulation-based methodology and a subject-specific dataset which can be used for generating synthetic video frames and sequences for data augmentation. With this methodology, we generated a multi-modal dataset. In addition, we supply simulation files that provide the ability to simultaneously sample from several confounding variables. The basis of the data is real motion capture data of subjects walking and running on a treadmill at different speeds. Results from gait recognition experiments suggest that information about the identity of subjects is retained within synthetically generated examples. The dataset and methodology allow studies into fully-invariant identity recognition spanning a far greater number of observation conditions than would otherwise be possible.","Mon, 24 Oct 2016 19:35:35 UTC (6,640 KB)"
"1717","DeepSpace: An Online Deep Learning Framework for Mobile Big Data to Understand Human Mobility Patterns","Xi Ouyang, Chaoyun Zhang, Pan Zhou, Hao Jiang, Shimin Gong","Computers and Society (cs.CY); Social and Information Networks (cs.SI)","In the recent years, the rapid spread of mobile device has create the vast amount of mobile data. However, some shallow-structure models such as support vector machine (SVM) have difficulty dealing with high dimensional data with the development of mobile network. In this paper, we analyze mobile data to predict human trajectories in order to understand human mobility pattern via a deep-structure model called ""DeepSpace"". To the best of out knowledge, it is the first time that the deep learning approach is applied to predicting human trajectories. Furthermore, we develop the vanilla convolutional neural network (CNN) to be an online learning system, which can deal with the continuous mobile data stream. In general, ""DeepSpace"" consists of two different prediction models corresponding to different scales in space (the coarse prediction model and fine prediction models). This two models constitute a hierarchical structure, which enable the whole architecture to be run in parallel. Finally, we test our model based on the data usage detail records (UDRs) from the mobile cellular network in a city of southeastern China, instead of the call detail records (CDRs) which are widely used by others as usual. The experiment results show that ""DeepSpace"" is promising in human trajectories prediction.","Sat, 22 Oct 2016 07:26:52 UTC (2,791 KB)[v2] Thu, 15 Nov 2018 02:57:09 UTC (4,259 KB)"
"1718","Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data","Nicolas Papernot, Martin Abadi, Ulfar Erlingsson, Ian Goodfellow, Kunal Talwar","Machine Learning (stat.ML); Cryptography and Security (cs.CR); Machine Learning (cs.LG)","Some machine learning applications involve training data that is sensitive, such as the medical histories of patients in a clinical trial. A model may inadvertently and implicitly store some of its training data; careful analysis of the model may therefore reveal sensitive information. To address this problem, we demonstrate a generally applicable approach to providing strong privacy guarantees for training data: Private Aggregation of Teacher Ensembles (PATE). The approach combines, in a black-box fashion, multiple models trained with disjoint datasets, such as records from different subsets of users. Because they rely directly on sensitive data, these models are not published, but instead used as ""teachers"" for a ""student"" model. The student learns to predict an output chosen by noisy voting among all of the teachers, and cannot directly access an individual teacher or the underlying data or parameters. The student's privacy properties can be understood both intuitively (since no single teacher and thus no single dataset dictates the student's training) and formally, in terms of differential privacy. These properties hold even if an adversary can not only query the student but also inspect its internal workings. Compared with previous work, the approach imposes only weak assumptions on how teachers are trained: it applies to any model, including non-convex models like DNNs. We achieve state-of-the-art privacy/utility trade-offs on MNIST and SVHN thanks to an improved privacy analysis and semi-supervised learning.","Tue, 18 Oct 2016 19:37:37 UTC (199 KB)[v2] Wed, 2 Nov 2016 13:18:56 UTC (199 KB)[v3] Mon, 7 Nov 2016 00:18:03 UTC (199 KB)[v4] Fri, 3 Mar 2017 18:56:43 UTC (218 KB)"
"1719","Master's Thesis : Deep Learning for Visual Recognition","Remi Cadene, Nicolas Thome, Matthieu Cord","Computer Vision and Pattern Recognition (cs.CV)","The goal of our research is to develop methods advancing automatic visual recognition. In order to predict the unique or multiple labels associated to an image, we study different kind of Deep Neural Networks architectures and methods for supervised features learning. We first draw up a state-of-the-art review of the Convolutional Neural Networks aiming to understand the history behind this family of statistical models, the limit of modern architectures and the novel techniques currently used to train deep CNNs. The originality of our work lies in our approach focusing on tasks with a low amount of data. We introduce different models and techniques to achieve the best accuracy on several kind of datasets, such as a medium dataset of food recipes (100k images) for building a web API, or a small dataset of satellite images (6,000) for the DSG online challenge that we've won. We also draw up the state-of-the-art in Weakly Supervised Learning, introducing different kind of CNNs able to localize regions of interest. Our last contribution is a framework, build on top of Torch7, for training and testing deep models on any visual recognition tasks and on datasets of any scale.","Tue, 18 Oct 2016 12:26:49 UTC (6,959 KB)"
"1720","ProQ3D: Improved model quality assessments using Deep Learning","Karolis Uziela, David Menendez Hurtado, Bjorn Wallner, Arne Elofsson","Biomolecules (q-bio.BM)","Summary: Protein quality assessment is a long-standing problem in bioinformatics. For more than a decade we have developed state-of-art predictors by carefully selecting and optimising inputs to a machine learning method. The correlation has increased from 0.60 in ProQ to 0.81 in ProQ2 and 0.85 in ProQ3 mainly by adding a large set of carefully tuned descriptions of a protein. Here, we show that a substantial improvement can be obtained using exactly the same inputs as in ProQ2 or ProQ3 but replacing the support vector machine by a deep neural network. This improves the Pearson correlation to 0.90 (0.85 using ProQ2 input features). Availability: ProQ3D is freely available both as a webserver and a stand-alone program at this http URL","Mon, 17 Oct 2016 16:11:57 UTC (1,379 KB)[v2] Tue, 18 Oct 2016 19:01:18 UTC (1,960 KB)"
"1721","Deep Learning Prototype Domains for Person Re-Identification","Arne Schumann, Shaogang Gong, Tobias Schuchert","Computer Vision and Pattern Recognition (cs.CV)","Person re-identification (re-id) is the task of matching multiple occurrences of the same person from different cameras, poses, lighting conditions, and a multitude of other factors which alter the visual appearance. Typically, this is achieved by learning either optimal features or matching metrics which are adapted to specific pairs of camera views dictated by the pairwise labelled training datasets. In this work, we formulate a deep learning based novel approach to automatic prototype-domain discovery for domain perceptive (adaptive) person re-id (rather than camera pair specific learning) for any camera views scalable to new unseen scenes without training data. We learn a separate re-id model for each of the discovered prototype-domains and during model deployment, use the person probe image to select automatically the model of the closest prototype domain. Our approach requires neither supervised nor unsupervised domain adaptation learning, i.e. no data available from the target domains. We evaluate extensively our model under realistic re-id conditions using automatically detected bounding boxes with low-resolution and partial occlusion. We show that our approach outperforms most of the state-of-the-art supervised and unsupervised methods on the latest CUHK-SYSU and PRW benchmarks.","Mon, 17 Oct 2016 11:26:19 UTC (4,370 KB)[v2] Tue, 19 Sep 2017 14:00:50 UTC (4,370 KB)"
"1722","Towards K-means-friendly Spaces: Simultaneous Deep Learning and Clustering","Bo Yang, Xiao Fu, Nicholas D. Sidiropoulos, Mingyi Hong","Machine Learning (cs.LG)","Most learning approaches treat dimensionality reduction (DR) and clustering separately (i.e., sequentially), but recent research has shown that optimizing the two tasks jointly can substantially improve the performance of both. The premise behind the latter genre is that the data samples are obtained via linear transformation of latent representations that are easy to cluster; but in practice, the transformation from the latent space to the data can be more complicated. In this work, we assume that this transformation is an unknown and possibly nonlinear function. To recover the `clustering-friendly' latent representations and to better cluster the data, we propose a joint DR and K-means clustering approach in which DR is accomplished via learning a deep neural network (DNN). The motivation is to keep the advantages of jointly optimizing the two tasks, while exploiting the deep neural network's ability to approximate any nonlinear function. This way, the proposed approach can work well for a broad class of generative models. Towards this end, we carefully design the DNN structure and the associated joint optimization criterion, and propose an effective and scalable algorithm to handle the formulated optimization problem. Experiments using different real datasets are employed to showcase the effectiveness of the proposed approach.","Sat, 15 Oct 2016 22:51:06 UTC (5,826 KB)[v2] Tue, 13 Jun 2017 22:40:26 UTC (646 KB)"
"1723","Deep Learning Ensembles for Melanoma Recognition in Dermoscopy Images","Noel Codella, Quoc-Bao Nguyen, Sharath Pankanti, David Gutman, Brian Helba, Allan Halpern, John R. Smith","Computer Vision and Pattern Recognition (cs.CV)","Melanoma is the deadliest form of skin cancer. While curable with early detection, only highly trained specialists are capable of accurately recognizing the disease. As expertise is in limited supply, automated systems capable of identifying disease could save lives, reduce unnecessary biopsies, and reduce costs. Toward this goal, we propose a system that combines recent developments in deep learning with established machine learning approaches, creating ensembles of methods that are capable of segmenting skin lesions, as well as analyzing the detected area and surrounding tissue for melanoma detection. The system is evaluated using the largest publicly available benchmark dataset of dermoscopic images, containing 900 training and 379 testing images. New state-of-the-art performance levels are demonstrated, leading to an improvement in the area under receiver operating characteristic curve of 7.5% (0.843 vs. 0.783), in average precision of 4% (0.649 vs. 0.624), and in specificity measured at the clinically relevant 95% sensitivity operating point 2.9 times higher than the previous state-of-the-art (36.8% specificity compared to 12.5%). Compared to the average of 8 expert dermatologists on a subset of 100 test images, the proposed system produces a higher accuracy (76% vs. 70.5%), and specificity (62% vs. 59%) evaluated at an equivalent sensitivity (82%).","Fri, 14 Oct 2016 22:31:34 UTC (1,488 KB)[v2] Tue, 18 Oct 2016 00:25:35 UTC (1,488 KB)"
"1724","Multi-Task Curriculum Transfer Deep Learning of Clothing Attributes","Qi Dong, Shaogang Gong, Xiatian Zhu","Computer Vision and Pattern Recognition (cs.CV)","Recognising detailed clothing characteristics (fine-grained attributes) in unconstrained images of people in-the-wild is a challenging task for computer vision, especially when there is only limited training data from the wild whilst most data available for model learning are captured in well-controlled environments using fashion models (well lit, no background clutter, frontal view, high-resolution). In this work, we develop a deep learning framework capable of model transfer learning from well-controlled shop clothing images collected from web retailers to in-the-wild images from the street. Specifically, we formulate a novel Multi-Task Curriculum Transfer (MTCT) deep learning method to explore multiple sources of different types of web annotations with multi-labelled fine-grained attributes. Our multi-task loss function is designed to extract more discriminative representations in training by jointly learning all attributes, and our curriculum strategy exploits the staged easy-to-complex transfer learning motivated by cognitive studies. We demonstrate the advantages of the MTCT model over the state-of-the-art methods on the X-Domain benchmark, a large scale clothing attribute dataset. Moreover, we show that the MTCT model has a notable advantage over contemporary models when the training data size is small.","Wed, 12 Oct 2016 11:17:16 UTC (742 KB)[v2] Thu, 13 Oct 2016 12:11:55 UTC (742 KB)[v3] Fri, 14 Oct 2016 10:32:54 UTC (742 KB)[v4] Sun, 25 Dec 2016 23:43:22 UTC (743 KB)"
"1725","Deep Learning Assessment of Tumor Proliferation in Breast Cancer Histological Images","Manan Shah, Christopher Rubadue, David Suster, Dayong Wang","Computer Vision and Pattern Recognition (cs.CV)","Current analysis of tumor proliferation, the most salient prognostic biomarker for invasive breast cancer, is limited to subjective mitosis counting by pathologists in localized regions of tissue images. This study presents the first data-driven integrative approach to characterize the severity of tumor growth and spread on a categorical and molecular level, utilizing multiple biologically salient deep learning classifiers to develop a comprehensive prognostic model. Our approach achieves pathologist-level performance on three-class categorical tumor severity prediction. It additionally pioneers prediction of molecular expression data from a tissue image, obtaining a Spearman's rank correlation coefficient of 0.60 with ex vivo mean calculated RNA expression. Furthermore, our framework is applied to identify over two hundred unprecedented biomarkers critical to the accurate assessment of tumor proliferation, validating our proposed integrative pipeline as the first to holistically and objectively analyze histopathological images.","Tue, 11 Oct 2016 19:00:35 UTC (620 KB)"
"1726","Deep Learning with Coherent Nanophotonic Circuits","Yichen Shen, Nicholas C. Harris, Scott Skirlo, Mihika Prabhu, Tom Baehr-Jones, Michael Hochberg, Xin Sun, Shijie Zhao, Hugo Larochelle, Dirk Englund, Marin Soljacic","Optics (physics.optics); Computational Physics (physics.comp-ph)","Artificial Neural Networks are computational network models inspired by signal processing in the brain. These models have dramatically improved the performance of many learning tasks, including speech and object recognition. However, today's computing hardware is inefficient at implementing neural networks, in large part because much of it was designed for von Neumann computing schemes. Significant effort has been made to develop electronic architectures tuned to implement artificial neural networks that improve upon both computational speed and energy efficiency. Here, we propose a new architecture for a fully-optical neural network that, using unique advantages of optics, promises a computational speed enhancement of at least two orders of magnitude over the state-of-the-art and three orders of magnitude in power efficiency for conventional learning tasks. We experimentally demonstrate essential parts of our architecture using a programmable nanophotonic processor.","Fri, 7 Oct 2016 18:30:10 UTC (1,108 KB)"
"1727","Xception: Deep Learning with Depthwise Separable Convolutions","Francois Chollet","Computer Vision and Pattern Recognition (cs.CV)","We present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and significantly outperforms Inception V3 on a larger image classification dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters.","Fri, 7 Oct 2016 17:51:51 UTC (772 KB)[v2] Tue, 11 Oct 2016 17:37:25 UTC (772 KB)[v3] Tue, 4 Apr 2017 18:40:27 UTC (768 KB)"
"1728","Morphology Generation for Statistical Machine Translation using Deep Learning Techniques","Marta R. Costa-jussa, Carlos Escolano","Computation and Language (cs.CL); Machine Learning (stat.ML)","Morphology in unbalanced languages remains a big challenge in the context of machine translation. In this paper, we propose to de-couple machine translation from morphology generation in order to better deal with the problem. We investigate the morphology simplification with a reasonable trade-off between expected gain and generation complexity. For the Chinese-Spanish task, optimum morphological simplification is in gender and number. For this purpose, we design a new classification architecture which, compared to other standard machine learning techniques, obtains the best results. This proposed neural-based architecture consists of several layers: an embedding, a convolutional followed by a recurrent neural network and, finally, ends with sigmoid and softmax layers. We obtain classification results over 98% accuracy in gender classification, over 93% in number classification, and an overall translation improvement of 0.7 METEOR.","Fri, 7 Oct 2016 09:59:13 UTC (302 KB)[v2] Mon, 6 Feb 2017 15:15:40 UTC (933 KB)"
"1729","Do They All Look the Same? Deciphering Chinese, Japanese and Koreans by Fine-Grained Deep Learning","Yu Wang, Haofu Liao, Yang Feng, Xiangyang Xu, Jiebo Luo","Computer Vision and Pattern Recognition (cs.CV)","We study to what extend Chinese, Japanese and Korean faces can be classified and which facial attributes offer the most important cues. First, we propose a novel way of obtaining large numbers of facial images with nationality labels. Then we train state-of-the-art neural networks with these labeled images. We are able to achieve an accuracy of 75.03% in the classification task, with chances being 33.33% and human accuracy 38.89% . Further, we train multiple facial attribute classifiers to identify the most distinctive features for each group. We find that Chinese, Japanese and Koreans do exhibit substantial differences in certain attributes, such as bangs, smiling, and bushy eyebrows. Along the way, we uncover several gender-related cross-country patterns as well. Our work, which complements existing APIs such as Microsoft Cognitive Services and Face++, could find potential applications in tourism, e-commerce, social media marketing, criminal justice and even counter-terrorism.","Thu, 6 Oct 2016 13:14:34 UTC (335 KB)[v2] Sun, 23 Oct 2016 01:26:37 UTC (4,240 KB)"
"1730","Multiple Regularizations Deep Learning for Paddy Growth Stages Classification from LANDSAT-8","Ines Heidieni Ikasari, Vina Ayumi, Mohamad Ivan Fanany, Sidik Mulyono","Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)","This study uses remote sensing technology that can provide information about the condition of the earth's surface area, fast, and spatially. The study area was in Karawang District, lying in the Northern part of West Java-Indonesia. We address a paddy growth stages classification using LANDSAT 8 image data obtained from multi-sensor remote sensing image taken in October 2015 to August 2016. This study pursues a fast and accurate classification of paddy growth stages by employing multiple regularizations learning on some deep learning methods such as DNN (Deep Neural Networks) and 1-D CNN (1-D Convolutional Neural Networks). The used regularizations are Fast Dropout, Dropout, and Batch Normalization. To evaluate the effectiveness, we also compared our method with other machine learning methods such as (Logistic Regression, SVM, Random Forest, and XGBoost). The data used are seven bands of LANDSAT-8 spectral data samples that correspond to paddy growth stages data obtained from i-Sky (eye in the sky) Innovation system. The growth stages are determined based on paddy crop phenology profile from time series of LANDSAT-8 images. The classification results show that MLP using multiple regularization Dropout and Batch Normalization achieves the highest accuracy for this dataset.","Thu, 6 Oct 2016 09:46:08 UTC (3,080 KB)"
"1731","Domain Adaptation with Soft-margin multiple feature-kernel learning beats Deep Learning for surveillance face recognition","Samik Banerjee, Sukhendu Das","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)","Face recognition (FR) is the most preferred mode for biometric-based surveillance, due to its passive nature of detecting subjects, amongst all different types of biometric traits. FR under surveillance scenario does not give satisfactory performance due to low contrast, noise and poor illumination conditions on probes, as compared to the training samples. A state-of-the-art technology, Deep Learning, even fails to perform well in these scenarios. We propose a novel soft-margin based learning method for multiple feature-kernel combinations, followed by feature transformed using Domain Adaptation, which outperforms many recent state-of-the-art techniques, when tested using three real-world surveillance face datasets.","Wed, 5 Oct 2016 11:48:56 UTC (2,366 KB)[v2] Thu, 27 Oct 2016 13:14:49 UTC (2,366 KB)"
"1732","Tutorial on Answering Questions about Images with Deep Learning","Mateusz Malinowski, Mario Fritz","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Together with the development of more accurate methods in Computer Vision and Natural Language Understanding, holistic architectures that answer on questions about the content of real-world images have emerged. In this tutorial, we build a neural-based approach to answer questions about images. We base our tutorial on two datasets: (mostly on) DAQUAR, and (a bit on) VQA. With small tweaks the models that we present here can achieve a competitive performance on both datasets, in fact, they are among the best methods that use a combination of LSTM with a global, full frame CNN representation of an image. We hope that after reading this tutorial, the reader will be able to use Deep Learning frameworks, such as Keras and introduced Kraino, to build various architectures that will lead to a further performance improvement on this challenging task.","Tue, 4 Oct 2016 16:29:28 UTC (1,299 KB)"
"1733","Applications of Online Deep Learning for Crisis Response Using Social Media Information","Dat Tien Nguyen, Shafiq Joty, Muhammad Imran, Hassan Sajjad, Prasenjit Mitra","Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (cs.LG)","During natural or man-made disasters, humanitarian response organizations look for useful information to support their decision-making processes. Social media platforms such as Twitter have been considered as a vital source of useful information for disaster response and management. Despite advances in natural language processing techniques, processing short and informal Twitter messages is a challenging task. In this paper, we propose to use Deep Neural Network (DNN) to address two types of information needs of response organizations: 1) identifying informative tweets and 2) classifying them into topical classes. DNNs use distributed representation of words and learn the representation as well as higher level features automatically for the classification task. We propose a new online algorithm based on stochastic gradient descent to train DNNs in an online fashion during disaster situations. We test our models using a crisis-related real-world Twitter dataset.","Tue, 4 Oct 2016 14:53:51 UTC (1,301 KB)[v2] Wed, 5 Oct 2016 09:50:15 UTC (1,302 KB)"
"1734","Comparing Human-Centric and Robot-Centric Sampling for Robot Deep Learning from Demonstrations","Michael Laskey, Caleb Chuck, Jonathan Lee, Jeffrey Mahler, Sanjay Krishnan, Kevin Jamieson, Anca Dragan, Ken Goldberg","Robotics (cs.RO); Machine Learning (cs.LG)","Motivated by recent advances in Deep Learning for robot control, this paper considers two learning algorithms in terms of how they acquire demonstrations. ""Human-Centric"" (HC) sampling is the standard supervised learning algorithm, where a human supervisor demonstrates the task by teleoperating the robot to provide trajectories consisting of state-control pairs. ""Robot-Centric"" (RC) sampling is an increasingly popular alternative used in algorithms such as DAgger, where a human supervisor observes the robot executing a learned policy and provides corrective control labels for each state visited. RC sampling can be challenging for human supervisors and prone to mislabeling. RC sampling can also induce error in policy performance because it repeatedly visits areas of the state space that are harder to learn. Although policies learned with RC sampling can be superior to HC sampling for standard learning models such as linear SVMs, policies learned with HC sampling may be comparable with highly-expressive learning models such as deep learning and hyper-parametric decision trees, which have little model error. We compare HC and RC using a grid world and a physical robot singulation task, where in the latter the input is a binary image of a connected set of objects on a planar worksurface and the policy generates a motion of the gripper to separate one object from the rest. We observe in simulation that for linear SVMs, policies learned with RC outperformed those learned with HC but that with deep models this advantage disappears. We also find that with RC, the corrective control labels provided by humans can be highly inconsistent. We prove there exists a class of examples where in the limit, HC is guaranteed to converge to an optimal policy while RC may fail to converge.","Tue, 4 Oct 2016 05:51:40 UTC (1,112 KB)[v2] Fri, 7 Oct 2016 16:54:51 UTC (1,112 KB)[v3] Wed, 29 Mar 2017 02:15:33 UTC (1,064 KB)"
"1735","Adaptive Neuron Apoptosis for Accelerating Deep Learning on Large Scale Systems","Charles Siegel, Jeff Daily, Abhinav Vishnu","Neural and Evolutionary Computing (cs.NE)","We present novel techniques to accelerate the convergence of Deep Learning algorithms by conducting low overhead removal of redundant neurons -- apoptosis of neurons -- which do not contribute to model learning, during the training phase itself. We provide in-depth theoretical underpinnings of our heuristics (bounding accuracy loss and handling apoptosis of several neuron types), and present the methods to conduct adaptive neuron apoptosis. Specifically, we are able to improve the training time for several datasets by 2-3x, while reducing the number of parameters by up to 30x (4-5x on average) on datasets such as ImageNet classification. For the Higgs Boson dataset, our implementation improves the accuracy (measured by Area Under Curve (AUC)) for classification from 0.88/1 to 0.94/1, while reducing the number of parameters by 3x in comparison to existing literature. The proposed methods achieve a 2.44x speedup in comparison to the default (no apoptosis) algorithm.","Mon, 3 Oct 2016 23:23:34 UTC (551 KB)"
"1736","Deep Learning the Quantum Phase Transitions in Random Two-Dimensional Electron Systems","Tomoki Ohtsuki, Tomi Ohtsuki","Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech)","Random electron systems show rich phases such as Anderson insulator, diffusive metal, quantum and anomalous quantum Hall insulator, Weyl semimetal, as well as strong/weak topological insulators. Eigenfunctions of each matter phase have specific features, but due to the random nature of systems, judging the matter phase from eigenfunctions is difficult. Here we propose the deep learning algorithm to capture the features of eigenfunctions. Localization-delocalization transition as well as disordered Chern insulator-Anderson insulator transition is discussed.","Mon, 3 Oct 2016 09:43:46 UTC (126 KB)[v2] Sun, 16 Oct 2016 00:59:09 UTC (129 KB)[v3] Fri, 18 Nov 2016 10:03:44 UTC (1,196 KB)"
"1737","Deep Learning Algorithms for Signal Recognition in Long Perimeter Monitoring Distributed Fiber Optic Sensors","A.V. Makarenko","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","In this paper, we show an approach to build deep learning algorithms for recognizing signals in distributed fiber optic monitoring and security systems for long perimeters. Synthesizing such detection algorithms poses a non-trivial research and development challenge, because these systems face stringent error (type I and II) requirements and operate in difficult signal-jamming environments, with intensive signal-like jamming and a variety of changing possible signal portraits of possible recognized events. To address these issues, we have developed a twolevel event detection architecture, where the primary classifier is based on an ensemble of deep convolutional networks, can recognize 7 classes of signals and receives time-space data frames as input. Using real-life data, we have shown that the applied methods result in efficient and robust multiclass detection algorithms that have a high degree of adaptability.","Sun, 2 Oct 2016 13:46:47 UTC (89 KB)"
"1738","Towards deep learning with segregated dendrites","Jordan Guergiuev, Timothy P. Lillicrap, Blake A. Richards","Neurons and Cognition (q-bio.NC)","Deep learning has led to significant advances in artificial intelligence, in part, by adopting strategies motivated by neurophysiology. However, it is unclear whether deep learning could occur in the real brain. Here, we show that a deep learning algorithm that utilizes multi-compartment neurons might help us to understand how the brain optimizes cost functions. Like neocortical pyramidal neurons, neurons in our model receive sensory information and higher-order feedback in electrotonically segregated compartments. Thanks to this segregation, the neurons in different layers of the network can coordinate synaptic weight updates. As a result, the network can learn to categorize images better than a single layer network. Furthermore, we show that our algorithm takes advantage of multilayer architectures to identify useful representations---the hallmark of deep learning. This work demonstrates that deep learning can be achieved using segregated dendritic compartments, which may help to explain the dendritic morphology of neocortical pyramidal neurons.","Sat, 1 Oct 2016 17:37:34 UTC (2,545 KB)[v2] Wed, 2 Nov 2016 18:07:26 UTC (2,546 KB)[v3] Fri, 7 Apr 2017 18:45:30 UTC (3,827 KB)"
"1739","Prediction of Prokaryotic and Eukaryotic Promoters Using Convolutional Deep Learning Neural Networks","Victor Solovyev, Ramzan Umarov","Genomics (q-bio.GN)","Accurate computational identification of promoters remains a challenge as these key DNA regulatory regions have variable structures composed of functional motifs that provide gene specific initiation of transcription. In this paper we utilize Convolutional Neural Networks (CNN) to analyze sequence characteristics of prokaryotic and eukaryotic promoters and build their predictive models. We trained the same CNN architecture on promoters of four very distant organisms: human, plant (Arabidopsis), and two bacteria (Escherichia coli and Mycoplasma pneumonia). We found that CNN trained on sigma70 subclass of Escherichia coli promoter gives an excellent classification of promoters and non-promoter sequences (Sn=0.90, Sp=0.96, CC=0.84). The Bacillus subtilis promoters identification CNN model achieves Sn=0.91, Sp=0.95, and CC=0.86. For human and Arabidopsis promoters we employ CNNs for identification of two well-known promoter classes (TATA and non-TATA promoters). CNNs models nicely recognize these complex functional regions. For human Sn/Sp/CC accuracy of prediction reached 0.95/0.98/0,90 on TATA and 0.90/0.98/0.89 for non-TATA promoter sequences, respectively. For Arabidopsis we observed Sn/Sp/CC 0.95/0.97/0.91 (TATA) and 0.94/0.94/0.86 (non-TATA) promoters. Thus, the developed CNN models (implemented in CNNProm program) demonstrated the ability of deep learning with grasping complex promoter sequence characteristics and achieve significantly higher accuracy compared to the previously developed promoter prediction programs. As the suggested approach does not require knowledge of any specific promoter features, it can be easily extended to identify promoters and other complex functional regions in sequences of many other and especially newly sequenced genomes. The CNNProm program is available to run at web server this http URL.","Sat, 1 Oct 2016 11:24:47 UTC (964 KB)"
"1740","Multi-view Self-supervised Deep Learning for 6D Pose Estimation in the Amazon Picking Challenge","Andy Zeng, Kuan-Ting Yu, Shuran Song, Daniel Suo, Ed Walker Jr., Alberto Rodriguez, Jianxiong Xiao","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)","Robot warehouse automation has attracted significant interest in recent years, perhaps most visibly in the Amazon Picking Challenge (APC). A fully autonomous warehouse pick-and-place system requires robust vision that reliably recognizes and locates objects amid cluttered environments, self-occlusions, sensor noise, and a large variety of objects. In this paper we present an approach that leverages multi-view RGB-D data and self-supervised, data-driven learning to overcome those difficulties. The approach was part of the MIT-Princeton Team system that took 3rd- and 4th- place in the stowing and picking tasks, respectively at APC 2016. In the proposed approach, we segment and label multiple views of a scene with a fully convolutional neural network, and then fit pre-scanned 3D object models to the resulting segmentation to get the 6D object pose. Training a deep neural network for segmentation typically requires a large amount of training data. We propose a self-supervised method to generate a large labeled dataset without tedious manual segmentation. We demonstrate that our system can reliably estimate the 6D pose of objects under a variety of scenarios. All code, data, and benchmarks are available at this http URL","Thu, 29 Sep 2016 19:39:13 UTC (2,091 KB)[v2] Sun, 2 Oct 2016 00:24:29 UTC (2,091 KB)[v3] Sun, 7 May 2017 20:12:55 UTC (2,091 KB)"
"1741","Variational Autoencoder for Deep Learning of Images, Labels and Captions","Yunchen Pu, Zhe Gan, Ricardo Henao, Xin Yuan, Chunyuan Li, Andrew Stevens, Lawrence Carin","Machine Learning (stat.ML); Machine Learning (cs.LG)","A novel variational autoencoder is developed to model images, as well as associated labels or captions. The Deep Generative Deconvolutional Network (DGDN) is used as a decoder of the latent image features, and a deep Convolutional Neural Network (CNN) is used as an image encoder; the CNN is used to approximate a distribution for the latent DGDN features/code. The latent code is also linked to generative models for labels (Bayesian support vector machine) or captions (recurrent neural network). When predicting a label/caption for a new image at test, averaging is performed across the distribution of latent codes; this is computationally efficient as a consequence of the learned CNN-based encoder. Since the framework is capable of modeling the image in the presence/absence of associated labels/captions, a new semi-supervised setting is manifested for CNN learning with images; the framework even allows unsupervised CNN learning, based on images alone.","Wed, 28 Sep 2016 15:56:15 UTC (535 KB)"
"1742","Deep learning for detection of bird vocalisations","Ilyas Potamitis","Sound (cs.SD); Machine Learning (cs.LG)","This work focuses on reliable detection of bird sound emissions as recorded in the open field. Acoustic detection of avian sounds can be used for the automatized monitoring of multiple bird taxa and querying in long-term recordings for species of interest for researchers, conservation practitioners, and decision makers. Recordings in the wild can be very noisy due to the exposure of the microphones to a large number of audio sources originating from all distances and directions, the number and identity of which cannot be known a-priori. The co-existence of the target vocalizations with abiotic interferences in an unconstrained environment is inefficiently treated by current approaches of audio signal enhancement. A technique that would spot only bird vocalization while ignoring other audio sources is of prime importance. These difficulties are tackled in this work, presenting a deep autoencoder that maps the audio spectrogram of bird vocalizations to its corresponding binary mask that encircles the spectral blobs of vocalizations while suppressing other audio sources. The procedure requires minimum human attendance, it is very fast during execution, thus suitable to scan massive volumes of data, in order to analyze them, evaluate insights and hypotheses, identify patterns of bird activity that, hopefully, finally lead to design policies on biodiversity issues.","Sun, 25 Sep 2016 15:56:06 UTC (1,171 KB)"
"1743","Deep learning based fence segmentation and removal from an image using a video sequence","Sankaraganesh Jonna, Krishna K. Nakka, Rajiv R. Sahay","Computer Vision and Pattern Recognition (cs.CV)","Conventional approaches to image de-fencing use multiple adjacent frames for segmentation of fences in the reference image and are limited to restoring images of static scenes only. In this paper, we propose a de-fencing algorithm for images of dynamic scenes using an occlusion-aware optical flow method. We divide the problem of image de-fencing into the tasks of automated fence segmentation from a single image, motion estimation under known occlusions and fusion of data from multiple frames of a captured video of the scene. Specifically, we use a pre-trained convolutional neural network to segment fence pixels from a single image. The knowledge of spatial locations of fences is used to subsequently estimate optical flow in the occluded frames of the video for the final data fusion step. We cast the fence removal problem in an optimization framework by modeling the formation of the degraded observations. The inverse problem is solved using fast iterative shrinkage thresholding algorithm (FISTA). Experimental results show the effectiveness of proposed algorithm.","Sun, 25 Sep 2016 10:35:23 UTC (8,752 KB)[v2] Fri, 21 Oct 2016 13:08:23 UTC (8,753 KB)"
"1744","Deep Learning in Multi-Layer Architectures of Dense Nuclei","Yonghua Yin, Erol Gelenbe","Neural and Evolutionary Computing (cs.NE); Computer Vision and Pattern Recognition (cs.CV)","We assume that, within the dense clusters of neurons that can be found in nuclei, cells may interconnect via soma-to-soma interactions, in addition to conventional synaptic connections. We illustrate this idea with a multi-layer architecture (MLA) composed of multiple clusters of recurrent sub-networks of spiking Random Neural Networks (RNN) with dense soma-to-soma interactions, and use this RNN-MLA architecture for deep learning. The inputs to the clusters are first normalised by adjusting the external arrival rates of spikes to each cluster. Then we apply this architecture to learning from multi-channel datasets. Numerical results based on both images and sensor based data, show the value of this novel architecture for deep learning.","Thu, 22 Sep 2016 20:55:16 UTC (409 KB)[v2] Thu, 29 Sep 2016 11:19:23 UTC (410 KB)"
"1745","How Useful is Region-based Classification of Remote Sensing Images in a Deep Learning Framework?","Nicolas Audebert (OBELIX, Palaiseau), Bertrand Le Saux (Palaiseau), Sebastien Lefevre (OBELIX)","Computer Vision and Pattern Recognition (cs.CV)","In this paper, we investigate the impact of segmentation algorithms as a preprocessing step for classification of remote sensing images in a deep learning framework. Especially, we address the issue of segmenting the image into regions to be classified using pre-trained deep neural networks as feature extractors for an SVM-based classifier. An efficient segmentation as a preprocessing step helps learning by adding a spatially-coherent structure to the data. Therefore, we compare algorithms producing superpixels with more traditional remote sensing segmentation algorithms and measure the variation in terms of classification accuracy. We establish that superpixel algorithms allow for a better classification accuracy as a homogenous and compact segmentation favors better generalization of the training samples.","Thu, 22 Sep 2016 08:21:20 UTC (1,703 KB)"
"1746","Deep-Learned Collision Avoidance Policy for Distributed Multi-Agent Navigation","Pinxin Long, Wenxi Liu, Jia Pan","Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","High-speed, low-latency obstacle avoidance that is insensitive to sensor noise is essential for enabling multiple decentralized robots to function reliably in cluttered and dynamic environments. While other distributed multi-agent collision avoidance systems exist, these systems require online geometric optimization where tedious parameter tuning and perfect sensing are necessary. We present a novel end-to-end framework to generate reactive collision avoidance policy for efficient distributed multi-agent navigation. Our method formulates an agent's navigation strategy as a deep neural network mapping from the observed noisy sensor measurements to the agent's steering commands in terms of movement velocity. We train the network on a large number of frames of collision avoidance data collected by repeatedly running a multi-agent simulator with different parameter settings. We validate the learned deep neural network policy in a set of simulated and real scenarios with noisy measurements and demonstrate that our method is able to generate a robust navigation strategy that is insensitive to imperfect sensing and works reliably in all situations. We also show that our method can be well generalized to scenarios that do not appear in our training data, including scenes with static obstacles and agents with different sizes. Videos are available at this https URL.","Thu, 22 Sep 2016 07:05:56 UTC (2,126 KB)[v2] Thu, 6 Jul 2017 07:41:45 UTC (2,244 KB)"
"1747","Deep Learning for Video Classification and Captioning","Zuxuan Wu, Ting Yao, Yanwei Fu, Yu-Gang Jiang","Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)","Accelerated by the tremendous increase in Internet bandwidth and storage space, video data has been generated, published and spread explosively, becoming an indispensable part of today's big data. In this paper, we focus on reviewing two lines of research aiming to stimulate the comprehension of videos with deep learning: video classification and video captioning. While video classification concentrates on automatically labeling video clips based on their semantic contents like human actions or complex events, video captioning attempts to generate a complete and natural sentence, enriching the single label as in video classification, to capture the most informative dynamics in videos. In addition, we also provide a review of popular benchmarks and competitions, which are critical for evaluating the technical progress of this vibrant field.","Thu, 22 Sep 2016 00:08:59 UTC (3,496 KB)[v2] Thu, 22 Feb 2018 14:59:32 UTC (1,283 KB)"
"1748","On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima","Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, Ping Tak Peter Tang","Machine Learning (cs.LG); Optimization and Control (math.OC)","The stochastic gradient descent (SGD) method and its variants are algorithms of choice for many Deep Learning tasks. These methods operate in a small-batch regime wherein a fraction of the training data, say $32$-$512$ data points, is sampled to compute an approximation to the gradient. It has been observed in practice that when using a larger batch there is a degradation in the quality of the model, as measured by its ability to generalize. We investigate the cause for this generalization drop in the large-batch regime and present numerical evidence that supports the view that large-batch methods tend to converge to sharp minimizers of the training and testing functions - and as is well known, sharp minima lead to poorer generalization. In contrast, small-batch methods consistently converge to flat minimizers, and our experiments support a commonly held view that this is due to the inherent noise in the gradient estimation. We discuss several strategies to attempt to help large-batch methods eliminate this generalization gap.","Thu, 15 Sep 2016 20:03:06 UTC (357 KB)[v2] Thu, 9 Feb 2017 20:38:16 UTC (376 KB)"
"1749","A Large Contextual Dataset for Classification, Detection and Counting of Cars with Deep Learning","T. Nathan Mundhenk, Goran Konjevod, Wesam A. Sakla, Kofi Boakye","Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC); Neural and Evolutionary Computing (cs.NE)","We have created a large diverse set of cars from overhead images, which are useful for training a deep learner to binary classify, detect and count them. The dataset and all related material will be made publically available. The set contains contextual matter to aid in identification of difficult targets. We demonstrate classification and detection on this dataset using a neural network we call ResCeption. This network combines residual learning with Inception-style layers and is used to count cars in one look. This is a new way to count objects rather than by localization or density estimation. It is fairly accurate, fast and easy to implement. Additionally, the counting method is not car or scene specific. It would be easy to train this method to count other kinds of objects and counting over new scenes requires no extra set up or assumptions about object locations.","Wed, 14 Sep 2016 21:44:58 UTC (3,125 KB)"
"1750","HMD Vision-based Teleoperating UGV and UAV for Hostile Environment using Deep Learning","Abhishek Sawarkar, Vishal Chaudhari, Rahul Chavan, Varun Zope, Akshay Budale, Faruk Kazi","Robotics (cs.RO)","The necessity of maintaining a robust antiterrorist task force has become imperative in recent times with resurgence of rogue element in the society. A well equipped combat force warrants the safety and security of citizens and the integrity of the sovereign state. In this paper we propose a novel teleoperating robot which can play a major role in combat, rescue and reconnaissance missions by substantially reducing loss of human soldiers in such hostile environments. The proposed robotic solution consists of an unmanned ground vehicle equipped with an IP camera visual system broadcasting real-time video data to a remote cloud server. With the advancement in machine learning algorithms in the field of computer vision, we incorporate state of the art deep convolutional neural networks to identify and predict individuals with malevolent intent. The classification is performed on every frame of the video stream by the trained network in the cloud server. The predicted output of the network is overlaid on the video stream with specific colour marks and prediction percentage. Finally the data is resized into half-side by side format and streamed to the head mount display worn by the human controller which facilitates first person view of the scenario. The ground vehicle is also coupled with an unmanned aerial vehicle for aerial surveillance. The proposed scheme is an assistive system and the final decision evidently lies with the human handler.","Wed, 14 Sep 2016 07:03:15 UTC (2,412 KB)"
"1751","Stride Length Estimation with Deep Learning","Julius Hannink, Thomas Kautz, Cristian F. Pasluosta, Jens Barth, Samuel Schulein, Karl-Gunter Gamann, Jochen Klucken, Bjoern M. Eskofier","Machine Learning (cs.LG)","Accurate estimation of spatial gait characteristics is critical to assess motor impairments resulting from neurological or musculoskeletal disease. Currently, however, methodological constraints limit clinical applicability of state-of-the-art double integration approaches to gait patterns with a clear zero-velocity phase. We describe a novel approach to stride length estimation that uses deep convolutional neural networks to map stride-specific inertial sensor data to the resulting stride length. The model is trained on a publicly available and clinically relevant benchmark dataset consisting of 1220 strides from 101 geriatric patients. Evaluation is done in a 10-fold cross validation and for three different stride definitions. Even though best results are achieved with strides defined from mid-stance to mid-stance with average accuracy and precision of 0.01 $\pm$ 5.37 cm, performance does not strongly depend on stride definition. The achieved precision outperforms state-of-the-art methods evaluated on this benchmark dataset by 3.0 cm (36%). Due to the independence of stride definition, the proposed method is not subject to the methodological constrains that limit applicability of state-of-the-art double integration methods. Furthermore, precision on the benchmark dataset could be improved. With more precise mobile stride length estimation, new insights to the progression of neurological disease or early indications might be gained. Due to the independence of stride definition, previously uncharted diseases in terms of mobile gait analysis can now be investigated by re-training and applying the proposed method.","Mon, 12 Sep 2016 09:23:34 UTC (1,379 KB)[v2] Tue, 11 Oct 2016 10:54:22 UTC (1,366 KB)[v3] Thu, 9 Mar 2017 15:30:28 UTC (1,248 KB)"
"1752","Automated detection of smuggled high-risk security threats using Deep Learning","Nicolas Jaccard, Thomas W. Rogers, Edward J. Morton, Lewis D. Griffin","Computer Vision and Pattern Recognition (cs.CV)","The security infrastructure is ill-equipped to detect and deter the smuggling of non-explosive devices that enable terror attacks such as those recently perpetrated in western Europe. The detection of so-called ""small metallic threats"" (SMTs) in cargo containers currently relies on statistical risk analysis, intelligence reports, and visual inspection of X-ray images by security officers. The latter is very slow and unreliable due to the difficulty of the task: objects potentially spanning less than 50 pixels have to be detected in images containing more than 2 million pixels against very complex and cluttered backgrounds. In this contribution, we demonstrate for the first time the use of Convolutional Neural Networks (CNNs), a type of Deep Learning, to automate the detection of SMTs in fullsize X-ray images of cargo containers. Novel approaches for dataset augmentation allowed to train CNNs from-scratch despite the scarcity of data available. We report fewer than 6% false alarms when detecting 90% SMTs synthetically concealed in stream-of-commerce images, which corresponds to an improvement of over an order of magnitude over conventional approaches such as Bag-of-Words (BoWs). The proposed scheme offers potentially super-human performance for a fraction of the time it would take for a security officers to carry out visual inspection (processing time is approximately 3.5s per container image).","Fri, 9 Sep 2016 14:14:52 UTC (7,291 KB)"
"1753","INSIGHT-1 at SemEval-2016 Task 5: Deep Learning for Multilingual Aspect-based Sentiment Analysis","Sebastian Ruder, Parsa Ghaffari, John G. Breslin","Computation and Language (cs.CL); Machine Learning (cs.LG)","This paper describes our deep learning-based approach to multilingual aspect-based sentiment analysis as part of SemEval 2016 Task 5. We use a convolutional neural network (CNN) for both aspect extraction and aspect-based sentiment analysis. We cast aspect extraction as a multi-label classification problem, outputting probabilities over aspects parameterized by a threshold. To determine the sentiment towards an aspect, we concatenate an aspect vector with every word embedding and apply a convolution over it. Our constrained system (unconstrained for English) achieves competitive results across all languages and domains, placing first or second in 5 and 7 out of 11 language-domain pairs for aspect category detection (slot 1) and sentiment polarity (slot 3) respectively, thereby demonstrating the viability of a deep learning-based approach for multilingual aspect-based sentiment analysis.","Fri, 9 Sep 2016 11:23:51 UTC (98 KB)[v2] Thu, 22 Sep 2016 10:04:18 UTC (98 KB)"
"1754","Extraction of Skin Lesions from Non-Dermoscopic Images Using Deep Learning","Mohammad H. Jafari, Ebrahim Nasr-Esfahani, Nader Karimi, S.M. Reza Soroushmehr, Shadrokh Samavi, Kayvan Najarian","Computer Vision and Pattern Recognition (cs.CV)","Melanoma is amongst most aggressive types of cancer. However, it is highly curable if detected in its early stages. Prescreening of suspicious moles and lesions for malignancy is of great importance. Detection can be done by images captured by standard cameras, which are more preferable due to low cost and availability. One important step in computerized evaluation of skin lesions is accurate detection of lesion region, i.e. segmentation of an image into two regions as lesion and normal skin. Accurate segmentation can be challenging due to burdens such as illumination variation and low contrast between lesion and healthy skin. In this paper, a method based on deep neural networks is proposed for accurate extraction of a lesion region. The input image is preprocessed and then its patches are fed to a convolutional neural network (CNN). Local texture and global structure of the patches are processed in order to assign pixels to lesion or normal classes. A method for effective selection of training patches is used for more accurate detection of a lesion border. The output segmentation mask is refined by some post processing operations. The experimental results of qualitative and quantitative evaluations demonstrate that our method can outperform other state-of-the-art algorithms exist in the literature.","Thu, 8 Sep 2016 11:05:27 UTC (2,063 KB)"
"1755","Object Specific Deep Learning Feature and Its Application to Face Detection","Xianxu Hou, Ke Sun, Linlin Shen, Guoping Qiu","Computer Vision and Pattern Recognition (cs.CV)","We present a method for discovering and exploiting object specific deep learning features and use face detection as a case study. Motivated by the observation that certain convolutional channels of a Convolutional Neural Network (CNN) exhibit object specific responses, we seek to discover and exploit the convolutional channels of a CNN in which neurons are activated by the presence of specific objects in the input image. A method for explicitly fine-tuning a pre-trained CNN to induce an object specific channel (OSC) and systematically identifying it for the human face object has been developed. Based on the basic OSC features, we introduce a multi-resolution approach to constructing robust face heatmaps for fast face detection in unconstrained settings. We show that multi-resolution OSC can be used to develop state of the art face detectors which have the advantage of being simple and compact.","Tue, 6 Sep 2016 01:35:13 UTC (6,848 KB)"
"1756","Accurate De Novo Prediction of Protein Contact Map by Ultra-Deep Learning Model","Sheng Wang, Siqi Sun, Zhen Li, Renyu Zhang, Jinbo Xu","Biomolecules (q-bio.BM); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)","Recently exciting progress has been made on protein contact prediction, but the predicted contacts for proteins without many sequence homologs is still of low quality and not very useful for de novo structure prediction. This paper presents a new deep learning method that predicts contacts by integrating both evolutionary coupling (EC) and sequence conservation information through an ultra-deep neural network formed by two deep residual networks. This deep neural network allows us to model very complex sequence-contact relationship as well as long-range inter-contact correlation. Our method greatly outperforms existing contact prediction methods and leads to much more accurate contact-assisted protein folding. Tested on three datasets of 579 proteins, the average top L long-range prediction accuracy obtained our method, the representative EC method CCMpred and the CASP11 winner MetaPSICOV is 0.47, 0.21 and 0.30, respectively; the average top L/10 long-range accuracy of our method, CCMpred and MetaPSICOV is 0.77, 0.47 and 0.59, respectively. Ab initio folding using our predicted contacts as restraints can yield correct folds (i.e., TMscore>0.6) for 203 test proteins, while that using MetaPSICOV- and CCMpred-predicted contacts can do so for only 79 and 62 proteins, respectively. Further, our contact-assisted models have much better quality than template-based models. Using our predicted contacts as restraints, we can (ab initio) fold 208 of the 398 membrane proteins with TMscore>0.5. By contrast, when the training proteins of our method are used as templates, homology modeling can only do so for 10 of them. One interesting finding is that even if we do not train our prediction models with any membrane proteins, our method works very well on membrane protein prediction. Finally, in recent blind CAMEO benchmark our method successfully folded 5 test proteins with a novel fold.","Fri, 2 Sep 2016 17:41:54 UTC (973 KB)[v2] Mon, 5 Sep 2016 15:39:23 UTC (1,063 KB)[v3] Thu, 15 Sep 2016 03:09:45 UTC (1,089 KB)[v4] Fri, 16 Sep 2016 23:08:52 UTC (1,372 KB)[v5] Mon, 7 Nov 2016 06:01:32 UTC (2,107 KB)[v6] Sun, 27 Nov 2016 22:32:50 UTC (2,350 KB)"
"1757","A deep learning model for estimating story points","Morakot Choetkiertikul, Hoa Khanh Dam, Truyen Tran, Trang Pham, Aditya Ghose, Tim Menzies","Software Engineering (cs.SE); Machine Learning (cs.LG); Machine Learning (stat.ML)","Although there has been substantial research in software analytics for effort estimation in traditional software projects, little work has been done for estimation in agile projects, especially estimating user stories or issues. Story points are the most common unit of measure used for estimating the effort involved in implementing a user story or resolving an issue. In this paper, we offer for the \emph{first} time a comprehensive dataset for story points-based estimation that contains 23,313 issues from 16 open source projects. We also propose a prediction model for estimating story points based on a novel combination of two powerful deep learning architectures: long short-term memory and recurrent highway network. Our prediction system is \emph{end-to-end} trainable from raw input data to prediction outcomes without any manual feature engineering. An empirical evaluation demonstrates that our approach consistently outperforms three common effort estimation baselines and two alternatives in both Mean Absolute Error and the Standardized Accuracy.","Fri, 2 Sep 2016 07:42:29 UTC (239 KB)[v2] Tue, 6 Sep 2016 06:18:04 UTC (239 KB)"
"1758","Defeating Image Obfuscation with Deep Learning","Richard McPherson, Reza Shokri, Vitaly Shmatikov","Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)","We demonstrate that modern image recognition methods based on artificial neural networks can recover hidden information from images protected by various forms of obfuscation. The obfuscation techniques considered in this paper are mosaicing (also known as pixelation), blurring (as used by YouTube), and P3, a recently proposed system for privacy-preserving photo sharing that encrypts the significant JPEG coefficients to make images unrecognizable by humans. We empirically show how to train artificial neural networks to successfully identify faces and recognize objects and handwritten digits even if the images are protected using any of the above obfuscation techniques.","Thu, 1 Sep 2016 21:38:15 UTC (1,374 KB)[v2] Tue, 6 Sep 2016 21:47:12 UTC (1,385 KB)"
"1759","Deep Learning Human Mind for Automated Visual Classification","Concetto Spampinato, Simone Palazzo, Isaak Kavasidis, Daniela Giordano, Mubarak Shah, Nasim Souly","Computer Vision and Pattern Recognition (cs.CV)","What if we could effectively read the mind and transfer human visual capabilities to computer vision methods? In this paper, we aim at addressing this question by developing the first visual object classifier driven by human brain signals. In particular, we employ EEG data evoked by visual object stimuli combined with Recurrent Neural Networks (RNN) to learn a discriminative brain activity manifold of visual categories. Afterwards, we train a Convolutional Neural Network (CNN)-based regressor to project images onto the learned manifold, thus effectively allowing machines to employ human brain-based features for automated visual classification. We use a 32-channel EEG to record brain activity of seven subjects while looking at images of 40 ImageNet object classes. The proposed RNN based approach for discriminating object classes using brain signals reaches an average accuracy of about 40%, which outperforms existing methods attempting to learn EEG visual object representations. As for automated object categorization, our human brain-driven approach obtains competitive performance, comparable to those achieved by powerful CNN models, both on ImageNet and CalTech 101, thus demonstrating its classification and generalization capabilities. This gives us a real hope that, indeed, human mind can be read and transferred to machines.","Thu, 1 Sep 2016 18:47:05 UTC (2,612 KB)"
"1760","Approaching the Computational Color Constancy as a Classification Problem through Deep Learning","Seoung Wug Oh, Seon Joo Kim","Computer Vision and Pattern Recognition (cs.CV)","Computational color constancy refers to the problem of computing the illuminant color so that the images of a scene under varying illumination can be normalized to an image under the canonical illumination. In this paper, we adopt a deep learning framework for the illumination estimation problem. The proposed method works under the assumption of uniform illumination over the scene and aims for the accurate illuminant color computation. Specifically, we trained the convolutional neural network to solve the problem by casting the color constancy problem as an illumination classification problem. We designed the deep learning architecture so that the output of the network can be directly used for computing the color of the illumination. Experimental results show that our deep network is able to extract useful features for the illumination estimation and our method outperforms all previous color constancy methods on multiple test datasets.","Mon, 29 Aug 2016 08:41:55 UTC (37,488 KB)"
"1761","Benchmarking State-of-the-Art Deep Learning Software Tools","Shaohuai Shi, Qiang Wang, Pengfei Xu, Xiaowen Chu","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","Deep learning has been shown as a successful machine learning method for a variety of tasks, and its popularity results in numerous open-source deep learning software tools. Training a deep network is usually a very time-consuming process. To address the computational challenge in deep learning, many tools exploit hardware features such as multi-core CPUs and many-core GPUs to shorten the training time. However, different tools exhibit different features and running performance when training different types of deep networks on different hardware platforms, which makes it difficult for end users to select an appropriate pair of software and hardware. In this paper, we aim to make a comparative study of the state-of-the-art GPU-accelerated deep learning software tools, including Caffe, CNTK, MXNet, TensorFlow, and Torch. We first benchmark the running performance of these tools with three popular types of neural networks on two CPU platforms and three GPU platforms. We then benchmark some distributed versions on multiple GPUs. Our contribution is two-fold. First, for end users of deep learning tools, our benchmarking results can serve as a guide to selecting appropriate hardware platforms and software tools. Second, for software developers of deep learning tools, our in-depth analysis points out possible future directions to further optimize the running performance.","Thu, 25 Aug 2016 18:48:16 UTC (314 KB)[v2] Fri, 26 Aug 2016 06:25:05 UTC (314 KB)[v3] Sat, 3 Sep 2016 16:40:32 UTC (410 KB)[v4] Sun, 11 Sep 2016 06:13:13 UTC (416 KB)[v5] Mon, 19 Sep 2016 07:09:07 UTC (415 KB)[v6] Wed, 25 Jan 2017 09:27:52 UTC (541 KB)[v7] Fri, 17 Feb 2017 11:02:08 UTC (336 KB)"
"1762","Towards Bayesian Deep Learning: A Framework and Some Existing Methods","Hao Wang, Dit-Yan Yeung","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","While perception tasks such as visual object recognition and text understanding play an important role in human intelligence, the subsequent tasks that involve inference, reasoning and planning require an even higher level of intelligence. The past few years have seen major advances in many perception tasks using deep learning models. For higher-level inference, however, probabilistic graphical models with their Bayesian nature are still more powerful and flexible. To achieve integrated intelligence that involves both perception and inference, it is naturally desirable to tightly integrate deep learning and Bayesian models within a principled probabilistic framework, which we call Bayesian deep learning. In this unified framework, the perception of text or images using deep learning can boost the performance of higher-level inference and in return, the feedback from the inference process is able to enhance the perception of text or images. This paper proposes a general framework for Bayesian deep learning and reviews its recent applications on recommender systems, topic models, and control. In this paper, we also discuss the relationship and differences between Bayesian deep learning and other related topics like Bayesian treatment of neural networks.","Wed, 24 Aug 2016 16:15:22 UTC (1,515 KB)[v2] Sat, 3 Sep 2016 15:32:04 UTC (1,515 KB)"
"1763","Deep learning is competing random forest in computational docking","Mohamed Khamis, Walid Gomaa, Basem Galal","Biomolecules (q-bio.BM); Machine Learning (cs.LG)","Computational docking is the core process of computer-aided drug design; it aims at predicting the best orientation and conformation of a small drug molecule when bound to a target large protein receptor. The docking quality is typically measured by a scoring function: a mathematical predictive model that produces a score representing the binding free energy and hence the stability of the resulting complex molecule. We analyze the performance of both learning techniques on the scoring power, the ranking power, docking power, and screening power using the PDBbind 2013 database. For the scoring and ranking powers, the proposed learning scoring functions depend on a wide range of features (energy terms, pharmacophore, intermolecular) that entirely characterize the protein-ligand complexes. For the docking and screening powers, the proposed learning scoring functions depend on the intermolecular features of the RF-Score to utilize a larger number of training complexes. For the scoring power, the DL\_RF scoring function achieves Pearson's correlation coefficient between the predicted and experimentally measured binding affinities of 0.799 versus 0.758 of the RF scoring function. For the ranking power, the DL scoring function ranks the ligands bound to fixed target protein with accuracy 54% for the high-level ranking and with accuracy 78% for the low-level ranking while the RF scoring function achieves (46% and 62%) respectively. For the docking power, the DL\_RF scoring function has a success rate when the three best-scored ligand binding poses are considered within 2 A root-mean-square-deviation from the native pose of 36.0% versus 30.2% of the RF scoring function. For the screening power, the DL scoring function has an average enrichment factor and success rate at the top 1% level of (2.69 and 6.45%) respectively versus (1.61 and 4.84%) respectively of the RF scoring function.","Tue, 23 Aug 2016 22:52:22 UTC (518 KB)"
"1764","Fathom: Reference Workloads for Modern Deep Learning Methods","Robert Adolf, Saketh Rama, Brandon Reagen, Gu-Yeon Wei, David Brooks","Machine Learning (cs.LG)","Deep learning has been popularized by its recent successes on challenging artificial intelligence problems. One of the reasons for its dominance is also an ongoing challenge: the need for immense amounts of computational power. Hardware architects have responded by proposing a wide array of promising ideas, but to date, the majority of the work has focused on specific algorithms in somewhat narrow application domains. While their specificity does not diminish these approaches, there is a clear need for more flexible solutions. We believe the first step is to examine the characteristics of cutting edge models from across the deep learning community. Consequently, we have assembled Fathom: a collection of eight archetypal deep learning workloads for study. Each of these models comes from a seminal work in the deep learning community, ranging from the familiar deep convolutional neural network of Krizhevsky et al., to the more exotic memory networks from Facebook's AI research group. Fathom has been released online, and this paper focuses on understanding the fundamental performance characteristics of each model. We use a set of application-level modeling tools built around the TensorFlow deep learning framework in order to analyze the behavior of the Fathom workloads. We present a breakdown of where time is spent, the similarities between the performance profiles of our models, an analysis of behavior in inference and training, and the effects of parallelism on scaling.","Tue, 23 Aug 2016 17:11:07 UTC (688 KB)"
"1765","An image compression and encryption scheme based on deep learning","Fei Hu, Changjiu Pu, Haowei Gao, Mengzi Tang, Li Li","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM)","Stacked Auto-Encoder (SAE) is a kind of deep learning algorithm for unsupervised learning. Which has multi layers that project the vector representation of input data into a lower vector space. These projection vectors are dense representations of the input data. As a result, SAE can be used for image compression. Using chaotic logistic map, the compression ones can further be encrypted. In this study, an application of image compression and encryption is suggested using SAE and chaotic logistic map. Experiments show that this application is feasible and effective. It can be used for image transmission and image protection on internet simultaneously.","Tue, 16 Aug 2016 14:51:25 UTC (1,009 KB)[v2] Sun, 9 Oct 2016 02:27:20 UTC (932 KB)"
"1766","Boosting Docking-based Virtual Screening with Deep Learning","Janaina Cruz Pereira, Ernesto Raul Caffarena, Cicero dos Santos","Quantitative Methods (q-bio.QM)","In this work, we propose a deep learning approach to improve docking-based virtual screening. The introduced deep neural network, DeepVS, uses the output of a docking program and learns how to extract relevant features from basic data such as atom and residues types obtained from protein-ligand complexes. Our approach introduces the use of atom and amino acid embeddings and implements an effective way of creating distributed vector representations of protein-ligand complexes by modeling the compound as a set of atom contexts that is further processed by a convolutional layer. One of the main advantages of the proposed method is that it does not require feature engineering. We evaluate DeepVS on the Directory of Useful Decoys (DUD), using the output of two docking programs: AutodockVina1.1.2 and Dock6.6. Using a strict evaluation with leave-one-out cross-validation, DeepVS outperforms the docking programs in both AUC ROC and enrichment factor. Moreover, using the output of AutodockVina1.1.2, DeepVS achieves an AUC ROC of 0.81, which, to the best of our knowledge, is the best AUC reported so far for virtual screening using the 40 receptors from DUD.","Wed, 17 Aug 2016 03:32:02 UTC (953 KB)[v2] Mon, 21 Nov 2016 00:34:57 UTC (2,577 KB)"
"1767","Stacked Approximated Regression Machine: A Simple Deep Learning Approach","Zhangyang Wang, Shiyu Chang, Qing Ling, Shuai Huang, Xia Hu, Honghui Shi, Thomas S. Huang","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)","With the agreement of my coauthors, I Zhangyang Wang would like to withdraw the manuscript ""Stacked Approximated Regression Machine: A Simple Deep Learning Approach"". Some experimental procedures were not included in the manuscript, which makes a part of important claims not meaningful. In the relevant research, I was solely responsible for carrying out the experiments; the other coauthors joined in the discussions leading to the main algorithm. Please see the updated text for more details.","Sun, 14 Aug 2016 05:35:11 UTC (148 KB)[v2] Thu, 8 Sep 2016 17:46:13 UTC (26 KB)"
"1768","Applying Deep Learning to Basketball Trajectories","Rajiv Shah, Rob Romijnders","Neural and Evolutionary Computing (cs.NE); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","One of the emerging trends for sports analytics is the growing use of player and ball tracking data. A parallel development is deep learning predictive approaches that use vast quantities of data with less reliance on feature engineering. This paper applies recurrent neural networks in the form of sequence modeling to predict whether a three-point shot is successful. The models are capable of learning the trajectory of a basketball without any knowledge of physics. For comparison, a baseline static machine learning model with a full set of features, such as angle and velocity, in addition to the positional data is also tested. Using a dataset of over 20,000 three pointers from NBA SportVu data, the models based simply on sequential positional data outperform a static feature rich machine learning model in predicting whether a three-point shot is successful. This suggests deep learning models may offer an improvement to traditional feature based machine learning methods for tracking data.","Fri, 12 Aug 2016 13:50:24 UTC (283 KB)[v2] Tue, 16 Aug 2016 18:36:44 UTC (283 KB)"
"1769","Neural Encoding and Decoding with Deep Learning for Dynamic Natural Vision","Haiguang Wen, Junxing Shi, Yizhen Zhang, Kun-Han Lu, Jiayue Cao, Zhongming Liu","Neurons and Cognition (q-bio.NC); Quantitative Methods (q-bio.QM)","Convolutional neural network (CNN) driven by image recognition has been shown to be able to explain cortical responses to static pictures at ventral-stream areas. Here, we further showed that such CNN could reliably predict and decode functional magnetic resonance imaging data from humans watching natural movies, despite its lack of any mechanism to account for temporal dynamics or feedback processing. Using separate data, encoding and decoding models were developed and evaluated for describing the bi-directional relationships be-tween the CNN and the brain. Through the encoding models, the CNN-predicted areas covered not only the ventral stream, but also the dorsal stream, albe-it to a lesser degree; single-voxel response was visualized as the specific pixel pattern that drove the response, revealing the distinct representation of individual cortical location; cortical activation was synthesized from natural images with high-throughput to map category representation, con-trast, and selectivity. Through the decoding models, fMRI signals were directly decoded to estimate the feature representations in both visual and semantic spaces, for direct visual reconstruction and seman-tic categorization, respectively. These results cor-roborate, generalize, and extend previous findings, and highlight the value of using deep learning, as an all-in-one model of the visual cortex, to understand and decode natural vision.","Thu, 11 Aug 2016 11:51:21 UTC (4,952 KB)[v2] Tue, 14 Nov 2017 17:35:51 UTC (3,868 KB)"
"1770","Mining Fashion Outfit Composition Using An End-to-End Deep Learning Approach on Set Data","Yuncheng Li, LiangLiang Cao, Jiang Zhu, Jiebo Luo","Multimedia (cs.MM); Machine Learning (cs.LG)","Composing fashion outfits involves deep understanding of fashion standards while incorporating creativity for choosing multiple fashion items (e.g., Jewelry, Bag, Pants, Dress). In fashion websites, popular or high-quality fashion outfits are usually designed by fashion experts and followed by large audiences. In this paper, we propose a machine learning system to compose fashion outfits automatically. The core of the proposed automatic composition system is to score fashion outfit candidates based on the appearances and meta-data. We propose to leverage outfit popularity on fashion oriented websites to supervise the scoring component. The scoring component is a multi-modal multi-instance deep learning system that evaluates instance aesthetics and set compatibility simultaneously. In order to train and evaluate the proposed composition system, we have collected a large scale fashion outfit dataset with 195K outfits and 368K fashion items from Polyvore. Although the fashion outfit scoring and composition is rather challenging, we have achieved an AUC of 85% for the scoring component, and an accuracy of 77% for a constrained composition task.","Wed, 10 Aug 2016 01:11:32 UTC (1,702 KB)[v2] Sat, 15 Apr 2017 05:26:23 UTC (4,884 KB)"
"1771","Deep Learning a Grasp Function for Grasping under Gripper Pose Uncertainty","Edward Johns, Stefan Leutenegger, Andrew J. Davison","Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","This paper presents a new method for parallel-jaw grasping of isolated objects from depth images, under large gripper pose uncertainty. Whilst most approaches aim to predict the single best grasp pose from an image, our method first predicts a score for every possible grasp pose, which we denote the grasp function. With this, it is possible to achieve grasping robust to the gripper's pose uncertainty, by smoothing the grasp function with the pose uncertainty function. Therefore, if the single best pose is adjacent to a region of poor grasp quality, that pose will no longer be chosen, and instead a pose will be chosen which is surrounded by a region of high grasp quality. To learn this function, we train a Convolutional Neural Network which takes as input a single depth image of an object, and outputs a score for each grasp pose across the image. Training data for this is generated by use of physics simulation and depth image simulation with 3D object meshes, to enable acquisition of sufficient data without requiring exhaustive real-world experiments. We evaluate with both synthetic and real experiments, and show that the learned grasp score is more robust to gripper pose uncertainty than when this uncertainty is not accounted for.","Sun, 7 Aug 2016 16:30:42 UTC (3,919 KB)"
"1772","Deep Learning the City : Quantifying Urban Perception At A Global Scale","Abhimanyu Dubey, Nikhil Naik, Devi Parikh, Ramesh Raskar, Cesar A. Hidalgo","Computer Vision and Pattern Recognition (cs.CV)","Computer vision methods that quantify the perception of urban environment are increasingly being used to study the relationship between a city's physical appearance and the behavior and health of its residents. Yet, the throughput of current methods is too limited to quantify the perception of cities across the world. To tackle this challenge, we introduce a new crowdsourced dataset containing 110,988 images from 56 cities, and 1,170,000 pairwise comparisons provided by 81,630 online volunteers along six perceptual attributes: safe, lively, boring, wealthy, depressing, and beautiful. Using this data, we train a Siamese-like convolutional neural architecture, which learns from a joint classification and ranking loss, to predict human judgments of pairwise image comparisons. Our results show that crowdsourcing combined with neural networks can produce urban perception data at the global scale.","Fri, 5 Aug 2016 05:58:35 UTC (8,206 KB)[v2] Mon, 12 Sep 2016 18:48:37 UTC (8,205 KB)"
"1773","Deep Learning for Detecting Multiple Space-Time Action Tubes in Videos","Suman Saha, Gurkirt Singh, Michael Sapienza, Philip H. S. Torr, Fabio Cuzzolin","Computer Vision and Pattern Recognition (cs.CV)","In this work, we propose an approach to the spatiotemporal localisation (detection) and classification of multiple concurrent actions within temporally untrimmed videos. Our framework is composed of three stages. In stage 1, appearance and motion detection networks are employed to localise and score actions from colour images and optical flow. In stage 2, the appearance network detections are boosted by combining them with the motion detection scores, in proportion to their respective spatial overlap. In stage 3, sequences of detection boxes most likely to be associated with a single action instance, called action tubes, are constructed by solving two energy maximisation problems via dynamic programming. While in the first pass, action paths spanning the whole video are built by linking detection boxes over time using their class-specific scores and their spatial overlap, in the second pass, temporal trimming is performed by ensuring label consistency for all constituting detection boxes. We demonstrate the performance of our algorithm on the challenging UCF101, J-HMDB-21 and LIRIS-HARL datasets, achieving new state-of-the-art results across the board and significantly increasing detection speed at test time. We achieve a huge leap forward in action detection performance and report a 20% and 11% gain in mAP (mean average precision) on UCF-101 and J-HMDB-21 datasets respectively when compared to the state-of-the-art.","Thu, 4 Aug 2016 13:38:38 UTC (6,468 KB)"
"1774","Density functionals from deep learning","Jeffrey M. McMahon","Computational Physics (physics.comp-ph); Chemical Physics (physics.chem-ph)","Density-functional theory is a formally exact description of a many-body quantum system in terms of its density; in practice, however, approximations to the universal density functional are required. In this work, a model based on deep learning is developed to approximate this functional. Deep learning allows computational models that are capable of naturally discovering intricate structure in large and/or high-dimensional data sets, with multiple levels of abstraction. As no assumptions are made as to the form of this structure, this approach is much more powerful and flexible than traditional approaches. As an example application, the model is shown to perform well on approximating the kinetic-energy density functional for noninteracting electrons. The model is analyzed in detail, and its advantages over conventional machine learning are discussed.","Mon, 1 Aug 2016 04:28:32 UTC (152 KB)"
"1775","Learning Robust Features using Deep Learning for Automatic Seizure Detection","Pierre Thodoroff, Joelle Pineau, Andrew Lim","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)","We present and evaluate the capacity of a deep neural network to learn robust features from EEG to automatically detect seizures. This is a challenging problem because seizure manifestations on EEG are extremely variable both inter- and intra-patient. By simultaneously capturing spectral, temporal and spatial information our recurrent convolutional neural network learns a general spatially invariant representation of a seizure. The proposed approach exceeds significantly previous results obtained on cross-patient classifiers both in terms of sensitivity and false positive rate. Furthermore, our model proves to be robust to missing channel and variable electrode montage.","Sun, 31 Jul 2016 14:28:15 UTC (1,372 KB)"
"1776","Image Prediction for Limited-angle Tomography via Deep Learning with Convolutional Neural Network","Hanming Zhang, Liang Li, Kai Qiao, Linyuan Wang, Bin Yan, Lei Li, Guoen Hu","Medical Physics (physics.med-ph); Computer Vision and Pattern Recognition (cs.CV)","Limited angle problem is a challenging issue in x-ray computed tomography (CT) field. Iterative reconstruction methods that utilize the additional prior can suppress artifacts and improve image quality, but unfortunately require increased computation time. An interesting way is to restrain the artifacts in the images reconstructed from the practical filtered back projection (FBP) method. Frikel and Quinto have proved that the streak artifacts in FBP results could be characterized. It indicates that the artifacts created by FBP method have specific and similar characteristics in a stationary limited-angle scanning configuration. Based on this understanding, this work aims at developing a method to extract and suppress specific artifacts of FBP reconstructions for limited-angle tomography. A data-driven learning-based method is proposed based on a deep convolutional neural network. An end-to-end mapping between the FBP and artifact-free images is learned and the implicit features involving artifacts will be extracted and suppressed via nonlinear mapping. The qualitative and quantitative evaluations of experimental results indicate that the proposed method show a stable and prospective performance on artifacts reduction and detail recovery for limited angle tomography. The presented strategy provides a simple and efficient approach for improving image quality of the reconstruction results from limited projection data.","Fri, 29 Jul 2016 07:31:18 UTC (1,078 KB)"
"1777","Efficient Hyperparameter Optimization of Deep Learning Algorithms Using Deterministic RBF Surrogates","Ilija Ilievski, Taimoor Akhtar, Jiashi Feng, Christine Annette Shoemaker","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)","Automatically searching for optimal hyperparameter configurations is of crucial importance for applying deep learning algorithms in practice. Recently, Bayesian optimization has been proposed for optimizing hyperparameters of various machine learning algorithms. Those methods adopt probabilistic surrogate models like Gaussian processes to approximate and minimize the validation error function of hyperparameter values. However, probabilistic surrogates require accurate estimates of sufficient statistics (e.g., covariance) of the error distribution and thus need many function evaluations with a sizeable number of hyperparameters. This makes them inefficient for optimizing hyperparameters of deep learning algorithms, which are highly expensive to evaluate. In this work, we propose a new deterministic and efficient hyperparameter optimization method that employs radial basis functions as error surrogates. The proposed mixed integer algorithm, called HORD, searches the surrogate for the most promising hyperparameter values through dynamic coordinate search and requires many fewer function evaluations. HORD does well in low dimensions but it is exceptionally better in higher dimensions. Extensive evaluations on MNIST and CIFAR-10 for four deep neural networks demonstrate HORD significantly outperforms the well-established Bayesian optimization methods such as GP, SMAC, and TPE. For instance, on average, HORD is more than 6 times faster than GP-EI in obtaining the best configuration of 19 hyperparameters.","Thu, 28 Jul 2016 05:03:32 UTC (4,136 KB)[v2] Sat, 21 Jan 2017 03:26:06 UTC (5,018 KB)"
"1778","Impact of Physical Activity on Sleep:A Deep Learning Based Exploration","Aarti Sathyanarayana, Shafiq Joty, Luis Fernandez-Luque, Ferda Ofli, Jaideep Srivastava, Ahmed Elmagarmid, Shahrad Taheri, Teresa Arora","Machine Learning (cs.LG)","The importance of sleep is paramount for maintaining physical, emotional and mental wellbeing. Though the relationship between sleep and physical activity is known to be important, it is not yet fully understood. The explosion in popularity of actigraphy and wearable devices, provides a unique opportunity to understand this relationship. Leveraging this information source requires new tools to be developed to facilitate data-driven research for sleep and activity patient-recommendations. In this paper we explore the use of deep learning to build sleep quality prediction models based on actigraphy data. We first use deep learning as a pure model building device by performing human activity recognition (HAR) on raw sensor data, and using deep learning to build sleep prediction models. We compare the deep learning models with those build using classical approaches, i.e. logistic regression, support vector machines, random forest and adaboost. Secondly, we employ the advantage of deep learning with its ability to handle high dimensional datasets. We explore several deep learning models on the raw wearable sensor output without performing HAR or any other feature extraction. Our results show that using a convolutional neural network on the raw wearables output improves the predictive value of sleep quality from physical activity, by an additional 8% compared to state-of-the-art non-deep learning approaches, which itself shows a 15% improvement over current practice. Moreover, utilizing deep learning on raw data eliminates the need for data pre-processing and simplifies the overall workflow to analyze actigraphy data for sleep and physical activity research.","Sun, 24 Jul 2016 12:12:03 UTC (493 KB)"
"1779","Classification of Alzheimer's Disease Structural MRI Data by Deep Learning Convolutional Neural Networks","Saman Sarraf, Ghassem Tofighi","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)","Recently, machine learning techniques especially predictive modeling and pattern recognition in biomedical sciences from drug delivery system to medical imaging has become one of the important methods which are assisting researchers to have deeper understanding of entire issue and to solve complex medical problems. Deep learning is a powerful machine learning algorithm in classification while extracting low to high-level features. In this paper, we used convolutional neural network to classify Alzheimer's brain from normal healthy brain. The importance of classifying this kind of medical data is to potentially develop a predict model or system in order to recognize the type disease from normal subjects or to estimate the stage of the disease. Classification of clinical data such as Alzheimer's disease has been always challenging and most problematic part has been always selecting the most discriminative features. Using Convolutional Neural Network (CNN) and the famous architecture LeNet-5, we successfully classified structural MRI data of Alzheimer's subjects from normal controls where the accuracy of test data on trained data reached 98.84%. This experiment suggests us the shift and scale invariant features extracted by CNN followed by deep learning classification is most powerful method to distinguish clinical data from healthy data in fMRI. This approach also enables us to expand our methodology to predict more complicated systems.","Fri, 22 Jul 2016 07:48:18 UTC (1,220 KB)[v2] Fri, 19 May 2017 20:41:51 UTC (1,228 KB)"
"1780","Deep Learning of Local RGB-D Patches for 3D Object Detection and 6D Pose Estimation","Wadim Kehl, Fausto Milletari, Federico Tombari, Slobodan Ilic, Nassir Navab","Computer Vision and Pattern Recognition (cs.CV)","We present a 3D object detection method that uses regressed descriptors of locally-sampled RGB-D patches for 6D vote casting. For regression, we employ a convolutional auto-encoder that has been trained on a large collection of random local patches. During testing, scene patch descriptors are matched against a database of synthetic model view patches and cast 6D object votes which are subsequently filtered to refined hypotheses. We evaluate on three datasets to show that our method generalizes well to previously unseen input data, delivers robust detection results that compete with and surpass the state-of-the-art while being scalable in the number of objects.","Wed, 20 Jul 2016 17:38:15 UTC (6,330 KB)"
"1781","Onsager-corrected deep learning for sparse linear inverse problems","Mark Borgerding, Philip Schniter","Information Theory (cs.IT); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning has gained great popularity due to its widespread success on many inference problems. We consider the application of deep learning to the sparse linear inverse problem encountered in compressive sensing, where one seeks to recover a sparse signal from a small number of noisy linear measurements. In this paper, we propose a novel neural-network architecture that decouples prediction errors across layers in the same way that the approximate message passing (AMP) algorithm decouples them across iterations: through Onsager correction. Numerical experiments suggest that our ""learned AMP"" network significantly improves upon Gregor and LeCun's ""learned ISTA"" network in both accuracy and complexity.","Wed, 20 Jul 2016 14:14:49 UTC (386 KB)"
"1782","Improved Deep Learning of Object Category using Pose Information","Jiaping Zhao, Laurent Itti","Computer Vision and Pattern Recognition (cs.CV)","Despite significant recent progress, the best available computer vision algorithms still lag far behind human capabilities, even for recognizing individual discrete objects under various poses, illuminations, and backgrounds. Here we present a new approach to using object pose information to improve deep network learning. While existing large-scale datasets, e.g. ImageNet, do not have pose information, we leverage the newly published turntable dataset, iLab-20M, which has ~22M images of 704 object instances shot under different lightings, camera viewpoints and turntable rotations, to do more controlled object recognition experiments. We introduce a new convolutional neural network architecture, what/where CNN (2W-CNN), built on a linear-chain feedforward CNN (e.g., AlexNet), augmented by hierarchical layers regularized by object poses. Pose information is only used as feedback signal during training, in addition to category information; during test, the feedforward network only predicts category. To validate the approach, we train both 2W-CNN and AlexNet using a fraction of the dataset, and 2W-CNN achieves 6% performance improvement in category prediction. We show mathematically that 2W-CNN has inherent advantages over AlexNet under the stochastic gradient descent (SGD) optimization procedure. Further more, we fine-tune object recognition on ImageNet by using the pretrained 2W-CNN and AlexNet features on iLab-20M, results show that significant improvements have been achieved, compared with training AlexNet from scratch. Moreover, fine-tuning 2W-CNN features performs even better than fine-tuning the pretrained AlexNet features. These results show pretrained features on iLab- 20M generalizes well to natural image datasets, and 2WCNN learns even better features for object recognition than AlexNet.","Wed, 20 Jul 2016 07:11:08 UTC (5,931 KB)[v2] Wed, 31 Aug 2016 19:07:10 UTC (6,231 KB)[v3] Sun, 22 Jan 2017 23:53:15 UTC (6,075 KB)"
"1783","Deep learning trends for focal brain pathology segmentation in MRI","Mohammad Havaei, Nicolas Guizard, Hugo Larochelle, Pierre-Marc Jodoin","Computer Vision and Pattern Recognition (cs.CV)","Segmentation of focal (localized) brain pathologies such as brain tumors and brain lesions caused by multiple sclerosis and ischemic strokes are necessary for medical diagnosis, surgical planning and disease development as well as other applications such as tractography. Over the years, attempts have been made to automate this process for both clinical and research reasons. In this regard, machine learning methods have long been a focus of attention. Over the past two years, the medical imaging field has seen a rise in the use of a particular branch of machine learning commonly known as deep learning. In the non-medical computer vision world, deep learning based methods have obtained state-of-the-art results on many datasets. Recent studies in computer aided diagnostics have shown deep learning methods (and especially convolutional neural networks - CNN) to yield promising results. In this chapter, we provide a survey of CNN methods applied to medical imaging with a focus on brain pathology segmentation. In particular, we discuss their characteristic peculiarities and their specific configuration and adjustments that are best suited to segment medical images. We also underline the intrinsic differences deep learning methods have with other machine learning methods.","Mon, 18 Jul 2016 19:52:00 UTC (685 KB)[v2] Mon, 23 Jan 2017 16:41:46 UTC (685 KB)[v3] Tue, 24 Jan 2017 02:44:48 UTC (685 KB)"
"1784","An Empirical Evaluation of various Deep Learning Architectures for Bi-Sequence Classification Tasks","Anirban Laha, Vikas Raykar","Computation and Language (cs.CL)","Several tasks in argumentation mining and debating, question-answering, and natural language inference involve classifying a sequence in the context of another sequence (referred as bi-sequence classification). For several single sequence classification tasks, the current state-of-the-art approaches are based on recurrent and convolutional neural networks. On the other hand, for bi-sequence classification problems, there is not much understanding as to the best deep learning architecture. In this paper, we attempt to get an understanding of this category of problems by extensive empirical evaluation of 19 different deep learning architectures (specifically on different ways of handling context) for various problems originating in natural language processing like debating, textual entailment and question-answering. Following the empirical evaluation, we offer our insights and conclusions regarding the architectures we have considered. We also establish the first deep learning baselines for three argumentation mining tasks.","Sun, 17 Jul 2016 11:15:38 UTC (2,532 KB)[v2] Sun, 2 Oct 2016 20:59:05 UTC (2,532 KB)"
"1785","Learning to Decode Linear Codes Using Deep Learning","Eliya Nachmani, Yair Beery, David Burshtein","Information Theory (cs.IT); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","A novel deep learning method for improving the belief propagation algorithm is proposed. The method generalizes the standard belief propagation algorithm by assigning weights to the edges of the Tanner graph. These edges are then trained using deep learning techniques. A well-known property of the belief propagation algorithm is the independence of the performance on the transmitted codeword. A crucial property of our new method is that our decoder preserved this property. Furthermore, this property allows us to learn only a single codeword instead of exponential number of code-words. Improvements over the belief propagation algorithm are demonstrated for various high density parity check codes.","Sat, 16 Jul 2016 19:09:26 UTC (1,340 KB)[v2] Fri, 30 Sep 2016 14:43:52 UTC (3,076 KB)"
"1786","Efficient and Robust Pedestrian Detection using Deep Learning for Human-Aware Navigation","Andre Mateus, David Ribeiro, Pedro Miraldo, Jacinto C. Nascimento","Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)","This paper addresses the problem of Human-Aware Navigation (HAN), using multi camera sensors to implement a vision-based person tracking system. The main contributions of this paper are as follows: a novel and efficient Deep Learning person detection and a standardization of human-aware constraints. In the first stage of the approach, we propose to cascade the Aggregate Channel Features (ACF) detector with a deep Convolutional Neural Network (CNN) to achieve fast and accurate Pedestrian Detection (PD). Regarding the human awareness (that can be defined as constraints associated with the robot's motion), we use a mixture of asymmetric Gaussian functions, to define the cost functions associated to each constraint. Both methods proposed herein are evaluated individually to measure the impact of each of the components. The final solution (including both the proposed pedestrian detection and the human-aware constraints) is tested in a typical domestic indoor scenario, in four distinct experiments. The results show that the robot is able to cope with human-aware constraints, defined after common proxemics and social rules.","Fri, 15 Jul 2016 10:16:45 UTC (6,136 KB)[v2] Thu, 28 Sep 2017 13:21:54 UTC (23,240 KB)"
"1787","A Real-Time Deep Learning Pedestrian Detector for Robot Navigation","David Ribeiro, Andre Mateus, Pedro Miraldo, Jacinto C. Nascimento","Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)","A real-time Deep Learning based method for Pedestrian Detection (PD) is applied to the Human-Aware robot navigation problem. The pedestrian detector combines the Aggregate Channel Features (ACF) detector with a deep Convolutional Neural Network (CNN) in order to obtain fast and accurate performance. Our solution is firstly evaluated using a set of real images taken from onboard and offboard cameras and, then, it is validated in a typical robot navigation environment with pedestrians (two distinct experiments are conducted). The results on both tests show that our pedestrian detector is robust and fast enough to be used on robot navigation applications.","Fri, 15 Jul 2016 09:58:08 UTC (5,428 KB)[v2] Tue, 19 Sep 2017 09:31:28 UTC (4,894 KB)"
"1788","Characterizing Driving Styles with Deep Learning","Weishan Dong, Jian Li, Renjie Yao, Changsheng Li, Ting Yuan, Lanjun Wang","Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","Characterizing driving styles of human drivers using vehicle sensor data, e.g., GPS, is an interesting research problem and an important real-world requirement from automotive industries. A good representation of driving features can be highly valuable for autonomous driving, auto insurance, and many other application scenarios. However, traditional methods mainly rely on handcrafted features, which limit machine learning algorithms to achieve a better performance. In this paper, we propose a novel deep learning solution to this problem, which could be the first attempt of extending deep learning to driving behavior analysis based on GPS data. The proposed approach can effectively extract high level and interpretable features describing complex driving patterns. It also requires significantly less human experience and work. The power of the learned driving style representations are validated through the driver identification problem using a large real dataset.","Wed, 13 Jul 2016 07:15:30 UTC (390 KB)[v2] Sat, 8 Oct 2016 05:21:00 UTC (605 KB)"
"1789","Deep Learning of Appearance Models for Online Object Tracking","Mengyao Zhai, Mehrsan Javan Roshtkhari, Greg Mori","Computer Vision and Pattern Recognition (cs.CV)","This paper introduces a novel deep learning based approach for vision based single target tracking. We address this problem by proposing a network architecture which takes the input video frames and directly computes the tracking score for any candidate target location by estimating the probability distributions of the positive and negative examples. This is achieved by combining a deep convolutional neural network with a Bayesian loss layer in a unified framework. In order to deal with the limited number of positive training examples, the network is pre-trained offline for a generic image feature representation and then is fine-tuned in multiple steps. An online fine-tuning step is carried out at every frame to learn the appearance of the target. We adopt a two-stage iterative algorithm to adaptively update the network parameters and maintain a probability density for target/non-target regions. The tracker has been tested on the standard tracking benchmark and the results indicate that the proposed solution achieves state-of-the-art tracking results.","Sat, 9 Jul 2016 06:15:20 UTC (900 KB)"
"1790","Deep Learning for Mortgage Risk","Justin Sirignano, Apaar Sadhwani, Kay Giesecke","Statistical Finance (q-fin.ST)","We develop a deep learning model of multi-period mortgage risk and use it to analyze an unprecedented dataset of origination and monthly performance records for over 120 million mortgages originated across the US between 1995 and 2014. Our estimators of term structures of conditional probabilities of prepayment, foreclosure and various states of delinquency incorporate the dynamics of a large number of loan-specific as well as macroeconomic variables down to the zip-code level. The estimators uncover the highly nonlinear nature of the relationship between the variables and borrower behavior, especially prepayment. They also highlight the effects of local economic conditions on borrower behavior. State unemployment has the greatest explanatory power among all variables, offering strong evidence of the tight connection between housing finance markets and the macroeconomy. The sensitivity of a borrower to changes in unemployment strongly depends upon current unemployment. It also significantly varies across the entire borrower population, which highlights the interaction of unemployment and many other variables. These findings have important implications for mortgage-backed security investors, rating agencies, and housing finance policymakers.","Fri, 8 Jul 2016 17:42:40 UTC (2,523 KB)[v2] Sat, 10 Mar 2018 11:29:52 UTC (2,685 KB)"
"1791","Applying Deep Learning to the Newsvendor Problem","Afshin Oroojlooyjadid, Lawrence Snyder, Martin Taka<U+010D>","Machine Learning (cs.LG)","The newsvendor problem is one of the most basic and widely applied inventory models. There are numerous extensions of this problem. If the probability distribution of the demand is known, the problem can be solved analytically. However, approximating the probability distribution is not easy and is prone to error; therefore, the resulting solution to the newsvendor problem may be not optimal. To address this issue, we propose an algorithm based on deep learning that optimizes the order quantities for all products based on features of the demand data. Our algorithm integrates the forecasting and inventory-optimization steps, rather than solving them separately, as is typically done, and does not require knowledge of the probability distributions of the demand. Numerical experiments on real-world data suggest that our algorithm outperforms other approaches, including data-driven and machine learning approaches, especially for demands with high volatility. Finally, in order to show how this approach can be used for other inventory optimization problems, we provide an extension for (r,Q) policies.","Thu, 7 Jul 2016 21:44:53 UTC (154 KB)[v2] Mon, 8 Aug 2016 14:02:31 UTC (154 KB)[v3] Thu, 31 Aug 2017 13:36:39 UTC (868 KB)[v4] Tue, 6 Mar 2018 18:39:00 UTC (1,126 KB)"
"1792","DeepChrome: Deep-learning for predicting gene expression from histone modifications","Ritambhara Singh, Jack Lanchantin, Gabriel Robins, Yanjun Qi","Machine Learning (cs.LG); Genomics (q-bio.GN)","Motivation: Histone modifications are among the most important factors that control gene regulation. Computational methods that predict gene expression from histone modification signals are highly desirable for understanding their combinatorial effects in gene regulation. This knowledge can help in developing 'epigenetic drugs' for diseases like cancer. Previous studies for quantifying the relationship between histone modifications and gene expression levels either failed to capture combinatorial effects or relied on multiple methods that separate predictions and combinatorial analysis. This paper develops a unified discriminative framework using a deep convolutional neural network to classify gene expression using histone modification data as input. Our system, called DeepChrome, allows automatic extraction of complex interactions among important features. To simultaneously visualize the combinatorial interactions among histone modifications, we propose a novel optimization-based technique that generates feature pattern maps from the learnt deep model. This provides an intuitive description of underlying epigenetic mechanisms that regulate genes. Results: We show that DeepChrome outperforms state-of-the-art models like Support Vector Machines and Random Forests for gene expression classification task on 56 different cell-types from REMC database. The output of our visualization technique not only validates the previous observations but also allows novel insights about combinatorial interactions among histone modification marks, some of which have recently been observed by experimental studies.","Thu, 7 Jul 2016 16:50:57 UTC (1,360 KB)"
"1793","Iterative Multi-domain Regularized Deep Learning for Anatomical Structure Detection and Segmentation from Ultrasound Images","Hao Chen, Yefeng Zheng, Jin-Hyeong Park, Pheng-Ann Heng, S. Kevin Zhou","Computer Vision and Pattern Recognition (cs.CV)","Accurate detection and segmentation of anatomical structures from ultrasound images are crucial for clinical diagnosis and biometric measurements. Although ultrasound imaging has been widely used with superiorities such as low cost and portability, the fuzzy border definition and existence of abounding artifacts pose great challenges for automatically detecting and segmenting the complex anatomical structures. In this paper, we propose a multi-domain regularized deep learning method to address this challenging problem. By leveraging the transfer learning from cross domains, the feature representations are effectively enhanced. The results are further improved by the iterative refinement. Moreover, our method is quite efficient by taking advantage of a fully convolutional network, which is formulated as an end-to-end learning framework of detection and segmentation. Extensive experimental results on a large-scale database corroborated that our method achieved a superior detection and segmentation accuracy, outperforming other methods by a significant margin and demonstrating competitive capability even compared to human performance.","Thu, 7 Jul 2016 02:21:25 UTC (2,717 KB)"
"1794","Automated 5-year Mortality Prediction using Deep Learning and Radiomics Features from Chest Computed Tomography","Gustavo Carneiro, Luke Oakden-Rayner, Andrew P. Bradley, Jacinto Nascimento, Lyle Palmer","Computer Vision and Pattern Recognition (cs.CV)","We propose new methods for the prediction of 5-year mortality in elderly individuals using chest computed tomography (CT). The methods consist of a classifier that performs this prediction using a set of features extracted from the CT image and segmentation maps of multiple anatomic structures. We explore two approaches: 1) a unified framework based on deep learning, where features and classifier are automatically learned in a single optimisation process; and 2) a multi-stage framework based on the design and selection/extraction of hand-crafted radiomics features, followed by the classifier learning process. Experimental results, based on a dataset of 48 annotated chest CTs, show that the deep learning model produces a mean 5-year mortality prediction accuracy of 68.5%, while radiomics produces a mean accuracy that varies between 56% to 66% (depending on the feature selection/extraction method and classifier). The successful development of the proposed models has the potential to make a profound impact in preventive and personalised healthcare.","Fri, 1 Jul 2016 14:44:37 UTC (852 KB)"
"1795","Deep Learning with Differential Privacy","Martin Abadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, Li Zhang","Machine Learning (stat.ML); Cryptography and Security (cs.CR); Machine Learning (cs.LG)","Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.","Fri, 1 Jul 2016 07:29:10 UTC (474 KB)[v2] Mon, 24 Oct 2016 11:59:40 UTC (512 KB)"
"1796","Detection of concealed cars in complex cargo X-ray imagery using Deep Learning","Nicolas Jaccard, Thomas W. Rogers, Edward J. Morton, Lewis D. Griffin","Computer Vision and Pattern Recognition (cs.CV)","Non-intrusive inspection systems based on X-ray radiography techniques are routinely used at transport hubs to ensure the conformity of cargo content with the supplied shipping manifest. As trade volumes increase and regulations become more stringent, manual inspection by trained operators is less and less viable due to low throughput. Machine vision techniques can assist operators in their task by automating parts of the inspection workflow. Since cars are routinely involved in trafficking, export fraud, and tax evasion schemes, they represent an attractive target for automated detection and flagging for subsequent inspection by operators. In this contribution, we describe a method for the detection of cars in X-ray cargo images based on trained-from-scratch Convolutional Neural Networks. By introducing an oversampling scheme that suitably addresses the low number of car images available for training, we achieved 100% car image classification rate for a false positive rate of 1-in-454. Cars that were partially or completely obscured by other goods, a modus operandi frequently adopted by criminals, were correctly detected. We believe that this level of performance suggests that the method is suitable for deployment in the field. It is expected that the generic object detection workflow described can be extended to other object classes given the availability of suitable training data.","Sun, 26 Jun 2016 19:45:22 UTC (9,121 KB)[v2] Fri, 9 Sep 2016 11:54:18 UTC (9,122 KB)"
"1797","Wide & Deep Learning for Recommender Systems","Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, Rohan Anil, Zakaria Haque, Lichan Hong, Vihan Jain, Xiaobing Liu, Hemal Shah","Machine Learning (cs.LG); Information Retrieval (cs.IR); Machine Learning (stat.ML)","Generalized linear models with nonlinear feature transformations are widely used for large-scale regression and classification problems with sparse inputs. Memorization of feature interactions through a wide set of cross-product feature transformations are effective and interpretable, while generalization requires more feature engineering effort. With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features. However, deep neural networks with embeddings can over-generalize and recommend less relevant items when the user-item interactions are sparse and high-rank. In this paper, we present Wide & Deep learning---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems. We productionized and evaluated the system on Google Play, a commercial mobile app store with over one billion active users and over one million apps. Online experiment results show that Wide & Deep significantly increased app acquisitions compared with wide-only and deep-only models. We have also open-sourced our implementation in TensorFlow.","Fri, 24 Jun 2016 19:07:02 UTC (208 KB)"
"1798","Deep Learning Relevance: Creating Relevant Information (as Opposed to Retrieving it)","Christina Lioma, Birger Larsen, Casper Petersen, Jakob Grue Simonsen","Information Retrieval (cs.IR)","What if Information Retrieval (IR) systems did not just retrieve relevant information that is stored in their indices, but could also ""understand"" it and synthesise it into a single document? We present a preliminary study that makes a first step towards answering this question. Given a query, we train a Recurrent Neural Network (RNN) on existing relevant information to that query. We then use the RNN to ""deep learn"" a single, synthetic, and we assume, relevant document for that query. We design a crowdsourcing experiment to assess how relevant the ""deep learned"" document is, compared to existing relevant documents. Users are shown a query and four wordclouds (of three existing relevant documents and our deep learned synthetic document). The synthetic document is ranked on average most relevant of all.","Fri, 24 Jun 2016 12:41:50 UTC (917 KB)[v2] Mon, 27 Jun 2016 08:27:29 UTC (918 KB)"
"1799","Deep Learning Markov Random Field for Semantic Segmentation","Ziwei Liu, Xiaoxiao Li, Ping Luo, Chen Change Loy, Xiaoou Tang","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Semantic segmentation tasks can be well modeled by Markov Random Field (MRF). This paper addresses semantic segmentation by incorporating high-order relations and mixture of label contexts into MRF. Unlike previous works that optimized MRFs using iterative algorithm, we solve MRF by proposing a Convolutional Neural Network (CNN), namely Deep Parsing Network (DPN), which enables deterministic end-to-end computation in a single forward pass. Specifically, DPN extends a contemporary CNN to model unary terms and additional layers are devised to approximate the mean field (MF) algorithm for pairwise terms. It has several appealing properties. First, different from the recent works that required many iterations of MF during back-propagation, DPN is able to achieve high performance by approximating one iteration of MF. Second, DPN represents various types of pairwise terms, making many existing models as its special cases. Furthermore, pairwise terms in DPN provide a unified framework to encode rich contextual information in high-dimensional data, such as images and videos. Third, DPN makes MF easier to be parallelized and speeded up, thus enabling efficient inference. DPN is thoroughly evaluated on standard semantic image/video segmentation benchmarks, where a single DPN model yields state-of-the-art segmentation accuracies on PASCAL VOC 2012, Cityscapes dataset and CamVid dataset.","Thu, 23 Jun 2016 08:52:39 UTC (3,408 KB)[v2] Tue, 8 Aug 2017 09:24:18 UTC (3,277 KB)"
"1800","Deep Learning for Identifying Metastatic Breast Cancer","Dayong Wang, Aditya Khosla, Rishab Gargeya, Humayun Irshad, Andrew H. Beck","Quantitative Methods (q-bio.QM); Computer Vision and Pattern Recognition (cs.CV)","The International Symposium on Biomedical Imaging (ISBI) held a grand challenge to evaluate computational systems for the automated detection of metastatic breast cancer in whole slide images of sentinel lymph node biopsies. Our team won both competitions in the grand challenge, obtaining an area under the receiver operating curve (AUC) of 0.925 for the task of whole slide image classification and a score of 0.7051 for the tumor localization task. A pathologist independently reviewed the same images, obtaining a whole slide image classification AUC of 0.966 and a tumor localization score of 0.733. Combining our deep learning system's predictions with the human pathologist's diagnoses increased the pathologist's AUC to 0.995, representing an approximately 85 percent reduction in human error rate. These results demonstrate the power of using deep learning to produce significant improvements in the accuracy of pathological diagnoses.","Sat, 18 Jun 2016 04:00:31 UTC (21,490 KB)"
"1801","DeepFood: Deep Learning-Based Food Image Recognition for Computer-Aided Dietary Assessment","Chang Liu, Yu Cao, Yan Luo, Guanling Chen, Vinod Vokkarane, Yunsheng Ma","Computer Vision and Pattern Recognition (cs.CV)","Worldwide, in 2014, more than 1.9 billion adults, 18 years and older, were overweight. Of these, over 600 million were obese. Accurately documenting dietary caloric intake is crucial to manage weight loss, but also presents challenges because most of the current methods for dietary assessment must rely on memory to recall foods eaten. The ultimate goal of our research is to develop computer-aided technical solutions to enhance and improve the accuracy of current measurements of dietary intake. Our proposed system in this paper aims to improve the accuracy of dietary assessment by analyzing the food images captured by mobile devices (e.g., smartphone). The key technique innovation in this paper is the deep learning-based food image recognition algorithms. Substantial research has demonstrated that digital imaging accurately estimates dietary intake in many environments and it has many advantages over other methods. However, how to derive the food information (e.g., food type and portion size) from food image effectively and efficiently remains a challenging and open research problem. We propose a new Convolutional Neural Network (CNN)-based food image recognition algorithm to address this problem. We applied our proposed approach to two real-world food image data sets (UEC-256 and Food-101) and achieved impressive results. To the best of our knowledge, these results outperformed all other reported work using these two data sets. Our experiments have demonstrated that the proposed approach is a promising solution for addressing the food image recognition problem. Our future work includes further improving the performance of the algorithms and integrating our system into a real-world mobile and cloud computing-based system to enhance the accuracy of current measurements of dietary intake.","Fri, 17 Jun 2016 21:03:19 UTC (218 KB)"
"1802","Early Visual Concept Learning with Unsupervised Deep Learning","Irina Higgins, Loic Matthey, Xavier Glorot, Arka Pal, Benigno Uria, Charles Blundell, Shakir Mohamed, Alexander Lerchner","Machine Learning (stat.ML); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)","Automated discovery of early visual concepts from raw image data is a major open challenge in AI research. Addressing this problem, we propose an unsupervised approach for learning disentangled representations of the underlying factors of variation. We draw inspiration from neuroscience, and show how this can be achieved in an unsupervised generative model by applying the same learning pressures as have been suggested to act in the ventral visual stream in the brain. By enforcing redundancy reduction, encouraging statistical independence, and exposure to data with transform continuities analogous to those to which human infants are exposed, we obtain a variational autoencoder (VAE) framework capable of learning disentangled factors. Our approach makes few assumptions and works well across a wide variety of datasets. Furthermore, our solution has useful emergent properties, such as zero-shot inference and an intuitive understanding of ""objectness"".","Fri, 17 Jun 2016 16:19:46 UTC (7,354 KB)[v2] Mon, 19 Sep 2016 19:50:49 UTC (5,086 KB)[v3] Tue, 20 Sep 2016 09:30:26 UTC (5,086 KB)"
"1803","Learning Abstract Classes using Deep Learning","Sebastian Stabinger, Antonio Rodriguez-Sanchez, Justus Piater","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)","Humans are generally good at learning abstract concepts about objects and scenes (e.g.\ spatial orientation, relative sizes, etc.). Over the last years convolutional neural networks have achieved almost human performance in recognizing concrete classes (i.e.\ specific object categories). This paper tests the performance of a current CNN (GoogLeNet) on the task of differentiating between abstract classes which are trivially differentiable for humans. We trained and tested the CNN on the two abstract classes of horizontal and vertical orientation and determined how well the network is able to transfer the learned classes to other, previously unseen objects.","Fri, 17 Jun 2016 12:51:23 UTC (60 KB)"
"1804","Deep Learning for Music","Allen Huang, Raymond Wu","Machine Learning (cs.LG); Sound (cs.SD)","Our goal is to be able to build a generative model from a deep neural network architecture to try to create music that has both harmony and melody and is passable as music composed by humans. Previous work in music generation has mainly been focused on creating a single melody. More recent work on polyphonic music modeling, centered around time series probability density estimation, has met some partial success. In particular, there has been a lot of work based off of Recurrent Neural Networks combined with Restricted Boltzmann Machines (RNN-RBM) and other similar recurrent energy based models. Our approach, however, is to perform end-to-end learning and generation with deep neural nets alone.","Wed, 15 Jun 2016 19:38:14 UTC (1,503 KB)"
"1805","Omnivore: An Optimizer for Multi-device Deep Learning on CPUs and GPUs","Stefan Hadjis, Ce Zhang, Ioannis Mitliagkas, Dan Iter, Christopher Re","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","We study the factors affecting training time in multi-device deep learning systems. Given a specification of a convolutional neural network, our goal is to minimize the time to train this model on a cluster of commodity CPUs and GPUs. We first focus on the single-node setting and show that by using standard batching and data-parallel techniques, throughput can be improved by at least 5.5x over state-of-the-art systems on CPUs. This ensures an end-to-end training speed directly proportional to the throughput of a device regardless of its underlying hardware, allowing each node in the cluster to be treated as a black box. Our second contribution is a theoretical and empirical study of the tradeoffs affecting end-to-end training time in a multiple-device setting. We identify the degree of asynchronous parallelization as a key factor affecting both hardware and statistical efficiency. We see that asynchrony can be viewed as introducing a momentum term. Our results imply that tuning momentum is critical in asynchronous parallel configurations, and suggest that published results that have not been fully tuned might report suboptimal performance for some configurations. For our third contribution, we use our novel understanding of the interaction between system and optimization dynamics to provide an efficient hyperparameter optimizer. Our optimizer involves a predictive model for the total time to convergence and selects an allocation of resources to minimize that time. We demonstrate that the most popular distributed deep learning systems fall within our tradeoff space, but do not optimize within the space. By doing this optimization, our prototype runs 1.9x to 12x faster than the fastest state-of-the-art systems.","Tue, 14 Jun 2016 18:21:04 UTC (2,439 KB)[v2] Mon, 18 Jul 2016 00:05:49 UTC (2,439 KB)[v3] Fri, 26 Aug 2016 13:04:00 UTC (2,439 KB)[v4] Wed, 19 Oct 2016 04:26:03 UTC (2,549 KB)"
"1806","Logic Tensor Networks: Deep Learning and Logical Reasoning from Data and Knowledge","Luciano Serafini, Artur d'Avila Garcez","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic in Computer Science (cs.LO); Neural and Evolutionary Computing (cs.NE)","We propose Logic Tensor Networks: a uniform framework for integrating automatic learning and reasoning. A logic formalism called Real Logic is defined on a first-order language whereby formulas have truth-value in the interval [0,1] and semantics defined concretely on the domain of real numbers. Logical constants are interpreted as feature vectors of real numbers. Real Logic promotes a well-founded integration of deductive reasoning on a knowledge-base and efficient data-driven relational machine learning. We show how Real Logic can be implemented in deep Tensor Neural Networks with the use of Google's tensorflow primitives. The paper concludes with experiments applying Logic Tensor Networks on a simple but representative example of knowledge completion.","Tue, 14 Jun 2016 15:25:28 UTC (29 KB)[v2] Thu, 7 Jul 2016 12:28:57 UTC (30 KB)"
"1807","Deep Learning with Darwin: Evolutionary Synthesis of Deep Neural Networks","Mohammad Javad Shafiee, Akshaya Mishra, Alexander Wong","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","Taking inspiration from biological evolution, we explore the idea of ""Can deep neural networks evolve naturally over successive generations into highly efficient deep neural networks?"" by introducing the notion of synthesizing new highly efficient, yet powerful deep neural networks over successive generations via an evolutionary process from ancestor deep neural networks. The architectural traits of ancestor deep neural networks are encoded using synaptic probability models, which can be viewed as the `DNA' of these networks. New descendant networks with differing network architectures are synthesized based on these synaptic probability models from the ancestor networks and computational environmental factor models, in a random manner to mimic heredity, natural selection, and random mutation. These offspring networks are then trained into fully functional networks, like one would train a newborn, and have more efficient, more diverse network architectures than their ancestor networks, while achieving powerful modeling capabilities. Experimental results for the task of visual saliency demonstrated that the synthesized `evolved' offspring networks can achieve state-of-the-art performance while having network architectures that are significantly more efficient (with a staggering $\sim$48-fold decrease in synapses by the fourth generation) compared to the original ancestor network.","Tue, 14 Jun 2016 14:36:55 UTC (2,608 KB)[v2] Tue, 12 Jul 2016 16:15:40 UTC (6,651 KB)[v3] Mon, 6 Feb 2017 22:51:33 UTC (6,713 KB)"
"1808","Towards an integration of deep learning and neuroscience","Adam Marblestone, Greg Wayne, Konrad Kording","Neurons and Cognition (q-bio.NC)","Neuroscience has focused on the detailed implementation of computation, studying neural codes, dynamics and circuits. In machine learning, however, artificial neural networks tend to eschew precisely designed codes, dynamics or circuits in favor of brute force optimization of a cost function, often using simple and relatively uniform initial architectures. Two recent developments have emerged within machine learning that create an opportunity to connect these seemingly divergent perspectives. First, structured architectures are used, including dedicated systems for attention, recursion and various forms of short- and long-term memory storage. Second, cost functions and training procedures have become more complex and are varied across layers and over time. Here we think about the brain in terms of these ideas. We hypothesize that (1) the brain optimizes cost functions, (2) these cost functions are diverse and differ across brain locations and over development, and (3) optimization operates within a pre-structured architecture matched to the computational problems posed by behavior. Such a heterogeneously optimized system, enabled by a series of interacting cost functions, serves to make learning data-efficient and precisely targeted to the needs of the organism. We suggest directions by which neuroscience could seek to refine and test these hypotheses.","Mon, 13 Jun 2016 05:08:39 UTC (235 KB)"
"1809","Mutual Exclusivity Loss for Semi-Supervised Deep Learning","Mehdi Sajjadi, Mehran Javanmardi, Tolga Tasdizen","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","In this paper we consider the problem of semi-supervised learning with deep Convolutional Neural Networks (ConvNets). Semi-supervised learning is motivated on the observation that unlabeled data is cheap and can be used to improve the accuracy of classifiers. In this paper we propose an unsupervised regularization term that explicitly forces the classifier's prediction for multiple classes to be mutually-exclusive and effectively guides the decision boundary to lie on the low density space between the manifolds corresponding to different classes of data. Our proposed approach is general and can be used with any backpropagation-based learning method. We show through different experiments that our method can improve the object recognition performance of ConvNets using unlabeled data.","Thu, 9 Jun 2016 23:15:16 UTC (726 KB)"
"1810","Apparent Age Estimation Using Ensemble of Deep Learning Models","Refik Can Malli, Mehmet Aygun, Hazim Kemal Ekenel","Computer Vision and Pattern Recognition (cs.CV)","In this paper, we address the problem of apparent age estimation. Different from estimating the real age of individuals, in which each face image has a single age label, in this problem, face images have multiple age labels, corresponding to the ages perceived by the annotators, when they look at these images. This provides an intriguing computer vision problem, since in generic image or object classification tasks, it is typical to have a single ground truth label per class. To account for multiple labels per image, instead of using average age of the annotated face image as the class label, we have grouped the face images that are within a specified age range. Using these age groups and their age-shifted groupings, we have trained an ensemble of deep learning models. Before feeding an input face image to a deep learning model, five facial landmark points are detected and used for 2-D alignment. We have employed and fine tuned convolutional neural networks (CNNs) that are based on VGG-16 [24] architecture and pretrained on the IMDB-WIKI dataset [22]. The outputs of these deep learning models are then combined to produce the final estimation. Proposed method achieves 0.3668 error in the final ChaLearn LAP 2016 challenge test set [5].","Thu, 9 Jun 2016 11:00:21 UTC (3,775 KB)"
"1811","A Comprehensive Analysis of Deep Learning Based Representation for Face Recognition","Mostafa Mehdipour Ghazi, Hazim Kemal Ekenel","Computer Vision and Pattern Recognition (cs.CV)","Deep learning based approaches have been dominating the face recognition field due to the significant performance improvement they have provided on the challenging wild datasets. These approaches have been extensively tested on such unconstrained datasets, on the Labeled Faces in the Wild and YouTube Faces, to name a few. However, their capability to handle individual appearance variations caused by factors such as head pose, illumination, occlusion, and misalignment has not been thoroughly assessed till now. In this paper, we present a comprehensive study to evaluate the performance of deep learning based face representation under several conditions including the varying head pose angles, upper and lower face occlusion, changing illumination of different strengths, and misalignment due to erroneous facial feature localization. Two successful and publicly available deep learning models, namely VGG-Face and Lightened CNN have been utilized to extract face representations. The obtained results show that although deep learning provides a powerful representation for face recognition, it can still benefit from preprocessing, for example, for pose and illumination normalization in order to achieve better performance under various conditions. Particularly, if these variations are not included in the dataset used to train the deep learning model, the role of preprocessing becomes more crucial. Experimental results also show that deep learning based representation is robust to misalignment and can tolerate facial feature localization errors up to 10% of the interocular distance.","Thu, 9 Jun 2016 10:25:24 UTC (1,101 KB)"
"1812","Structured Convolution Matrices for Energy-efficient Deep learning","Rathinakumar Appuswamy, Tapan Nayak, John Arthur, Steven Esser, Paul Merolla, Jeffrey Mckinstry, Timothy Melano, Myron Flickner, Dharmendra Modha","Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","We derive a relationship between network representation in energy-efficient neuromorphic architectures and block Toplitz convolutional matrices. Inspired by this connection, we develop deep convolutional networks using a family of structured convolutional matrices and achieve state-of-the-art trade-off between energy efficiency and classification accuracy for well-known image recognition tasks. We also put forward a novel method to train binary convolutional networks by utilising an existing connection between noisy-rectified linear units and binary activations.","Wed, 8 Jun 2016 05:31:43 UTC (637 KB)"
"1813","Deep Learning Convolutional Networks for Multiphoton Microscopy Vasculature Segmentation","Petteri Teikari, Marc Santos, Charissa Poon, Kullervo Hynynen","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)","Recently there has been an increasing trend to use deep learning frameworks for both 2D consumer images and for 3D medical images. However, there has been little effort to use deep frameworks for volumetric vascular segmentation. We wanted to address this by providing a freely available dataset of 12 annotated two-photon vasculature microscopy stacks. We demonstrated the use of deep learning framework consisting both 2D and 3D convolutional filters (ConvNet). Our hybrid 2D-3D architecture produced promising segmentation result. We derived the architectures from Lee et al. who used the ZNN framework initially designed for electron microscope image segmentation. We hope that by sharing our volumetric vasculature datasets, we will inspire other researchers to experiment with vasculature dataset and improve the used network architectures.","Wed, 8 Jun 2016 02:57:00 UTC (3,776 KB)"
"1814","A Deep-Learning Approach for Operation of an Automated Realtime Flare Forecast","Yuko Hada-Muranushi, Takayuki Muranushi, Ayumi Asai, Daisuke Okanohara, Rudy Raymond, Gentaro Watanabe, Shigeru Nemoto, Kazunari Shibata","Solar and Stellar Astrophysics (astro-ph.SR); Machine Learning (cs.LG)","Automated forecasts serve important role in space weather science, by providing statistical insights to flare-trigger mechanisms, and by enabling tailor-made forecasts and high-frequency forecasts. Only by realtime forecast we can experimentally measure the performance of flare-forecasting methods while confidently avoiding overlearning. We have been operating unmanned flare forecast service since August, 2015 that provides 24-hour-ahead forecast of solar flares, every 12 minutes. We report the method and prediction results of the system.","Mon, 6 Jun 2016 00:02:20 UTC (1,258 KB)"
"1815","A Deep Learning Approach to Block-based Compressed Sensing of Images","Amir Adler, David Boublil, Michael Elad, Michael Zibulevsky","Computer Vision and Pattern Recognition (cs.CV)","Compressed sensing (CS) is a signal processing framework for efficiently reconstructing a signal from a small number of measurements, obtained by linear projections of the signal. Block-based CS is a lightweight CS approach that is mostly suitable for processing very high-dimensional images and videos: it operates on local patches, employs a low-complexity reconstruction operator and requires significantly less memory to store the sensing matrix. In this paper we present a deep learning approach for block-based CS, in which a fully-connected network performs both the block-based linear sensing and non-linear reconstruction stages. During the training phase, the sensing matrix and the non-linear reconstruction operator are \emph{jointly} optimized, and the proposed approach outperforms state-of-the-art both in terms of reconstruction quality and computation time. For example, at a 25% sensing rate the average PSNR advantage is 0.77dB and computation time is over 200-times faster.","Sun, 5 Jun 2016 14:40:54 UTC (3,289 KB)"
"1816","Asynchrony begets Momentum, with an Application to Deep Learning","Ioannis Mitliagkas, Ce Zhang, Stefan Hadjis, Christopher Re","Machine Learning (stat.ML); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Optimization and Control (math.OC)","Asynchronous methods are widely used in deep learning, but have limited theoretical justification when applied to non-convex problems. We show that running stochastic gradient descent (SGD) in an asynchronous manner can be viewed as adding a momentum-like term to the SGD iteration. Our result does not assume convexity of the objective function, so it is applicable to deep learning systems. We observe that a standard queuing model of asynchrony results in a form of momentum that is commonly used by deep learning practitioners. This forges a link between queuing theory and asynchrony in deep learning systems, which could be useful for systems builders. For convolutional neural networks, we experimentally validate that the degree of asynchrony directly correlates with the momentum, confirming our main result. An important implication is that tuning the momentum parameter is important when considering different levels of asynchrony. We assert that properly tuned momentum reduces the number of steps required for convergence. Finally, our theory suggests new ways of counteracting the adverse effects of asynchrony: a simple mechanism like using negative algorithmic momentum can improve performance under high asynchrony. Since asynchronous methods have better hardware efficiency, this result may shed light on when asynchronous execution is more efficient for deep learning systems.","Tue, 31 May 2016 19:16:56 UTC (586 KB)[v2] Fri, 25 Nov 2016 12:00:28 UTC (1,696 KB)"
"1817","The use of deep learning in image segmentation, classification and detection","M.S. Badea, I.I. Felea, L.M. Florea, C. Vertan","Computer Vision and Pattern Recognition (cs.CV)","Recent years have shown that deep learned neural networks are a valuable tool in the field of computer vision. This paper addresses the use of two different kinds of network architectures, namely LeNet and Network in Network (NiN). They will be compared in terms of both performance and computational efficiency by addressing the classification and detection problems. In this paper, multiple databases will be used to test the networks. One of them contains images depicting burn wounds from pediatric cases, another one contains an extensive number of art images and other facial databases were used for facial keypoints detection.","Tue, 31 May 2016 13:09:40 UTC (493 KB)"
"1818","Robust Deep-Learning-Based Road-Prediction for Augmented Reality Navigation Systems","Matthias Limmer, Julian Forster, Dennis Baudach, Florian Schule, Roland Schweiger, Hendrik P.A. Lensch","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)","This paper proposes an approach that predicts the road course from camera sensors leveraging deep learning techniques. Road pixels are identified by training a multi-scale convolutional neural network on a large number of full-scene-labeled night-time road images including adverse weather conditions. A framework is presented that applies the proposed approach to longer distance road course estimation, which is the basis for an augmented reality navigation application. In this framework long range sensor data (radar) and data from a map database are fused with short range sensor data (camera) to produce a precise longitudinal and lateral localization and road course estimation. The proposed approach reliably detects roads with and without lane markings and thus increases the robustness and availability of road course estimations and augmented reality navigation. Evaluations on an extensive set of high precision ground truth data taken from a differential GPS and an inertial measurement unit show that the proposed approach reaches state-of-the-art performance without the limitation of requiring existing lane markings.","Tue, 31 May 2016 09:00:33 UTC (2,494 KB)"
"1819","Self Paced Deep Learning for Weakly Supervised Object Detection","Enver Sangineto, Moin Nabi, Dubravko Culibrk, Nicu Sebe","Computer Vision and Pattern Recognition (cs.CV)","In a weakly-supervised scenario object detectors need to be trained using image-level annotation alone. Since bounding-box-level ground truth is not available, most of the solutions proposed so far are based on an iterative, Multiple Instance Learning framework in which the current classifier is used to select the highest-confidence boxes in each image, which are treated as pseudo-ground truth in the next training iteration. However, the errors of an immature classifier can make the process drift, usually introducing many of false positives in the training dataset. To alleviate this problem, we propose in this paper a training protocol based on the self-paced learning paradigm. The main idea is to iteratively select a subset of images and boxes that are the most reliable, and use them for training. While in the past few years similar strategies have been adopted for SVMs and other classifiers, we are the first showing that a self-paced approach can be used with deep-network-based classifiers in an end-to-end training pipeline. The method we propose is built on the fully-supervised Fast-RCNN architecture and can be applied to similar architectures which represent the input image as a bag of boxes. We show state-of-the-art results on Pascal VOC 2007, Pascal VOC 2010 and ILSVRC 2013. On ILSVRC 2013 our results based on a low-capacity AlexNet network outperform even those weakly-supervised approaches which are based on much higher-capacity networks.","Tue, 24 May 2016 20:34:03 UTC (4,786 KB)[v2] Tue, 16 May 2017 16:04:30 UTC (6,372 KB)[v3] Wed, 21 Feb 2018 16:33:44 UTC (5,651 KB)"
"1820","Deep Learning without Poor Local Minima","Kenji Kawaguchi","Machine Learning (stat.ML); Machine Learning (cs.LG); Optimization and Control (math.OC)","In this paper, we prove a conjecture published in 1989 and also partially address an open problem announced at the Conference on Learning Theory (COLT) 2015. With no unrealistic assumption, we first prove the following statements for the squared loss function of deep linear neural networks with any depth and any widths: 1) the function is non-convex and non-concave, 2) every local minimum is a global minimum, 3) every critical point that is not a global minimum is a saddle point, and 4) there exist ""bad"" saddle points (where the Hessian has no negative eigenvalue) for the deeper networks (with more than three layers), whereas there is no bad saddle point for the shallow networks (with three layers). Moreover, for deep nonlinear neural networks, we prove the same four statements via a reduction to a deep linear model under the independence assumption adopted from recent work. As a result, we present an instance, for which we can answer the following question: how difficult is it to directly train a deep model in theory? It is more difficult than the classical machine learning models (because of the non-convexity), but not too difficult (because of the nonexistence of poor local minima). Furthermore, the mathematically proven existence of bad saddle points for deeper models would suggest a possible open problem. We note that even though we have advanced the theoretical foundations of deep learning and non-convex optimization, there is still a gap between theory and practice.","Mon, 23 May 2016 17:34:20 UTC (33 KB)[v2] Mon, 22 Aug 2016 14:26:22 UTC (39 KB)[v3] Tue, 27 Dec 2016 22:47:50 UTC (39 KB)"
"1821","Generative Choreography using Deep Learning","Luka Crnkovic-Friis, Louise Crnkovic-Friis","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Neural and Evolutionary Computing (cs.NE)","Recent advances in deep learning have enabled the extraction of high-level features from raw sensor data which has opened up new possibilities in many different fields, including computer generated choreography. In this paper we present a system chor-rnn for generating novel choreographic material in the nuanced choreographic language and style of an individual choreographer. It also shows promising results in producing a higher level compositional cohesion, rather than just generating sequences of movement. At the core of chor-rnn is a deep recurrent neural network trained on raw motion capture data and that can generate new dance sequences for a solo dancer. Chor-rnn can be used for collaborative human-machine choreography or as a creative catalyst, serving as inspiration for a choreographer.","Mon, 23 May 2016 07:36:49 UTC (269 KB)"
"1822","DLAU: A Scalable Deep Learning Accelerator Unit on FPGA","Chao Wang, Qi Yu, Lei Gong, Xi Li, Yuan Xie, Xuehai Zhou","Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC); Neural and Evolutionary Computing (cs.NE)","As the emerging field of machine learning, deep learning shows excellent ability in solving complex learning problems. However, the size of the networks becomes increasingly large scale due to the demands of the practical applications, which poses significant challenge to construct a high performance implementations of deep learning neural networks. In order to improve the performance as well to maintain the low power cost, in this paper we design DLAU, which is a scalable accelerator architecture for large-scale deep learning networks using FPGA as the hardware prototype. The DLAU accelerator employs three pipelined processing units to improve the throughput and utilizes tile techniques to explore locality for deep learning applications. Experimental results on the state-of-the-art Xilinx FPGA board demonstrate that the DLAU accelerator is able to achieve up to 36.1x speedup comparing to the Intel Core2 processors, with the power consumption at 234mW.","Mon, 23 May 2016 04:56:04 UTC (910 KB)"
"1823","DeepLearningKit - an GPU Optimized Deep Learning Framework for Apple's iOS, OS X and tvOS developed in Metal and Swift","Amund Tveit, Torbjrn Morland, Thomas Brox Rst","Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC); Neural and Evolutionary Computing (cs.NE)","In this paper we present DeepLearningKit - an open source framework that supports using pretrained deep learning models (convolutional neural networks) for iOS, OS X and tvOS. DeepLearningKit is developed in Metal in order to utilize the GPU efficiently and Swift for integration with applications, e.g. iOS-based mobile apps on iPhone/iPad, tvOS-based apps for the big screen, or OS X desktop applications. The goal is to support using deep learning models trained with popular frameworks such as Caffe, Torch, TensorFlow, Theano, Pylearn, Deeplearning4J and Mocha. Given the massive GPU resources and time required to train Deep Learning models we suggest an App Store like model to distribute and download pretrained and reusable Deep Learning models.","Sun, 15 May 2016 23:19:48 UTC (3,390 KB)"
"1824","LightNet: A Versatile, Standalone Matlab-based Environment for Deep Learning","Chengxi Ye, Chen Zhao, Yezhou Yang, Cornelia Fermuller, Yiannis Aloimonos","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)","LightNet is a lightweight, versatile and purely Matlab-based deep learning framework. The idea underlying its design is to provide an easy-to-understand, easy-to-use and efficient computational platform for deep learning research. The implemented framework supports major deep learning architectures such as Multilayer Perceptron Networks (MLP), Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN). The framework also supports both CPU and GPU computation, and the switch between them is straightforward. Different applications in computer vision, natural language processing and robotics are demonstrated as experiments.","Mon, 9 May 2016 20:33:30 UTC (114 KB)[v2] Fri, 13 May 2016 00:20:14 UTC (114 KB)[v3] Tue, 2 Aug 2016 04:00:30 UTC (118 KB)"
"1825","Ask Your Neurons: A Deep Learning Approach to Visual Question Answering","Mateusz Malinowski, Marcus Rohrbach, Mario Fritz","Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)","We address a question answering task on real-world images that is set up as a Visual Turing Test. By combining latest advances in image representation and natural language processing, we propose Ask Your Neurons, a scalable, jointly trained, end-to-end formulation to this problem. In contrast to previous efforts, we are facing a multi-modal problem where the language output (answer) is conditioned on visual and natural language inputs (image and question). We provide additional insights into the problem by analyzing how much information is contained only in the language part for which we provide a new human baseline. To study human consensus, which is related to the ambiguities inherent in this challenging task, we propose two novel metrics and collect additional answers which extend the original DAQUAR dataset to DAQUAR-Consensus. Moreover, we also extend our analysis to VQA, a large-scale question answering about images dataset, where we investigate some particular design choices and show the importance of stronger visual models. At the same time, we achieve strong performance of our model that still uses a global image representation. Finally, based on such analysis, we refine our Ask Your Neurons on DAQUAR, which also leads to a better performance on this challenging task.","Mon, 9 May 2016 19:04:23 UTC (4,583 KB)[v2] Thu, 24 Nov 2016 10:30:18 UTC (3,940 KB)"
"1826","Distributed stochastic optimization for deep learning (thesis)","Sixin Zhang","Machine Learning (cs.LG)","We study the problem of how to distribute the training of large-scale deep learning models in the parallel computing environment. We propose a new distributed stochastic optimization method called Elastic Averaging SGD (EASGD). We analyze the convergence rate of the EASGD method in the synchronous scenario and compare its stability condition with the existing ADMM method in the round-robin scheme. An asynchronous and momentum variant of the EASGD method is applied to train deep convolutional neural networks for image classification on the CIFAR and ImageNet datasets. Our approach accelerates the training and furthermore achieves better test accuracy. It also requires a much smaller amount of communication than other common baseline approaches such as the DOWNPOUR method. We then investigate the limit in speedup of the initial and the asymptotic phase of the mini-batch SGD, the momentum SGD, and the EASGD methods. We find that the spread of the input data distribution has a big impact on their initial convergence rate and stability region. We also find a surprising connection between the momentum SGD and the EASGD method with a negative moving average rate. A non-convex case is also studied to understand when EASGD can get trapped by a saddle point. Finally, we scale up the EASGD method by using a tree structured network topology. We show empirically its advantage and challenge. We also establish a connection between the EASGD and the DOWNPOUR method with the classical Jacobi and the Gauss-Seidel method, thus unifying a class of distributed stochastic optimization methods.","Sat, 7 May 2016 16:55:22 UTC (4,615 KB)"
"1827","DeepPicker: a Deep Learning Approach for Fully Automated Particle Picking in Cryo-EM","Feng Wang, Huichao Gong, Gaochao liu, Meijing Li, Chuangye Yan, Tian Xia, Xueming Li, Jianyang Zeng","Quantitative Methods (q-bio.QM); Machine Learning (cs.LG)","Particle picking is a time-consuming step in single-particle analysis and often requires significant interventions from users, which has become a bottleneck for future automated electron cryo-microscopy (cryo-EM). Here we report a deep learning framework, called DeepPicker, to address this problem and fill the current gaps toward a fully automated cryo-EM pipeline. DeepPicker employs a novel cross-molecule training strategy to capture common features of particles from previously-analyzed micrographs, and thus does not require any human intervention during particle picking. Tests on the recently-published cryo-EM data of three complexes have demonstrated that our deep learning based scheme can successfully accomplish the human-level particle picking process and identify a sufficient number of particles that are comparable to those manually by human experts. These results indicate that DeepPicker can provide a practically useful tool to significantly reduce the time and manual effort spent in single-particle analysis and thus greatly facilitate high-resolution cryo-EM structure determination.","Fri, 6 May 2016 06:51:02 UTC (6,509 KB)"
"1828","Accelerating Deep Learning with Shrinkage and Recall","Shuai Zheng, Abhinav Vishnu, Chris Ding","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)","Deep Learning is a very powerful machine learning model. Deep Learning trains a large number of parameters for multiple layers and is very slow when data is in large scale and the architecture size is large. Inspired from the shrinking technique used in accelerating computation of Support Vector Machines (SVM) algorithm and screening technique used in LASSO, we propose a shrinking Deep Learning with recall (sDLr) approach to speed up deep learning computation. We experiment shrinking Deep Learning with recall (sDLr) using Deep Neural Network (DNN), Deep Belief Network (DBN) and Convolution Neural Network (CNN) on 4 data sets. Results show that the speedup using shrinking Deep Learning with recall (sDLr) can reach more than 2.0 while still giving competitive classification performance.","Wed, 4 May 2016 18:17:37 UTC (276 KB)[v2] Mon, 19 Sep 2016 19:27:39 UTC (4,119 KB)"
"1829","Unsupervised Total Variation Loss for Semi-supervised Deep Learning of Semantic Segmentation","Mehran Javanmardi, Mehdi Sajjadi, Ting Liu, Tolga Tasdizen","Computer Vision and Pattern Recognition (cs.CV)","We introduce a novel unsupervised loss function for learning semantic segmentation with deep convolutional neural nets (ConvNet) when densely labeled training images are not available. More specifically, the proposed loss function penalizes the L1-norm of the gradient of the label probability vector image , i.e. total variation, produced by the ConvNet. This can be seen as a regularization term that promotes piecewise smoothness of the label probability vector image produced by the ConvNet during learning. The unsupervised loss function is combined with a supervised loss in a semi-supervised setting to learn ConvNets that can achieve high semantic segmentation accuracy even when only a tiny percentage of the pixels in the training images are labeled. We demonstrate significant improvements over the purely supervised setting in the Weizmann horse, Stanford background and Sift Flow datasets. Furthermore, we show that using the proposed piecewise smoothness constraint in the learning phase significantly outperforms post-processing results from a purely supervised approach with Markov Random Fields (MRF). Finally, we note that the framework we introduce is general and can be used to learn to label other types of structures such as curvilinear structures by modifying the unsupervised loss function accordingly.","Wed, 4 May 2016 18:17:25 UTC (1,787 KB)[v2] Tue, 17 May 2016 20:46:35 UTC (1,787 KB)[v3] Tue, 7 Aug 2018 20:21:16 UTC (1,945 KB)"
"1830","Phase 3: DCL System Using Deep Learning Approaches for Land-based or Ship-based Real-Time Recognition and Localization of Marine Mammals - Bioacoustic Applicaitons","Peter J. Dugan, Christopher W. Clark, Yann Andre LeCun, Sofie M. Van Parijs","Distributed, Parallel, and Cluster Computing (cs.DC)","Goals of this research phase is to investigate advanced detection and classification pardims useful for data-mining passive large passive acoustic archives. Technical objectives are to develop and refine a High Performance Computing, Acoustic Data Accelerator (HPC-ADA) along with MATLAB based software based on time series acoustic signal Detection cLassification using Machine learning Algorithms, called DeLMA. Data scientists and biologists integrate to use the HPC-ADA and DeLMA technologies to explore data using newly developed techniques aimed at inspection of data extracted at large spatial and temporal scales.","Tue, 3 May 2016 16:54:46 UTC (775 KB)[v2] Thu, 5 May 2016 18:29:19 UTC (499 KB)"
"1831","Phase 4: DCL System Using Deep Learning Approaches for Land-Based or Ship-Based Real-Time Recognition and Localization of Marine Mammals - Distributed Processing and Big Data Applications","Peter J. Dugan, Christopher W. Clark, Yann Andre LeCun, Sofie M. Van Parijs","Distributed, Parallel, and Cluster Computing (cs.DC)","While the animal bioacoustics community at large is collecting huge amounts of acoustic data at an unprecedented pace, processing these data is problematic. Currently in bioacoustics, there is no effective way to achieve high performance computing using commericial off the shelf (COTS) or government off the shelf (GOTS) tools. Although several advances have been made in the open source and commercial software community, these offerings either support specific applications that do not integrate well with data formats in bioacoustics or they are too general. Furthermore, complex algorithms that use deep learning strategies require special considerations, such as very large libraiers of exemplars (whale sounds) readily available for algorithm training and testing. Detection-classification for passive acoustics is a data-mining strategy and our goals are aligned with best practices that appeal to the general data mining and machine learning communities where the problem of processing large data is common. Therefore, the objective of this work is to advance the state-of-the art for data-mining large passive acoustic datasets as they pertain to bioacoustics. With this basic deficiency recognized at the forefront, portions of the grant were dedicated to fostering deep-learning by way of international competitions (kaggle.com) meant to attract deep-learning solutions. The focus of this early work was targeted to make significant progress in addressing big data systems and advanced algorithms over the duration of the grant from 2012 to 2015. This early work provided simulataneous advances in systems-algorithms research while supporting various collaborations and projects.","Tue, 3 May 2016 16:54:07 UTC (714 KB)[v2] Thu, 5 May 2016 18:35:16 UTC (286 KB)"
"1832","Phase 2: DCL System Using Deep Learning Approaches for Land-based or Ship-based Real-Time Recognition and Localization of Marine Mammals - Machine Learning Detection Algorithms","Peter J. Dugan, Christopher W. Clark, Yann Andre LeCun, Sofie M. Van Parijs","Computer Vision and Pattern Recognition (cs.CV)","Overarching goals for this work aim to advance the state of the art for detection, classification and localization (DCL) in the field of bioacoustics. This goal is primarily achieved by building a generic framework for detection-classification (DC) using a fast, efficient and scalable architecture, demonstrating the capabilities of this system using on a variety of low-frequency mid-frequency cetacean sounds. Two primary goals are to develop transferable technologies for detection and classification in, one: the area of advanced algorithms, such as deep learning and other methods; and two: advanced systems, capable of real-time and archival processing. For each key area, we will focus on producing publications from this work and providing tools and software to the community where/when possible. Currently massive amounts of acoustic data are being collected by various institutions, corporations and national defense agencies. The long-term goal is to provide technical capability to analyze the data using automatic algorithms for (DC) based on machine intelligence. The goal of the automation is to provide effective and efficient mechanisms by which to process large acoustic datasets for understanding the bioacoustic behaviors of marine mammals. This capability will provide insights into the potential ecological impacts and influences of anthropogenic ocean sounds. This work focuses on building technologies using a maturity model based on DARPA 6.1 and 6.2 processes, for basic and applied research, respectively.","Tue, 3 May 2016 16:36:30 UTC (915 KB)[v2] Thu, 5 May 2016 18:28:21 UTC (573 KB)"
"1833","Music transcription modelling and composition using deep learning","Bob L. Sturm, Joao Felipe Santos, Oded Ben-Tal, Iryna Korshunova","Sound (cs.SD); Machine Learning (cs.LG)","We apply deep learning methods, specifically long short-term memory (LSTM) networks, to music transcription modelling and composition. We build and train LSTM networks using approximately 23,000 music transcriptions expressed with a high-level vocabulary (ABC notation), and use them to generate new transcriptions. Our practical aim is to create music transcription models useful in particular contexts of music composition. We present results from three perspectives: 1) at the population level, comparing descriptive statistics of the set of training transcriptions and generated transcriptions; 2) at the individual level, examining how a generated transcription reflects the conventions of a music practice in the training transcriptions (Celtic folk); 3) at the application level, using the system for idea generation in music composition. We make our datasets, software and sound examples open and available: \url{this https URL}.","Fri, 29 Apr 2016 08:03:00 UTC (128 KB)"
"1834","Deep Learning for Saliency Prediction in Natural Video","Souad Chaabouni, Jenny Benois-Pineau, Ofer Hadar, Chokri Ben Amar","Computer Vision and Pattern Recognition (cs.CV)","The purpose of this paper is the detection of salient areas in natural video by using the new deep learning techniques. Salient patches in video frames are predicted first. Then the predicted visual fixation maps are built upon them. We design the deep architecture on the basis of CaffeNet implemented with Caffe toolkit. We show that changing the way of data selection for optimisation of network parameters, we can save computation cost up to 12 times. We extend deep learning approaches for saliency prediction in still images with RGB values to specificity of video using the sensitivity of the human visual system to residual motion. Furthermore, we complete primary colour pixel values by contrast features proposed in classical visual attention prediction models. The experiments are conducted on two publicly available datasets. The first is IRCCYN video database containing 31 videos with an overall amount of 7300 frames and eye fixations of 37 subjects. The second one is HOLLYWOOD2 provided 2517 movie clips with the eye fixations of 19 subjects. On IRCYYN dataset, the accuracy obtained is of 89.51%. On HOLLYWOOD2 dataset, results in prediction of saliency of patches show the improvement up to 2% with regard to RGB use only. The resulting accuracy of 76, 6% is obtained. The AUC metric in comparison of predicted saliency maps with visual fixation maps shows the increase up to 16% on a sample of video clips from this dataset.","Wed, 27 Apr 2016 10:34:21 UTC (8,189 KB)"
"1835","Deep Learning for Reward Design to Improve Monte Carlo Tree Search in ATARI Games","Xiaoxiao Guo, Satinder Singh, Richard Lewis, Honglak Lee","Artificial Intelligence (cs.AI)","Monte Carlo Tree Search (MCTS) methods have proven powerful in planning for sequential decision-making problems such as Go and video games, but their performance can be poor when the planning depth and sampling trajectories are limited or when the rewards are sparse. We present an adaptation of PGRD (policy-gradient for reward-design) for learning a reward-bonus function to improve UCT (a MCTS algorithm). Unlike previous applications of PGRD in which the space of reward-bonus functions was limited to linear functions of hand-coded state-action-features, we use PGRD with a multi-layer convolutional neural network to automatically learn features from raw perception as well as to adapt the non-linear reward-bonus function parameters. We also adopt a variance-reducing gradient method to improve PGRD's performance. The new method improves UCT's performance on multiple ATARI games compared to UCT without the reward bonus. Combining PGRD and Deep Learning in this way should make adapting rewards for MCTS algorithms far more widely and practically applicable than before.","Sun, 24 Apr 2016 23:51:18 UTC (970 KB)"
"1836","Deep Learning with Eigenvalue Decay Regularizer","Oswaldo Ludwig","Machine Learning (cs.LG)","This paper extends our previous work on regularization of neural networks using Eigenvalue Decay by employing a soft approximation of the dominant eigenvalue in order to enable the calculation of its derivatives in relation to the synaptic weights, and therefore the application of back-propagation, which is a primary demand for deep learning. Moreover, we extend our previous theoretical analysis to deep neural networks and multiclass classification problems. Our method is implemented as an additional regularizer in Keras, a modular neural networks library written in Python, and evaluated in the benchmark data sets Reuters Newswire Topics Classification, IMDB database for binary sentiment classification, MNIST database of handwritten digits and CIFAR-10 data set for image classification.","Sun, 24 Apr 2016 05:17:04 UTC (67 KB)[v2] Sat, 30 Apr 2016 13:03:48 UTC (67 KB)[v3] Sun, 8 May 2016 10:07:34 UTC (17 KB)"
"1837","Deep Learning for Short-Term Traffic Flow Prediction","Nicholas Polson, Vadim Sokolov","Applications (stat.AP)","We develop a deep learning model to predict traffic flows. The main contribution is development of an architecture that combines a linear model that is fitted using $\ell_1$ regularization and a sequence of $\tanh$ layers. The challenge of predicting traffic flows are the sharp nonlinearities due to transitions between free flow, breakdown, recovery and congestion. We show that deep learning architectures can capture these nonlinear spatio-temporal effects. The first layer identifies spatio-temporal relations among predictors and other layers model nonlinear relations. We illustrate our methodology on road sensor data from Interstate I-55 and predict traffic flows during two special events; a Chicago Bears football game and an extreme snowstorm event. Both cases have sharp traffic flow regime changes, occurring very suddenly, and we show how deep learning provides precise short term traffic flow predictions.","Fri, 15 Apr 2016 14:54:30 UTC (1,711 KB)[v2] Mon, 10 Oct 2016 23:29:33 UTC (2,261 KB)[v3] Mon, 27 Feb 2017 22:58:03 UTC (2,325 KB)"
"1838","Using Deep Learning for Image-Based Plant Disease Detection","Sharada Prasanna Mohanty, David Hughes, Marcel Salathe","Computer Vision and Pattern Recognition (cs.CV)","Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. The combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. Using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). The trained model achieves an accuracy of 99.35% on a held-out test set, demonstrating the feasibility of this approach. When testing the model on a set of images collected from trusted online sources - i.e. taken under conditions different from the images used for training - the model still achieves an accuracy of 31.4%. While this accuracy is much higher than the one based on random selection (2.6%), a more diverse set of training data is needed to improve the general accuracy. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path towards smartphone-assisted crop disease diagnosis on a massive global scale.","Mon, 11 Apr 2016 22:44:20 UTC (3,436 KB)[v2] Fri, 15 Apr 2016 14:05:34 UTC (4,123 KB)"
"1839","Towards Bayesian Deep Learning: A Survey","Hao Wang, Dit-Yan Yeung","Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","While perception tasks such as visual object recognition and text understanding play an important role in human intelligence, the subsequent tasks that involve inference, reasoning and planning require an even higher level of intelligence. The past few years have seen major advances in many perception tasks using deep learning models. For higher-level inference, however, probabilistic graphical models with their Bayesian nature are still more powerful and flexible. To achieve integrated intelligence that involves both perception and inference, it is naturally desirable to tightly integrate deep learning and Bayesian models within a principled probabilistic framework, which we call Bayesian deep learning. In this unified framework, the perception of text or images using deep learning can boost the performance of higher-level inference and in return, the feedback from the inference process is able to enhance the perception of text or images. This survey provides a general introduction to Bayesian deep learning and reviews its recent applications on recommender systems, topic models, and control. In this survey, we also discuss the relationship and differences between Bayesian deep learning and other related topics like Bayesian treatment of neural networks.","Wed, 6 Apr 2016 15:35:08 UTC (1,631 KB)[v2] Thu, 7 Apr 2016 06:17:44 UTC (1,628 KB)"
"1840","Correlated and Individual Multi-Modal Deep Learning for RGB-D Object Recognition","Ziyan Wang, Jiwen Lu, Ruogu Lin, Jianjiang Feng, Jie zhou","Computer Vision and Pattern Recognition (cs.CV)","In this paper, we propose a new correlated and individual multi-modal deep learning (CIMDL) method for RGB-D object recognition. Unlike most conventional RGB-D object recognition methods which extract features from the RGB and depth channels individually, our CIMDL jointly learns feature representations from raw RGB-D data with a pair of deep neural networks, so that the sharable and modal-specific information can be simultaneously exploited. Specifically, we construct a pair of deep convolutional neural networks (CNNs) for the RGB and depth data, and concatenate them at the top layer of the network with a loss function which learns a new feature space where both correlated part and the individual part of the RGB-D information are well modelled. The parameters of the whole networks are updated by using the back-propagation criterion. Experimental results on two widely used RGB-D object image benchmark datasets clearly show that our method outperforms state-of-the-arts.","Wed, 6 Apr 2016 15:06:02 UTC (1,708 KB)[v2] Thu, 7 Apr 2016 12:08:07 UTC (1,708 KB)[v3] Fri, 9 Dec 2016 13:56:02 UTC (934 KB)"
"1841","Comparative Deep Learning of Hybrid Representations for Image Recommendations","Chenyi Lei, Dong Liu, Weiping Li, Zheng-Jun Zha, Houqiang Li","Computer Vision and Pattern Recognition (cs.CV)","In many image-related tasks, learning expressive and discriminative representations of images is essential, and deep learning has been studied for automating the learning of such representations. Some user-centric tasks, such as image recommendations, call for effective representations of not only images but also preferences and intents of users over images. Such representations are termed \emph{hybrid} and addressed via a deep learning approach in this paper. We design a dual-net deep network, in which the two sub-networks map input images and preferences of users into a same latent semantic space, and then the distances between images and users in the latent space are calculated to make decisions. We further propose a comparative deep learning (CDL) method to train the deep network, using a pair of images compared against one user to learn the pattern of their relative distances. The CDL embraces much more training data than naive deep learning, and thus achieves superior performance than the latter, with no cost of increasing network complexity. Experimental results with real-world data sets for image recommendations have shown the proposed dual-net network and CDL greatly outperform other state-of-the-art image recommendation solutions.","Tue, 5 Apr 2016 13:34:28 UTC (1,037 KB)"
"1842","Classification of Alzheimer's Disease using fMRI Data and Deep Learning Convolutional Neural Networks","Saman Sarraf, Ghassem Tofighi","Computer Vision and Pattern Recognition (cs.CV)","Over the past decade, machine learning techniques especially predictive modeling and pattern recognition in biomedical sciences from drug delivery system to medical imaging has become one of the important methods which are assisting researchers to have deeper understanding of entire issue and to solve complex medical problems. Deep learning is power learning machine learning algorithm in classification while extracting high-level features. In this paper, we used convolutional neural network to classify Alzheimer's brain from normal healthy brain. The importance of classifying this kind of medical data is to potentially develop a predict model or system in order to recognize the type disease from normal subjects or to estimate the stage of the disease. Classification of clinical data such as Alzheimer's disease has been always challenging and most problematic part has been always selecting the most discriminative features. Using Convolutional Neural Network (CNN) and the famous architecture LeNet-5, we successfully classified functional MRI data of Alzheimer's subjects from normal controls where the accuracy of test data on trained data reached 96.85%. This experiment suggests us the shift and scale invariant features extracted by CNN followed by deep learning classification is most powerful method to distinguish clinical data from healthy data in fMRI. This approach also enables us to expand our methodology to predict more complicated systems.","Tue, 29 Mar 2016 04:30:07 UTC (544 KB)"
"1843","Deep Learning At Scale and At Ease","Wei Wang, Gang Chen, Haibo Chen, Tien Tuan Anh Dinh, Jinyang Gao, Beng Chin Ooi, Kian-Lee Tan, Sheng Wang","Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC)","Recently, deep learning techniques have enjoyed success in various multimedia applications, such as image classification and multi-modal data analysis. Large deep learning models are developed for learning rich representations of complex data. There are two challenges to overcome before deep learning can be widely adopted in multimedia and other applications. One is usability, namely the implementation of different models and training algorithms must be done by non-experts without much effort especially when the model is large and complex. The other is scalability, that is the deep learning system must be able to provision for a huge demand of computing resources for training large models with massive datasets. To address these two challenges, in this paper, we design a distributed deep learning platform called SINGA which has an intuitive programming model based on the common layer abstraction of deep learning models. Good scalability is achieved through flexible distributed training architecture and specific optimization techniques. SINGA runs on GPUs as well as on CPUs, and we show that it outperforms many other state-of-the-art deep learning systems. Our experience with developing and training deep learning models for real-life multimedia applications in SINGA shows that the platform is both usable and scalable.","Fri, 25 Mar 2016 08:46:02 UTC (4,461 KB)"
"1844","Probabilistic Reasoning via Deep Learning: Neural Association Models","Quan Liu, Hui Jiang, Andrew Evdokimov, Zhen-Hua Ling, Xiaodan Zhu, Si Wei, Yu Hu","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","In this paper, we propose a new deep learning approach, called neural association model (NAM), for probabilistic reasoning in artificial intelligence. We propose to use neural networks to model association between any two events in a domain. Neural networks take one event as input and compute a conditional probability of the other event to model how likely these two events are to be associated. The actual meaning of the conditional probabilities varies between applications and depends on how the models are trained. In this work, as two case studies, we have investigated two NAM structures, namely deep neural networks (DNN) and relation-modulated neural nets (RMNN), on several probabilistic reasoning tasks in AI, including recognizing textual entailment, triple classification in multi-relational knowledge bases and commonsense reasoning. Experimental results on several popular datasets derived from WordNet, FreeBase and ConceptNet have all demonstrated that both DNNs and RMNNs perform equally well and they can significantly outperform the conventional methods available for these reasoning tasks. Moreover, compared with DNNs, RMNNs are superior in knowledge transfer, where a pre-trained model can be quickly extended to an unseen relation after observing only a few training samples. To further prove the effectiveness of the proposed models, in this work, we have applied NAMs to solving challenging Winograd Schema (WS) problems. Experiments conducted on a set of WS problems prove that the proposed models have the potential for commonsense reasoning.","Thu, 24 Mar 2016 18:54:18 UTC (314 KB)[v2] Wed, 3 Aug 2016 14:31:17 UTC (1,461 KB)"
"1845","A guide to convolution arithmetic for deep learning","Vincent Dumoulin, Francesco Visin","Machine Learning (stat.ML); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.","Wed, 23 Mar 2016 17:52:21 UTC (208 KB)[v2] Thu, 11 Jan 2018 18:54:25 UTC (482 KB)"
"1846","CSI-based Fingerprinting for Indoor Localization: A Deep Learning Approach","Xuyu Wang, Lingjun Gao, Shiwen Mao, Santosh Pandey","Networking and Internet Architecture (cs.NI)","With the fast growing demand of location-based services in indoor environments, indoor positioning based on fingerprinting has attracted a lot of interest due to its high accuracy. In this paper, we present a novel deep learning based indoor fingerprinting system using Channel State Information (CSI), which is termed DeepFi. Based on three hypotheses on CSI, the DeepFi system architecture includes an off-line training phase and an on-line localization phase. In the off-line training phase, deep learning is utilized to train all the weights of a deep network as fingerprints. Moreover, a greedy learning algorithm is used to train the weights layer-by-layer to reduce complexity. In the on-line localization phase, we use a probabilistic method based on the radial basis function to obtain the estimated location. Experimental results are presented to confirm that DeepFi can effectively reduce location error compared with three existing methods in two representative indoor environments.","Wed, 23 Mar 2016 06:53:55 UTC (4,228 KB)"
"1847","Deep Learning in Bioinformatics","Seonwoo Min, Byunghan Lee, Sungroh Yoon","Machine Learning (cs.LG); Genomics (q-bio.GN)","In the era of big data, transformation of biomedical big data into valuable knowledge has been one of the most important challenges in bioinformatics. Deep learning has advanced rapidly since the early 2000s and now demonstrates state-of-the-art performance in various fields. Accordingly, application of deep learning in bioinformatics to gain insight from data has been emphasized in both academia and industry. Here, we review deep learning in bioinformatics, presenting examples of current research. To provide a useful and comprehensive perspective, we categorize research both by the bioinformatics domain (i.e., omics, biomedical imaging, biomedical signal processing) and deep learning architecture (i.e., deep neural networks, convolutional neural networks, recurrent neural networks, emergent architectures) and present brief descriptions of each study. Additionally, we discuss theoretical and practical issues of deep learning in bioinformatics and suggest future research directions. We believe that this review will provide valuable insights and serve as a starting point for researchers to apply deep learning approaches in their bioinformatics studies.","Mon, 21 Mar 2016 13:55:02 UTC (5,644 KB)[v2] Wed, 23 Mar 2016 03:01:37 UTC (982 KB)[v3] Sat, 26 Mar 2016 05:14:12 UTC (5,984 KB)[v4] Mon, 4 Apr 2016 09:48:55 UTC (4,075 KB)[v5] Sun, 19 Jun 2016 09:16:30 UTC (809 KB)"
"1848","Emotion Classification from Noisy Speech - A Deep Learning Approach","Rajib Rana","Human-Computer Interaction (cs.HC)","This paper investigates the performance of Deep Learning for speech emotion classification when the speech is compounded with noise. It reports on the classification accuracy and concludes with the future directions for achieving greater robustness for emotion recognition from noisy speech.","Fri, 18 Mar 2016 16:09:09 UTC (190 KB)[v2] Tue, 22 Mar 2016 00:13:58 UTC (190 KB)[v3] Tue, 12 Apr 2016 13:47:25 UTC (340 KB)"
"1849","Comparing Time and Frequency Domain for Audio Event Recognition Using Deep Learning","Lars Hertel, Huy Phan, Alfred Mertins","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG); Sound (cs.SD)","Recognizing acoustic events is an intricate problem for a machine and an emerging field of research. Deep neural networks achieve convincing results and are currently the state-of-the-art approach for many tasks. One advantage is their implicit feature learning, opposite to an explicit feature extraction of the input signal. In this work, we analyzed whether more discriminative features can be learned from either the time-domain or the frequency-domain representation of the audio signal. For this purpose, we trained multiple deep networks with different architectures on the Freiburg-106 and ESC-10 datasets. Our results show that feature learning from the frequency domain is superior to the time domain. Moreover, additionally using convolution and pooling layers, to explore local structures of the audio signal, significantly improves the recognition performance and achieves state-of-the-art results.","Fri, 18 Mar 2016 10:38:23 UTC (166 KB)"
"1850","Bank distress in the news: Describing events through deep learning","Samuel Ronnqvist, Peter Sarlin","Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Neural and Evolutionary Computing (cs.NE); Computational Finance (q-fin.CP)","While many models are purposed for detecting the occurrence of significant events in financial systems, the task of providing qualitative detail on the developments is not usually as well automated. We present a deep learning approach for detecting relevant discussion in text and extracting natural language descriptions of events. Supervised by only a small set of event information, comprising entity names and dates, the model is leveraged by unsupervised learning of semantic vector representations on extensive text data. We demonstrate applicability to the study of financial risk based on news (6.6M articles), particularly bank distress and government interventions (243 events), where indices can signal the level of bank-stress-related reporting at the entity level, or aggregated at national or European level, while being coupled with explanations. Thus, we exemplify how text, as timely, widely available and descriptive data, can serve as a useful complementary source of information for financial and systemic risk analytics.","Thu, 17 Mar 2016 20:06:27 UTC (245 KB)[v2] Tue, 27 Dec 2016 23:24:49 UTC (334 KB)"
"1851","Structured and Efficient Variational Deep Learning with Matrix Gaussian Posteriors","Christos Louizos, Max Welling","Machine Learning (stat.ML); Machine Learning (cs.LG)","We introduce a variational Bayesian neural network where the parameters are governed via a probability distribution on random matrices. Specifically, we employ a matrix variate Gaussian \cite{gupta1999matrix} parameter posterior distribution where we explicitly model the covariance among the input and output dimensions of each layer. Furthermore, with approximate covariance matrices we can achieve a more efficient way to represent those correlations that is also cheaper than fully factorized parameter posteriors. We further show that with the ""local reprarametrization trick"" \cite{kingma2015variational} on this posterior distribution we arrive at a Gaussian Process \cite{rasmussen2006gaussian} interpretation of the hidden units in each layer and we, similarly with \cite{gal2015dropout}, provide connections with deep Gaussian processes. We continue in taking advantage of this duality and incorporate ""pseudo-data"" \cite{snelson2005sparse} in our model, which in turn allows for more efficient sampling while maintaining the properties of the original model. The validity of the proposed approach is verified through extensive experiments.","Tue, 15 Mar 2016 16:01:14 UTC (543 KB)[v2] Thu, 31 Mar 2016 10:21:07 UTC (543 KB)[v3] Mon, 4 Apr 2016 11:29:16 UTC (543 KB)[v4] Sun, 29 May 2016 07:18:12 UTC (543 KB)[v5] Thu, 23 Jun 2016 19:03:47 UTC (543 KB)"
"1852","Revealing the Hidden Patterns of News Photos: Analysis of Millions of News Photos Using GDELT and Deep Learning-based Vision APIs","Haewoon Kwak, Jisun An","Computers and Society (cs.CY); Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR)","In this work, we analyze more than two million news photos published in January 2016. We demonstrate i) which objects appear the most in news photos; ii) what the sentiments of news photos are; iii) whether the sentiment of news photos is aligned with the tone of the text; iv) how gender is treated; and v) how differently political candidates are portrayed. To our best knowledge, this is the first large-scale study of news photo contents using deep learning-based vision APIs.","Tue, 15 Mar 2016 02:23:53 UTC (540 KB)[v2] Thu, 24 Mar 2016 04:44:12 UTC (540 KB)"
"1853","DROW: Real-Time Deep Learning based Wheelchair Detection in 2D Range Data","Lucas Beyer, Alexander Hermans, Bastian Leibe","Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","We introduce the DROW detector, a deep learning based detector for 2D range data. Laser scanners are lighting invariant, provide accurate range data, and typically cover a large field of view, making them interesting sensors for robotics applications. So far, research on detection in laser range data has been dominated by hand-crafted features and boosted classifiers, potentially losing performance due to suboptimal design choices. We propose a Convolutional Neural Network (CNN) based detector for this task. We show how to effectively apply CNNs for detection in 2D range data, and propose a depth preprocessing step and voting scheme that significantly improve CNN performance. We demonstrate our approach on wheelchairs and walkers, obtaining state of the art detection results. Apart from the training data, none of our design choices limits the detector to these two classes, though. We provide a ROS node for our detector and release our dataset containing 464k laser scans, out of which 24k were annotated.","Tue, 8 Mar 2016 19:39:19 UTC (886 KB)[v2] Mon, 5 Dec 2016 18:06:28 UTC (881 KB)"
"1854","Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection","Sergey Levine, Peter Pastor, Alex Krizhevsky, Deirdre Quillen","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","We describe a learning-based approach to hand-eye coordination for robotic grasping from monocular images. To learn hand-eye coordination for grasping, we trained a large convolutional neural network to predict the probability that task-space motion of the gripper will result in successful grasps, using only monocular camera images and independently of camera calibration or the current robot pose. This requires the network to observe the spatial relationship between the gripper and objects in the scene, thus learning hand-eye coordination. We then use this network to servo the gripper in real time to achieve successful grasps. To train our network, we collected over 800,000 grasp attempts over the course of two months, using between 6 and 14 robotic manipulators at any given time, with differences in camera placement and hardware. Our experimental evaluation demonstrates that our method achieves effective real-time control, can successfully grasp novel objects, and corrects mistakes by continuous servoing.","Mon, 7 Mar 2016 18:53:00 UTC (5,414 KB)[v2] Thu, 24 Mar 2016 23:01:46 UTC (6,485 KB)[v3] Sat, 2 Apr 2016 23:50:24 UTC (6,485 KB)[v4] Sun, 28 Aug 2016 23:32:37 UTC (6,486 KB)"
"1855","Variational methods for Conditional Multimodal Deep Learning","Gaurav Pandey, Ambedkar Dukkipati","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","In this paper, we address the problem of conditional modality learning, whereby one is interested in generating one modality given the other. While it is straightforward to learn a joint distribution over multiple modalities using a deep multimodal architecture, we observe that such models aren't very effective at conditional generation. Hence, we address the problem by learning conditional distributions between the modalities. We use variational methods for maximizing the corresponding conditional log-likelihood. The resultant deep model, which we refer to as conditional multimodal autoencoder (CMMA), forces the latent representation obtained from a single modality alone to be `close' to the joint representation obtained from multiple modalities. We use the proposed model to generate faces from attributes. We show that the faces generated from attributes using the proposed model, are qualitatively and quantitatively more representative of the attributes from which they were generated, than those obtained by other deep generative models. We also propose a secondary task, whereby the existing faces are modified by modifying the corresponding attributes. We observe that the modifications in face introduced by the proposed model are representative of the corresponding modifications in attributes.","Sun, 6 Mar 2016 07:33:03 UTC (3,936 KB)[v2] Fri, 26 Aug 2016 10:57:41 UTC (4,792 KB)"
"1856","Evaluation of Deep Learning based Pose Estimation for Sign Language Recognition","Srujana Gattupalli, Amir Ghaderi, Vassilis Athitsos","Computer Vision and Pattern Recognition (cs.CV)","Human body pose estimation and hand detection are two important tasks for systems that perform computer vision-based sign language recognition(SLR). However, both tasks are challenging, especially when the input is color videos, with no depth information. Many algorithms have been proposed in the literature for these tasks, and some of the most successful recent algorithms are based on deep learning. In this paper, we introduce a dataset for human pose estimation for SLR domain. We evaluate the performance of two deep learning based pose estimation methods, by performing user-independent experiments on our dataset. We also perform transfer learning, and we obtain results that demonstrate that transfer learning can improve pose estimation accuracy. The dataset and results from these methods can create a useful baseline for future works.","Mon, 29 Feb 2016 17:45:10 UTC (1,986 KB)[v2] Sun, 17 Apr 2016 16:56:41 UTC (0 KB)[v3] Tue, 19 Apr 2016 23:43:10 UTC (1,984 KB)"
"1857","Multimodal Emotion Recognition Using Multimodal Deep Learning","Wei Liu, Wei-Long Zheng, Bao-Liang Lu","Human-Computer Interaction (cs.HC); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","To enhance the performance of affective models and reduce the cost of acquiring physiological signals for real-world applications, we adopt multimodal deep learning approach to construct affective models from multiple physiological signals. For unimodal enhancement task, we indicate that the best recognition accuracy of 82.11% on SEED dataset is achieved with shared representations generated by Deep AutoEncoder (DAE) model. For multimodal facilitation tasks, we demonstrate that the Bimodal Deep AutoEncoder (BDAE) achieves the mean accuracies of 91.01% and 83.25% on SEED and DEAP datasets, respectively, which are much superior to the state-of-the-art approaches. For cross-modal learning task, our experimental results demonstrate that the mean accuracy of 66.34% is achieved on SEED dataset through shared representations generated by EEG-based DAE as training samples and shared representations generated by eye-based DAE as testing sample, and vice versa.","Fri, 26 Feb 2016 07:43:14 UTC (162 KB)"
"1858","Scalable and Sustainable Deep Learning via Randomized Hashing","Ryan Spring, Anshumali Shrivastava","Machine Learning (stat.ML); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Current deep learning architectures are growing larger in order to learn from complex datasets. These architectures require giant matrix multiplication operations to train millions of parameters. Conversely, there is another growing trend to bring deep learning to low-power, embedded devices. The matrix operations, associated with both training and testing of deep networks, are very expensive from a computational and energy standpoint. We present a novel hashing based technique to drastically reduce the amount of computation needed to train and test deep networks. Our approach combines recent ideas from adaptive dropouts and randomized hashing for maximum inner product search to select the nodes with the highest activation efficiently. Our new algorithm for deep learning reduces the overall computational cost of forward and back-propagation by operating on significantly fewer (sparse) nodes. As a consequence, our algorithm uses only 5% of the total multiplications, while keeping on average within 1% of the accuracy of the original model. A unique property of the proposed hashing based back-propagation is that the updates are always sparse. Due to the sparse gradient updates, our algorithm is ideally suited for asynchronous and parallel training leading to near linear speedup with increasing number of cores. We demonstrate the scalability and sustainability (energy efficiency) of our proposed algorithm via rigorous experimental evaluations on several real datasets.","Fri, 26 Feb 2016 05:07:23 UTC (372 KB)[v2] Mon, 5 Dec 2016 04:52:36 UTC (341 KB)"
"1859","DeepSpark: A Spark-Based Distributed Deep Learning Framework for Commodity Clusters","Hanjoo Kim, Jaehong Park, Jaehee Jang, Sungroh Yoon","Machine Learning (cs.LG)","The increasing complexity of deep neural networks (DNNs) has made it challenging to exploit existing large-scale data processing pipelines for handling massive data and parameters involved in DNN training. Distributed computing platforms and GPGPU-based acceleration provide a mainstream solution to this computational challenge. In this paper, we propose DeepSpark, a distributed and parallel deep learning framework that exploits Apache Spark on commodity clusters. To support parallel operations, DeepSpark automatically distributes workloads and parameters to Caffe/Tensorflow-running nodes using Spark, and iteratively aggregates training results by a novel lock-free asynchronous variant of the popular elastic averaging stochastic gradient descent based update scheme, effectively complementing the synchronized processing capabilities of Spark. DeepSpark is an on-going project, and the current release is available at this http URL.","Fri, 26 Feb 2016 04:18:21 UTC (3,754 KB)[v2] Tue, 8 Mar 2016 08:32:16 UTC (3,755 KB)[v3] Sat, 1 Oct 2016 02:44:07 UTC (439 KB)"
"1860","Mobile Big Data Analytics Using Deep Learning and Apache Spark","Mohammad Abu Alsheikh, Dusit Niyato, Shaowei Lin, Hwee-Pink Tan, Zhu Han","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","The proliferation of mobile devices, such as smartphones and Internet of Things (IoT) gadgets, results in the recent mobile big data (MBD) era. Collecting MBD is unprofitable unless suitable analytics and learning methods are utilized for extracting meaningful information and hidden patterns from data. This article presents an overview and brief tutorial of deep learning in MBD analytics and discusses a scalable learning framework over Apache Spark. Specifically, a distributed deep learning is executed as an iterative MapReduce computing on many Spark workers. Each Spark worker learns a partial deep model on a partition of the overall MBD, and a master deep model is then built by averaging the parameters of all partial models. This Spark-based framework speeds up the learning of deep models consisting of many hidden layers and millions of parameters. We use a context-aware activity recognition application with a real-world dataset containing millions of samples to validate our framework and assess its speedup effectiveness.","Tue, 23 Feb 2016 04:32:02 UTC (939 KB)"
"1861","Distributed Deep Learning Using Synchronous Stochastic Gradient Descent","Dipankar Das, Sasikanth Avancha, Dheevatsa Mudigere, Karthikeyan Vaidynathan, Srinivas Sridharan, Dhiraj Kalamkar, Bharat Kaul, Pradeep Dubey","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","We design and implement a distributed multinode synchronous SGD algorithm, without altering hyper parameters, or compressing data, or altering algorithmic behavior. We perform a detailed analysis of scaling, and identify optimal design points for different networks. We demonstrate scaling of CNNs on 100s of nodes, and present what we believe to be record training throughputs. A 512 minibatch VGG-A CNN training run is scaled 90X on 128 nodes. Also 256 minibatch VGG-A and OverFeat-FAST networks are scaled 53X and 42X respectively on a 64 node cluster. We also demonstrate the generality of our approach via best-in-class 6.5X scaling for a 7-layer DNN on 16 nodes. Thereafter we attempt to democratize deep-learning by training on an Ethernet based AWS cluster and show ~14X scaling on 16 nodes.","Mon, 22 Feb 2016 10:31:24 UTC (313 KB)"
"1862","Deep Learning in Finance","J. B. Heaton, N. G. Polson, J. H. Witte","Machine Learning (cs.LG)","We explore the use of deep learning hierarchical models for problems in financial prediction and classification. Financial prediction problems -- such as those presented in designing and pricing securities, constructing portfolios, and risk management -- often involve large data sets with complex data interactions that currently are difficult or impossible to specify in a full economic model. Applying deep learning methods to these problems can produce more useful results than standard methods in finance. In particular, deep learning can detect and exploit interactions in the data that are, at least currently, invisible to any existing financial economic theory.","Sun, 21 Feb 2016 18:19:56 UTC (476 KB)[v2] Tue, 23 Feb 2016 19:14:51 UTC (475 KB)[v3] Sun, 14 Jan 2018 13:19:20 UTC (475 KB)"
"1863","Node-By-Node Greedy Deep Learning for Interpretable Features","Ke Wu, Malik Magdon-Ismail","Machine Learning (cs.LG)","Multilayer networks have seen a resurgence under the umbrella of deep learning. Current deep learning algorithms train the layers of the network sequentially, improving algorithmic performance as well as providing some regularization. We present a new training algorithm for deep networks which trains \emph{each node in the network} sequentially. Our algorithm is orders of magnitude faster, creates more interpretable internal representations at the node level, while not sacrificing on the ultimate out-of-sample performance.","Fri, 19 Feb 2016 15:36:38 UTC (1,172 KB)"
"1864","Audio Recording Device Identification Based on Deep Learning","Simeng Qi, Zheng Huang, Yan Li, Shaopei Shi","Sound (cs.SD); Machine Learning (cs.LG)","In this paper we present a research on identification of audio recording devices from background noise, thus providing a method for forensics. The audio signal is the sum of speech signal and noise signal. Usually, people pay more attention to speech signal, because it carries the information to deliver. So a great amount of researches have been dedicated to getting higher Signal-Noise-Ratio (SNR). There are many speech enhancement algorithms to improve the quality of the speech, which can be seen as reducing the noise. However, noises can be regarded as the intrinsic fingerprint traces of an audio recording device. These digital traces can be characterized and identified by new machine learning techniques. Therefore, in our research, we use the noise as the intrinsic features. As for the identification, multiple classifiers of deep learning methods are used and compared. The identification result shows that the method of getting feature vector from the noise of each device and identifying them with deep learning techniques is viable, and well-preformed.","Thu, 18 Feb 2016 05:49:37 UTC (191 KB)[v2] Wed, 27 Apr 2016 02:32:38 UTC (692 KB)"
"1865","On the Use of Deep Learning for Blind Image Quality Assessment","Simone Bianco, Luigi Celona, Paolo Napoletano, Raimondo Schettini","Computer Vision and Pattern Recognition (cs.CV)","In this work we investigate the use of deep learning for distortion-generic blind image quality assessment. We report on different design choices, ranging from the use of features extracted from pre-trained Convolutional Neural Networks (CNNs) as a generic image description, to the use of features extracted from a CNN fine-tuned for the image quality task. Our best proposal, named DeepBIQ, estimates the image quality by average pooling the scores predicted on multiple sub-regions of the original image. The score of each sub-region is computed using a Support Vector Regression (SVR) machine taking as input features extracted using a CNN fine-tuned for category-based image quality assessment. Experimental results on the LIVE In the Wild Image Quality Challenge Database and on the LIVE Image Quality Assessment Database show that DeepBIQ outperforms the state-of-the-art methods compared, having a Linear Correlation Coefficient (LCC) with human subjective scores of almost 0.91 and 0.98 respectively. Furthermore, in most of the cases, the quality score predictions of DeepBIQ are closer to the average observer than those of a generic human observer.","Wed, 17 Feb 2016 19:12:50 UTC (2,185 KB)[v2] Thu, 18 Feb 2016 08:44:00 UTC (2,155 KB)[v3] Thu, 26 May 2016 13:22:46 UTC (2,668 KB)[v4] Wed, 11 Jan 2017 15:11:47 UTC (1,552 KB)[v5] Tue, 4 Apr 2017 14:12:38 UTC (1,370 KB)"
"1866","Deep Learning on FPGAs: Past, Present, and Future","Griffin Lacey, Graham W. Taylor, Shawki Areibi","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Machine Learning (stat.ML)","The rapid growth of data size and accessibility in recent years has instigated a shift of philosophy in algorithm design for artificial intelligence. Instead of engineering algorithms by hand, the ability to learn composable systems automatically from massive amounts of data has led to ground-breaking performance in important domains such as computer vision, speech recognition, and natural language processing. The most popular class of techniques used in these domains is called deep learning, and is seeing significant attention from industry. However, these models require incredible amounts of data and compute power to train, and are limited by the need for better hardware acceleration to accommodate scaling beyond current data and model sizes. While the current solution has been to use clusters of graphics processing units (GPU) as general purpose processors (GPGPU), the use of field programmable gate arrays (FPGA) provide an interesting alternative. Current trends in design tools for FPGAs have made them more compatible with the high-level software practices typically practiced in the deep learning community, making FPGAs more accessible to those who build and deploy models. Since FPGA architectures are flexible, this could also allow researchers the ability to explore model-level optimizations beyond what is possible on fixed architectures such as GPUs. As well, FPGAs tend to provide high performance per watt of power consumption, which is of particular importance for application scientists interested in large scale server-based deployment or resource-limited embedded applications. This review takes a look at deep learning and FPGAs from a hardware acceleration perspective, identifying trends and innovations that make these technologies a natural fit, and motivates a discussion on how FPGAs may best serve the needs of the deep learning community moving forward.","Sat, 13 Feb 2016 03:50:37 UTC (762 KB)"
"1867","Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms","Tom Zahavy, Bingyi Kang, Alex Sivak, Jiashi Feng, Huan Xu, Shie Mannor","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","The question why deep learning algorithms generalize so well has attracted increasing research interest. However, most of the well-established approaches, such as hypothesis capacity, stability or sparseness, have not provided complete explanations (Zhang et al., 2016; Kawaguchi et al., 2017). In this work, we focus on the robustness approach (Xu & Mannor, 2012), i.e., if the error of a hypothesis will not change much due to perturbations of its training examples, then it will also generalize well. As most deep learning algorithms are stochastic (e.g., Stochastic Gradient Descent, Dropout, and Bayes-by-backprop), we revisit the robustness arguments of Xu & Mannor, and introduce a new approach, ensemble robustness, that concerns the robustness of a population of hypotheses. Through the lens of ensemble robustness, we reveal that a stochastic learning algorithm can generalize well as long as its sensitiveness to adversarial perturbations is bounded in average over training examples. Moreover, an algorithm may be sensitive to some adversarial examples (Goodfellow et al., 2015) but still generalize well. To support our claims, we provide extensive simulations for different deep learning algorithms and different network architectures exhibiting a strong correlation between ensemble robustness and the ability to generalize.","Sun, 7 Feb 2016 16:50:14 UTC (1,448 KB)[v2] Wed, 10 Feb 2016 01:59:39 UTC (1,414 KB)[v3] Wed, 29 Jun 2016 21:02:34 UTC (337 KB)[v4] Sun, 5 Nov 2017 12:18:24 UTC (2,570 KB)"
"1868","A Deep Learning Approach to Unsupervised Ensemble Learning","Uri Shaham, Xiuyuan Cheng, Omer Dror, Ariel Jaffe, Boaz Nadler, Joseph Chang, Yuval Kluger","Machine Learning (stat.ML); Machine Learning (cs.LG)","We show how deep learning methods can be applied in the context of crowdsourcing and unsupervised ensemble learning. First, we prove that the popular model of Dawid and Skene, which assumes that all classifiers are conditionally independent, is {\em equivalent} to a Restricted Boltzmann Machine (RBM) with a single hidden node. Hence, under this model, the posterior probabilities of the true labels can be instead estimated via a trained RBM. Next, to address the more general case, where classifiers may strongly violate the conditional independence assumption, we propose to apply RBM-based Deep Neural Net (DNN). Experimental results on various simulated and real-world datasets demonstrate that our proposed DNN approach outperforms other state-of-the-art methods, in particular when the data violates the conditional independence assumption.","Sat, 6 Feb 2016 17:56:59 UTC (361 KB)"
"1869","Improved Dropout for Shallow and Deep Learning","Zhe Li, Boqing Gong, Tianbao Yang","Machine Learning (cs.LG); Machine Learning (stat.ML)","Dropout has been witnessed with great success in training deep neural networks by independently zeroing out the outputs of neurons at random. It has also received a surge of interest for shallow learning, e.g., logistic regression. However, the independent sampling for dropout could be suboptimal for the sake of convergence. In this paper, we propose to use multinomial sampling for dropout, i.e., sampling features or neurons according to a multinomial distribution with different probabilities for different features/neurons. To exhibit the optimal dropout probabilities, we analyze the shallow learning with multinomial dropout and establish the risk bound for stochastic optimization. By minimizing a sampling dependent factor in the risk bound, we obtain a distribution-dependent dropout with sampling probabilities dependent on the second order statistics of the data distribution. To tackle the issue of evolving distribution of neurons in deep learning, we propose an efficient adaptive dropout (named \textbf{evolutional dropout}) that computes the sampling probabilities on-the-fly from a mini-batch of examples. Empirical studies on several benchmark datasets demonstrate that the proposed dropouts achieve not only much faster convergence and but also a smaller testing error than the standard dropout. For example, on the CIFAR-100 data, the evolutional dropout achieves relative improvements over 10\% on the prediction performance and over 50\% on the convergence speed compared to the standard dropout.","Sat, 6 Feb 2016 05:41:57 UTC (145 KB)[v2] Sun, 4 Dec 2016 05:31:19 UTC (454 KB)"
"1870","A Deep Learning Based Fast Image Saliency Detection Algorithm","Hengyue Pan, Hui Jiang","Computer Vision and Pattern Recognition (cs.CV)","In this paper, we propose a fast deep learning method for object saliency detection using convolutional neural networks. In our approach, we use a gradient descent method to iteratively modify the input images based on the pixel-wise gradients to reduce a pre-defined cost function, which is defined to measure the class-specific objectness and clamp the class-irrelevant outputs to maintain image background. The pixel-wise gradients can be efficiently computed using the back-propagation algorithm. We further apply SLIC superpixels and LAB color based low level saliency features to smooth and refine the gradients. Our methods are quite computationally efficient, much faster than other deep learning based saliency methods. Experimental results on two benchmark tasks, namely Pascal VOC 2012 and MSRA10k, have shown that our proposed methods can generate high-quality salience maps, at least comparable with many slow and complicated deep learning methods. Comparing with the pure low-level methods, our approach excels in handling many difficult images, which contain complex background, highly-variable salient objects, multiple objects, and/or very small salient objects.","Mon, 1 Feb 2016 16:14:57 UTC (2,475 KB)"
"1871","An Iterative Deep Learning Framework for Unsupervised Discovery of Speech Features and Linguistic Units with Applications on Spoken Term Detection","Cheng-Tao Chung, Cheng-Yu Tsai, Hsiang-Hung Lu, Chia-Hsiang Liu, Hung-yi Lee, Lin-shan Lee","Computation and Language (cs.CL); Machine Learning (cs.LG)","In this work we aim to discover high quality speech features and linguistic units directly from unlabeled speech data in a zero resource scenario. The results are evaluated using the metrics and corpora proposed in the Zero Resource Speech Challenge organized at Interspeech 2015. A Multi-layered Acoustic Tokenizer (MAT) was proposed for automatic discovery of multiple sets of acoustic tokens from the given corpus. Each acoustic token set is specified by a set of hyperparameters that describe the model configuration. These sets of acoustic tokens carry different characteristics fof the given corpus and the language behind, thus can be mutually reinforced. The multiple sets of token labels are then used as the targets of a Multi-target Deep Neural Network (MDNN) trained on low-level acoustic features. Bottleneck features extracted from the MDNN are then used as the feedback input to the MAT and the MDNN itself in the next iteration. We call this iterative deep learning framework the Multi-layered Acoustic Tokenizing Deep Neural Network (MAT-DNN), which generates both high quality speech features for the Track 1 of the Challenge and acoustic tokens for the Track 2 of the Challenge. In addition, we performed extra experiments on the same corpora on the application of query-by-example spoken term detection. The experimental results showed the iterative deep learning framework of MAT-DNN improved the detection performance due to better underlying speech features and acoustic tokens.","Mon, 1 Feb 2016 08:37:56 UTC (633 KB)"
"1872","Deep Learning For Smile Recognition","Patrick O. Glauner","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Inspired by recent successes of deep learning in computer vision, we propose a novel application of deep convolutional neural networks to facial expression recognition, in particular smile recognition. A smile recognition test accuracy of 99.45% is achieved for the Denver Intensity of Spontaneous Facial Action (DISFA) database, significantly outperforming existing approaches based on hand-crafted features with accuracies ranging from 65.55% to 79.67%. The novelty of this approach includes a comprehensive model selection of the architecture parameters, allowing to find an appropriate architecture for each expression such as smile. This is feasible because all experiments were run on a Tesla K40c GPU, allowing a speedup of factor 10 over traditional computations on a CPU.","Sat, 30 Jan 2016 23:59:04 UTC (68 KB)[v2] Tue, 25 Jul 2017 04:46:01 UTC (68 KB)"
"1873","Deep Learning Based Semantic Video Indexing and Retrieval","Anna Podlesnaya, Sergey Podlesnyy","Information Retrieval (cs.IR)","We share the implementation details and testing results for video retrieval system based exclusively on features extracted by convolutional neural networks. We show that deep learned features might serve as universal signature for semantic content of video useful in many search and retrieval tasks. We further show that graph-based storage structure for video index allows to efficiently retrieving the content with complicated spatial and temporal search queries.","Thu, 28 Jan 2016 13:43:30 UTC (1,361 KB)"
"1874","Deep Learning Driven Visual Path Prediction from a Single Image","Siyu Huang, Xi Li, Zhongfei Zhang, Zhouzhou He, Fei Wu, Wei Liu, Jinhui Tang, Yueting Zhuang","Computer Vision and Pattern Recognition (cs.CV)","Capabilities of inference and prediction are significant components of visual systems. In this paper, we address an important and challenging task of them: visual path prediction. Its goal is to infer the future path for a visual object in a static scene. This task is complicated as it needs high-level semantic understandings of both the scenes and motion patterns underlying video sequences. In practice, cluttered situations have also raised higher demands on the effectiveness and robustness of the considered models. Motivated by these observations, we propose a deep learning framework which simultaneously performs deep feature learning for visual representation in conjunction with spatio-temporal context modeling. After that, we propose a unified path planning scheme to make accurate future path prediction based on the analytic results of the context models. The highly effective visual representation and deep context models ensure that our framework makes a deep semantic understanding of the scene and motion pattern, consequently improving the performance of the visual path prediction task. In order to comprehensively evaluate the model's performance on the visual path prediction task, we construct two large benchmark datasets from the adaptation of video tracking datasets. The qualitative and quantitative experimental results show that our approach outperforms the existing approaches and owns a better generalization capability.","Wed, 27 Jan 2016 05:04:31 UTC (3,459 KB)"
"1875","Hough-CNN: Deep Learning for Segmentation of Deep Brain Regions in MRI and Ultrasound","Fausto Milletari, Seyed-Ahmad Ahmadi, Christine Kroll, Annika Plate, Verena Rozanski, Juliana Maiostre, Johannes Levin, Olaf Dietrich, Birgit Ertl-Wagner, Kai Botzel, Nassir Navab","Computer Vision and Pattern Recognition (cs.CV)","In this work we propose a novel approach to perform segmentation by leveraging the abstraction capabilities of convolutional neural networks (CNNs). Our method is based on Hough voting, a strategy that allows for fully automatic localisation and segmentation of the anatomies of interest. This approach does not only use the CNN classification outcomes, but it also implements voting by exploiting the features produced by the deepest portion of the network. We show that this learning-based segmentation method is robust, multi-region, flexible and can be easily adapted to different modalities. In the attempt to show the capabilities and the behaviour of CNNs when they are applied to medical image analysis, we perform a systematic study of the performances of six different network architectures, conceived according to state-of-the-art criteria, in various situations. We evaluate the impact of both different amount of training data and different data dimensionality (2D, 2.5D and 3D) on the final results. We show results on both MRI and transcranial US volumes depicting respectively 26 regions of the basal ganglia and the midbrain.","Tue, 26 Jan 2016 13:25:01 UTC (1,332 KB)[v2] Thu, 28 Jan 2016 14:00:36 UTC (4,018 KB)[v3] Sun, 31 Jan 2016 19:35:15 UTC (1,263 KB)"
"1876","Deep Learning Applied to Image and Text Matching","Afroze Ibrahim Baqapuri","Machine Learning (cs.LG); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)","The ability to describe images with natural language sentences is the hallmark for image and language understanding. Such a system has wide ranging applications such as annotating images and using natural sentences to search for images.In this project we focus on the task of bidirectional image retrieval: such asystem is capable of retrieving an image based on a sentence (image search) andretrieve sentence based on an image query (image annotation). We present asystem based on a global ranking objective function which uses a combinationof convolutional neural networks (CNN) and multi layer perceptrons (MLP).It takes a pair of image and sentence and processes them in different channels,finally embedding it into a common multimodal vector space. These embeddingsencode abstract semantic information about the two inputs and can be comparedusing traditional information retrieval approaches. For each such pair, the modelreturns a score which is interpretted as a similarity metric. If this score is high,the image and sentence are likely to convey similar meaning, and if the score is low then they are likely not to. The visual input is modeled via deep convolutional neural network. On theother hand we explore three models for the textual module. The first one isbag of words with an MLP. The second one uses n-grams (bigram, trigrams,and a combination of trigram & skip-grams) with an MLP. The third is morespecialized deep network specific for modeling variable length sequences (SSE).We report comparable performance to recent work in the field, even though ouroverall model is simpler. We also show that the training time choice of how wecan generate our negative samples has a significant impact on performance, and can be used to specialize the bi-directional system in one particular task.","Mon, 14 Sep 2015 17:19:33 UTC (376 KB)"
"1877","Deep Learning of Part-based Representation of Data Using Sparse Autoencoders with Nonnegativity Constraints","Ehsan Hosseini-Asl, Jacek M. Zurada, Olfa Nasraoui","Machine Learning (cs.LG); Machine Learning (stat.ML)","We demonstrate a new deep learning autoencoder network, trained by a nonnegativity constraint algorithm (NCAE), that learns features which show part-based representation of data. The learning algorithm is based on constraining negative weights. The performance of the algorithm is assessed based on decomposing data into parts and its prediction performance is tested on three standard image data sets and one text dataset. The results indicate that the nonnegativity constraint forces the autoencoder to learn features that amount to a part-based representation of data, while improving sparsity and reconstruction quality in comparison with the traditional sparse autoencoder and Nonnegative Matrix Factorization. It is also shown that this newly acquired representation improves the prediction performance of a deep neural network.","Tue, 12 Jan 2016 05:33:03 UTC (4,039 KB)"
"1878","Deep Learning over Multi-field Categorical Data: A Case Study on User Response Prediction","Weinan Zhang, Tianming Du, Jun Wang","Machine Learning (cs.LG); Information Retrieval (cs.IR)","Predicting user responses, such as click-through rate and conversion rate, are critical in many web applications including web search, personalised recommendation, and online advertising. Different from continuous raw features that we usually found in the image and audio domains, the input features in web space are always of multi-field and are mostly discrete and categorical while their dependencies are little known. Major user response prediction models have to either limit themselves to linear models or require manually building up high-order combination features. The former loses the ability of exploring feature interactions, while the latter results in a heavy computation in the large feature space. To tackle the issue, we propose two novel models using deep neural networks (DNNs) to automatically learn effective patterns from categorical feature interactions and make predictions of users' ad clicks. To get our DNNs efficiently work, we propose to leverage three feature transformation methods, i.e., factorisation machines (FMs), restricted Boltzmann machines (RBMs) and denoising auto-encoders (DAEs). This paper presents the structure of our models and their efficient training algorithms. The large-scale experiments with real-world data demonstrate that our methods work better than major state-of-the-art models.","Mon, 11 Jan 2016 10:04:40 UTC (3,075 KB)"
"1879","Deep Learning for Limit Order Books","Justin Sirignano","Trading and Market Microstructure (q-fin.TR)","This paper develops a new neural network architecture for modeling spatial distributions (i.e., distributions on R^d) which is computationally efficient and specifically designed to take advantage of the spatial structure of limit order books. The new architecture yields a low-dimensional model of price movements deep into the limit order book, allowing more effective use of information from deep in the limit order book (i.e., many levels beyond the best bid and best ask). This ""spatial neural network"" models the joint distribution of the state of the limit order book at a future time conditional on the current state of the limit order book. The spatial neural network outperforms other models such as the naive empirical model, logistic regression (with nonlinear features), and a standard neural network architecture. Both neural networks strongly outperform the logistic regression model. Due to its more effective use of information deep in the limit order book, the spatial neural network especially outperforms the standard neural network in the tail of the distribution, which is important for risk management applications. The models are trained and tested on nearly 500 stocks. Techniques from deep learning such as dropout are employed to improve performance. Due to the significant computational challenges associated with the large amount of data, models are trained with a cluster of 50 GPUs.","Fri, 8 Jan 2016 19:35:04 UTC (321 KB)[v2] Thu, 14 Jan 2016 20:10:00 UTC (313 KB)[v3] Wed, 10 Feb 2016 15:14:18 UTC (342 KB)[v4] Fri, 15 Apr 2016 08:18:24 UTC (417 KB)[v5] Sun, 22 May 2016 12:03:12 UTC (468 KB)[v6] Tue, 14 Jun 2016 07:53:19 UTC (477 KB)[v7] Tue, 5 Jul 2016 15:39:13 UTC (480 KB)"
"1880","Brain4Cars: Car That Knows Before You Do via Sensory-Fusion Deep Learning Architecture","Ashesh Jain, Hema S Koppula, Shane Soh, Bharad Raghavan, Avi Singh, Ashutosh Saxena","Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Advanced Driver Assistance Systems (ADAS) have made driving safer over the last decade. They prepare vehicles for unsafe road conditions and alert drivers if they perform a dangerous maneuver. However, many accidents are unavoidable because by the time drivers are alerted, it is already too late. Anticipating maneuvers beforehand can alert drivers before they perform the maneuver and also give ADAS more time to avoid or prepare for the danger. In this work we propose a vehicular sensor-rich platform and learning algorithms for maneuver anticipation. For this purpose we equip a car with cameras, Global Positioning System (GPS), and a computing device to capture the driving context from both inside and outside of the car. In order to anticipate maneuvers, we propose a sensory-fusion deep learning architecture which jointly learns to anticipate and fuse multiple sensory streams. Our architecture consists of Recurrent Neural Networks (RNNs) that use Long Short-Term Memory (LSTM) units to capture long temporal dependencies. We propose a novel training procedure which allows the network to predict the future given only a partial temporal context. We introduce a diverse data set with 1180 miles of natural freeway and city driving, and show that we can anticipate maneuvers 3.5 seconds before they occur in real-time with a precision and recall of 90.5\% and 87.4\% respectively.","Tue, 5 Jan 2016 05:25:14 UTC (3,099 KB)"
"1881","A Combined Deep-Learning and Deformable-Model Approach to Fully Automatic Segmentation of the Left Ventricle in Cardiac MRI","M. R. Avendi, A. Kheradvar, H. Jafarkhani","Computer Vision and Pattern Recognition (cs.CV)","Segmentation of the left ventricle (LV) from cardiac magnetic resonance imaging (MRI) datasets is an essential step for calculation of clinical indices such as ventricular volume and ejection fraction. In this work, we employ deep learning algorithms combined with deformable models to develop and evaluate a fully automatic segmentation tool for the LV from short-axis cardiac MRI datasets. The method employs deep learning algorithms to learn the segmentation task from the ground true data. Convolutional networks are employed to automatically detect the LV chamber in MRI dataset. Stacked autoencoders are utilized to infer the shape of the LV. The inferred shape is incorporated into deformable models to improve the accuracy and robustness of the segmentation. We validated our method using 45 cardiac MR datasets taken from the MICCAI 2009 LV segmentation challenge and showed that it outperforms the state-of-the art methods. Excellent agreement with the ground truth was achieved. Validation metrics, percentage of good contours, Dice metric, average perpendicular distance and conformity, were computed as 96.69%, 0.94, 1.81mm and 0.86, versus those of 79.2%-95.62%, 0.87-0.9, 1.76-2.97mm and 0.67-0.78, obtained by other methods, respectively.","Fri, 25 Dec 2015 03:35:15 UTC (13,884 KB)"
"1882","Implementation of deep learning algorithm for automatic detection of brain tumors using intraoperative IR-thermal mapping data","A.V. Makarenko, M.G. Volovik","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)","The efficiency of deep machine learning for automatic delineation of tumor areas has been demonstrated for intraoperative neuronavigation using active IR-mapping with the use of the cold test. The proposed approach employs a matrix IR-imager to remotely register the space-time distribution of surface temperature pattern, which is determined by the dynamics of local cerebral blood flow. The advantages of this technique are non-invasiveness, zero risks for the health of patients and medical staff, low implementation and operational costs, ease and speed of use. Traditional IR-diagnostic technique has a crucial limitation - it involves a diagnostician who determines the boundaries of tumor areas, which gives rise to considerable uncertainty, which can lead to diagnosis errors that are difficult to control. The current study demonstrates that implementing deep learning algorithms allows to eliminate the explained drawback.","Tue, 22 Dec 2015 11:52:26 UTC (149 KB)"
"1883","Deep Learning with S-shaped Rectified Linear Activation Units","Xiaojie Jin, Chunyan Xu, Jiashi Feng, Yunchao Wei, Junjun Xiong, Shuicheng Yan","Computer Vision and Pattern Recognition (cs.CV)","Rectified linear activation units are important components for state-of-the-art deep convolutional networks. In this paper, we propose a novel S-shaped rectified linear activation unit (SReLU) to learn both convex and non-convex functions, imitating the multiple function forms given by the two fundamental laws, namely the Webner-Fechner law and the Stevens law, in psychophysics and neural sciences. Specifically, SReLU consists of three piecewise linear functions, which are formulated by four learnable parameters. The SReLU is learned jointly with the training of the whole deep network through back propagation. During the training phase, to initialize SReLU in different layers, we propose a ""freezing"" method to degenerate SReLU into a predefined leaky rectified linear unit in the initial several training epochs and then adaptively learn the good initial values. SReLU can be universally used in the existing deep networks with negligible additional parameters and computation cost. Experiments with two popular CNN architectures, Network in Network and GoogLeNet on scale-various benchmarks including CIFAR10, CIFAR100, MNIST and ImageNet demonstrate that SReLU achieves remarkable improvement compared to other activation functions.","Tue, 22 Dec 2015 10:54:26 UTC (110 KB)"
"1884","A C++ library for Multimodal Deep Learning","Jian Jin","Machine Learning (cs.LG)","MDL, Multimodal Deep Learning Library, is a deep learning framework that supports multiple models, and this document explains its philosophy and functionality. MDL runs on Linux, Mac, and Unix platforms. It depends on OpenCV.","Tue, 22 Dec 2015 01:27:23 UTC (1,305 KB)[v2] Mon, 28 Dec 2015 20:00:20 UTC (1,304 KB)[v3] Tue, 29 Dec 2015 13:39:52 UTC (1,304 KB)[v4] Tue, 12 Apr 2016 17:34:29 UTC (1,258 KB)"
"1885","Deep Learning for Surface Material Classification Using Haptic And Visual Information","Haitian Zheng, Lu Fang, Mengqi Ji, Matti Strese, Yigitcan Ozer, Eckehard Steinbach","Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","When a user scratches a hand-held rigid tool across an object surface, an acceleration signal can be captured, which carries relevant information about the surface. More importantly, such a haptic signal is complementary to the visual appearance of the surface, which suggests the combination of both modalities for the recognition of the surface material. In this paper, we present a novel deep learning method dealing with the surface material classification problem based on a Fully Convolutional Network (FCN), which takes as input the aforementioned acceleration signal and a corresponding image of the surface texture. Compared to previous surface material classification solutions, which rely on a careful design of hand-crafted domain-specific features, our method automatically extracts discriminative features utilizing the advanced deep learning methodologies. Experiments performed on the TUM surface material database demonstrate that our method achieves state-of-the-art classification accuracy robustly and efficiently.","Mon, 21 Dec 2015 15:22:16 UTC (8,593 KB)[v2] Sun, 1 May 2016 07:00:56 UTC (14,540 KB)"
"1886","Poseidon: A System Architecture for Efficient GPU-based Deep Learning on Multiple Machines","Hao Zhang, Zhiting Hu, Jinliang Wei, Pengtao Xie, Gunhee Kim, Qirong Ho, Eric Xing","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC)","Deep learning (DL) has achieved notable successes in many machine learning tasks. A number of frameworks have been developed to expedite the process of designing and training deep neural networks (DNNs), such as Caffe, Torch and Theano. Currently they can harness multiple GPUs on a single machine, but are unable to use GPUs that are distributed across multiple machines; as even average-sized DNNs can take days to train on a single GPU with 100s of GBs to TBs of data, distributed GPUs present a prime opportunity for scaling up DL. However, the limited bandwidth available on commodity Ethernet networks presents a bottleneck to distributed GPU training, and prevents its trivial realization. To investigate how to adapt existing frameworks to efficiently support distributed GPUs, we propose Poseidon, a scalable system architecture for distributed inter-machine communication in existing DL frameworks. We integrate Poseidon with Caffe and evaluate its performance at training DNNs for object recognition. Poseidon features three key contributions that accelerate DNN training on clusters: (1) a three-level hybrid architecture that allows Poseidon to support both CPU-only and GPU-equipped clusters, (2) a distributed wait-free backpropagation (DWBP) algorithm to improve GPU utilization and to balance communication, and (3) a structure-aware communication protocol (SACP) to minimize communication overheads. We empirically show that Poseidon converges to same objectives as a single machine, and achieves state-of-art training speedup across multiple models and well-established datasets using a commodity GPU cluster of 8 nodes (e.g. 4.5x speedup on AlexNet, 4x on GoogLeNet, 4x on CIFAR-10). On the much larger ImageNet22K dataset, Poseidon with 8 nodes achieves better speedup and competitive accuracy to recent CPU-based distributed systems such as Adam and Le et al., which use 10s to 1000s of nodes.","Sat, 19 Dec 2015 09:55:37 UTC (1,535 KB)"
"1887","Deep-Spying: Spying using Smartwatch and Deep Learning","Tony Beltramelli, Sebastian Risi","Cryptography and Security (cs.CR); Computers and Society (cs.CY); Machine Learning (cs.LG)","Wearable technologies are today on the rise, becoming more common and broadly available to mainstream users. In fact, wristband and armband devices such as smartwatches and fitness trackers already took an important place in the consumer electronics market and are becoming ubiquitous. By their very nature of being wearable, these devices, however, provide a new pervasive attack surface threatening users privacy, among others. In the meantime, advances in machine learning are providing unprecedented possibilities to process complex data efficiently. Allowing patterns to emerge from high dimensional unavoidably noisy data. The goal of this work is to raise awareness about the potential risks related to motion sensors built-in wearable devices and to demonstrate abuse opportunities leveraged by advanced neural network architectures. The LSTM-based implementation presented in this research can perform touchlogging and keylogging on 12-keys keypads with above-average accuracy even when confronted with raw unprocessed data. Thus demonstrating that deep neural networks are capable of making keystroke inference attacks based on motion sensors easier to achieve by removing the need for non-trivial pre-processing pipelines and carefully engineered feature extraction strategies. Our results suggest that the complete technological ecosystem of a user can be compromised when a wearable wristband device is worn.","Thu, 17 Dec 2015 14:58:26 UTC (5,999 KB)"
"1888","Deep Learning Stock Volatility with Google Domestic Trends","Ruoxuan Xiong, Eric P. Nichols, Yuan Shen","Computational Finance (q-fin.CP)","We have applied a Long Short-Term Memory neural network to model S&P 500 volatility, incorporating Google domestic trends as indicators of the public mood and macroeconomic factors. In a held-out test set, our Long Short-Term Memory model gives a mean absolute percentage error of 24.2%, outperforming linear Ridge/Lasso and autoregressive GARCH benchmarks by at least 31%. This evaluation is based on an optimal observation and normalization scheme which maximizes the mutual information between domestic trends and daily volatility in the training set. Our preliminary investigation shows strong promise for better predicting stock behavior via deep learning and neural network models.","Tue, 15 Dec 2015 20:21:13 UTC (772 KB)[v2] Wed, 16 Dec 2015 01:17:30 UTC (772 KB)[v3] Tue, 16 Feb 2016 03:04:43 UTC (775 KB)"
"1889","Deep Learning-Based Image Kernel for Inductive Transfer","Neeraj Kumar, Animesh Karmakar, Ranti Dev Sharma, Abhinav Mittal, Amit Sethi","Computer Vision and Pattern Recognition (cs.CV)","We propose a method to classify images from target classes with a small number of training examples based on transfer learning from non-target classes. Without using any more information than class labels for samples from non-target classes, we train a Siamese net to estimate the probability of two images to belong to the same class. With some post-processing, output of the Siamese net can be used to form a gram matrix of a Mercer kernel. Coupled with a support vector machine (SVM), such a kernel gave reasonable classification accuracy on target classes without any fine-tuning. When the Siamese net was only partially fine-tuned using a small number of samples from the target classes, the resulting classifier outperformed the state-of-the-art and other alternatives. We share class separation capabilities and insights into the learning process of such a kernel on MNIST, Dogs vs. Cats, and CIFAR-10 datasets.","Sun, 13 Dec 2015 17:12:45 UTC (487 KB)[v2] Wed, 3 Feb 2016 06:59:54 UTC (1,098 KB)[v3] Tue, 16 Feb 2016 09:51:27 UTC (2,053 KB)"
"1890","Deep Learning Algorithms with Applications to Video Analytics for A Smart City: A Survey","Li Wang, Dennis Sng","Computer Vision and Pattern Recognition (cs.CV)","Deep learning has recently achieved very promising results in a wide range of areas such as computer vision, speech recognition and natural language processing. It aims to learn hierarchical representations of data by using deep architecture models. In a smart city, a lot of data (e.g. videos captured from many distributed sensors) need to be automatically processed and analyzed. In this paper, we review the deep learning algorithms applied to video analytics of smart city in terms of different research topics: object detection, object tracking, face recognition, image classification and scene labeling.","Thu, 10 Dec 2015 03:23:54 UTC (2,519 KB)"
"1891","Deep Learning for Single and Multi-Session i-Vector Speaker Recognition","Omid Ghahabi, Javier Hernando","Sound (cs.SD); Machine Learning (cs.LG)","The promising performance of Deep Learning (DL) in speech recognition has motivated the use of DL in other speech technology applications such as speaker recognition. Given i-vectors as inputs, the authors proposed an impostor selection algorithm and a universal model adaptation process in a hybrid system based on Deep Belief Networks (DBN) and Deep Neural Networks (DNN) to discriminatively model each target speaker. In order to have more insight into the behavior of DL techniques in both single and multi-session speaker enrollment tasks, some experiments have been carried out in this paper in both scenarios. Additionally, the parameters of the global model, referred to as universal DBN (UDBN), are normalized before adaptation. UDBN normalization facilitates training DNNs specifically with more than one hidden layer. Experiments are performed on the NIST SRE 2006 corpus. It is shown that the proposed impostor selection algorithm and UDBN adaptation process enhance the performance of conventional DNNs 8-20 % and 16-20 % in terms of EER for the single and multi-session tasks, respectively. In both scenarios, the proposed architectures outperform the baseline systems obtaining up to 17 % reduction in EER.","Tue, 8 Dec 2015 17:34:49 UTC (1,125 KB)"
"1892","Proposition of a Theoretical Model for Missing Data Imputation using Deep Learning and Evolutionary Algorithms","Collins Leke, Tshilidzi Marwala, Satyakama Paul","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG)","In the last couple of decades, there has been major advancements in the domain of missing data imputation. The techniques in the domain include amongst others: Expectation Maximization, Neural Networks with Evolutionary Algorithms or optimization techniques and K-Nearest Neighbor approaches to solve the problem. The presence of missing data entries in databases render the tasks of decision-making and data analysis nontrivial. As a result this area has attracted a lot of research interest with the aim being to yield accurate and time efficient and sensitive missing data imputation techniques especially when time sensitive applications are concerned like power plants and winding processes. In this article, considering arbitrary and monotone missing data patterns, we hypothesize that the use of deep neural networks built using autoencoders and denoising autoencoders in conjunction with genetic algorithms, swarm intelligence and maximum likelihood estimator methods as novel data imputation techniques will lead to better imputed values than existing techniques. Also considered are the missing at random, missing completely at random and missing not at random missing data mechanisms. We also intend to use fuzzy logic in tandem with deep neural networks to perform the missing data imputation tasks, as well as different building blocks for the deep neural networks like Stacked Restricted Boltzmann Machines and Deep Belief Networks to test our hypothesis. The motivation behind this article is the need for missing data imputation techniques that lead to better imputed values than existing methods with higher accuracies and lower errors.","Fri, 4 Dec 2015 10:39:59 UTC (358 KB)"
"1893","Recognizing Semantic Features in Faces using Deep Learning","Amogh Gudi","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","The human face constantly conveys information, both consciously and subconsciously. However, as basic as it is for humans to visually interpret this information, it is quite a big challenge for machines. Conventional semantic facial feature recognition and analysis techniques are already in use and are based on physiological heuristics, but they suffer from lack of robustness and high computation time. This thesis aims to explore ways for machines to learn to interpret semantic information available in faces in an automated manner without requiring manual design of feature detectors, using the approach of Deep Learning. This thesis provides a study of the effects of various factors and hyper-parameters of deep neural networks in the process of determining an optimal network configuration for the task of semantic facial feature recognition. This thesis explores the effectiveness of the system to recognize the various semantic features (like emotions, age, gender, ethnicity etc.) present in faces. Furthermore, the relation between the effect of high-level concepts on low level features is explored through an analysis of the similarities in low-level descriptors of different semantic features. This thesis also demonstrates a novel idea of using a deep network to generate 3-D Active Appearance Models of faces from real-world 2-D images. For a more detailed report on this work, please see [arXiv:1512.00743v1].","Wed, 2 Dec 2015 15:46:26 UTC (7,968 KB)[v2] Wed, 19 Oct 2016 13:33:44 UTC (3,854 KB)"
"1894","Cost-aware Pre-training for Multiclass Cost-sensitive Deep Learning","Yu-An Chung, Hsuan-Tien Lin, Shao-Wen Yang","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Deep learning has been one of the most prominent machine learning techniques nowadays, being the state-of-the-art on a broad range of applications where automatic feature extraction is needed. Many such applications also demand varying costs for different types of mis-classification errors, but it is not clear whether or how such cost information can be incorporated into deep learning to improve performance. In this work, we propose a novel cost-aware algorithm that takes into account the cost information into not only the training stage but also the pre-training stage of deep learning. The approach allows deep learning to conduct automatic feature extraction with the cost information effectively. Extensive experimental results demonstrate that the proposed approach outperforms other deep learning models that do not digest the cost information in the pre-training stage.","Mon, 30 Nov 2015 14:54:28 UTC (36 KB)[v2] Sat, 23 Jan 2016 07:30:13 UTC (39 KB)[v3] Tue, 24 May 2016 04:00:11 UTC (73 KB)"
"1895","Applying deep learning to classify pornographic images and videos","Mohamed Moustafa","Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Neural and Evolutionary Computing (cs.NE)","It is no secret that pornographic material is now a one-click-away from everyone, including children and minors. General social media networks are striving to isolate adult images and videos from normal ones. Intelligent image analysis methods can help to automatically detect and isolate questionable images in media. Unfortunately, these methods require vast experience to design the classifier including one or more of the popular computer vision feature descriptors. We propose to build a classifier based on one of the recently flourishing deep learning techniques. Convolutional neural networks contain many layers for both automatic features extraction and classification. The benefit is an easier system to build (no need for hand-crafting features and classifiers). Additionally, our experiments show that it is even more accurate than the state of the art methods on the most recent benchmark dataset.","Sat, 28 Nov 2015 13:55:25 UTC (327 KB)"
"1896","The Limitations of Deep Learning in Adversarial Settings","Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z. Berkay Celik, Ananthram Swami","Cryptography and Security (cs.CR); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","Deep learning takes advantage of large datasets and computationally efficient training algorithms to outperform other approaches at various machine learning tasks. However, imperfections in the training phase of deep neural networks make them vulnerable to adversarial samples: inputs crafted by adversaries with the intent of causing deep neural networks to misclassify. In this work, we formalize the space of adversaries against deep neural networks (DNNs) and introduce a novel class of algorithms to craft adversarial samples based on a precise understanding of the mapping between inputs and outputs of DNNs. In an application to computer vision, we show that our algorithms can reliably produce samples correctly classified by human subjects but misclassified in specific targets by a DNN with a 97% adversarial success rate while only modifying on average 4.02% of the input features per sample. We then evaluate the vulnerability of different sample classes to adversarial perturbations by defining a hardness measure. Finally, we describe preliminary work outlining defenses against adversarial samples by defining a predictive measure of distance between a benign input and a target classification.","Tue, 24 Nov 2015 01:07:08 UTC (963 KB)"
"1897","Pushing the Boundaries of Boundary Detection using Deep Learning","Iasonas Kokkinos","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","In this work we show that adapting Deep Convolutional Neural Network training to the task of boundary detection can result in substantial improvements over the current state-of-the-art in boundary detection. Our contributions consist firstly in combining a careful design of the loss for boundary detection training, a multi-resolution architecture and training with external data to improve the detection accuracy of the current state of the art. When measured on the standard Berkeley Segmentation Dataset, we improve theoptimal dataset scale F-measure from 0.780 to 0.808 - while human performance is at 0.803. We further improve performance to 0.813 by combining deep learning with grouping, integrating the Normalized Cuts technique within a deep network. We also examine the potential of our boundary detector in conjunction with the task of semantic segmentation and demonstrate clear improvements over state-of-the-art systems. Our detector is fully integrated in the popular Caffe framework and processes a 320x420 image in less than a second.","Mon, 23 Nov 2015 19:54:09 UTC (6,946 KB)[v2] Fri, 22 Jan 2016 15:31:32 UTC (6,945 KB)"
"1898","Detecting Road Surface Wetness from Audio: A Deep Learning Approach","Irman Abdi<U+0107>, Lex Fridman, Erik Marchi, Daniel E Brown, William Angell, Bryan Reimer, Bjorn Schuller","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Sound (cs.SD)","We introduce a recurrent neural network architecture for automated road surface wetness detection from audio of tire-surface interaction. The robustness of our approach is evaluated on 785,826 bins of audio that span an extensive range of vehicle speeds, noises from the environment, road surface types, and pavement conditions including international roughness index (IRI) values from 25 in/mi to 1400 in/mi. The training and evaluation of the model are performed on different roads to minimize the impact of environmental and other external factors on the accuracy of the classification. We achieve an unweighted average recall (UAR) of 93.2% across all vehicle speeds including 0 mph. The classifier still works at 0 mph because the discriminating signal is present in the sound of other vehicles driving by.","Sun, 22 Nov 2015 17:20:23 UTC (1,049 KB)[v2] Fri, 4 Dec 2015 20:05:22 UTC (2,415 KB)"
"1899","Comparative Study of Deep Learning Software Frameworks","Soheil Bahrampour, Naveen Ramakrishnan, Lukas Schott, Mohak Shah","Machine Learning (cs.LG)","Deep learning methods have resulted in significant performance improvements in several application domains and as such several software frameworks have been developed to facilitate their implementation. This paper presents a comparative study of five deep learning frameworks, namely Caffe, Neon, TensorFlow, Theano, and Torch, on three aspects: extensibility, hardware utilization, and speed. The study is performed on several types of deep learning architectures and we evaluate the performance of the above frameworks when employed on a single machine for both (multi-threaded) CPU and GPU (Nvidia Titan X) settings. The speed performance metrics used here include the gradient computation time, which is important during the training phase of deep networks, and the forward time, which is important from the deployment perspective of trained networks. For convolutional networks, we also report how each of these frameworks support various convolutional algorithms and their corresponding performance. From our experiments, we observe that Theano and Torch are the most easily extensible frameworks. We observe that Torch is best suited for any deep architecture on CPU, followed by Theano. It also achieves the best performance on the GPU for large convolutional and fully connected networks, followed closely by Neon. Theano achieves the best performance on GPU for training and deployment of LSTM networks. Caffe is the easiest for evaluating the performance of standard deep architectures. Finally, TensorFlow is a very flexible framework, similar to Theano, but its performance is currently not competitive compared to the other studied frameworks.","Thu, 19 Nov 2015 22:51:38 UTC (209 KB)[v2] Mon, 4 Jan 2016 22:03:33 UTC (210 KB)[v3] Wed, 30 Mar 2016 00:54:34 UTC (281 KB)"
"1900","How much data is needed to train a medical image deep learning system to achieve necessary high accuracy?","Junghwan Cho, Kyewook Lee, Ellie Shin, Garry Choy, Synho Do","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)","The use of Convolutional Neural Networks (CNN) in natural image classification systems has produced very impressive results. Combined with the inherent nature of medical images that make them ideal for deep-learning, further application of such systems to medical image classification holds much promise. However, the usefulness and potential impact of such a system can be completely negated if it does not reach a target accuracy. In this paper, we present a study on determining the optimum size of the training data set necessary to achieve high classification accuracy with low variance in medical image classification systems. The CNN was applied to classify axial Computed Tomography (CT) images into six anatomical classes. We trained the CNN using six different sizes of training data set (5, 10, 20, 50, 100, and 200) and then tested the resulting system with a total of 6000 CT images. All images were acquired from the Massachusetts General Hospital (MGH) Picture Archiving and Communication System (PACS). Using this data, we employ the learning curve approach to predict classification accuracy at a given training sample size. Our research will present a general methodology for determining the training data set size necessary to achieve a certain target classification accuracy that can be easily applied to other problems within such systems.","Thu, 19 Nov 2015 20:38:43 UTC (2,696 KB)[v2] Thu, 7 Jan 2016 21:08:10 UTC (2,698 KB)"
"1901","Predicting online user behaviour using deep learning algorithms","Armando Vieira","Machine Learning (cs.LG); Machine Learning (stat.ML)","We propose a robust classifier to predict buying intentions based on user behaviour within a large e-commerce website. In this work we compare traditional machine learning techniques with the most advanced deep learning approaches. We show that both Deep Belief Networks and Stacked Denoising auto-Encoders achieved a substantial improvement by extracting features from high dimensional data during the pre-train phase. They prove also to be more convenient to deal with severe class imbalance.","Thu, 19 Nov 2015 16:47:00 UTC (90 KB)[v2] Sat, 21 Nov 2015 18:53:45 UTC (91 KB)[v3] Thu, 26 May 2016 11:53:55 UTC (180 KB)"
"1902","Deep Learning for Tactile Understanding From Visual and Haptic Data","Yang Gao, Lisa Anne Hendricks, Katherine J. Kuchenbecker, Trevor Darrell","Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Robots which interact with the physical world will benefit from a fine-grained tactile understanding of objects and surfaces. Additionally, for certain tasks, robots may need to know the haptic properties of an object before touching it. To enable better tactile understanding for robots, we propose a method of classifying surfaces with haptic adjectives (e.g., compressible or smooth) from both visual and physical interaction data. Humans typically combine visual predictions and feedback from physical interactions to accurately predict haptic properties and interact with the world. Inspired by this cognitive pattern, we propose and explore a purely visual haptic prediction model. Purely visual models enable a robot to ""feel"" without physical interaction. Furthermore, we demonstrate that using both visual and physical interaction signals together yields more accurate haptic classification. Our models take advantage of recent advances in deep neural networks by employing a unified approach to learning features for physical interaction and visual observations. Even though we employ little domain specific knowledge, our model still achieves better results than methods based on hand-designed features.","Thu, 19 Nov 2015 05:52:15 UTC (680 KB)[v2] Tue, 12 Apr 2016 00:16:21 UTC (1,970 KB)"
"1903","Staleness-aware Async-SGD for Distributed Deep Learning","Wei Zhang, Suyog Gupta, Xiangru Lian, Ji Liu","Machine Learning (cs.LG)","Deep neural networks have been shown to achieve state-of-the-art performance in several machine learning tasks. Stochastic Gradient Descent (SGD) is the preferred optimization algorithm for training these networks and asynchronous SGD (ASGD) has been widely adopted for accelerating the training of large-scale deep networks in a distributed computing environment. However, in practice it is quite challenging to tune the training hyperparameters (such as learning rate) when using ASGD so as achieve convergence and linear speedup, since the stability of the optimization algorithm is strongly influenced by the asynchronous nature of parameter updates. In this paper, we propose a variant of the ASGD algorithm in which the learning rate is modulated according to the gradient staleness and provide theoretical guarantees for convergence of this algorithm. Experimental verification is performed on commonly-used image classification benchmarks: CIFAR10 and Imagenet to demonstrate the superior effectiveness of the proposed approach, compared to SSGD (Synchronous SGD) and the conventional ASGD algorithm.","Wed, 18 Nov 2015 20:53:33 UTC (1,436 KB)[v2] Thu, 19 Nov 2015 16:36:23 UTC (1,436 KB)[v3] Mon, 14 Dec 2015 20:34:57 UTC (1,460 KB)[v4] Sat, 19 Dec 2015 22:38:52 UTC (1,474 KB)[v5] Tue, 5 Apr 2016 06:21:03 UTC (1,504 KB)"
"1904","Identifying the Absorption Bump with Deep Learning","Min Li, Sudeep Gaddam, Xiaolin Li, Yinan Zhao, Jingzhe Ma, Jian Ge","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","The pervasive interstellar dust grains provide significant insights to understand the formation and evolution of the stars, planetary systems, and the galaxies, and may harbor the building blocks of life. One of the most effective way to analyze the dust is via their interaction with the light from background sources. The observed extinction curves and spectral features carry the size and composition information of dust. The broad absorption bump at 2175 Angstrom is the most prominent feature in the extinction curves. Traditionally, statistical methods are applied to detect the existence of the absorption bump. These methods require heavy preprocessing and the co-existence of other reference features to alleviate the influence from the noises. In this paper, we apply Deep Learning techniques to detect the broad absorption bump. We demonstrate the key steps for training the selected models and their results. The success of Deep Learning based method inspires us to generalize a common methodology for broader science discovery problems. We present our on-going work to build the DeepDis system for such kind of applications.","Tue, 17 Nov 2015 22:27:05 UTC (733 KB)[v2] Fri, 20 Nov 2015 14:20:46 UTC (733 KB)"
"1905","Structural-RNN: Deep Learning on Spatio-Temporal Graphs","Ashesh Jain, Amir R. Zamir, Silvio Savarese, Ashutosh Saxena","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Robotics (cs.RO)","Deep Recurrent Neural Network architectures, though remarkably capable at modeling sequences, lack an intuitive high-level spatio-temporal structure. That is while many problems in computer vision inherently have an underlying high-level structure and can benefit from it. Spatio-temporal graphs are a popular tool for imposing such high-level intuitions in the formulation of real world problems. In this paper, we propose an approach for combining the power of high-level spatio-temporal graphs and sequence learning success of Recurrent Neural Networks~(RNNs). We develop a scalable method for casting an arbitrary spatio-temporal graph as a rich RNN mixture that is feedforward, fully differentiable, and jointly trainable. The proposed method is generic and principled as it can be used for transforming any spatio-temporal graph through employing a certain set of well defined steps. The evaluations of the proposed approach on a diverse set of problems, ranging from modeling human motion to object interactions, shows improvement over the state-of-the-art with a large margin. We expect this method to empower new approaches to problem formulation through high-level spatio-temporal graphs and Recurrent Neural Networks.","Tue, 17 Nov 2015 07:49:58 UTC (4,165 KB)[v2] Fri, 20 Nov 2015 01:26:23 UTC (4,165 KB)[v3] Mon, 11 Apr 2016 19:00:24 UTC (2,823 KB)"
"1906","On the interplay of network structure and gradient convergence in deep learning","Vamsi K Ithapu, Sathya N Ravi, Vikas Singh","Machine Learning (cs.LG); Machine Learning (stat.ML)","The regularization and output consistency behavior of dropout and layer-wise pretraining for learning deep networks have been fairly well studied. However, our understanding of how the asymptotic convergence of backpropagation in deep architectures is related to the structural properties of the network and other design choices (like denoising and dropout rate) is less clear at this time. An interesting question one may ask is whether the network architecture and input data statistics may guide the choices of learning parameters and vice versa. In this work, we explore the association between such structural, distributional and learnability aspects vis-a-vis their interaction with parameter convergence rates. We present a framework to address these questions based on convergence of backpropagation for general nonconvex objectives using first-order information. This analysis suggests an interesting relationship between feature denoising and dropout. Building upon these results, we obtain a setup that provides systematic guidance regarding the choice of learning parameters and network sizes that achieve a certain level of convergence (in the optimization sense) often mediated by statistical attributes of the inputs. Our results are supported by a set of experimental evaluations as well as independent empirical observations reported by other groups.","Tue, 17 Nov 2015 07:31:56 UTC (181 KB)[v2] Thu, 19 Nov 2015 21:49:44 UTC (446 KB)[v3] Thu, 7 Jan 2016 21:47:36 UTC (1,244 KB)[v4] Mon, 18 Jan 2016 20:17:03 UTC (1,248 KB)[v5] Tue, 29 Mar 2016 23:16:43 UTC (1,257 KB)[v6] Mon, 3 Oct 2016 16:21:39 UTC (218 KB)[v7] Tue, 4 Oct 2016 20:56:42 UTC (218 KB)[v8] Wed, 22 Feb 2017 17:28:01 UTC (252 KB)"
"1907","Jet-Images -- Deep Learning Edition","Luke de Oliveira, Michael Kagan, Lester Mackey, Benjamin Nachman, Ariel Schwartzman","High Energy Physics - Phenomenology (hep-ph); Data Analysis, Statistics and Probability (physics.data-an); Machine Learning (stat.ML)","Building on the notion of a particle physics detector as a camera and the collimated streams of high energy particles, or jets, it measures as an image, we investigate the potential of machine learning techniques based on deep learning architectures to identify highly boosted W bosons. Modern deep learning algorithms trained on jet images can out-perform standard physically-motivated feature driven approaches to jet tagging. We develop techniques for visualizing how these features are learned by the network and what additional information is used to improve performance. This interplay between physically-motivated feature driven tools and supervised learning algorithms is general and can be used to significantly increase the sensitivity to discover new particles and new forces, and gain a deeper understanding of the physics within jets.","Mon, 16 Nov 2015 21:44:37 UTC (8,829 KB)[v2] Mon, 4 Apr 2016 01:17:53 UTC (5,772 KB)[v3] Sun, 22 Jan 2017 18:38:57 UTC (6,163 KB)"
"1908","Deep learning is a good steganalysis tool when embedding key is reused for different images, even if there is a cover source-mismatch","Lionel Pibre, Pasquet Jerome, Dino Ienco, Marc Chaumont","Multimedia (cs.MM); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Since the BOSS competition, in 2010, most steganalysis approaches use a learning methodology involving two steps: feature extraction, such as the Rich Models (RM), for the image representation, and use of the Ensemble Classifier (EC) for the learning step. In 2015, Qian et al. have shown that the use of a deep learning approach that jointly learns and computes the features, is very promising for the steganalysis. In this paper, we follow-up the study of Qian et al., and show that, due to intrinsic joint minimization, the results obtained from a Convolutional Neural Network (CNN) or a Fully Connected Neural Network (FNN), if well parameterized, surpass the conventional use of a RM with an EC. First, numerous experiments were conducted in order to find the best "" shape "" of the CNN. Second, experiments were carried out in the clairvoyant scenario in order to compare the CNN and FNN to an RM with an EC. The results show more than 16% reduction in the classification error with our CNN or FNN. Third, experiments were also performed in a cover-source mismatch setting. The results show that the CNN and FNN are naturally robust to the mismatch problem. In Addition to the experiments, we provide discussions on the internal mechanisms of a CNN, and weave links with some previously stated ideas, in order to understand the impressive results we obtained.","Mon, 16 Nov 2015 07:59:14 UTC (361 KB)[v2] Fri, 12 Jan 2018 07:49:46 UTC (749 KB)"
"1909","8-Bit Approximations for Parallelism in Deep Learning","Tim Dettmers","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG)","The creation of practical deep learning data-products often requires parallelization across processors and computers to make deep learning feasible on large data sets, but bottlenecks in communication bandwidth make it difficult to attain good speedups through parallelism. Here we develop and test 8-bit approximation algorithms which make better use of the available bandwidth by compressing 32-bit gradients and nonlinear activations to 8-bit approximations. We show that these approximations do not decrease predictive performance on MNIST, CIFAR10, and ImageNet for both model and data parallelism and provide a data transfer speedup of 2x relative to 32-bit parallelism. We build a predictive model for speedups based on our experimental data, verify its validity on known speedup data, and show that we can obtain a speedup of 50x and more on a system of 96 GPUs compared to a speedup of 23x for 32-bit. We compare our data types with other methods and show that 8-bit approximations achieve state-of-the-art speedups for model parallelism. Thus 8-bit approximation is an efficient method to parallelize convolutional networks on very large systems of GPUs.","Sat, 14 Nov 2015 14:04:51 UTC (218 KB)[v2] Sun, 22 Nov 2015 10:25:58 UTC (224 KB)[v3] Mon, 4 Jan 2016 20:32:52 UTC (190 KB)[v4] Fri, 19 Feb 2016 16:26:30 UTC (191 KB)"
"1910","LSTM-based Deep Learning Models for Non-factoid Answer Selection","Ming Tan, Cicero dos Santos, Bing Xiang, Bowen Zhou","Computation and Language (cs.CL); Machine Learning (cs.LG)","In this paper, we apply a general deep learning (DL) framework for the answer selection task, which does not depend on manually defined features or linguistic tools. The basic framework is to build the embeddings of questions and answers based on bidirectional long short-term memory (biLSTM) models, and measure their closeness by cosine similarity. We further extend this basic model in two directions. One direction is to define a more composite representation for questions and answers by combining convolutional neural network with the basic framework. The other direction is to utilize a simple but efficient attention mechanism in order to generate the answer representation according to the question context. Several variations of models are provided. The models are examined by two datasets, including TREC-QA and InsuranceQA. Experimental results demonstrate that the proposed models substantially outperform several strong baselines.","Thu, 12 Nov 2015 22:01:54 UTC (109 KB)[v2] Wed, 18 Nov 2015 15:00:46 UTC (199 KB)[v3] Thu, 7 Jan 2016 17:56:29 UTC (130 KB)[v4] Mon, 28 Mar 2016 04:12:45 UTC (122 KB)"
"1911","A new humanlike facial attractiveness predictor with cascaded fine-tuning deep learning model","Jie Xu, Lianwen Jin, Lingyu Liang, Ziyong Feng, Duorui Xie","Computer Vision and Pattern Recognition (cs.CV)","This paper proposes a deep leaning method to address the challenging facial attractiveness prediction problem. The method constructs a convolutional neural network of facial beauty prediction using a new deep cascaded fine-turning scheme with various face inputting channels, such as the original RGB face image, the detail layer image, and the lighting layer image. With a carefully designed CNN model of deep structure, large input size and small convolutional kernels, we have achieved a high prediction correlation of 0.88. This result convinces us that the problem of facial attractiveness prediction can be solved by deep learning approach, and it also shows the important roles of the facial smoothness, lightness, and color information that were involved in facial beauty perception, which is consistent with the result of recent psychology studies. Furthermore, we analyze the high-level features learnt by CNN through visualization of its hidden layers, and some interesting phenomena were observed. It is found that the contours and appearance of facial features, especially eyes and moth, are the most significant facial attributes for facial attractiveness prediction, which is also consistent with the visual perception intuition of human.","Sun, 8 Nov 2015 09:59:04 UTC (1,220 KB)"
"1912","Distributed Deep Learning for Question Answering","Minwei Feng, Bing Xiang, Bowen Zhou","Machine Learning (cs.LG); Computation and Language (cs.CL); Distributed, Parallel, and Cluster Computing (cs.DC)","This paper is an empirical study of the distributed deep learning for question answering subtasks: answer selection and question classification. Comparison studies of SGD, MSGD, ADADELTA, ADAGRAD, ADAM/ADAMAX, RMSPROP, DOWNPOUR and EASGD/EAMSGD algorithms have been presented. Experimental results show that the distributed framework based on the message passing interface can accelerate the convergence speed at a sublinear scale. This paper demonstrates the importance of distributed training. For example, with 48 workers, a 24x speedup is achievable for the answer selection task and running time is decreased from 138.2 hours to 5.81 hours, which will increase the productivity significantly.","Tue, 3 Nov 2015 23:18:35 UTC (41 KB)[v2] Fri, 13 May 2016 15:41:54 UTC (42 KB)[v3] Thu, 4 Aug 2016 16:41:37 UTC (32 KB)"
"1913","Estimation of effective temperatures in quantum annealers for sampling applications: A case study with possible applications in deep learning","Marcello Benedetti, John Realpe-Gomez, Rupak Biswas, Alejandro Perdomo-Ortiz","Quantum Physics (quant-ph)","An increase in the efficiency of sampling from Boltzmann distributions would have a significant impact on deep learning and other machine-learning applications. Recently, quantum annealers have been proposed as a potential candidate to speed up this task, but several limitations still bar these state-of-the-art technologies from being used effectively. One of the main limitations is that, while the device may indeed sample from a Boltzmann-like distribution, quantum dynamical arguments suggest it will do so with an {\it instance-dependent} effective temperature, different from its physical temperature. Unless this unknown temperature can be unveiled, it might not be possible to effectively use a quantum annealer for Boltzmann sampling. In this work, we propose a strategy to overcome this challenge with a simple effective-temperature estimation algorithm. We provide a systematic study assessing the impact of the effective temperatures in the learning of a special class of a restricted Boltzmann machine embedded on quantum hardware, which can serve as a building block for deep-learning architectures. We also provide a comparison to $k$-step contrastive divergence (CD-$k$) with $k$ up to 100. Although assuming a suitable fixed effective temperature also allows us to outperform one step contrastive divergence (CD-1), only when using an instance-dependent effective temperature do we find a performance close to that of CD-100 for the case studied here.","Mon, 26 Oct 2015 19:46:34 UTC (944 KB)[v2] Tue, 27 Oct 2015 19:14:21 UTC (944 KB)[v3] Wed, 2 Mar 2016 08:54:39 UTC (716 KB)[v4] Tue, 9 Aug 2016 14:59:34 UTC (965 KB)"
"1914","Empirical Study on Deep Learning Models for Question Answering","Yang Yu, Wei Zhang, Chung-Wei Hang, Bing Xiang, Bowen Zhou","Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","In this paper we explore deep learning models with memory component or attention mechanism for question answering task. We combine and compare three models, Neural Machine Translation, Neural Turing Machine, and Memory Networks for a simulated QA data set. This paper is the first one that uses Neural Machine Translation and Neural Turing Machines for solving QA tasks. Our results suggest that the combination of attention and memory have potential to solve certain QA problem.","Mon, 26 Oct 2015 16:03:27 UTC (215 KB)[v2] Tue, 27 Oct 2015 16:56:48 UTC (215 KB)[v3] Fri, 20 Nov 2015 15:36:56 UTC (231 KB)"
"1915","A Framework for Distributed Deep Learning Layer Design in Python","Clay McLeod","Machine Learning (cs.LG)","In this paper, a framework for testing Deep Neural Network (DNN) design in Python is presented. First, big data, machine learning (ML), and Artificial Neural Networks (ANNs) are discussed to familiarize the reader with the importance of such a system. Next, the benefits and detriments of implementing such a system in Python are presented. Lastly, the specifics of the system are explained, and some experimental results are presented to prove the effectiveness of the system.","Sun, 25 Oct 2015 21:04:12 UTC (2,115 KB)"
"1916","Vehicle Speed Prediction using Deep Learning","Joe Lemieux, Yuan Ma","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Global optimization of the energy consumption of dual power source vehicles such as hybrid electric vehicles, plug-in hybrid electric vehicles, and plug in fuel cell electric vehicles requires knowledge of the complete route characteristics at the beginning of the trip. One of the main characteristics is the vehicle speed profile across the route. The profile will translate directly into energy requirements for a given vehicle. However, the vehicle speed that a given driver chooses will vary from driver to driver and from time to time, and may be slower, equal to, or faster than the average traffic flow. If the specific driver speed profile can be predicted, the energy usage can be optimized across the route chosen. The purpose of this paper is to research the application of Deep Learning techniques to this problem to identify at the beginning of a drive cycle the driver specific vehicle speed profile for an individual driver repeated drive cycle, which can be used in an optimization algorithm to minimize the amount of fossil fuel energy used during the trip.","Sun, 25 Oct 2015 05:52:59 UTC (506 KB)"
"1917","A Survey: Time Travel in Deep Learning Space: An Introduction to Deep Learning Models and How Deep Learning Models Evolved from the Initial Ideas","Haohan Wang, Bhiksha Raj","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","This report will show the history of deep learning evolves. It will trace back as far as the initial belief of connectionism modelling of brain, and come back to look at its early stage realization: neural networks. With the background of neural network, we will gradually introduce how convolutional neural network, as a representative of deep discriminative models, is developed from neural networks, together with many practical techniques that can help in optimization of neural networks. On the other hand, we will also trace back to see the evolution history of deep generative models, to see how researchers balance the representation power and computation complexity to reach Restricted Boltzmann Machine and eventually reach Deep Belief Nets. Further, we will also look into the development history of modelling time series data with neural networks. We start with Time Delay Neural Networks and move further to currently famous model named Recurrent Neural Network and its extension Long Short Term Memory. We will also briefly look into how to construct deep recurrent neural networks. Finally, we will conclude this report with some interesting open-ended questions of deep neural networks.","Fri, 16 Oct 2015 05:37:06 UTC (978 KB)[v2] Fri, 6 Nov 2015 19:41:13 UTC (978 KB)"
"1918","Improved Deep Learning Baselines for Ubuntu Corpus Dialogs","Rudolf Kadlec, Martin Schmid, Jan Kleindienst","Computation and Language (cs.CL)","This paper presents results of our experiments for the next utterance ranking on the Ubuntu Dialog Corpus -- the largest publicly available multi-turn dialog corpus. First, we use an in-house implementation of previously reported models to do an independent evaluation using the same data. Second, we evaluate the performances of various LSTMs, Bi-LSTMs and CNNs on the dataset. Third, we create an ensemble by averaging predictions of multiple models. The ensemble further improves the performance and it achieves a state-of-the-art result for the next utterance ranking on this dataset. Finally, we discuss our future plans using this corpus.","Tue, 13 Oct 2015 15:56:26 UTC (87 KB)[v2] Tue, 3 Nov 2015 08:23:50 UTC (88 KB)"
"1919","Large-scale Artificial Neural Network: MapReduce-based Deep Learning","Kairan Sun, Xu Wei, Gengtao Jia, Risheng Wang, Ruizhi Li","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Faced with continuously increasing scale of data, original back-propagation neural network based machine learning algorithm presents two non-trivial challenges: huge amount of data makes it difficult to maintain both efficiency and accuracy; redundant data aggravates the system workload. This project is mainly focused on the solution to the issues above, combining deep learning algorithm with cloud computing platform to deal with large-scale data. A MapReduce-based handwriting character recognizer will be designed in this project to verify the efficiency improvement this mechanism will achieve on training and practical large-scale data. Careful discussion and experiment will be developed to illustrate how deep learning algorithm works to train handwritten digits data, how MapReduce is implemented on deep learning neural network, and why this combination accelerates computation. Besides performance, the scalability and robustness will be mentioned in this report as well. Our system comes with two demonstration software that visually illustrates our handwritten digit recognition/encoding application.","Fri, 9 Oct 2015 15:45:44 UTC (893 KB)"
"1920","Structured Transforms for Small-Footprint Deep Learning","Vikas Sindhwani, Tara N. Sainath, Sanjiv Kumar","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","We consider the task of building compact deep learning pipelines suitable for deployment on storage and power constrained mobile devices. We propose a unified framework to learn a broad family of structured parameter matrices that are characterized by the notion of low displacement rank. Our structured transforms admit fast function and gradient evaluation, and span a rich range of parameter sharing configurations whose statistical modeling capacity can be explicitly tuned along a continuum from structured to unstructured. Experimental results show that these transforms can significantly accelerate inference and forward/backward passes during training, and offer superior accuracy-compactness-speed tradeoffs in comparison to a number of existing techniques. In keyword spotting applications in mobile speech recognition, our methods are much more effective than standard linear low-rank bottleneck layers and nearly retain the performance of state of the art models, while providing more than 3.5-fold compression.","Tue, 6 Oct 2015 19:42:22 UTC (75 KB)"
"1921","Predicting Daily Activities From Egocentric Images Using Deep Learning","Daniel Castro, Steven Hickson, Vinay Bettadapura, Edison Thomaz, Gregory Abowd, Henrik Christensen, Irfan Essa","Computer Vision and Pattern Recognition (cs.CV)","We present a method to analyze images taken from a passive egocentric wearable camera along with the contextual information, such as time and day of week, to learn and predict everyday activities of an individual. We collected a dataset of 40,103 egocentric images over a 6 month period with 19 activity classes and demonstrate the benefit of state-of-the-art deep learning techniques for learning and predicting daily activities. Classification is conducted using a Convolutional Neural Network (CNN) with a classification method we introduce called a late fusion ensemble. This late fusion ensemble incorporates relevant contextual information and increases our classification accuracy. Our technique achieves an overall accuracy of 83.07% in predicting a person's activity across the 19 activity classes. We also demonstrate some promising results from two additional users by fine-tuning the classifier with one day of training data.","Tue, 6 Oct 2015 13:56:50 UTC (4,485 KB)"
"1922","Conditional Deep Learning for Energy-Efficient and Enhanced Pattern Recognition","Priyadarshini Panda, Abhronil Sengupta, Kaushik Roy","Computer Vision and Pattern Recognition (cs.CV)","Deep learning neural networks have emerged as one of the most powerful classification tools for vision related applications. However, the computational and energy requirements associated with such deep nets can be quite high, and hence their energy-efficient implementation is of great interest. Although traditionally the entire network is utilized for the recognition of all inputs, we observe that the classification difficulty varies widely across inputs in real-world datasets; only a small fraction of inputs require the full computational effort of a network, while a large majority can be classified correctly with very low effort. In this paper, we propose Conditional Deep Learning (CDL) where the convolutional layer features are used to identify the variability in the difficulty of input instances and conditionally activate the deeper layers of the network. We achieve this by cascading a linear network of output neurons for each convolutional layer and monitoring the output of the linear network to decide whether classification can be terminated at the current stage or not. The proposed methodology thus enables the network to dynamically adjust the computational effort depending upon the difficulty of the input data while maintaining competitive classification accuracy. We evaluate our approach on the MNIST dataset. Our experiments demonstrate that our proposed CDL yields 1.91x reduction in average number of operations per input, which translates to 1.84x improvement in energy. In addition, our results show an improvement in classification accuracy from 97.5% to 98.9% as compared to the original network.","Tue, 29 Sep 2015 23:08:09 UTC (2,412 KB)[v2] Thu, 1 Oct 2015 13:56:35 UTC (2,420 KB)[v3] Sat, 3 Oct 2015 12:23:00 UTC (0 KB)[v4] Tue, 6 Oct 2015 01:45:50 UTC (2,423 KB)[v5] Tue, 24 Nov 2015 17:04:59 UTC (2,430 KB)[v6] Thu, 28 Jan 2016 18:34:42 UTC (2,485 KB)"
"1923","Semantics, Representations and Grammars for Deep Learning","David Balduzzi","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","Deep learning is currently the subject of intensive study. However, fundamental concepts such as representations are not formally defined -- researchers ""know them when they see them"" -- and there is no common language for describing and analyzing algorithms. This essay proposes an abstract framework that identifies the essential features of current practice and may provide a foundation for future developments. The backbone of almost all deep learning algorithms is backpropagation, which is simply a gradient computation distributed over a neural network. The main ingredients of the framework are thus, unsurprisingly: (i) game theory, to formalize distributed optimization; and (ii) communication protocols, to track the flow of zeroth and first-order information. The framework allows natural definitions of semantics (as the meaning encoded in functions), representations (as functions whose semantics is chosen to optimized a criterion) and grammars (as communication protocols equipped with first-order convergence guarantees). Much of the essay is spent discussing examples taken from the literature. The ultimate aim is to develop a graphical language for describing the structure of deep learning algorithms that backgrounds the details of the optimization procedure and foregrounds how the components interact. Inspiration is taken from probabilistic graphical models and factor graphs, which capture the essential structural features of multivariate distributions.","Tue, 29 Sep 2015 08:14:21 UTC (44 KB)"
"1924","From Facial Parts Responses to Face Detection: A Deep Learning Approach","Shuo Yang, Ping Luo, Chen Change Loy, Xiaoou Tang","Computer Vision and Pattern Recognition (cs.CV)","In this paper, we propose a novel deep convolutional network (DCN) that achieves outstanding performance on FDDB, PASCAL Face, and AFW. Specifically, our method achieves a high recall rate of 90.99% on the challenging FDDB benchmark, outperforming the state-of-the-art method by a large margin of 2.91%. Importantly, we consider finding faces from a new perspective through scoring facial parts responses by their spatial structure and arrangement. The scoring mechanism is carefully formulated considering challenging cases where faces are only partially visible. This consideration allows our network to detect faces under severe occlusion and unconstrained pose variation, which are the main difficulty and bottleneck of most existing face detection approaches. We show that despite the use of DCN, our network can achieve practical runtime speed.","Tue, 22 Sep 2015 02:59:31 UTC (4,212 KB)"
"1925","A Statistical Theory of Deep Learning via Proximal Splitting","Nicholas G. Polson, Brandon T. Willard, Massoud Heidari","Machine Learning (stat.ML)","In this paper we develop a statistical theory and an implementation of deep learning models. We show that an elegant variable splitting scheme for the alternating direction method of multipliers optimises a deep learning objective. We allow for non-smooth non-convex regularisation penalties to induce sparsity in parameter weights. We provide a link between traditional shallow layer statistical models such as principal component and sliced inverse regression and deep layer models. We also define the degrees of freedom of a deep learning predictor and a predictive MSE criteria to perform model selection for comparing architecture designs. We focus on deep multiclass logistic learning although our methods apply more generally. Our results suggest an interesting and previously under-exploited relationship between deep learning and proximal splitting techniques. To illustrate our methodology, we provide a multi-class logit classification analysis of Fisher's Iris data where we illustrate the convergence of our algorithm. Finally, we conclude with directions for future research.","Sun, 20 Sep 2015 21:39:47 UTC (45 KB)"
"1926","Telugu OCR Framework using Deep Learning","Rakesh Achanta, Trevor Hastie","Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","In this paper, we address the task of Optical Character Recognition(OCR) for the Telugu script. We present an end-to-end framework that segments the text image, classifies the characters and extracts lines using a language model. The segmentation is based on mathematical morphology. The classification module, which is the most challenging task of the three, is a deep convolutional neural network. The language is modelled as a third degree markov chain at the glyph level. Telugu script is a complex alphasyllabary and the language is agglutinative, making the problem hard. In this paper we apply the latest advances in neural networks to achieve state-of-the-art error rates. We also review convolutional neural networks in great detail and expound the statistical justification behind the many tricks needed to make Deep Learning work.","Sun, 20 Sep 2015 03:35:05 UTC (1,166 KB)[v2] Wed, 15 Feb 2017 02:29:04 UTC (1,175 KB)"
"1927","Modelling Uncertainty in Deep Learning for Camera Relocalization","Alex Kendall, Roberto Cipolla","Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","We present a robust and real-time monocular six degree of freedom visual relocalization system. We use a Bayesian convolutional neural network to regress the 6-DOF camera pose from a single RGB image. It is trained in an end-to-end manner with no need of additional engineering or graph optimisation. The algorithm can operate indoors and outdoors in real time, taking under 6ms to compute. It obtains approximately 2m and 6 degrees accuracy for very large scale outdoor scenes and 0.5m and 10 degrees accuracy indoors. Using a Bayesian convolutional neural network implementation we obtain an estimate of the model's relocalization uncertainty and improve state of the art localization accuracy on a large scale outdoor dataset. We leverage the uncertainty measure to estimate metric relocalization error and to detect the presence or absence of the scene in the input image. We show that the model's uncertainty is caused by images being dissimilar to the training dataset in either pose or appearance.","Sat, 19 Sep 2015 16:01:05 UTC (4,942 KB)[v2] Thu, 18 Feb 2016 13:30:25 UTC (4,942 KB)"
"1928","A catalog of visual-like morphologies in the 5 CANDELS fields using deep-learning","M. Huertas-Company (1), R. Gravet (1), G. Cabrera-Vives (2), P.G. Perez-Gonzalez (3), J.S. Kartaltepe (4), G. Barro (5), M. Bernardi (6), S. Mei (1), F. Shankar (7), P. Dimauro (1), E.F. Bell (8), D. Kocevski (9), D.C. Koo (5), S.M. Faber (5), D.H. Mcintosh (10) ((1) GEPI, Observatoire de Paris, CNRS, Universit\'e Paris Diderot (2) Department of Computer Science and Center for Mathematical Modeling, University of Chile, Santiago, Chile (3) Departamento de Astrof\'isica, Facultad de CC. F\'isicas, Universidad Complutense de Madrid (4) School of Physics and Astronomy, Rochester Institute of Technology (5) UCO/Lick Observatory, Department of Astronomy and Astrophysics, University of California (6) Department of Physics and Astronomy, University of Pennsylvania, (7) Department of Physics and Astronomy, University of Southampton, (8) Department of Astronomy, University of Michigan, (9) Department of Physics and Astronomy, University of Kentucky, (10) Department of Physics \& Astronomy, University of Missouri-Kansas City)","Astrophysics of Galaxies (astro-ph.GA); Cosmology and Nongalactic Astrophysics (astro-ph.CO)","We present a catalog of visual like H-band morphologies of $\sim50.000$ galaxies ($H_{f160w}<24.5$) in the 5 CANDELS fields (GOODS-N, GOODS-S, UDS, EGS and COSMOS). Morphologies are estimated with Convolutional Neural Networks (ConvNets). The median redshift of the sample is $<z>\sim1.25$. The algorithm is trained on GOODS-S for which visual classifications are publicly available and then applied to the other 4 fields. Following the CANDELS main morphology classification scheme, our model retrieves the probabilities for each galaxy of having a spheroid, a disk, presenting an irregularity, being compact or point source and being unclassifiable. ConvNets are able to predict the fractions of votes given a galaxy image with zero bias and $\sim10\%$ scatter. The fraction of miss-classifications is less than $1\%$. Our classification scheme represents a major improvement with respect to CAS (Concentration-Asymmetry-Smoothness)-based methods, which hit a $20-30\%$ contamination limit at high z. The catalog is released with the present paper via the $\href{this http URL}{Rainbow\,database}$","Thu, 17 Sep 2015 20:21:32 UTC (11,393 KB)"
"1929","On the Expressive Power of Deep Learning: A Tensor Analysis","Nadav Cohen, Or Sharir, Amnon Shashua","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG); Numerical Analysis (cs.NA); Machine Learning (stat.ML)","It has long been conjectured that hypotheses spaces suitable for data that is compositional in nature, such as text or images, may be more efficiently represented with deep hierarchical networks than with shallow ones. Despite the vast empirical evidence supporting this belief, theoretical justifications to date are limited. In particular, they do not account for the locality, sharing and pooling constructs of convolutional networks, the most successful deep learning architecture to date. In this work we derive a deep network architecture based on arithmetic circuits that inherently employs locality, sharing and pooling. An equivalence between the networks and hierarchical tensor factorizations is established. We show that a shallow network corresponds to CP (rank-1) decomposition, whereas a deep network corresponds to Hierarchical Tucker decomposition. Using tools from measure theory and matrix algebra, we prove that besides a negligible set, all functions that can be implemented by a deep network of polynomial size, require exponential size in order to be realized (or even approximated) by a shallow network. Since log-space computation transforms our networks into SimNets, the result applies directly to a deep learning architecture demonstrating promising empirical performance. The construction and theory developed in this paper shed new light on various practices and ideas employed by the deep learning community.","Wed, 16 Sep 2015 19:32:54 UTC (767 KB)[v2] Sun, 14 Feb 2016 16:31:49 UTC (412 KB)[v3] Fri, 27 May 2016 19:07:22 UTC (409 KB)"
"1930","Adapting Resilient Propagation for Deep Learning","Alan Mosca, George D. Magoulas","Neural and Evolutionary Computing (cs.NE); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)","The Resilient Propagation (Rprop) algorithm has been very popular for backpropagation training of multilayer feed-forward neural networks in various applications. The standard Rprop however encounters difficulties in the context of deep neural networks as typically happens with gradient-based learning algorithms. In this paper, we propose a modification of the Rprop that combines standard Rprop steps with a special drop out technique. We apply the method for training Deep Neural Networks as standalone components and in ensemble formulations. Results on the MNIST dataset show that the proposed modification alleviates standard Rprop's problems demonstrating improved learning speed and accuracy.","Tue, 15 Sep 2015 15:55:29 UTC (20 KB)[v2] Wed, 16 Sep 2015 11:45:48 UTC (21 KB)"
"1931","Hierarchical Deep Learning Architecture For 10K Objects Classification","Atul Laxman Katole, Krishna Prasad Yellapragada, Amish Kumar Bedi, Sehaj Singh Kalra, Mynepalli Siva Chaitanya","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Evolution of visual object recognition architectures based on Convolutional Neural Networks & Convolutional Deep Belief Networks paradigms has revolutionized artificial Vision Science. These architectures extract & learn the real world hierarchical visual features utilizing supervised & unsupervised learning approaches respectively. Both the approaches yet cannot scale up realistically to provide recognition for a very large number of objects as high as 10K. We propose a two level hierarchical deep learning architecture inspired by divide & conquer principle that decomposes the large scale recognition architecture into root & leaf level model architectures. Each of the root & leaf level models is trained exclusively to provide superior results than possible by any 1-level deep learning architecture prevalent today. The proposed architecture classifies objects in two steps. In the first step the root level model classifies the object in a high level category. In the second step, the leaf level recognition model for the recognized high level category is selected among all the leaf models. This leaf level model is presented with the same input object image which classifies it in a specific category. Also we propose a blend of leaf level models trained with either supervised or unsupervised learning approaches. Unsupervised learning is suitable whenever labelled data is scarce for the specific leaf level models. Currently the training of leaf level models is in progress; where we have trained 25 out of the total 47 leaf level models as of now. We have trained the leaf models with the best case top-5 error rate of 3.2% on the validation data set for the particular leaf models. Also we demonstrate that the validation error of the leaf level models saturates towards the above mentioned accuracy as the number of epochs are increased to more than sixty.","Mon, 7 Sep 2015 08:49:39 UTC (708 KB)"
"1932","Distributed Compressive Sensing: A Deep Learning Approach","Hamid Palangi, Rabab Ward, Li Deng","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)","Various studies that address the compressed sensing problem with Multiple Measurement Vectors (MMVs) have been recently carried. These studies assume the vectors of the different channels to be jointly sparse. In this paper, we relax this condition. Instead we assume that these sparse vectors depend on each other but that this dependency is unknown. We capture this dependency by computing the conditional probability of each entry in each vector being non-zero, given the ""residuals"" of all previous vectors. To estimate these probabilities, we propose the use of the Long Short-Term Memory (LSTM)[1], a data driven model for sequence modelling that is deep in time. To calculate the model parameters, we minimize a cross entropy cost function. To reconstruct the sparse vectors at the decoder, we propose a greedy solver that uses the above model to estimate the conditional probabilities. By performing extensive experiments on two real world datasets, we show that the proposed method significantly outperforms the general MMV solver (the Simultaneous Orthogonal Matching Pursuit (SOMP)) and a number of the model-based Bayesian methods. The proposed method does not add any complexity to the general compressive sensing encoder. The trained model is used just at the decoder. As the proposed method is a data driven method, it is only applicable when training data is available. In many applications however, training data is indeed available, e.g. in recorded images and videos.","Thu, 20 Aug 2015 08:57:29 UTC (1,290 KB)[v2] Mon, 7 Sep 2015 01:15:11 UTC (1,508 KB)[v3] Wed, 11 May 2016 22:18:13 UTC (2,747 KB)"
"1933","A Deep Learning Approach to Structured Signal Recovery","Ali Mousavi, Ankit B. Patel, Richard G. Baraniuk","Machine Learning (cs.LG); Machine Learning (stat.ML)","In this paper, we develop a new framework for sensing and recovering structured signals. In contrast to compressive sensing (CS) systems that employ linear measurements, sparse representations, and computationally complex convex/greedy algorithms, we introduce a deep learning framework that supports both linear and mildly nonlinear measurements, that learns a structured representation from training data, and that efficiently computes a signal estimate. In particular, we apply a stacked denoising autoencoder (SDA), as an unsupervised feature learner. SDA enables us to capture statistical dependencies between the different elements of certain signals and improve signal recovery performance as compared to the CS approach.","Mon, 17 Aug 2015 15:46:09 UTC (2,970 KB)"
"1934","Pose-Guided Human Parsing with Deep Learned Features","Fangting Xia, Jun Zhu, Peng Wang, Alan Yuille","Computer Vision and Pattern Recognition (cs.CV)","Parsing human body into semantic regions is crucial to human-centric analysis. In this paper, we propose a segment-based parsing pipeline that explores human pose information, i.e. the joint location of a human model, which improves the part proposal, accelerates the inference and regularizes the parsing process at the same time. Specifically, we first generate part segment proposals with respect to human joints predicted by a deep model, then part- specific ranking models are trained for segment selection using both pose-based features and deep-learned part potential features. Finally, the best ensemble of the proposed part segments are inferred though an And-Or Graph. We evaluate our approach on the popular Penn-Fudan pedestrian parsing dataset, and demonstrate the effectiveness of using the pose information for each stage of the parsing pipeline. Finally, we show that our approach yields superior part segmentation accuracy comparing to the state-of-the-art methods.","Mon, 17 Aug 2015 00:05:38 UTC (10,198 KB)[v2] Wed, 25 Nov 2015 02:07:11 UTC (6,454 KB)"
"1935","Improving Decision Analytics with Deep Learning: The Case of Financial Disclosures","Stefan Feuerriegel, Ralph Fehrer","Machine Learning (stat.ML); Computation and Language (cs.CL); Machine Learning (cs.LG)","Decision analytics commonly focuses on the text mining of financial news sources in order to provide managerial decision support and to predict stock market movements. Existing predictive frameworks almost exclusively apply traditional machine learning methods, whereas recent research indicates that traditional machine learning methods are not sufficiently capable of extracting suitable features and capturing the non-linear nature of complex tasks. As a remedy, novel deep learning models aim to overcome this issue by extending traditional neural network models with additional hidden layers. Indeed, deep learning has been shown to outperform traditional methods in terms of predictive performance. In this paper, we adapt the novel deep learning technique to financial decision support. In this instance, we aim to predict the direction of stock movements following financial disclosures. As a result, we show how deep learning can outperform the accuracy of random forests as a benchmark for machine learning by 5.66%.","Sun, 9 Aug 2015 07:39:24 UTC (626 KB)[v2] Wed, 4 Jul 2018 09:32:57 UTC (625 KB)"
"1936","Using Deep Learning for Detecting Spoofing Attacks on Speech Signals","Alan Godoy, Flavio Simoes, Jose Augusto Stuchi, Marcus de Assis Angeloni, Mario Uliani, Ricardo Violato","Sound (cs.SD); Computation and Language (cs.CL); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)","It is well known that speaker verification systems are subject to spoofing attacks. The Automatic Speaker Verification Spoofing and Countermeasures Challenge -- ASVSpoof2015 -- provides a standard spoofing database, containing attacks based on synthetic speech, along with a protocol for experiments. This paper describes CPqD's systems submitted to the ASVSpoof2015 Challenge, based on deep neural networks, working both as a classifier and as a feature extraction module for a GMM and a SVM classifier. Results show the validity of this approach, achieving less than 0.5\% EER for known attacks.","Fri, 7 Aug 2015 16:20:52 UTC (218 KB)[v2] Tue, 19 Jan 2016 16:27:49 UTC (349 KB)"
"1937","Applying Deep Learning to Answer Selection: A Study and An Open Task","Minwei Feng, Bing Xiang, Michael R. Glass, Lidan Wang, Bowen Zhou","Computation and Language (cs.CL); Machine Learning (cs.LG)","We apply a general deep learning framework to address the non-factoid question answering task. Our approach does not rely on any linguistic tools and can be applied to different languages or domains. Various architectures are presented and compared. We create and release a QA corpus and setup a new QA task in the insurance domain. Experimental results demonstrate superior performance compared to the baseline methods and various technologies give further improvements. For this highly challenging task, the top-1 accuracy can reach up to 65.3% on a test set, which indicates a great potential for practical use.","Fri, 7 Aug 2015 01:54:04 UTC (18 KB)[v2] Fri, 2 Oct 2015 18:23:16 UTC (22 KB)"
"1938","On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units","Zhibin Liao, Gustavo Carneiro","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Deep feedforward neural networks with piecewise linear activations are currently producing the state-of-the-art results in several public datasets. The combination of deep learning models and piecewise linear activation functions allows for the estimation of exponentially complex functions with the use of a large number of subnetworks specialized in the classification of similar input examples. During the training process, these subnetworks avoid overfitting with an implicit regularization scheme based on the fact that they must share their parameters with other subnetworks. Using this framework, we have made an empirical observation that can improve even more the performance of such models. We notice that these models assume a balanced initial distribution of data points with respect to the domain of the piecewise linear activation function. If that assumption is violated, then the piecewise linear activation units can degenerate into purely linear activation units, which can result in a significant reduction of their capacity to learn complex functions. Furthermore, as the number of model layers increases, this unbalanced initial distribution makes the model ill-conditioned. Therefore, we propose the introduction of batch normalisation units into deep feedforward neural networks with piecewise linear activations, which drives a more balanced use of these activation units, where each region of the activation function is trained with a relatively large proportion of training samples. Also, this batch normalisation promotes the pre-conditioning of very deep learning models. We show that by introducing maxout and batch normalisation units to the network in network model results in a model that produces classification results that are better than or comparable to the current state of the art in CIFAR-10, CIFAR-100, MNIST, and SVHN datasets.","Mon, 3 Aug 2015 07:24:07 UTC (1,405 KB)[v2] Sun, 1 Nov 2015 06:44:10 UTC (2,118 KB)"
"1939","Deep Learning for Single-View Instance Recognition","David Held, Sebastian Thrun, Silvio Savarese","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Robotics (cs.RO)","Deep learning methods have typically been trained on large datasets in which many training examples are available. However, many real-world product datasets have only a small number of images available for each product. We explore the use of deep learning methods for recognizing object instances when we have only a single training example per class. We show that feedforward neural networks outperform state-of-the-art methods for recognizing objects from novel viewpoints even when trained from just a single image per object. To further improve our performance on this task, we propose to take advantage of a supplementary dataset in which we observe a separate set of objects from multiple viewpoints. We introduce a new approach for training deep learning methods for instance recognition with limited training data, in which we use an auxiliary multi-view dataset to train our network to be robust to viewpoint changes. We find that this approach leads to a more robust classifier for recognizing objects from novel viewpoints, outperforming previous state-of-the-art approaches including keypoint-matching, template-based techniques, and sparse coding.","Wed, 29 Jul 2015 20:11:12 UTC (9,006 KB)"
"1940","Detect & Describe: Deep learning of bank stress in the news","Samuel Ronnqvist, Peter Sarlin","Computational Finance (q-fin.CP); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Risk Management (q-fin.RM)","News is a pertinent source of information on financial risks and stress factors, which nevertheless is challenging to harness due to the sparse and unstructured nature of natural text. We propose an approach based on distributional semantics and deep learning with neural networks to model and link text to a scarce set of bank distress events. Through unsupervised training, we learn semantic vector representations of news articles as predictors of distress events. The predictive model that we learn can signal coinciding stress with an aggregated index at bank or European level, while crucially allowing for automatic extraction of text descriptions of the events, based on passages with high stress levels. The method offers insight that models based on other types of data cannot provide, while offering a general means for interpreting this type of semantic-predictive model. We model bank distress with data on 243 events and 6.6M news articles for 101 large European banks.","Sat, 25 Jul 2015 18:47:09 UTC (139 KB)"
"1941","Multimodal Deep Learning for Robust RGB-D Object Recognition","Andreas Eitel, Jost Tobias Springenberg, Luciano Spinello, Martin Riedmiller, Wolfram Burgard","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Robotics (cs.RO)","Robust object recognition is a crucial ingredient of many, if not all, real-world robotics applications. This paper leverages recent progress on Convolutional Neural Networks (CNNs) and proposes a novel RGB-D architecture for object recognition. Our architecture is composed of two separate CNN processing streams - one for each modality - which are consecutively combined with a late fusion network. We focus on learning with imperfect sensor data, a typical problem in real-world robotics tasks. For accurate learning, we introduce a multi-stage training methodology and two crucial ingredients for handling depth data with CNNs. The first, an effective encoding of depth information for CNNs that enables learning without the need for large depth datasets. The second, a data augmentation scheme for robust learning with depth images by corrupting them with realistic noise patterns. We present state-of-the-art results on the RGB-D object dataset and show recognition in challenging RGB-D real-world noisy settings.","Fri, 24 Jul 2015 12:20:19 UTC (1,012 KB)[v2] Tue, 18 Aug 2015 13:04:29 UTC (1,012 KB)"
"1942","Deep Learning and Music Adversaries","Corey Kereliuk, Bob L. Sturm, Jan Larsen","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Sound (cs.SD)","An adversary is essentially an algorithm intent on making a classification system perform in some particular way given an input, e.g., increase the probability of a false negative. Recent work builds adversaries for deep learning systems applied to image object recognition, which exploits the parameters of the system to find the minimal perturbation of the input image such that the network misclassifies it with high confidence. We adapt this approach to construct and deploy an adversary of deep learning systems applied to music content analysis. In our case, however, the input to the systems is magnitude spectral frames, which requires special care in order to produce valid input audio signals from network-derived perturbations. For two different train-test partitionings of two benchmark datasets, and two different deep architectures, we find that this adversary is very effective in defeating the resulting systems. We find the convolutional networks are more robust, however, compared with systems based on a majority vote over individually classified audio frames. Furthermore, we integrate the adversary into the training of new deep systems, but do not find that this improves their resilience against the same adversary.","Thu, 16 Jul 2015 20:24:18 UTC (2,257 KB)"
"1943","Achieving Synergy in Cognitive Behavior of Humanoids via Deep Learning of Dynamic Visuo-Motor-Attentional Coordination","Jungsik Hwang, Minju Jung, Naveen Madapana, Jinhyung Kim, Minkyu Choi, Jun Tani","Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)","The current study examines how adequate coordination among different cognitive processes including visual recognition, attention switching, action preparation and generation can be developed via learning of robots by introducing a novel model, the Visuo-Motor Deep Dynamic Neural Network (VMDNN). The proposed model is built on coupling of a dynamic vision network, a motor generation network, and a higher level network allocated on top of these two. The simulation experiments using the iCub simulator were conducted for cognitive tasks including visual object manipulation responding to human gestures. The results showed that synergetic coordination can be developed via iterative learning through the whole network when spatio-temporal hierarchy and temporal one can be self-organized in the visual pathway and in the motor pathway, respectively, such that the higher level can manipulate them with abstraction.","Thu, 9 Jul 2015 02:10:03 UTC (725 KB)"
"1944","The Potential of the Intel Xeon Phi for Supervised Deep Learning","Andre Viebke, Sabri Pllana","Distributed, Parallel, and Cluster Computing (cs.DC)","Supervised learning of Convolutional Neural Networks (CNNs), also known as supervised Deep Learning, is a computationally demanding process. To find the most suitable parameters of a network for a given application, numerous training sessions are required. Therefore, reducing the training time per session is essential to fully utilize CNNs in practice. While numerous research groups have addressed the training of CNNs using GPUs, so far not much attention has been paid to the Intel Xeon Phi coprocessor. In this paper we investigate empirically and theoretically the potential of the Intel Xeon Phi for supervised learning of CNNs. We design and implement a parallelization scheme named CHAOS that exploits both the thread- and SIMD-parallelism of the coprocessor. Our approach is evaluated on the Intel Xeon Phi 7120P using the MNIST dataset of handwritten digits for various thread counts and CNN architectures. Results show a 103.5x speed up when training our large network for 15 epochs using 244 threads, compared to one thread on the coprocessor. Moreover, we develop a performance model and use it to assess our implementation and answer what-if questions.","Tue, 30 Jun 2015 12:54:09 UTC (1,521 KB)"
"1945","Global Optimality in Tensor Factorization, Deep Learning, and Beyond","Benjamin D. Haeffele, Rene Vidal","Numerical Analysis (cs.NA); Machine Learning (cs.LG); Machine Learning (stat.ML)","Techniques involving factorization are found in a wide range of applications and have enjoyed significant empirical success in many fields. However, common to a vast majority of these problems is the significant disadvantage that the associated optimization problems are typically non-convex due to a multilinear form or other convexity destroying transformation. Here we build on ideas from convex relaxations of matrix factorizations and present a very general framework which allows for the analysis of a wide range of non-convex factorization problems - including matrix factorization, tensor factorization, and deep neural network training formulations. We derive sufficient conditions to guarantee that a local minimum of the non-convex optimization problem is a global minimum and show that if the size of the factorized variables is large enough then from any initialization it is possible to find a global minimizer using a purely local descent algorithm. Our framework also provides a partial theoretical justification for the increasingly common use of Rectified Linear Units (ReLUs) in deep neural networks and offers guidance on deep network architectures and regularization strategies to facilitate efficient optimization.","Wed, 24 Jun 2015 20:08:47 UTC (31 KB)"
"1946","Dual Memory Architectures for Fast Deep Learning of Stream Data via an Online-Incremental-Transfer Strategy","Sang-Woo Lee, Min-Oh Heo, Jiwon Kim, Jeonghee Kim, Byoung-Tak Zhang","Machine Learning (cs.LG)","The online learning of deep neural networks is an interesting problem of machine learning because, for example, major IT companies want to manage the information of the massive data uploaded on the web daily, and this technology can contribute to the next generation of lifelong learning. We aim to train deep models from new data that consists of new classes, distributions, and tasks at minimal computational cost, which we call online deep learning. Unfortunately, deep neural network learning through classical online and incremental methods does not work well in both theory and practice. In this paper, we introduce dual memory architectures for online incremental deep learning. The proposed architecture consists of deep representation learners and fast learnable shallow kernel networks, both of which synergize to track the information of new data. During the training phase, we use various online, incremental ensemble, and transfer learning techniques in order to achieve lower error of the architecture. On the MNIST, CIFAR-10, and ImageNet image recognition tasks, the proposed dual memory architectures performs much better than the classical online and incremental ensemble algorithm, and their accuracies are similar to that of the batch learner.","Mon, 15 Jun 2015 04:44:38 UTC (669 KB)"
"1947","LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop","Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, Jianxiong Xiao","Computer Vision and Pattern Recognition (cs.CV)","While there has been remarkable progress in the performance of visual recognition algorithms, the state-of-the-art models tend to be exceptionally data-hungry. Large labeled training datasets, expensive and tedious to produce, are required to optimize millions of parameters in deep network models. Lagging behind the growth in model capacity, the available datasets are quickly becoming outdated in terms of size and density. To circumvent this bottleneck, we propose to amplify human effort through a partially automated labeling scheme, leveraging deep learning with humans in the loop. Starting from a large set of candidate images for each category, we iteratively sample a subset, ask people to label them, classify the others with a trained model, split the set into positives, negatives, and unlabeled based on the classification confidence, and then iterate with the unlabeled set. To assess the effectiveness of this cascading procedure and enable further progress in visual recognition research, we construct a new image dataset, LSUN. It contains around one million labeled images for each of 10 scene categories and 20 object categories. We experiment with training popular convolutional networks and find that they achieve substantial performance gains when trained on this dataset.","Wed, 10 Jun 2015 15:38:47 UTC (54,558 KB)[v2] Fri, 19 Jun 2015 19:12:05 UTC (54,558 KB)[v3] Sat, 4 Jun 2016 09:51:30 UTC (5,741 KB)"
"1948","Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning","Yarin Gal, Zoubin Ghahramani","Machine Learning (stat.ML); Machine Learning (cs.LG)","Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.","Sat, 6 Jun 2015 12:30:43 UTC (1,715 KB)[v2] Thu, 27 Aug 2015 13:39:15 UTC (2,065 KB)[v3] Sun, 27 Sep 2015 15:15:31 UTC (2,068 KB)[v4] Sat, 31 Oct 2015 19:45:05 UTC (2,069 KB)[v5] Wed, 25 May 2016 18:48:52 UTC (2,384 KB)[v6] Tue, 4 Oct 2016 16:50:26 UTC (2,383 KB)"
"1949","Blocks and Fuel: Frameworks for deep learning","Bart van Merrienboer, Dzmitry Bahdanau, Vincent Dumoulin, Dmitriy Serdyuk, David Warde-Farley, Jan Chorowski, Yoshua Bengio","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","We introduce two Python frameworks to train neural networks on large datasets: Blocks and Fuel. Blocks is based on Theano, a linear algebra compiler with CUDA-support. It facilitates the training of complex neural network models by providing parametrized Theano operations, attaching metadata to Theano's symbolic computational graph, and providing an extensive set of utilities to assist training the networks, e.g. training algorithms, logging, monitoring, visualization, and serialization. Fuel provides a standard format for machine learning datasets. It allows the user to easily iterate over large datasets, performing many types of pre-processing on the fly.","Mon, 1 Jun 2015 19:28:27 UTC (10 KB)"
"1950","Boosting-like Deep Learning For Pedestrian Detection","Lei Wang, Baochang Zhang","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","This paper proposes boosting-like deep learning (BDL) framework for pedestrian detection. Due to overtraining on the limited training samples, overfitting is a major problem of deep learning. We incorporate a boosting-like technique into deep learning to weigh the training samples, and thus prevent overtraining in the iterative process. We theoretically give the details of derivation of our algorithm, and report the experimental results on open data sets showing that BDL achieves a better stable performance than the state-of-the-arts. Our approach achieves 15.85% and 3.81% reduction in the average miss rate compared with ACF and JointDeep on the largest Caltech benchmark dataset, respectively.","Tue, 26 May 2015 03:52:52 UTC (1,213 KB)"
"1951","Deep Learning for Semantic Part Segmentation with High-Level Guidance","S. Tsogkas, I. Kokkinos, G. Papandreou, A. Vedaldi","Computer Vision and Pattern Recognition (cs.CV)","In this work we address the task of segmenting an object into its parts, or semantic part segmentation. We start by adapting a state-of-the-art semantic segmentation system to this task, and show that a combination of a fully-convolutional Deep CNN system coupled with Dense CRF labelling provides excellent results for a broad range of object categories. Still, this approach remains agnostic to high-level constraints between object parts. We introduce such prior information by means of the Restricted Boltzmann Machine, adapted to our task and train our model in an discriminative fashion, as a hidden CRF, demonstrating that prior information can yield additional improvements. We also investigate the performance of our approach ``in the wild'', without information concerning the objects' bounding boxes, using an object detector to guide a multi-scale segmentation scheme. We evaluate the performance of our approach on the Penn-Fudan and LFW datasets for the tasks of pedestrian parsing and face labelling respectively. We show superior performance with respect to competitive methods that have been extensively engineered on these benchmarks, as well as realistic qualitative results on part segmentation, even for occluded or deformable objects. We also provide quantitative and extensive qualitative results on three classes from the PASCAL Parts dataset. Finally, we show that our multi-scale segmentation scheme can boost accuracy, recovering segmentations for finer parts.","Sun, 10 May 2015 21:12:31 UTC (2,368 KB)[v2] Tue, 24 Nov 2015 14:22:43 UTC (2,654 KB)"
"1952","Deep Learning for Medical Image Segmentation","Matthew Lai","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)","This report provides an overview of the current state of the art deep learning architectures and optimisation techniques, and uses the ADNI hippocampus MRI dataset as an example to compare the effectiveness and efficiency of different convolutional architectures on the task of patch-based 3-dimensional hippocampal segmentation, which is important in the diagnosis of Alzheimer's Disease. We found that a slightly unconventional ""stacked 2D"" approach provides much better classification performance than simple 2D patches without requiring significantly more computational power. We also examined the popular ""tri-planar"" approach used in some recently published studies, and found that it provides much better results than the 2D approaches, but also with a moderate increase in computational power requirement. Finally, we evaluated a full 3D convolutional architecture, and found that it provides marginally better results than the tri-planar approach, but at the cost of a very significant increase in computational power requirement.","Fri, 8 May 2015 11:35:53 UTC (271 KB)"
"1953","Deep Learning for Object Saliency Detection and Image Segmentation","Hengyue Pan, Bo Wang, Hui Jiang","Computer Vision and Pattern Recognition (cs.CV)","In this paper, we propose several novel deep learning methods for object saliency detection based on the powerful convolutional neural networks. In our approach, we use a gradient descent method to iteratively modify an input image based on the pixel-wise gradients to reduce a cost function measuring the class-specific objectness of the image. The pixel-wise gradients can be efficiently computed using the back-propagation algorithm. The discrepancy between the modified image and the original one may be used as a saliency map for the image. Moreover, we have further proposed several new training methods to learn saliency-specific convolutional nets for object saliency detection, in order to leverage the available pixel-wise segmentation information. Our methods are extremely computationally efficient (processing 20-40 images per second in one GPU). In this work, we use the computed saliency maps for image segmentation. Experimental results on two benchmark tasks, namely Microsoft COCO and Pascal VOC 2012, have shown that our proposed methods can generate high-quality salience maps, clearly outperforming many existing methods. In particular, our approaches excel in handling many difficult images, which contain complex background, highly-variable salient objects, multiple objects, and/or very small salient objects.","Tue, 5 May 2015 20:03:07 UTC (5,027 KB)"
"1954","Modeling Representation of Videos for Anomaly Detection using Deep Learning: A Review","Yong Shean Chong, Yong Haur Tay","Computer Vision and Pattern Recognition (cs.CV)","This review article surveys the current progresses made toward video-based anomaly detection. We address the most fundamental aspect for video anomaly detection, that is, video feature representation. Much research works have been done in finding the right representation to perform anomaly detection in video streams accurately with an acceptable false alarm rate. However, this is very challenging due to large variations in environment and human movement, and high space-time complexity due to huge dimensionality of video data. The weakly supervised nature of deep learning algorithms can help in learning representations from the video data itself instead of manually designing the right feature for specific scenes. In this paper, we would like to review the existing methods of modeling video representations using deep learning techniques for the task of anomaly detection and action recognition.","Mon, 4 May 2015 05:16:08 UTC (183 KB)"
"1955","Can deep learning help you find the perfect match?","Harm de Vries, Jason Yosinski","Machine Learning (cs.LG)","Is he/she my type or not? The answer to this question depends on the personal preferences of the one asking it. The individual process of obtaining a full answer may generally be difficult and time consuming, but often an approximate answer can be obtained simply by looking at a photo of the potential match. Such approximate answers based on visual cues can be produced in a fraction of a second, a phenomenon that has led to a series of recently successful dating apps in which users rate others positively or negatively using primarily a single photo. In this paper we explore using convolutional networks to create a model of an individual's personal preferences based on rated photos. This introduced task is difficult due to the large number of variations in profile pictures and the noise in attractiveness labels. Toward this task we collect a dataset comprised of $9364$ pictures and binary labels for each. We compare performance of convolutional models trained in three ways: first directly on the collected dataset, second with features transferred from a network trained to predict gender, and third with features transferred from a network trained on ImageNet. Our findings show that ImageNet features transfer best, producing a model that attains $68.1\%$ accuracy on the test set and is moderately successful at predicting matches.","Sat, 2 May 2015 17:20:23 UTC (358 KB)[v2] Sat, 20 Jun 2015 15:41:45 UTC (123 KB)"
"1956","Multi-Object Classification and Unsupervised Scene Understanding Using Deep Learning Features and Latent Tree Probabilistic Models","Tejaswi Nimmagadda, Anima Anandkumar","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","Deep learning has shown state-of-art classification performance on datasets such as ImageNet, which contain a single object in each image. However, multi-object classification is far more challenging. We present a unified framework which leverages the strengths of multiple machine learning methods, viz deep learning, probabilistic models and kernel methods to obtain state-of-art performance on Microsoft COCO, consisting of non-iconic images. We incorporate contextual information in natural images through a conditional latent tree probabilistic model (CLTM), where the object co-occurrences are conditioned on the extracted fc7 features from pre-trained Imagenet CNN as input. We learn the CLTM tree structure using conditional pairwise probabilities for object co-occurrences, estimated through kernel methods, and we learn its node and edge potentials by training a new 3-layer neural network, which takes fc7 features as input. Object classification is carried out via inference on the learnt conditional tree model, and we obtain significant gain in precision-recall and F-measures on MS-COCO, especially for difficult object categories. Moreover, the latent variables in the CLTM capture scene information: the images with top activations for a latent node have common themes such as being a grasslands or a food scene, and on on. In addition, we show that a simple k-means clustering of the inferred latent nodes alone significantly improves scene classification performance on the MIT-Indoor dataset, without the need for any retraining, and without using scene labels during training. Thus, we present a unified framework for multi-object classification and unsupervised scene understanding.","Sat, 2 May 2015 03:23:46 UTC (3,153 KB)"
"1957","Joint Object and Part Segmentation using Deep Learned Potentials","Peng Wang, Xiaohui Shen, Zhe Lin, Scott Cohen, Brian Price, Alan Yuille","Computer Vision and Pattern Recognition (cs.CV)","Segmenting semantic objects from images and parsing them into their respective semantic parts are fundamental steps towards detailed object understanding in computer vision. In this paper, we propose a joint solution that tackles semantic object and part segmentation simultaneously, in which higher object-level context is provided to guide part segmentation, and more detailed part-level localization is utilized to refine object segmentation. Specifically, we first introduce the concept of semantic compositional parts (SCP) in which similar semantic parts are grouped and shared among different objects. A two-channel fully convolutional network (FCN) is then trained to provide the SCP and object potentials at each pixel. At the same time, a compact set of segments can also be obtained from the SCP predictions of the network. Given the potentials and the generated segments, in order to explore long-range context, we finally construct an efficient fully connected conditional random field (FCRF) to jointly predict the final object and part labels. Extensive evaluation on three different datasets shows that our approach can mutually enhance the performance of object and part segmentation, and outperforms the current state-of-the-art on both tasks.","Fri, 1 May 2015 20:35:24 UTC (3,055 KB)"
"1958","A Deep Learning Model for Structured Outputs with High-order Interaction","Hongyu Guo, Xiaodan Zhu, Martin Renqiang Min","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Many real-world applications are associated with structured data, where not only input but also output has interplay. However, typical classification and regression models often lack the ability of simultaneously exploring high-order interaction within input and that within output. In this paper, we present a deep learning model aiming to generate a powerful nonlinear functional mapping from structured input to structured output. More specifically, we propose to integrate high-order hidden units, guided discriminative pretraining, and high-order auto-encoders for this purpose. We evaluate the model with three datasets, and obtain state-of-the-art performances among competitive methods. Our current work focuses on structured output regression, which is a less explored area, although the model can be extended to handle structured label classification.","Wed, 29 Apr 2015 20:58:52 UTC (109 KB)"
"1959","Caffe con Troll: Shallow Ideas to Speed Up Deep Learning","Stefan Hadjis, Firas Abuzaid, Ce Zhang, Christopher Re","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","We present Caffe con Troll (CcT), a fully compatible end-to-end version of the popular framework Caffe with rebuilt internals. We built CcT to examine the performance characteristics of training and deploying general-purpose convolutional neural networks across different hardware architectures. We find that, by employing standard batching optimizations for CPU training, we achieve a 4.5x throughput improvement over Caffe on popular networks like CaffeNet. Moreover, with these improvements, the end-to-end training time for CNNs is directly proportional to the FLOPS delivered by the CPU, which enables us to efficiently train hybrid CPU-GPU systems for CNNs.","Thu, 16 Apr 2015 19:11:08 UTC (256 KB)[v2] Tue, 26 May 2015 20:12:33 UTC (296 KB)"
"1960","Societal, Economic, Ethical and Legal Challenges of the Digital Revolution: From Big Data to Deep Learning, Artificial Intelligence, and Manipulative Technologies","Dirk Helbing","Computers and Society (cs.CY); Physics and Society (physics.soc-ph)","In the wake of the on-going digital revolution, we will see a dramatic transformation of our economy and most of our societal institutions. While the benefits of this transformation can be massive, there are also tremendous risks to our society. After the automation of many production processes and the creation of self-driving vehicles, the automation of society is next. This is moving us to a tipping point and to a crossroads: we must decide between a society in which the actions are determined in a top-down way and then implemented by coercion or manipulative technologies (such as personalized ads and nudging) or a society, in which decisions are taken in a free and participatory way and mutually coordinated. Modern information and communication systems (ICT) enable both, but the latter has economic and strategic benefits. The fundaments of human dignity, autonomous decision-making, and democracies are shaking, but I believe that they need to be vigorously defended, as they are not only core principles of livable societies, but also the basis of greater efficiency and success.","Wed, 15 Apr 2015 00:31:39 UTC (1,572 KB)"
"1961","A Group Theoretic Perspective on Unsupervised Deep Learning","Arnab Paul, Suresh Venkatasubramanian","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","Why does Deep Learning work? What representations does it capture? How do higher-order representations emerge? We study these questions from the perspective of group theory, thereby opening a new approach towards a theory of Deep learning. One factor behind the recent resurgence of the subject is a key algorithmic step called {\em pretraining}: first search for a good generative model for the input samples, and repeat the process one layer at a time. We show deeper implications of this simple principle, by establishing a connection with the interplay of orbits and stabilizers of group actions. Although the neural networks themselves may not form groups, we show the existence of {\em shadow} groups whose elements serve as close approximations. Over the shadow groups, the pre-training step, originally introduced as a mechanism to better initialize a network, becomes equivalent to a search for features with minimal orbits. Intuitively, these features are in a way the {\em simplest}. Which explains why a deep learning network learns simple features first. Next, we show how the same principle, when repeated in the deeper layers, can capture higher order representations, and why representation complexity increases as the layers get deeper.","Wed, 8 Apr 2015 22:39:05 UTC (90 KB)[v2] Wed, 15 Apr 2015 22:03:36 UTC (90 KB)[v3] Tue, 21 Apr 2015 06:05:52 UTC (90 KB)"
"1962","When Face Recognition Meets with Deep Learning: an Evaluation of Convolutional Neural Networks for Face Recognition","Guosheng Hu, Yongxin Yang, Dong Yi, Josef Kittler, William Christmas, Stan Z. Li, Timothy Hospedales","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Deep learning, in particular Convolutional Neural Network (CNN), has achieved promising results in face recognition recently. However, it remains an open question: why CNNs work well and how to design a 'good' architecture. The existing works tend to focus on reporting CNN architectures that work well for face recognition rather than investigate the reason. In this work, we conduct an extensive evaluation of CNN-based face recognition systems (CNN-FRS) on a common ground to make our work easily reproducible. Specifically, we use public database LFW (Labeled Faces in the Wild) to train CNNs, unlike most existing CNNs trained on private databases. We propose three CNN architectures which are the first reported architectures trained using LFW data. This paper quantitatively compares the architectures of CNNs and evaluate the effect of different implementation choices. We identify several useful properties of CNN-FRS. For instance, the dimensionality of the learned features can be significantly reduced without adverse effect on face recognition accuracy. In addition, traditional metric learning method exploiting CNN-learned features is evaluated. Experiments show two crucial factors to good CNN-FRS performance are the fusion of multiple CNNs and metric learning. To make our work reproducible, source code and models will be made publicly available.","Thu, 9 Apr 2015 15:27:49 UTC (238 KB)"
"1963","Pixel-wise Deep Learning for Contour Detection","Jyh-Jing Hwang, Tyng-Luh Liu","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","We address the problem of contour detection via per-pixel classifications of edge point. To facilitate the process, the proposed approach leverages with DenseNet, an efficient implementation of multiscale convolutional neural networks (CNNs), to extract an informative feature vector for each pixel and uses an SVM classifier to accomplish contour detection. In the experiment of contour detection, we look into the effectiveness of combining per-pixel features from different CNN layers and verify their performance on BSDS500.","Wed, 8 Apr 2015 14:44:20 UTC (13 KB)"
"1964","An Empirical Evaluation of Deep Learning on Highway Driving","Brody Huval, Tao Wang, Sameep Tandon, Jeff Kiske, Will Song, Joel Pazhayampallil, Mykhaylo Andriluka, Pranav Rajpurkar, Toki Migimatsu, Royce Cheng-Yue, Fernando Mujica, Adam Coates, Andrew Y. Ng","Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)","Numerous groups have applied a variety of deep learning techniques to computer vision problems in highway perception scenarios. In this paper, we presented a number of empirical evaluations of recent deep learning advances. Computer vision, combined with deep learning, has the potential to bring about a relatively inexpensive, robust solution to autonomous driving. To prepare deep learning for industry uptake and practical applications, neural networks will require large data sets that represent all possible driving environments and scenarios. We collect a large data set of highway data and apply deep learning and computer vision algorithms to problems such as car and lane detection. We show how existing convolutional neural networks (CNNs) can be used to perform lane and vehicle detection while running at frame rates required for a real-time system. Our results lend credence to the hypothesis that deep learning holds promise for autonomous driving.","Tue, 7 Apr 2015 19:41:59 UTC (3,744 KB)[v2] Thu, 9 Apr 2015 19:53:22 UTC (3,744 KB)[v3] Fri, 17 Apr 2015 01:27:14 UTC (3,744 KB)"
"1965","Modeling Spatial-Temporal Clues in a Hybrid Deep Learning Framework for Video Classification","Zuxuan Wu, Xi Wang, Yu-Gang Jiang, Hao Ye, Xiangyang Xue","Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)","Classifying videos according to content semantics is an important problem with a wide range of applications. In this paper, we propose a hybrid deep learning framework for video classification, which is able to model static spatial information, short-term motion, as well as long-term temporal clues in the videos. Specifically, the spatial and the short-term motion features are extracted separately by two Convolutional Neural Networks (CNN). These two types of CNN-based features are then combined in a regularized feature fusion network for classification, which is able to learn and utilize feature relationships for improved performance. In addition, Long Short Term Memory (LSTM) networks are applied on top of the two features to further model longer-term temporal clues. The main contribution of this work is the hybrid learning framework that can model several important aspects of the video data. We also show that (1) combining the spatial and the short-term motion features in the regularized fusion network is better than direct classification and fusion using the CNN with a softmax layer, and (2) the sequence-based LSTM is highly complementary to the traditional classification strategy without considering the temporal frame orders. Extensive experiments are conducted on two popular and challenging benchmarks, the UCF-101 Human Actions and the Columbia Consumer Videos (CCV). On both benchmarks, our framework achieves to-date the best reported performance: $91.3\%$ on the UCF-101 and $83.5\%$ on the CCV.","Tue, 7 Apr 2015 11:53:46 UTC (303 KB)"
"1966","A Probabilistic Theory of Deep Learning","Ankit B. Patel, Tan Nguyen, Richard G. Baraniuk","Machine Learning (stat.ML); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","A grand challenge in machine learning is the development of computational algorithms that match or outperform humans in perceptual inference tasks that are complicated by nuisance variation. For instance, visual object recognition involves the unknown object position, orientation, and scale in object recognition while speech recognition involves the unknown voice pronunciation, pitch, and speed. Recently, a new breed of deep learning algorithms have emerged for high-nuisance inference tasks that routinely yield pattern recognition systems with near- or super-human capabilities. But a fundamental question remains: Why do they work? Intuitions abound, but a coherent framework for understanding, analyzing, and synthesizing deep learning architectures has remained elusive. We answer this question by developing a new probabilistic framework for deep learning based on the Deep Rendering Model: a generative probabilistic model that explicitly captures latent nuisance variation. By relaxing the generative model to a discriminative one, we can recover two of the current leading deep learning systems, deep convolutional neural networks and random decision forests, providing insights into their successes and shortcomings, as well as a principled route to their improvement.","Thu, 2 Apr 2015 18:38:38 UTC (5,300 KB)"
"1967","Implementation of a Practical Distributed Calculation System with Browsers and JavaScript, and Application to Distributed Deep Learning","Ken Miura, Tatsuya Harada","Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Mathematical Software (cs.MS); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","Deep learning can achieve outstanding results in various fields. However, it requires so significant computational power that graphics processing units (GPUs) and/or numerous computers are often required for the practical application. We have developed a new distributed calculation framework called ""Sashimi"" that allows any computer to be used as a distribution node only by accessing a website. We have also developed a new JavaScript neural network framework called ""Sukiyaki"" that uses general purpose GPUs with web browsers. Sukiyaki performs 30 times faster than a conventional JavaScript library for deep convolutional neural networks (deep CNNs) learning. The combination of Sashimi and Sukiyaki, as well as new distribution algorithms, demonstrates the distributed deep learning of deep CNNs only with web browsers on various devices. The libraries that comprise the proposed methods are available under MIT license at this http URL.","Thu, 19 Mar 2015 12:41:29 UTC (5,420 KB)"
"1968","Deep Learning and the Information Bottleneck Principle","Naftali Tishby, Noga Zaslavsky","Machine Learning (cs.LG)","Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.","Mon, 9 Mar 2015 09:39:41 UTC (192 KB)"
"1969","EmoNets: Multimodal deep learning approaches for emotion recognition in video","Samira Ebrahimi Kahou, Xavier Bouthillier, Pascal Lamblin, Caglar Gulcehre, Vincent Michalski, Kishore Konda, Sebastien Jean, Pierre Froumenty, Yann Dauphin, Nicolas Boulanger-Lewandowski, Raul Chandias Ferrari, Mehdi Mirza, David Warde-Farley, Aaron Courville, Pascal Vincent, Roland Memisevic, Christopher Pal, Yoshua Bengio","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)","The task of the emotion recognition in the wild (EmotiW) Challenge is to assign one of seven emotions to short video clips extracted from Hollywood style movies. The videos depict acted-out emotions under realistic conditions with a large degree of variation in attributes such as pose and illumination, making it worthwhile to explore approaches which consider combinations of features from multiple modalities for label assignment. In this paper we present our approach to learning several specialist models using deep learning techniques, each focusing on one modality. Among these are a convolutional neural network, focusing on capturing visual information in detected faces, a deep belief net focusing on the representation of the audio stream, a K-Means based ""bag-of-mouths"" model, which extracts visual features around the mouth region and a relational autoencoder, which addresses spatio-temporal aspects of videos. We explore multiple methods for the combination of cues from these modalities into one common classifier. This achieves a considerably greater accuracy than predictions from our strongest single-modality classifier. Our method was the winning submission in the 2013 EmotiW challenge and achieved a test set accuracy of 47.67% on the 2014 dataset.","Thu, 5 Mar 2015 22:03:26 UTC (573 KB)[v2] Mon, 30 Mar 2015 00:55:02 UTC (574 KB)"
"1970","Toxicity Prediction using Deep Learning","Thomas Unterthiner, Andreas Mayr, Gunter Klambauer, Sepp Hochreiter","Machine Learning (stat.ML); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Biomolecules (q-bio.BM)","Everyday we are exposed to various chemicals via food additives, cleaning and cosmetic products and medicines -- and some of them might be toxic. However testing the toxicity of all existing compounds by biological experiments is neither financially nor logistically feasible. Therefore the government agencies NIH, EPA and FDA launched the Tox21 Data Challenge within the ""Toxicology in the 21st Century"" (Tox21) initiative. The goal of this challenge was to assess the performance of computational methods in predicting the toxicity of chemical compounds. State of the art toxicity prediction methods build upon specifically-designed chemical descriptors developed over decades. Though Deep Learning is new to the field and was never applied to toxicity prediction before, it clearly outperformed all other participating methods. In this application paper we show that deep nets automatically learn features resembling well-established toxicophores. In total, our Deep Learning approach won both of the panel-challenges (nuclear receptors and stress response) as well as the overall Grand Challenge, and thereby sets a new standard in tox prediction.","Wed, 4 Mar 2015 20:18:55 UTC (398 KB)"
"1971","When Are Tree Structures Necessary for Deep Learning of Representations?","Jiwei Li, Minh-Thang Luong, Dan Jurafsky, Eudard Hovy","Artificial Intelligence (cs.AI); Computation and Language (cs.CL)","Recursive neural models, which use syntactic parse trees to recursively generate representations bottom-up, are a popular architecture. But there have not been rigorous evaluations showing for exactly which tasks this syntax-based method is appropriate. In this paper we benchmark {\bf recursive} neural models against sequential {\bf recurrent} neural models (simple recurrent and LSTM models), enforcing apples-to-apples comparison as much as possible. We investigate 4 tasks: (1) sentiment classification at the sentence level and phrase level; (2) matching questions to answer-phrases; (3) discourse parsing; (4) semantic relation extraction (e.g., {\em component-whole} between nouns). Our goal is to understand better when, and why, recursive models can outperform simpler models. We find that recursive models help mainly on tasks (like semantic relation extraction) that require associating headwords across a long distance, particularly on very long sequences. We then introduce a method for allowing recurrent models to achieve similar performance: breaking long sentences into clause-like units at punctuation and processing them separately before combining. Our results thus help understand the limitations of both classes of models, and suggest directions for improving recurrent models.","Sat, 28 Feb 2015 21:39:31 UTC (578 KB)[v2] Fri, 6 Mar 2015 18:16:50 UTC (584 KB)[v3] Fri, 24 Apr 2015 17:14:49 UTC (585 KB)[v4] Thu, 18 Jun 2015 22:07:45 UTC (679 KB)[v5] Tue, 18 Aug 2015 05:59:18 UTC (261 KB)"
"1972","Hands Deep in Deep Learning for Hand Pose Estimation","Markus Oberweger, Paul Wohlhart, Vincent Lepetit","Computer Vision and Pattern Recognition (cs.CV)","We introduce and evaluate several architectures for Convolutional Neural Networks to predict the 3D joint locations of a hand given a depth map. We first show that a prior on the 3D pose can be easily introduced and significantly improves the accuracy and reliability of the predictions. We also show how to use context efficiently to deal with ambiguities between fingers. These two contributions allow us to significantly outperform the state-of-the-art on several challenging benchmarks, both in terms of accuracy and computation times.","Tue, 24 Feb 2015 13:39:55 UTC (1,125 KB)[v2] Fri, 2 Dec 2016 15:41:25 UTC (1,125 KB)"
"1973","Deep Learning for Multi-label Classification","Jesse Read, Fernando Perez-Cruz","Machine Learning (cs.LG); Artificial Intelligence (cs.AI)","In multi-label classification, the main focus has been to develop ways of learning the underlying dependencies between labels, and to take advantage of this at classification time. Developing better feature-space representations has been predominantly employed to reduce complexity, e.g., by eliminating non-helpful feature attributes from the input space prior to (or during) training. This is an important task, since many multi-label methods typically create many different copies or views of the same input data as they transform it, and considerable memory can be saved by taking advantage of redundancy. In this paper, we show that a proper development of the feature space can make labels less interdependent and easier to model and predict at inference time. For this task we use a deep learning approach with restricted Boltzmann machines. We present a deep network that, in an empirical evaluation, outperforms a number of competitive methods from the literature","Wed, 17 Dec 2014 12:06:47 UTC (339 KB)"
"1974","Towards Biologically Plausible Deep Learning","Yoshua Bengio, Dong-Hyun Lee, Jorg Bornschein, Thomas Mesnard, Zhouhan Lin","Machine Learning (cs.LG)","Neuroscientists have long criticised deep learning algorithms as incompatible with current knowledge of neurobiology. We explore more biologically plausible versions of deep representation learning, focusing here mostly on unsupervised learning but developing a learning mechanism that could account for supervised, unsupervised and reinforcement learning. The starting point is that the basic learning rule believed to govern synaptic weight updates (Spike-Timing-Dependent Plasticity) arises out of a simple update rule that makes a lot of sense from a machine learning point of view and can be interpreted as gradient descent on some objective function so long as the neuronal dynamics push firing rates towards better values of the objective function (be it supervised, unsupervised, or reward-driven). The second main idea is that this corresponds to a form of the variational EM algorithm, i.e., with approximate rather than exact posteriors, implemented by neural dynamics. Another contribution of this paper is that the gradients required for updating the hidden states in the above variational interpretation can be estimated using an approximation that only requires propagating activations forward and backward, with pairs of layers learning to form a denoising auto-encoder. Finally, we extend the theory about the probabilistic interpretation of auto-encoders to justify improved sampling schemes based on the generative interpretation of denoising auto-encoders, and we validate all these ideas on generative learning tasks.","Sat, 14 Feb 2015 01:11:25 UTC (264 KB)[v2] Wed, 25 Nov 2015 04:13:44 UTC (264 KB)[v3] Tue, 9 Aug 2016 01:57:09 UTC (293 KB)"
"1975","Applying deep learning techniques on medical corpora from the World Wide Web: a prototypical system and evaluation","Jose Antonio Minarro-Gimenez, Oscar Marin-Alonso, Matthias Samwald","Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","BACKGROUND: The amount of biomedical literature is rapidly growing and it is becoming increasingly difficult to keep manually curated knowledge bases and ontologies up-to-date. In this study we applied the word2vec deep learning toolkit to medical corpora to test its potential for identifying relationships from unstructured text. We evaluated the efficiency of word2vec in identifying properties of pharmaceuticals based on mid-sized, unstructured medical text corpora available on the web. Properties included relationships to diseases ('may treat') or physiological processes ('has physiological effect'). We compared the relationships identified by word2vec with manually curated information from the National Drug File - Reference Terminology (NDF-RT) ontology as a gold standard. RESULTS: Our results revealed a maximum accuracy of 49.28% which suggests a limited ability of word2vec to capture linguistic regularities on the collected medical corpora compared with other published results. We were able to document the influence of different parameter settings on result accuracy and found and unexpected trade-off between ranking quality and accuracy. Pre-processing corpora to reduce syntactic variability proved to be a good strategy for increasing the utility of the trained vector models. CONCLUSIONS: Word2vec is a very efficient implementation for computing vector representations and for its ability to identify relationships in textual data without any prior domain knowledge. We found that the ranking and retrieved results generated by word2vec were not of sufficient quality for automatic population of knowledge bases and ontologies, but could serve as a starting point for further manual curation.","Thu, 12 Feb 2015 14:44:15 UTC (1,025 KB)"
"1976","Large-Scale Deep Learning on the YFCC100M Dataset","Karl Ni, Roger Pearce, Kofi Boakye, Brian Van Essen, Damian Borth, Barry Chen, Eric Wang","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)","We present a work-in-progress snapshot of learning with a 15 billion parameter deep learning network on HPC architectures applied to the largest publicly available natural image and video dataset released to-date. Recent advancements in unsupervised deep neural networks suggest that scaling up such networks in both model and training dataset size can yield significant improvements in the learning of concepts at the highest layers. We train our three-layer deep neural network on the Yahoo! Flickr Creative Commons 100M dataset. The dataset comprises approximately 99.2 million images and 800,000 user-created videos from Yahoo's Flickr image and video sharing platform. Training of our network takes eight days on 98 GPU nodes at the High Performance Computing Center at Lawrence Livermore National Laboratory. Encouraging preliminary results and future research directions are presented and discussed.","Wed, 11 Feb 2015 19:24:36 UTC (2,202 KB)"
"1977","Using Distance Estimation and Deep Learning to Simplify Calibration in Food Calorie Measurement","Pallavi Kuhad, Abdulsalam Yassine, Shervin Shirmohammadi","Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)","High calorie intake in the human body on the one hand, has proved harmful in numerous occasions leading to several diseases and on the other hand, a standard amount of calorie intake has been deemed essential by dieticians to maintain the right balance of calorie content in human body. As such, researchers have proposed a variety of automatic tools and systems to assist users measure their calorie in-take. In this paper, we consider the category of those tools that use image processing to recognize the food, and we propose a method for fully automatic and user-friendly calibration of the dimension of the food portion sizes, which is needed in order to measure food portion weight and its ensuing amount of calories. Experimental results show that our method, which uses deep learning, mobile cloud computing, distance estimation and size calibration inside a mobile device, leads to an accuracy improvement to 95% on average compared to previous work","Wed, 11 Feb 2015 13:27:01 UTC (1,044 KB)[v2] Mon, 23 Mar 2015 11:45:11 UTC (0 KB)"
"1978","Deep Learning with Limited Numerical Precision","Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, Pritish Narayanan","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","Training of large-scale deep neural networks is often constrained by the available computational resources. We study the effect of limited precision data representation and computation on neural network training. Within the context of low-precision fixed-point computations, we observe the rounding scheme to play a crucial role in determining the network's behavior during training. Our results show that deep networks can be trained using only 16-bit wide fixed-point number representation when using stochastic rounding, and incur little to no degradation in the classification accuracy. We also demonstrate an energy-efficient hardware accelerator that implements low-precision fixed-point arithmetic with stochastic rounding.","Mon, 9 Feb 2015 16:37:29 UTC (400 KB)"
"1979","Deep learning of fMRI big data: a novel approach to subject-transfer decoding","Sotetsu Koyamada, Yumi Shikauchi, Ken Nakae, Masanori Koyama, Shin Ishii","Machine Learning (stat.ML); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)","As a technology to read brain states from measurable brain activities, brain decoding are widely applied in industries and medical sciences. In spite of high demands in these applications for a universal decoder that can be applied to all individuals simultaneously, large variation in brain activities across individuals has limited the scope of many studies to the development of individual-specific decoders. In this study, we used deep neural network (DNN), a nonlinear hierarchical model, to construct a subject-transfer decoder. Our decoder is the first successful DNN-based subject-transfer decoder. When applied to a large-scale functional magnetic resonance imaging (fMRI) database, our DNN-based decoder achieved higher decoding accuracy than other baseline methods, including support vector machine (SVM). In order to analyze the knowledge acquired by this decoder, we applied principal sensitivity analysis (PSA) to the decoder and visualized the discriminative features that are common to all subjects in the dataset. Our PSA successfully visualized the subject-independent features contributing to the subject-transferability of the trained decoder.","Sat, 31 Jan 2015 11:58:26 UTC (19,267 KB)"
"1980","maxDNN: An Efficient Convolution Kernel for Deep Learning with Maxwell GPUs","Andrew Lavin","Neural and Evolutionary Computing (cs.NE); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)","This paper describes maxDNN, a computationally efficient convolution kernel for deep learning with the NVIDIA Maxwell GPU. maxDNN reaches 96.3% computational efficiency on typical deep learning network architectures. The design combines ideas from cuda-convnet2 with the Maxas SGEMM assembly code. We only address forward propagation (FPROP) operation of the network, but we believe that the same techniques used here will be effective for backward propagation (BPROP) as well.","Tue, 27 Jan 2015 01:19:12 UTC (24 KB)[v2] Wed, 28 Jan 2015 01:16:33 UTC (24 KB)[v3] Fri, 30 Jan 2015 23:50:49 UTC (24 KB)"
"1981","Statistical-mechanical analysis of pre-training and fine tuning in deep learning","Masayuki Ohzeki","Machine Learning (stat.ML); Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)","In this paper, we present a statistical-mechanical analysis of deep learning. We elucidate some of the essential components of deep learning---pre-training by unsupervised learning and fine tuning by supervised learning. We formulate the extraction of features from the training data as a margin criterion in a high-dimensional feature-vector space. The self-organized classifier is then supplied with small amounts of labelled data, as in deep learning. Although we employ a simple single-layer perceptron model, rather than directly analyzing a multi-layer neural network, we find a nontrivial phase transition that is dependent on the number of unlabelled data in the generalization error of the resultant classifier. In this sense, we evaluate the efficacy of the unsupervised learning component of deep learning. The analysis is performed by the replica method, which is a sophisticated tool in statistical mechanics. We validate our result in the manner of deep learning, using a simple iterative algorithm to learn the weight vector on the basis of belief propagation.","Mon, 19 Jan 2015 07:24:21 UTC (366 KB)"
"1982","Deep Learning with Nonparametric Clustering","Gang Chen","Machine Learning (cs.LG)","Clustering is an essential problem in machine learning and data mining. One vital factor that impacts clustering performance is how to learn or design the data representation (or features). Fortunately, recent advances in deep learning can learn unsupervised features effectively, and have yielded state of the art performance in many classification problems, such as character recognition, object recognition and document categorization. However, little attention has been paid to the potential of deep learning for unsupervised clustering problems. In this paper, we propose a deep belief network with nonparametric clustering. As an unsupervised method, our model first leverages the advantages of deep learning for feature representation and dimension reduction. Then, it performs nonparametric clustering under a maximum margin framework -- a discriminative clustering model and can be trained online efficiently in the code space. Lastly model parameters are refined in the deep belief network. Thus, this model can learn features for clustering and infer model complexity in an unified framework. The experimental results show the advantage of our approach over competitive baselines.","Tue, 13 Jan 2015 17:26:26 UTC (274 KB)"
"1983","Joint Deep Learning for Car Detection","Seyedshams Feyzabadi","Computer Vision and Pattern Recognition (cs.CV)","Traditional object recognition approaches apply feature extraction, part deformation handling, occlusion handling and classification sequentially while they are independent from each other. Ouyang and Wang proposed a model for jointly learning of all of the mentioned processes using one deep neural network. We utilized, and manipulated their toolbox in order to apply it in car detection scenarios where it had not been tested. Creating a single deep architecture from these components, improves the interaction between them and can enhance the performance of the whole system. We believe that the approach can be used as a general purpose object detection toolbox. We tested the algorithm on UIUC car dataset, and achieved an outstanding result. The accuracy of our method was 97 % while the previously reported results showed an accuracy of up to 91 %. We strongly believe that having an experiment on a larger dataset can show the advantage of using deep models over shallow ones.","Thu, 25 Dec 2014 18:55:49 UTC (592 KB)[v2] Thu, 14 Jul 2016 17:57:31 UTC (587 KB)"
"1984","Deep learning with Elastic Averaging SGD","Sixin Zhang, Anna Choromanska, Yann LeCun","Machine Learning (cs.LG); Machine Learning (stat.ML)","We study the problem of stochastic optimization for deep learning in the parallel computing environment under communication constraints. A new algorithm is proposed in this setting where the communication and coordination of work among concurrent processes (local workers), is based on an elastic force which links the parameters they compute with a center variable stored by the parameter server (master). The algorithm enables the local workers to perform more exploration, i.e. the algorithm allows the local variables to fluctuate further from the center variable by reducing the amount of communication between local workers and the master. We empirically demonstrate that in the deep learning setting, due to the existence of many local optima, allowing more exploration can lead to the improved performance. We propose synchronous and asynchronous variants of the new algorithm. We provide the stability analysis of the asynchronous variant in the round-robin scheme and compare it with the more common parallelized method ADMM. We show that the stability of EASGD is guaranteed when a simple stability condition is satisfied, which is not the case for ADMM. We additionally propose the momentum-based version of our algorithm that can be applied in both synchronous and asynchronous settings. Asynchronous variant of the algorithm is applied to train convolutional neural networks for image classification on the CIFAR and ImageNet datasets. Experiments demonstrate that the new algorithm accelerates the training of deep architectures compared to DOWNPOUR and other common baseline approaches and furthermore is very communication efficient.","Sat, 20 Dec 2014 13:22:23 UTC (2,167 KB)[v2] Mon, 29 Dec 2014 20:50:02 UTC (2,167 KB)[v3] Mon, 5 Jan 2015 01:18:40 UTC (4,782 KB)[v4] Wed, 25 Feb 2015 19:00:29 UTC (1,123 KB)[v5] Wed, 29 Apr 2015 11:56:24 UTC (1,123 KB)[v6] Sat, 6 Jun 2015 00:20:58 UTC (1,289 KB)[v7] Sat, 8 Aug 2015 02:52:48 UTC (1,290 KB)[v8] Sun, 25 Oct 2015 12:12:52 UTC (3,648 KB)"
"1985","Why does Deep Learning work? - A perspective from Group Theory","Arnab Paul, Suresh Venkatasubramanian","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","Why does Deep Learning work? What representations does it capture? How do higher-order representations emerge? We study these questions from the perspective of group theory, thereby opening a new approach towards a theory of Deep learning. One factor behind the recent resurgence of the subject is a key algorithmic step called pre-training: first search for a good generative model for the input samples, and repeat the process one layer at a time. We show deeper implications of this simple principle, by establishing a connection with the interplay of orbits and stabilizers of group actions. Although the neural networks themselves may not form groups, we show the existence of {\em shadow} groups whose elements serve as close approximations. Over the shadow groups, the pre-training step, originally introduced as a mechanism to better initialize a network, becomes equivalent to a search for features with minimal orbits. Intuitively, these features are in a way the {\em simplest}. Which explains why a deep learning network learns simple features first. Next, we show how the same principle, when repeated in the deeper layers, can capture higher order representations, and why representation complexity increases as the layers get deeper.","Sat, 20 Dec 2014 07:28:46 UTC (1,125 KB)[v2] Wed, 24 Dec 2014 02:22:01 UTC (1,123 KB)[v3] Sat, 28 Feb 2015 07:19:35 UTC (1,127 KB)"
"1986","In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning","Behnam Neyshabur, Ryota Tomioka, Nathan Srebro","Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)","We present experiments demonstrating that some other form of capacity control, different from network size, plays a central role in learning multilayer feed-forward networks. We argue, partially through analogy to matrix factorization, that this is an inductive bias that can help shed light on deep learning.","Sat, 20 Dec 2014 06:52:25 UTC (49 KB)[v2] Tue, 3 Mar 2015 21:00:09 UTC (46 KB)[v3] Fri, 6 Mar 2015 18:51:37 UTC (42 KB)[v4] Thu, 16 Apr 2015 18:48:31 UTC (43 KB)"
"1987","Purine: A bi-graph based deep learning framework","Min Lin, Shuo Li, Xuan Luo, Shuicheng Yan","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG)","In this paper, we introduce a novel deep learning framework, termed Purine. In Purine, a deep network is expressed as a bipartite graph (bi-graph), which is composed of interconnected operators and data tensors. With the bi-graph abstraction, networks are easily solvable with event-driven task dispatcher. We then demonstrate that different parallelism schemes over GPUs and/or CPUs on single or multiple PCs can be universally implemented by graph composition. This eases researchers from coding for various parallelization schemes, and the same dispatcher can be used for solving variant graphs. Scheduled by the task dispatcher, memory transfers are fully overlapped with other computations, which greatly reduce the communication overhead and help us achieve approximate linear acceleration.","Fri, 19 Dec 2014 08:20:10 UTC (942 KB)[v2] Mon, 22 Dec 2014 03:18:46 UTC (943 KB)[v3] Tue, 20 Jan 2015 02:17:39 UTC (943 KB)[v4] Mon, 16 Mar 2015 16:13:46 UTC (943 KB)[v5] Thu, 16 Apr 2015 13:09:33 UTC (943 KB)"
"1988","Quantum Deep Learning","Nathan Wiebe, Ashish Kapoor, Krysta M. Svore","Quantum Physics (quant-ph); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","In recent years, deep learning has had a profound impact on machine learning and artificial intelligence. At the same time, algorithms for quantum computers have been shown to efficiently solve some problems that are intractable on conventional, classical computers. We show that quantum computing not only reduces the time required to train a deep restricted Boltzmann machine, but also provides a richer and more comprehensive framework for deep learning than classical computing and leads to significant improvements in the optimization of the underlying objective function. Our quantum methods also permit efficient training of full Boltzmann machines and multi-layer, fully connected models and do not have well known classical counterparts.","Wed, 10 Dec 2014 23:05:16 UTC (411 KB)[v2] Fri, 22 May 2015 00:20:28 UTC (192 KB)"
"1989","Sequential Labeling with online Deep Learning","Gang Chen, Ran Xu, Sargur Srihari","Machine Learning (cs.LG)","Deep learning has attracted great attention recently and yielded the state of the art performance in dimension reduction and classification problems. However, it cannot effectively handle the structured output prediction, e.g. sequential labeling. In this paper, we propose a deep learning structure, which can learn discriminative features for sequential labeling problems. More specifically, we add the inter-relationship between labels in our deep learning structure, in order to incorporate the context information from the sequential data. Thus, our model is more powerful than linear Conditional Random Fields (CRFs) because the objective function learns latent non-linear features so that target labeling can be better predicted. We pretrain the deep structure with stacked restricted Boltzmann machines (RBMs) for feature learning and optimize our objective function with online learning algorithm, a mixture of perceptron training and stochastic gradient descent. We test our model on different challenge tasks, and show that our model outperforms significantly over the completive baselines.","Wed, 10 Dec 2014 18:16:12 UTC (314 KB)[v2] Thu, 12 Mar 2015 20:38:28 UTC (315 KB)[v3] Mon, 4 May 2015 01:41:46 UTC (315 KB)"
"1990","Multimodal Transfer Deep Learning with Applications in Audio-Visual Recognition","Seungwhan Moon, Suyoun Kim, Haohan Wang","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG)","We propose a transfer deep learning (TDL) framework that can transfer the knowledge obtained from a single-modal neural network to a network with a different modality. Specifically, we show that we can leverage speech data to fine-tune the network trained for video recognition, given an initial set of audio-video parallel dataset within the same semantics. Our approach first learns the analogy-preserving embeddings between the abstract representations learned from intermediate layers of each network, allowing for semantics-level transfer between the source and target modalities. We then apply our neural network operation that fine-tunes the target network with the additional knowledge transferred from the source network, while keeping the topology of the target network unchanged. While we present an audio-visual recognition task as an application of our approach, our framework is flexible and thus can work with any multimodal dataset, or with any already-existing deep networks that share the common underlying semantics. In this work in progress report, we aim to provide comprehensive results of different configurations of the proposed approach on two widely used audio-visual datasets, and we discuss potential applications of the proposed approach.","Tue, 9 Dec 2014 21:12:19 UTC (554 KB)[v2] Thu, 18 Feb 2016 19:56:41 UTC (248 KB)"
"1991","Deep Learning for Answer Sentence Selection","Lei Yu, Karl Moritz Hermann, Phil Blunsom, Stephen Pulman","Computation and Language (cs.CL)","Answer sentence selection is the task of identifying sentences that contain the answer to a given question. This is an important problem in its own right as well as in the larger context of open domain question answering. We propose a novel approach to solving this task via means of distributed representations, and learn to match questions with answers by considering their semantic encoding. This contrasts prior work on this task, which typically relies on classifiers with large numbers of hand-crafted syntactic and semantic features and various external resources. Our approach does not require any feature engineering nor does it involve specialist linguistic data, making this model easily applicable to a wide range of domains and languages. Experimental results on a standard benchmark dataset from TREC demonstrate that---despite its simplicity---our model matches state of the art performance on the answer sentence selection task.","Thu, 4 Dec 2014 11:53:02 UTC (64 KB)"
"1992","Pedestrian Detection aided by Deep Learning Semantic Tasks","Yonglong Tian, Ping Luo, Xiaogang Wang, Xiaoou Tang","Computer Vision and Pattern Recognition (cs.CV)","Deep learning methods have achieved great success in pedestrian detection, owing to its ability to learn features from raw pixels. However, they mainly capture middle-level representations, such as pose of pedestrian, but confuse positive with hard negative samples, which have large ambiguity, e.g. the shape and appearance of `tree trunk' or `wire pole' are similar to pedestrian in certain viewpoint. This ambiguity can be distinguished by high-level representation. To this end, this work jointly optimizes pedestrian detection with semantic tasks, including pedestrian attributes (e.g. `carrying backpack') and scene attributes (e.g. `road', `tree', and `horizontal'). Rather than expensively annotating scene attributes, we transfer attributes information from existing scene segmentation datasets to the pedestrian dataset, by proposing a novel deep model to learn high-level features from multiple tasks and multiple data sources. Since distinct tasks have distinct convergence rates and data from different datasets have different distributions, a multi-task objective function is carefully designed to coordinate tasks and reduce discrepancies among datasets. The importance coefficients of tasks and network parameters in this objective function can be iteratively estimated. Extensive evaluations show that the proposed approach outperforms the state-of-the-art on the challenging Caltech and ETH datasets, where it reduces the miss rates of previous deep models by 17 and 5.5 percent, respectively.","Sat, 29 Nov 2014 04:34:23 UTC (2,897 KB)"
"1993","Deep Learning Face Attributes in the Wild","Ziwei Liu, Ping Luo, Xiaogang Wang, Xiaoou Tang","Computer Vision and Pattern Recognition (cs.CV)","Predicting face attributes in the wild is challenging due to complex face variations. We propose a novel deep learning framework for attribute prediction in the wild. It cascades two CNNs, LNet and ANet, which are fine-tuned jointly with attribute tags, but pre-trained differently. LNet is pre-trained by massive general object categories for face localization, while ANet is pre-trained by massive face identities for attribute prediction. This framework not only outperforms the state-of-the-art with a large margin, but also reveals valuable facts on learning face representation. (1) It shows how the performances of face localization (LNet) and attribute prediction (ANet) can be improved by different pre-training strategies. (2) It reveals that although the filters of LNet are fine-tuned only with image-level attribute tags, their response maps over entire images have strong indication of face locations. This fact enables training LNet for face localization with only image-level annotations, but without face bounding boxes or landmarks, which are required by all attribute recognition works. (3) It also demonstrates that the high-level hidden neurons of ANet automatically discover semantic concepts after pre-training with massive face identities, and such concepts are significantly enriched after fine-tuning with attribute tags. Each attribute can be well explained with a sparse linear combination of these concepts.","Fri, 28 Nov 2014 07:13:54 UTC (4,601 KB)[v2] Thu, 10 Sep 2015 06:05:30 UTC (8,409 KB)[v3] Thu, 24 Sep 2015 13:52:26 UTC (8,409 KB)"
"1994","Investigating the Role of Prior Disambiguation in Deep-learning Compositional Models of Meaning","Jianpeng Cheng, Dimitri Kartsaklis, Edward Grefenstette","Computation and Language (cs.CL); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","This paper aims to explore the effect of prior disambiguation on neural network- based compositional models, with the hope that better semantic representations for text compounds can be produced. We disambiguate the input word vectors before they are fed into a compositional deep net. A series of evaluations shows the positive effect of prior disambiguation for such deep models.","Sat, 15 Nov 2014 06:32:49 UTC (13 KB)"
"1995","SelfieBoost: A Boosting Algorithm for Deep Learning","Shai Shalev-Shwartz","Machine Learning (stat.ML); Machine Learning (cs.LG)","We describe and analyze a new boosting algorithm for deep learning called SelfieBoost. Unlike other boosting algorithms, like AdaBoost, which construct ensembles of classifiers, SelfieBoost boosts the accuracy of a single network. We prove a $\log(1/ュ)$ convergence rate for SelfieBoost under some ""SGD success"" assumption which seems to hold in practice.","Thu, 13 Nov 2014 03:34:32 UTC (9 KB)[v2] Sat, 8 Apr 2017 06:06:38 UTC (9 KB)"
"1996","Non-parametric Bayesian Learning with Deep Learning Structure and Its Applications in Wireless Networks","Erte Pan, Zhu Han","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Networking and Internet Architecture (cs.NI); Machine Learning (stat.ML)","In this paper, we present an infinite hierarchical non-parametric Bayesian model to extract the hidden factors over observed data, where the number of hidden factors for each layer is unknown and can be potentially infinite. Moreover, the number of layers can also be infinite. We construct the model structure that allows continuous values for the hidden factors and weights, which makes the model suitable for various applications. We use the Metropolis-Hastings method to infer the model structure. Then the performance of the algorithm is evaluated by the experiments. Simulation results show that the model fits the underlying structure of simulated data.","Thu, 16 Oct 2014 22:29:12 UTC (104 KB)[v2] Thu, 23 Oct 2014 21:55:30 UTC (116 KB)"
"1997","An exact mapping between the Variational Renormalization Group and Deep Learning","Pankaj Mehta, David J. Schwab","Machine Learning (stat.ML); Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Deep learning is a broad set of techniques that uses multiple layers of representation to automatically learn relevant features directly from structured data. Recently, such techniques have yielded record-breaking results on a diverse set of difficult machine learning tasks in computer vision, speech recognition, and natural language processing. Despite the enormous success of deep learning, relatively little is understood theoretically about why these techniques are so successful at feature learning and compression. Here, we show that deep learning is intimately related to one of the most important and successful techniques in theoretical physics, the renormalization group (RG). RG is an iterative coarse-graining scheme that allows for the extraction of relevant features (i.e. operators) as a physical system is examined at different length scales. We construct an exact mapping from the variational renormalization group, first introduced by Kadanoff, and deep learning architectures based on Restricted Boltzmann Machines (RBMs). We illustrate these ideas using the nearest-neighbor Ising Model in one and two-dimensions. Our results suggests that deep learning algorithms may be employing a generalized RG-like scheme to learn relevant features from data.","Tue, 14 Oct 2014 20:00:09 UTC (797 KB)"
"1998","Enhanced Higgs to $ン^+ン^-$ Searches with Deep Learning","Pierre Baldi, Peter Sadowski, Daniel Whiteson","High Energy Physics - Phenomenology (hep-ph); Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)","The Higgs boson is thought to provide the interaction that imparts mass to the fundamental fermions, but while measurements at the Large Hadron Collider (LHC) are consistent with this hypothesis, current analysis techniques lack the statistical power to cross the traditional 5$ヲ$ significance barrier without more data. \emph{Deep learning} techniques have the potential to increase the statistical power of this analysis by \emph{automatically} learning complex, high-level data representations. In this work, deep neural networks are used to detect the decay of the Higgs to a pair of tau leptons. A Bayesian optimization algorithm is used to tune the network architecture and training algorithm hyperparameters, resulting in a deep network of eight non-linear processing layers that improves upon the performance of shallow classifiers even without the use of features specifically engineered by physicists for this application. The improvement in discovery significance is equivalent to an increase in the accumulated dataset of 25\%.","Mon, 13 Oct 2014 20:00:03 UTC (98 KB)"
"1999","cuDNN: Efficient Primitives for Deep Learning","Sharan Chetlur, Cliff Woolley, Philippe Vandermersch, Jonathan Cohen, John Tran, Bryan Catanzaro, Evan Shelhamer","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG); Mathematical Software (cs.MS)","We present a library of efficient implementations of deep learning primitives. Deep learning workloads are computationally intensive, and optimizing their kernels is difficult and time-consuming. As parallel architectures evolve, kernels must be reoptimized, which makes maintaining codebases difficult over time. Similar issues have long been addressed in the HPC community by libraries such as the Basic Linear Algebra Subroutines (BLAS). However, there is no analogous library for deep learning. Without such a library, researchers implementing deep learning workloads on parallel processors must create and optimize their own implementations of the main computational kernels, and this work must be repeated as new parallel processors emerge. To address this problem, we have created a library similar in intent to BLAS, with optimized routines for deep learning workloads. Our implementation contains routines for GPUs, although similarly to the BLAS library, these routines could be implemented for other platforms. The library is easy to integrate into existing frameworks, and provides optimized performance and memory usage. For example, integrating cuDNN into Caffe, a popular framework for convolutional networks, improves performance by 36% on a standard model while also reducing memory consumption.","Fri, 3 Oct 2014 06:16:43 UTC (193 KB)[v2] Thu, 9 Oct 2014 06:00:21 UTC (193 KB)[v3] Thu, 18 Dec 2014 01:13:16 UTC (100 KB)"
"2000","A Deep Learning Approach to Data-driven Parameterizations for Statistical Parametric Speech Synthesis","Prasanna Kumar Muthukumar, Alan W. Black","Computation and Language (cs.CL); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Nearly all Statistical Parametric Speech Synthesizers today use Mel Cepstral coefficients as the vocal tract parameterization of the speech signal. Mel Cepstral coefficients were never intended to work in a parametric speech synthesis framework, but as yet, there has been little success in creating a better parameterization that is more suited to synthesis. In this paper, we use deep learning algorithms to investigate a data-driven parameterization technique that is designed for the specific requirements of synthesis. We create an invertible, low-dimensional, noise-robust encoding of the Mel Log Spectrum by training a tapered Stacked Denoising Autoencoder (SDA). This SDA is then unwrapped and used as the initialization for a Multi-Layer Perceptron (MLP). The MLP is fine-tuned by training it to reconstruct the input at the output layer. This MLP is then split down the middle to form encoding and decoding networks. These networks produce a parameterization of the Mel Log Spectrum that is intended to better fulfill the requirements of synthesis. Results are reported for experiments conducted using this resulting parameterization with the ClusterGen speech synthesizer.","Tue, 30 Sep 2014 14:20:29 UTC (72 KB)"
"2001","MoDeep: A Deep Learning Framework Using Motion Features for Human Pose Estimation","Arjun Jain, Jonathan Tompson, Yann LeCun, Christoph Bregler","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","In this work, we propose a novel and efficient method for articulated human pose estimation in videos using a convolutional network architecture, which incorporates both color and motion features. We propose a new human body pose dataset, FLIC-motion, that extends the FLIC dataset with additional motion features. We apply our architecture to this dataset and report significantly better performance than current state-of-the-art pose detection systems.","Sun, 28 Sep 2014 21:32:15 UTC (7,934 KB)"
"2002","Deep Learning Representation using Autoencoder for 3D Shape Retrieval","Zhuotun Zhu, Xinggang Wang, Song Bai, Cong Yao, Xiang Bai","Computer Vision and Pattern Recognition (cs.CV)","We study the problem of how to build a deep learning representation for 3D shape. Deep learning has shown to be very effective in variety of visual applications, such as image classification and object detection. However, it has not been successfully applied to 3D shape recognition. This is because 3D shape has complex structure in 3D space and there are limited number of 3D shapes for feature learning. To address these problems, we project 3D shapes into 2D space and use autoencoder for feature learning on the 2D images. High accuracy 3D shape retrieval performance is obtained by aggregating the features learned on 2D images. In addition, we show the proposed deep learning feature is complementary to conventional local image descriptors. By combing the global deep learning representation and the local descriptor representation, our method can obtain the state-of-the-art performance on 3D shape retrieval benchmarks.","Thu, 25 Sep 2014 06:27:28 UTC (906 KB)"
"2003","Building Program Vector Representations for Deep Learning","Lili Mou, Ge Li, Yuxuan Liu, Hao Peng, Zhi Jin, Yan Xu, Lu Zhang","Software Engineering (cs.SE); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Deep learning has made significant breakthroughs in various fields of artificial intelligence. Advantages of deep learning include the ability to capture highly complicated features, weak involvement of human engineering, etc. However, it is still virtually impossible to use deep learning to analyze programs since deep architectures cannot be trained effectively with pure back propagation. In this pioneering paper, we propose the ""coding criterion"" to build program vector representations, which are the premise of deep learning for program analysis. Our representation learning approach directly makes deep learning a reality in this new field. We evaluate the learned vector representations both qualitatively and quantitatively. We conclude, based on the experiments, the coding criterion is successful in building program representations. To evaluate whether deep learning is beneficial for program analysis, we feed the representations to deep neural networks, and achieve higher accuracy in the program classification task than ""shallow"" methods, such as logistic regression and the support vector machine. This result confirms the feasibility of deep learning to analyze programs. It also gives primary evidence of its success in this new field. We believe deep learning will become an outstanding technique for program analysis in the near future.","Thu, 11 Sep 2014 08:44:28 UTC (189 KB)"
"2004","Collaborative Deep Learning for Recommender Systems","Hao Wang, Naiyan Wang, Dit-Yan Yeung","Machine Learning (cs.LG); Computation and Language (cs.CL); Information Retrieval (cs.IR); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","Collaborative filtering (CF) is a successful approach commonly used by many recommender systems. Conventional CF-based methods use the ratings given to items by users as the sole source of information for learning to make recommendation. However, the ratings are often very sparse in many applications, causing CF-based methods to degrade significantly in their recommendation performance. To address this sparsity problem, auxiliary information such as item content information may be utilized. Collaborative topic regression (CTR) is an appealing recent method taking this approach which tightly couples the two components that learn from two different sources of information. Nevertheless, the latent representation learned by CTR may not be very effective when the auxiliary information is very sparse. To address this problem, we generalize recent advances in deep learning from i.i.d. input to non-i.i.d. (CF-based) input and propose in this paper a hierarchical Bayesian model called collaborative deep learning (CDL), which jointly performs deep representation learning for the content information and collaborative filtering for the ratings (feedback) matrix. Extensive experiments on three real-world datasets from different domains show that CDL can significantly advance the state of the art.","Wed, 10 Sep 2014 03:05:22 UTC (893 KB)[v2] Thu, 18 Jun 2015 09:23:37 UTC (1,170 KB)"
"2005","Exponentially Increasing the Capacity-to-Computation Ratio for Conditional Computation in Deep Learning","Kyunghyun Cho, Yoshua Bengio","Machine Learning (stat.ML); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Many state-of-the-art results obtained with deep networks are achieved with the largest models that could be trained, and if more computation power was available, we might be able to exploit much larger datasets in order to improve generalization ability. Whereas in learning algorithms such as decision trees the ratio of capacity (e.g., the number of parameters) to computation is very favorable (up to exponentially more parameters than computation), the ratio is essentially 1 for deep neural networks. Conditional computation has been proposed as a way to increase the capacity of a deep neural network without increasing the amount of computation required, by activating some parameters and computation ""on-demand"", on a per-example basis. In this note, we propose a novel parametrization of weight matrices in neural networks which has the potential to increase up to exponentially the ratio of the number of parameters to computation. The proposed approach is based on turning on some parameters (weight matrices) when specific bit patterns of hidden unit activations are obtained. In order to better control for the overfitting that might result, we propose a parametrization that is tree-structured, where each node of the tree corresponds to a prefix of a sequence of sign bits, or gating units, associated with hidden units.","Sat, 28 Jun 2014 06:45:51 UTC (15 KB)"
"2006","Deep Learning Multi-View Representation for Face Recognition","Zhenyao Zhu, Ping Luo, Xiaogang Wang, Xiaoou Tang","Computer Vision and Pattern Recognition (cs.CV)","Various factors, such as identities, views (poses), and illuminations, are coupled in face images. Disentangling the identity and view representations is a major challenge in face recognition. Existing face recognition systems either use handcrafted features or learn features discriminatively to improve recognition accuracy. This is different from the behavior of human brain. Intriguingly, even without accessing 3D data, human not only can recognize face identity, but can also imagine face images of a person under different viewpoints given a single 2D image, making face perception in the brain robust to view changes. In this sense, human brain has learned and encoded 3D face models from 2D images. To take into account this instinct, this paper proposes a novel deep neural net, named multi-view perceptron (MVP), which can untangle the identity and view features, and infer a full spectrum of multi-view images in the meanwhile, given a single 2D face image. The identity features of MVP achieve superior performance on the MultiPIE dataset. MVP is also capable to interpolate and predict images under viewpoints that are unobserved in the training data.","Thu, 26 Jun 2014 17:09:25 UTC (1,062 KB)"
"2007","Deep Learning Face Representation by Joint Identification-Verification","Yi Sun, Xiaogang Wang, Xiaoou Tang","Computer Vision and Pattern Recognition (cs.CV)","The key challenge of face recognition is to develop effective feature representations for reducing intra-personal variations while enlarging inter-personal differences. In this paper, we show that it can be well solved with deep learning and using both face identification and verification signals as supervision. The Deep IDentification-verification features (DeepID2) are learned with carefully designed deep convolutional networks. The face identification task increases the inter-personal variations by drawing DeepID2 extracted from different identities apart, while the face verification task reduces the intra-personal variations by pulling DeepID2 extracted from the same identity together, both of which are essential to face recognition. The learned DeepID2 features can be well generalized to new identities unseen in the training data. On the challenging LFW dataset, 99.15% face verification accuracy is achieved. Compared with the best deep learning result on LFW, the error rate has been significantly reduced by 67%.","Wed, 18 Jun 2014 15:42:16 UTC (2,035 KB)"
"2008","Deep Learning in Neural Networks: An Overview","Juergen Schmidhuber","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG)","In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks.","Wed, 30 Apr 2014 18:39:00 UTC (99 KB)[v2] Wed, 28 May 2014 15:33:51 UTC (111 KB)[v3] Wed, 2 Jul 2014 16:05:33 UTC (113 KB)[v4] Wed, 8 Oct 2014 10:00:38 UTC (117 KB)"
"2009","PCANet: A Simple Deep Learning Baseline for Image Classification?","Tsung-Han Chan, Kui Jia, Shenghua Gao, Jiwen Lu, Zinan Zeng, Yi Ma","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","In this work, we propose a very simple deep learning network for image classification which comprises only the very basic data processing components: cascaded principal component analysis (PCA), binary hashing, and block-wise histograms. In the proposed architecture, PCA is employed to learn multistage filter banks. It is followed by simple binary hashing and block histograms for indexing and pooling. This architecture is thus named as a PCA network (PCANet) and can be designed and learned extremely easily and efficiently. For comparison and better understanding, we also introduce and study two simple variations to the PCANet, namely the RandNet and LDANet. They share the same topology of PCANet but their cascaded filters are either selected randomly or learned from LDA. We have tested these basic networks extensively on many benchmark visual datasets for different tasks, such as LFW for face verification, MultiPIE, Extended Yale B, AR, FERET datasets for face recognition, as well as MNIST for hand-written digits recognition. Surprisingly, for all tasks, such a seemingly naive PCANet model is on par with the state of the art features, either prefixed, highly hand-crafted or carefully learned (by DNNs). Even more surprisingly, it sets new records for many classification tasks in Extended Yale B, AR, FERET datasets, and MNIST variations. Additional experiments on other public datasets also demonstrate the potential of the PCANet serving as a simple but highly competitive baseline for texture classification and object recognition.","Mon, 14 Apr 2014 15:02:17 UTC (1,033 KB)[v2] Thu, 28 Aug 2014 15:20:44 UTC (842 KB)"
"2010","Sparse Coding: A Deep Learning using Unlabeled Data for High - Level Representation","R. Vidya, Dr.G.M.Nasira, R. P. Jaia Priyankka","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","Sparse coding algorithm is an learning algorithm mainly for unsupervised feature for finding succinct, a little above high - level Representation of inputs, and it has successfully given a way for Deep learning. Our objective is to use High - Level Representation data in form of unlabeled category to help unsupervised learning task. when compared with labeled data, unlabeled data is easier to acquire because, unlike labeled data it does not follow some particular class labels. This really makes the Deep learning wider and applicable to practical problems and learning. The main problem with sparse coding is it uses Quadratic loss function and Gaussian noise mode. So, its performs is very poor when binary or integer value or other Non- Gaussian type data is applied. Thus first we propose an algorithm for solving the L1 - regularized convex optimization algorithm for the problem to allow High - Level Representation of unlabeled data. Through this we derive a optimal solution for describing an approach to Deep learning algorithm by using sparse code.","Sun, 6 Apr 2014 09:50:45 UTC (416 KB)"
"2011","Searching for Exotic Particles in High-Energy Physics with Deep Learning","Pierre Baldi, Peter Sadowski, Daniel Whiteson","High Energy Physics - Phenomenology (hep-ph); High Energy Physics - Experiment (hep-ex)","Collisions at high-energy particle colliders are a traditionally fruitful source of exotic particle discoveries. Finding these rare particles requires solving difficult signal-versus-background classification problems, hence machine learning approaches are often used. Standard approaches have relied on `shallow' machine learning models that have a limited capacity to learn complex non-linear functions of the inputs, and rely on a pain-staking search through manually constructed non-linear features. Progress on this problem has slowed, as a variety of techniques have shown equivalent performance. Recent advances in the field of deep learning make it possible to learn more complex functions and better discriminate between signal and background classes. Using benchmark datasets, we show that deep learning methods need no manually constructed inputs and yet improve the classification metric by as much as 8\% over the best current approaches. This demonstrates that deep learning approaches can improve the power of collider searches for exotic particles.","Wed, 19 Feb 2014 17:20:08 UTC (227 KB)[v2] Thu, 5 Jun 2014 16:59:45 UTC (559 KB)"
"2012","Deep learning for class-generic object detection","Brody Huval, Adam Coates, Andrew Ng","Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)","We investigate the use of deep neural networks for the novel task of class generic object detection. We show that neural networks originally designed for image recognition can be trained to detect objects within images, regardless of their class, including objects for which no bounding box labels have been provided. In addition, we show that bounding box labels yield a 1% performance increase on the ImageNet recognition challenge.","Tue, 24 Dec 2013 20:38:18 UTC (821 KB)"
"2013","Learning Paired-associate Images with An Unsupervised Deep Learning Architecture","Ti Wang, Daniel L. Silver","Neural and Evolutionary Computing (cs.NE); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)","This paper presents an unsupervised multi-modal learning system that learns associative representation from two input modalities, or channels, such that input on one channel will correctly generate the associated response at the other and vice versa. In this way, the system develops a kind of supervised classification model meant to simulate aspects of human associative memory. The system uses a deep learning architecture (DLA) composed of two input/output channels formed from stacked Restricted Boltzmann Machines (RBM) and an associative memory network that combines the two channels. The DLA is trained on pairs of MNIST handwritten digit images to develop hierarchical features and associative representations that are able to reconstruct one image given its paired-associate. Experiments show that the multi-modal learning system generates models that are as accurate as back-propagation networks but with the advantage of a bi-directional network and unsupervised learning from either paired or non-paired training examples.","Fri, 20 Dec 2013 23:07:25 UTC (320 KB)[v2] Fri, 10 Jan 2014 23:19:26 UTC (336 KB)"
"2014","Deep learning for neuroimaging: a validation study","Sergey M. Plis, Devon R. Hjelm, Ruslan Salakhutdinov, Vince D. Calhoun","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG); Machine Learning (stat.ML)","Deep learning methods have recently made notable advances in the tasks of classification and representation learning. These tasks are important for brain imaging and neuroscience discovery, making the methods attractive for porting to a neuroimager's toolbox. Success of these methods is, in part, explained by the flexibility of deep learning models. However, this flexibility makes the process of porting to new areas a difficult parameter optimization problem. In this work we demonstrate our results (and feasible parameter ranges) in application of deep learning methods to structural and functional brain imaging data. We also describe a novel constraint-based approach to visualizing high dimensional data. We use it to analyze the effect of parameter choices on data transformations. Our results show that deep learning methods are able to learn physiologically important representations and detect latent relations in neuroimaging data.","Fri, 20 Dec 2013 08:30:55 UTC (4,326 KB)[v2] Wed, 8 Jan 2014 04:22:55 UTC (4,262 KB)[v3] Wed, 19 Feb 2014 16:00:08 UTC (5,338 KB)"
"2015","Distributional Models and Deep Learning Embeddings: Combining the Best of Both Worlds","Irina Sergienya, Hinrich Schutze","Computation and Language (cs.CL)","There are two main approaches to the distributed representation of words: low-dimensional deep learning embeddings and high-dimensional distributional models, in which each dimension corresponds to a context word. In this paper, we combine these two approaches by learning embeddings based on distributional-model vectors - as opposed to one-hot vectors as is standardly done in deep learning. We show that the combined approach has better performance on a word relatedness judgment task.","Thu, 19 Dec 2013 14:18:14 UTC (15 KB)[v2] Tue, 14 Jan 2014 17:33:49 UTC (15 KB)[v3] Tue, 18 Feb 2014 14:17:46 UTC (15 KB)"
"2016","My First Deep Learning System of 1991 + Deep Learning Timeline 1962-2013","Jurgen Schmidhuber","Neural and Evolutionary Computing (cs.NE)","Deep Learning has attracted significant attention in recent years. Here I present a brief overview of my first Deep Learner of 1991, and its historic context, with a timeline of Deep Learning highlights.","Thu, 19 Dec 2013 13:45:45 UTC (255 KB)"
"2017","Generative NeuroEvolution for Deep Learning","Phillip Verbancsics, Josh Harguess","Neural and Evolutionary Computing (cs.NE); Computer Vision and Pattern Recognition (cs.CV)","An important goal for the machine learning (ML) community is to create approaches that can learn solutions with human-level capability. One domain where humans have held a significant advantage is visual processing. A significant approach to addressing this gap has been machine learning approaches that are inspired from the natural systems, such as artificial neural networks (ANNs), evolutionary computation (EC), and generative and developmental systems (GDS). Research into deep learning has demonstrated that such architectures can achieve performance competitive with humans on some visual tasks; however, these systems have been primarily trained through supervised and unsupervised learning algorithms. Alternatively, research is showing that evolution may have a significant role in the development of visual systems. Thus this paper investigates the role neuro-evolution (NE) can take in deep learning. In particular, the Hypercube-based NeuroEvolution of Augmenting Topologies is a NE approach that can effectively learn large neural structures by training an indirect encoding that compresses the ANN weight pattern as a function of geometry. The results show that HyperNEAT struggles with performing image classification by itself, but can be effective in training a feature extractor that other ML approaches can learn from. Thus NeuroEvolution combined with other ML methods provides an intriguing area of research that can replicate the processes in nature.","Wed, 18 Dec 2013 22:14:31 UTC (601 KB)"
"2018","Deep Learning Embeddings for Discontinuous Linguistic Units","Wenpeng Yin, Hinrich Schutze","Computation and Language (cs.CL)","Deep learning embeddings have been successfully used for many natural language processing problems. Embeddings are mostly computed for word forms although a number of recent papers have extended this to other linguistic units like morphemes and phrases. In this paper, we argue that learning embeddings for discontinuous linguistic units should also be considered. In an experimental evaluation on coreference resolution, we show that such embeddings perform better than word form embeddings.","Wed, 18 Dec 2013 13:34:16 UTC (16 KB)[v2] Thu, 19 Dec 2013 11:01:02 UTC (15 KB)"
"2019","Deep Learning by Scattering","Stephane Mallat, Irene Waldspurger","Machine Learning (cs.LG); Machine Learning (stat.ML)","We introduce general scattering transforms as mathematical models of deep neural networks with l2 pooling. Scattering networks iteratively apply complex valued unitary operators, and the pooling is performed by a complex modulus. An expected scattering defines a contractive representation of a high-dimensional probability distribution, which preserves its mean-square norm. We show that unsupervised learning can be casted as an optimization of the space contraction to preserve the volume occupied by unlabeled examples, at each layer of the network. Supervised learning and classification are performed with an averaged scattering, which provides scattering estimations for multiple classes.","Mon, 24 Jun 2013 07:52:45 UTC (227 KB)[v2] Thu, 25 Jun 2015 17:26:01 UTC (227 KB)"
"2020","Predicting Parameters in Deep Learning","Misha Denil, Babak Shakibi, Laurent Dinh, Marc'Aurelio Ranzato, Nando de Freitas","Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)","We demonstrate that there is significant redundancy in the parameterization of several deep learning models. Given only a few weight values for each feature it is possible to accurately predict the remaining values. Moreover, we show that not only can the parameter values be predicted, but many of them need not be learned at all. We train several different architectures by learning only a small number of weights and predicting the rest. In the best case we are able to predict more than 95% of the weights of a network without any drop in accuracy.","Mon, 3 Jun 2013 19:16:26 UTC (324 KB)[v2] Mon, 27 Oct 2014 11:49:08 UTC (340 KB)"
"2021","Deep Learning using Linear Support Vector Machines","Yichuan Tang","Machine Learning (cs.LG); Machine Learning (stat.ML)","Recently, fully-connected and convolutional neural networks have been trained to achieve state-of-the-art performance on a wide variety of tasks such as speech recognition, image classification, natural language processing, and bioinformatics. For classification tasks, most of these ""deep learning"" models employ the softmax activation function for prediction and minimize cross-entropy loss. In this paper, we demonstrate a small but consistent advantage of replacing the softmax layer with a linear support vector machine. Learning minimizes a margin-based loss instead of the cross-entropy loss. While there have been various combinations of neural nets and SVMs in prior art, our results using L2-SVMs show that by simply replacing softmax with linear SVMs gives significant gains on popular deep learning datasets MNIST, CIFAR-10, and the ICML 2013 Representation Learning Workshop's face expression recognition challenge.","Sun, 2 Jun 2013 18:46:58 UTC (379 KB)[v2] Tue, 9 Jul 2013 21:30:59 UTC (381 KB)[v3] Mon, 23 Dec 2013 21:16:45 UTC (381 KB)[v4] Sat, 21 Feb 2015 16:58:39 UTC (381 KB)"
"2022","Deep Learning of Representations: Looking Forward","Yoshua Bengio","Machine Learning (cs.LG)","Deep learning research aims at discovering learning algorithms that discover multiple levels of distributed representations, with higher levels representing more abstract concepts. Although the study of deep learning has already led to impressive theoretical results, learning algorithms and breakthrough experiments, several challenges lie ahead. This paper proposes to examine some of these challenges, centering on the questions of scaling deep learning algorithms to much larger models and datasets, reducing optimization difficulties due to ill-conditioning or local minima, designing more efficient and powerful inference and sampling procedures, and learning to disentangle the factors of variation underlying the observed data. It also proposes a few forward-looking research directions aimed at overcoming these challenges.","Thu, 2 May 2013 14:33:28 UTC (46 KB)[v2] Fri, 7 Jun 2013 02:35:21 UTC (54 KB)"
"2023","Understanding Boltzmann Machine and Deep Learning via A Confident Information First Principle","Xiaozhao Zhao, Yuexian Hou, Qian Yu, Dawei Song, Wenjie Li","Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG); Machine Learning (stat.ML)","Typical dimensionality reduction methods focus on directly reducing the number of random variables while retaining maximal variations in the data. In this paper, we consider the dimensionality reduction in parameter spaces of binary multivariate distributions. We propose a general Confident-Information-First (CIF) principle to maximally preserve parameters with confident estimates and rule out unreliable or noisy parameters. Formally, the confidence of a parameter can be assessed by its Fisher information, which establishes a connection with the inverse variance of any unbiased estimate for the parameter via the Cramer-Rao bound. We then revisit Boltzmann machines (BM) and theoretically show that both single-layer BM without hidden units (SBM) and restricted BM (RBM) can be solidly derived using the CIF principle. This can not only help us uncover and formalize the essential parts of the target density that SBM and RBM capture, but also suggest that the deep neural network consisting of several layers of RBM can be seen as the layer-wise application of CIF. Guided by the theoretical analysis, we develop a sample-specific CIF-based contrastive divergence (CD-CIF) algorithm for SBM and a CIF-based iterative projection procedure (IP) for RBM. Both CD-CIF and IP are studied in a series of density estimation experiments.","Sat, 16 Feb 2013 05:49:15 UTC (56 KB)[v2] Mon, 25 Feb 2013 06:53:55 UTC (56 KB)[v3] Sat, 23 Mar 2013 06:20:51 UTC (56 KB)[v4] Fri, 12 Apr 2013 13:28:59 UTC (57 KB)[v5] Wed, 17 Apr 2013 11:05:06 UTC (57 KB)[v6] Mon, 3 Jun 2013 11:18:46 UTC (36 KB)[v7] Wed, 9 Oct 2013 16:55:26 UTC (363 KB)"
"2024","Two SVDs produce more focal deep learning representations","Hinrich Schuetze, Christian Scheible","Computation and Language (cs.CL); Machine Learning (cs.LG)","A key characteristic of work on deep learning and neural networks in general is that it relies on representations of the input that support generalization, robust inference, domain adaptation and other desirable functionalities. Much recent progress in the field has focused on efficient and effective methods for computing representations. In this paper, we propose an alternative method that is more efficient than prior work and produces representations that have a property we call focality -- a property we hypothesize to be important for neural network representations. The method consists of a simple application of two consecutive SVDs and is inspired by Anandkumar (2012).","Wed, 16 Jan 2013 08:37:39 UTC (84 KB)[v2] Sat, 11 May 2013 12:17:44 UTC (41 KB)"
"2025","Deep Learning for Detecting Robotic Grasps","Ian Lenz, Honglak Lee, Ashutosh Saxena","Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)","We consider the problem of detecting robotic grasps in an RGB-D view of a scene containing objects. In this work, we apply a deep learning approach to solve this problem, which avoids time-consuming hand-design of features. This presents two main challenges. First, we need to evaluate a huge number of candidate grasps. In order to make detection fast, as well as robust, we present a two-step cascaded structure with two deep networks, where the top detections from the first are re-evaluated by the second. The first network has fewer features, is faster to run, and can effectively prune out unlikely candidate grasps. The second, with more features, is slower but has to run only on the top few detections. Second, we need to handle multimodal inputs well, for which we present a method to apply structured regularization on the weights based on multimodal group regularization. We demonstrate that our method outperforms the previous state-of-the-art methods in robotic grasp detection, and can be used to successfully execute grasps on two different robotic platforms.","Wed, 16 Jan 2013 05:33:56 UTC (1,085 KB)[v2] Fri, 18 Jan 2013 00:10:20 UTC (3,785 KB)[v3] Thu, 21 Feb 2013 00:40:34 UTC (4,172 KB)[v4] Fri, 3 May 2013 06:54:42 UTC (6,214 KB)[v5] Fri, 2 Aug 2013 18:15:54 UTC (8,126 KB)[v6] Thu, 21 Aug 2014 18:17:37 UTC (4,556 KB)"
"2026","Deep learning and the renormalization group","Cedric Beny","Quantum Physics (quant-ph)","Renormalization group (RG) methods, which model the way in which the effective behavior of a system depends on the scale at which it is observed, are key to modern condensed-matter theory and particle physics. We compare the ideas behind the RG on the one hand and deep machine learning on the other, where depth and scale play a similar role. In order to illustrate this connection, we review a recent numerical method based on the RG---the multiscale entanglement renormalization ansatz (MERA)---and show how it can be converted into a learning algorithm based on a generative hierarchical Bayesian network model. Under the assumption---common in physics---that the distribution to be learned is fully characterized by local correlations, this algorithm involves only explicit evaluation of probabilities, hence doing away with sampling.","Mon, 14 Jan 2013 20:50:08 UTC (29 KB)[v2] Tue, 15 Jan 2013 15:46:59 UTC (31 KB)[v3] Tue, 29 Jan 2013 16:22:07 UTC (31 KB)[v4] Wed, 13 Mar 2013 17:54:51 UTC (32 KB)"
"2027","Krylov Subspace Descent for Deep Learning","Oriol Vinyals, Daniel Povey","Machine Learning (stat.ML); Optimization and Control (math.OC)","In this paper, we propose a second order optimization method to learn models where both the dimensionality of the parameter space and the number of training samples is high. In our method, we construct on each iteration a Krylov subspace formed by the gradient and an approximation to the Hessian matrix, and then use a subset of the training data samples to optimize over this subspace. As with the Hessian Free (HF) method of [7], the Hessian matrix is never explicitly constructed, and is computed using a subset of data. In practice, as in HF, we typically use a positive definite substitute for the Hessian matrix such as the Gauss-Newton matrix. We investigate the effectiveness of our proposed method on deep neural networks, and compare its performance to widely used methods such as stochastic gradient descent, conjugate gradient descent and L-BFGS, and also to HF. Our method leads to faster convergence than either L-BFGS or HF, and generally performs better than either of them in cross-validation accuracy. It is also simpler and more general than HF, as it does not require a positive semi-definite approximation of the Hessian matrix to work well nor the setting of a damping parameter. The chief drawback versus HF is the need for memory to store a basis for the Krylov subspace.","Fri, 18 Nov 2011 02:15:32 UTC (26 KB)"
